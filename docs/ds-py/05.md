

# *第五章*

# 掌握结构化数据

## 学习目标

本章结束时，您将能够:

*   使用结构化数据创建高度精确的模型
*   使用 XGBoost 库来训练增压模型
*   使用 Keras 库来训练神经网络模型
*   微调模型参数以获得最佳精度
*   使用交叉验证
*   保存并加载训练好的模型

本章将介绍如何创建高度精确的结构化数据模型的基础知识。

## 简介

有两种主要类型的数据，结构化和非结构化。结构化数据是指具有定义格式的数据，通常是表格形式，例如存储在 Excel 表或关系数据库中的数据。非结构化数据没有预定义的模式。任何不能存储在表中的东西都属于这一类。示例包括语音文件、图像和 pdf。

在本章中，我们将重点关注结构化数据以及使用 XGBoost 和 Keras 创建机器学习模型。XGBoost 算法被行业专家和研究人员广泛使用，因为它提供高精度模型的速度很快，也因为它的分布式特性。分布式指的是并行处理数据和训练模型的能力；这使得数据科学家的培训速度更快，周转时间更短。另一方面，Keras 让我们创建神经网络模型。在某些情况下，神经网络比 boosting 算法工作得更好，但找到正确的网络和正确的网络配置是很困难的。以下主题将帮助您熟悉这两个库，确保您可以在数据科学之旅中处理任何结构化数据。

## 助推算法

Boosting 是一种提高任何学习算法准确性的方法。Boosting 通过将粗略的高级规则组合成比任何单一规则都更准确的单一预测来工作。迭代地，训练数据集的子集被摄取到“弱”算法中以生成弱模型。这些弱模型然后被组合以形成最终预测。两个最有效的提升算法是梯度提升机器和 XGBoost。

### 梯度推进机(GBM)

GBM 使用分类树作为弱算法。这些结果是通过使用可微分损失函数改进这些弱模型的估计而产生的。该模型通过考虑先前树木的净损失来拟合连续的树木；因此，每棵树在最终解决方案中都是部分存在的。因此，提升树降低了算法的速度，并且它们提供的透明度给出了更好的结果。GBM 算法有很多参数，它对噪声和极值很敏感。同时，GBM 会过度拟合数据，因此需要一个合适的停止点，但它通常是最好的模型。

### XGBoost(极限梯度推进)

XGBoost 是全世界研究人员在对结构化数据建模时的首选算法。XGBoost 也使用树作为弱算法。那么，为什么当数据科学家看到结构化数据时，首先想到的是算法呢？XGBoost 是可移植的和分布式的，这意味着它可以很容易地用于不同的架构，可以使用多个核心(单机)或多个机器(集群)。另外，XGBoost 库是用 C++编写的，这使得它很快。它在处理大型数据集时也很有用，因为它允许您将数据存储在外部磁盘上，而不是将所有数据加载到内存中。

#### 注意

你可以在这里阅读更多关于 XGBoost 的内容:https://arxiv.org/abs/1603.02754

### 练习 44:使用 XGBoost 库执行分类

在本练习中，我们将使用 Python 的 XGBoost 库对批发客户数据集(https://github . com/TrainingByPackt/Data-Science-with-Python/tree/master/chapter 05/Data)执行分类。数据集包含批发分销商客户的购买数据。它包括各种产品类别的年度支出。我们将根据各种产品的年度支出来预测渠道。这里的通道描述了客户是 horeca(酒店/餐厅/咖啡馆)还是零售客户。

1.  从虚拟环境中打开 Jupyter 笔记本。
2.  为我们将用来计算精确度的函数导入 XGBoost、Pandas 和 sklearn。要了解我们的模型如何运行，准确性是必需的。

    ```
    import pandas as pd
    import xgboost as xgb from sklearn.metrics import accuracy_score
    ```

3.  使用 pandas 读取批发客户数据集，并使用以下命令检查它是否被成功加载:

    ```
    data = pd.read_csv("data/wholesale-data.csv")
    ```

4.  使用`head()`命令检查数据集的前五个条目。输出如下截图所示:

    ```
    data.head()
    ```

    ![Figure 5.1: Screenshot showing first five elements of dataset](image/C13322_05_01.jpg)

    ###### 图 5.1:显示数据集前五个元素的屏幕截图

5.  现在“`data`”数据框已经有了所有的数据。它有目标变量，在我们的例子中是“`Channel`”，还有预测变量。因此，我们将数据分为特征(预测值)和标签(目标值)。

    ```
    X = data.copy()X.drop("Channel", inplace = True, axis = 1)Y = data.Channel
    ```

6.  如前几章所述，创建训练集和测试集。这里，我们使用 80:20 的分割，因为数据集中的数据点数较少。你可以尝试不同的分割方式。

    ```
    X_train, X_test = X[:int(X.shape[0]*0.8)].values, X[int(X.shape[0]*0.8):].values Y_train, Y_test = Y[:int(Y.shape[0]*0.8)].values, Y[int(Y.shape[0]*0.8):].values
    ```

7.  将 pandas 数据帧转换为 DMatrix，这是一种内部数据结构，XGBoost 使用它来存储训练和测试数据集。

    ```
    train = xgb.DMatrix(X_train, label=Y_train)test = xgb.DMatrix(X_test, label=Y_test)
    ```

8.  Specify the training parameters and train the model.

    #### 注意

    我们将在下一节深入讨论这些参数。

    ```
    param = {'max_depth':6, 'eta':0.1, 'silent':1, 'objective':'multi:softmax', 'num_class': 3}num_round = 5 model = xgb.train(param, train, num_round)
    ```

    #### 注意

    默认情况下，XGBoost 使用所有可用的线程进行多处理。为了限制这种情况，可以使用 nthread 参数。更多信息请参考下一节。

9.  使用我们刚刚创建的模型预测测试集的“`Channel`”值。

    ```
    preds = model.predict(test)
    ```

10.  Get the accuracy of the model that we have trained for the test dataset.

    ```
    acc = accuracy_score(Y_test, preds)print("Accuracy: %.2f%%" % (acc * 100.0))
    ```

    输出截图如下:

![Figure 6.2: Final accuracy](image/C13322_05_02.jpg)

###### 图 5.2:最终精度

恭喜你！您刚刚制作了第一个 XGBoost 模型，不需要太多的微调就可以达到大约 90%的准确率！

## XG Boost 库

我们用来执行上述分类的库被命名为 XGBoost。该库使用它拥有的许多参数实现了许多定制。在接下来的小节中，我们将深入了解 XGBoost 库的不同参数和功能。

#### 注意

有关 XGBoost 的更多信息，请参考网站:https://XGBoost . readthedocs . io

爱宁

下面列出了影响任何 XGBoost 模型训练的参数。

*   `booster`: Even though we mentioned in the introduction that the base learner of XGBoost is a regression tree, using this library, we can use linear regression as the weak learner as well. Another weak learner, DART booster, is a new method to tree boosting, which drops trees at random to prevent overfitting. To use tree boosting, pass "`gbtree`" (default); for linear regression, pass "`gblinear`"; and for tree boosting with dropout, pass "`dart`".

    #### 注意

    你可以从这篇文章中了解到更多关于 DART 的信息:http://www . jmlr . org/proceedings/papers/v 38/korlakaivinayak 15 . pdf

*   `silent` : 0 打印训练日志，1 为静默模式。
*   `nthread`: This signifies the number of parallel threads to be used. It defaults to the maximum number of threads available in the system.

    #### 注意

    参数 silent 已被弃用，并已被 verbosity 取代，它采用以下任何值:0 (silent)、1 (warning)、2 (info)、3 (debug)。

*   `seed`:这是随机数发生器的种子值。在此设置一个常量值以获得可重复的结果。默认值为 0。
*   `objective`: This is a function that the model tries to minimize. The next few points cover the objective functions.

    `reg:linear`:线性回归应与连续目标变量一起使用(回归问题)。(默认)

    `binary:logistic`:二元分类时使用的逻辑回归。它输出概率而不是类别。

    这是二进制分类，输出 0 或 1 的预测，而不是概率。当你不关心概率的时候用这个。

    `multi:softmax`:如果您想进行多类别分类，使用 softmax 物镜进行分类。为此，必须将`num_class`参数设置为类的数量。

    `multi:softprob`:这与 softmax 的工作原理相同，但是输出预测每个数据点的概率，而不是预测一个类。

*   `eval_metric`: The performance of a model needs to be observed on the validation set (as discussed in *Chapter 1*, *Introduction to Data Science and Data Preprocessing*). This parameter takes the evaluation metric for the validation data. The default metric is chosen according to the objective function (`rmse` for regression and `logloss` for classification). You can use multiple evaluation metrics.

    均方根误差(RMSE)对大误差的惩罚更大。因此，当误差 1 比误差 3 大三倍时，这是合适的。

    `mae`:平均绝对误差(MAE)可用于偏离 1°类似于偏离 3°的情况。

    下图显示了随着实际值和预测值之间差异的增加，误差也在增加。在这里，它将是以下内容:

![Figure 5.3: Difference between actual and predicted value](image/C13322_05_03.jpg)

###### 图 5.3:实际值和预测值之间的差异

![Figure 5.4: Variation of penalty with variation in error; |X| is mae and X2  is rmse](image/C13322_05_04.jpg)

###### 图 5.4:惩罚随误差变化的变化；|X|是 mae，X2 是 rmse

`logloss`:负对数似然， **logloss** 是分类损失函数。最小化模型的`logloss`相当于最大化模型的准确性。它在数学上定义为:

![Figure 5.5: Logloss equation diagram](image/C13322_05_05.jpg)

###### 图 5.5:对数损耗方程图

这里，N 是数据点的数量，M 是类的数量，并且取决于预测是否正确，M 是 1 或 0，是数据点 *i* 的预测标签 *j* 的概率。

`AUC` : **曲线下的区域**广泛用于二值分类。如果你的数据集有一个**类不平衡问题**，你应该总是使用这个。当您的数据没有被分成大小相似的类时，就会出现类不平衡问题；例如，如果 A 类占 90%的数据，B 类占 10%的数据。我们将在处理不平衡数据集一节中讨论更多的类不平衡问题。

`aucpr`:在**精确召回** ( **PR** )曲线下的面积与 AUC 曲线相同，但是在高度不平衡的数据集的情况下应该是优选的。我们将在处理不平衡数据集一节中讨论这个问题。

#### 注意

无论何时使用二进制数据集，都应该将 AUC 或 AUCPR 作为经验法则。

**树助推器**

下面列出了特定于基于树的模型的参数:

*   `eta`:这是学习率。按照第 1 章、*数据科学和数据预处理介绍*中的讨论，修改该值以防止过拟合。学习率由每一步中更新的权重决定。权重的梯度乘以这个值，然后加到权重上。默认值为 0.3，最大值为 1，最小值为 0。
*   `gamma`: This is the minimum loss reduction to make a partition. The larger gamma is, the more conservative the algorithm will be. Being more conservative prevents overfitting. The value depends on the dataset and other parameters used. It ranges from 0 to infinity and the default value is 0\. A lower value leads to shallow trees and larger values give rise to deeper trees.

    #### 注意

    大于 1 的 Gamma 值通常不会产生好的结果。

*   `max_depth`:这是在*第三章*，*通过 Sklearn* 介绍 ML 中讨论的任何树的最大深度。增加最大深度会使模型更容易过度拟合。0 表示没有限制。默认为 6。
*   `subsample`:设置为 0.5 将导致算法在生长树之前随机采样一半的训练数据。这可以防止过度拟合。子采样在每个增强迭代中发生一次，默认为 1，这使得模型采用完整的数据集而不是样本。
*   这是 L2 正则化术语。L2 正则化将系数的平方值作为惩罚项添加到损失函数中。增加该值可以防止过度拟合。其默认值为 1。
*   `alpha`:这是 L1 正则项。L1 正则化将系数的绝对幅度作为惩罚项添加到损失函数中。增加该值可以防止过度拟合。其默认值为 0。
*   当等级高度不平衡时，这很有用。我们将在接下来的章节中了解更多关于不平衡数据的知识。考虑引入的典型值:负实例之和/正实例之和。其默认值为 1。
*   `predictor`: There are two predictors. `cpu_predictor` uses CPU for prediction. It is the default. `gpu_predictor` uses GPU for prediction.

    #### 注释

    在这里得到所有参数的列表:https://xgboost.readthedocs.io/en/latest/parameter.html

### 控制 olling 模型过度拟合

如果您在训练数据集上观察到高精度，但在测试数据集上观察到低精度，则您的模型过度适应训练数据，如在*第 1 章*、*数据科学和数据预处理简介*中所见。在 XGBoost 中有两种主要的方法来限制过度拟合:

*   **控制模型复杂度**:修改`max_depth`、`min_child_weight`和`gamma`，同时监控训练和测试指标，以获得最佳模型，而不会过度适应训练数据集。在接下来的几节中，您将会了解到更多这方面的内容。
*   **给模型增加随机性，使训练对噪声具有鲁棒性**:使用子样本参数获得训练数据的子样本。将参数子采样设置为 0.5 将使库在创建弱模型之前随机采样一半的训练数据集。`colsample_bytree`与二次采样功能相同，但使用列而不是行。

为了更好地理解，请参见下图中的训练和准确性图表:

![Figure 5.6: Training and accuracy graphs](image/C13322_05_06.jpg)

###### 图 5.6:训练和准确性图表

要理解具有过度拟合和适当拟合模型的数据集的概念化，请参考下图:

![Figure 5.7: Illustration of a dataset with overfit and proper-fit models](image/C13322_05_07.jpg)

###### 图 5.7:带有过度拟合和适当拟合模型的数据集示意图

#### 注意

黑线代表具有适当拟合的模型，而红线代表的模型过度拟合数据集。

### 处理不平衡的数据集

不平衡数据集给数据科学家带来了很多问题。不平衡数据集的一个例子是信用卡欺诈数据。在这里，大约 95%的交易是合法的，只有 5%是欺诈性的。在这种情况下，预测每个交易都是正确交易的模型将获得 95%的准确性，但是，这是一个非常糟糕的模型。要查看您的类的分布，您可以使用以下函数:

```
data['target_variable'].value_counts()
```

输出如下所示:

![Figure 6.8: Class distribution](image/C13322_05_08.jpg)

###### 图 5.8:类别分布

要处理不平衡的数据集，可以使用以下方法:

*   **欠采样记录数量较多的类别**:在信用卡欺诈的情况下，您可以随机采样合法交易，以获得与欺诈记录相等的记录。这将导致欺诈和合法两个阶层的平均分配。
*   **对记录较少的类别进行过采样**:在信用卡欺诈的情况下，您可以通过添加新数据点或复制现有数据点来引入更多欺诈交易样本。这将导致两个阶层的平均分配，**欺诈**和**合法**。
*   **用 scale_pos_weight** 平衡正负权重:您可以使用此参数为数据点数量较少的类别分配较高的权重，从而人为平衡类别。该参数的值可以是:

![Figure 5.9: Value parameter equation](image/C13322_05_09.jpg)

###### 图 5.9:值参数方程

您可以使用以下代码检查类的分布:

```
positive = sum(Y == 1)
negative = sum(Y == 0)
scale_pos_weight = negative/positive
```

*   **使用 AUC 或 AUCPR 进行评估**:如前所述，AUC 和 AUCPR 指标对不平衡的数据集很敏感，与准确性不同，准确性为大多数时间预测多数类的坏模型提供了高值。AUC 只能对二元分类问题作图。这是预测值的不同阈值(0，0.01，0.02… 1)下的**真阳性率与假阳性率**的表示。如下图所示:

![Figure 5.10: TPR and FPR equations](image/C13322_05_10.jpg)

###### 图 5.10: TPR 和 FPR 方程

度量是我们在绘制了 **TPR** 和 **FPR** 之后得到的曲线下的面积。当处理高度倾斜的数据集时，AUCPR 给出了更好的图像，因此是首选的。AUCPR 是不同阈值下的精确度和召回率的表示

![Figure 6.11: Precision and recall equations](image/C13322_05_11.jpg)

###### 图 5.11:精确度和召回率公式

作为一个经验法则，当处理不平衡的类时，您应该使用 AUC 或 AUCPR 作为评估指标，因为它给出了模型的更清晰的图像。

#### 注意

机器学习算法无法轻松处理字符串或表示为字符串的分类变量，因此我们必须将其转换为数字。

### 活动 14: 训练和预测一个人的收入

在本活动中，我们将尝试预测个人收入是否超过 50，000 美元。成人收入数据集(https://github . com/TrainingByPackt/Data-Science-with-Python/tree/master/chapter 05/Data)的数据来自 1994 年的人口普查数据集(【https://archive.ics.uci.edu/ml/datasets/adult】T3)，包含诸如收入、个人教育资格和职业等信息。让我们来看看下面的场景:你在一家汽车公司工作，你需要创建一个系统，通过这个系统，你公司的销售代表可以决定把什么样的汽车卖给哪个人。

为此，您需要创建一个机器学习模型来预测潜在买家的收入，从而为销售人员提供正确的信息来销售正确的汽车。

1.  使用 pandas 加载收入数据集(`adult-data.csv`)。
2.  The data should look like this:![Figure 5.12: Screenshot showing five elements of census dataset](image/C13322_05_12.jpg)

    ###### 图 5.12:显示人口普查数据集五个元素的屏幕截图

    使用以下代码指定列名:

    ```
    data = pd.read_csv("../data/adult-data.csv", names=['age', 'workclass','education-num', 'occupation', 'capital-gain', 'capital-loss', 'hoursper-week', 'income'])
    ```

3.  使用 sklearn 将所有分类变量从字符串转换为整数。
4.  使用 XGBoost 库进行预测，并进行参数调整，将准确率提高到 80%以上。

我们使用数据集成功预测了收入，准确率约为 83%。

#### 注意

这项活动的解决方案可在第 360 页找到。

## 外部存储器的使用

当您有一个非常大的数据集而无法加载到您的 RAM 中时，XGBoost 库的外部内存特性将会帮助您。该特性将为您训练 XGBoost 模型，而无需将整个数据集加载到 RAM 上。

使用此功能需要最少的努力；您只需要在文件名末尾添加一个缓存前缀。

```
train = xgb.DMatrix('data/wholesale-data.dat.train#train.cache')
```

该功能仅支持`libsvm`文件。因此，我们现在将把 pandas 中加载的数据集转换成一个`libsvm`文件，以便与外部存储器特性一起使用。

#### 注意

根据数据集的大小，您可能需要分批执行此操作。

```
from sklearn.datasets import dump_svmlight_file
dump_svmlight_file(X_train, Y_train, 'data/wholesale-data.dat.train', zero_based=True, multilabel=False)
```

这里，`X_train`和`Y_train`分别是预测变量和目标变量。`libsvm`文件将被保存到数据文件夹中。

## 交叉验证

交叉验证是一种帮助数据科学家根据看不见的数据评估他们的模型的技术。当数据集不够大而无法创建三个分割(训练、测试和验证)时，这很有帮助。交叉验证通过向模型呈现相同数据的不同分区来帮助模型避免过度拟合。它的工作原理是为每次交叉验证提供数据集的不同训练和验证集。10 重交叉验证是使用最多的，其中数据集被划分为 10 个完全不同的子集，并在其中的每个子集上进行训练，最后，对指标进行平均，以获得模型的准确预测性能。在每一轮交叉验证中，我们做以下工作:

1.  混洗数据集并将其分成 k 个不同的组(对于 10 次交叉验证，k=10)。
2.  在 k-1 组上训练模型，并在 1 组上测试。
3.  评估模型并存储结果。
4.  对不同的组重复步骤 2 和 3，直到所有 k 个组合都被训练好。
5.  最终指标是不同轮次中生成的指标的平均值。

![Figure 5.13: Illustration of a cross-validation dataset](image/C13322_05_13.jpg)

###### 图 5.13:交叉验证数据集的图示

XGBoost 库有一个内置函数来执行交叉验证。本节将帮助您熟悉它的使用。

### 练习 45:使用交叉验证寻找最佳超参数

在本练习中，我们将使用 Python 的 XGBoost 库从之前的练习中找到成人数据集的最佳超参数。为此，我们将利用库的交叉验证特性。

1.  Load the census dataset from *Activity 14* and perform all the preprocessing steps.

    ```
    import pandas as pd
    import numpy as np
    data = pd.read_csv("../data/adult-data.csv", names=['age', 'workclass', 'fnlwgt', 'education-num', 'occupation', 'capital-gain', 'capital-loss', 'hours-per-week', 'income'])
    ```

    使用 sklearn 的标签编码器对字符串进行编码。首先，导入标签编码器，然后逐个编码所有的字符串分类列。

    ```
    from sklearn.preprocessing import LabelEncoder
    data['workclass'] = LabelEncoder().fit_transform(data['workclass'])
    data['occupation'] = LabelEncoder().fit_transform(data['occupation'])
    data['income'] = LabelEncoder().fit_transform(data['income'])
    ```

2.  从数据中生成训练集和测试集，并将数据转换为数据矩阵。

    ```
    import xgboost as xgb
    X = data.copy()
    X.drop("income", inplace = True, axis = 1)
    Y = data.income
    X_train, X_test = X[:int(X.shape[0]*0.8)].values, X[int(X.shape[0]*0.8):].values
    Y_train, Y_test = Y[:int(Y.shape[0]*0.8)].values, Y[int(Y.shape[0]*0.8):].values
    train = xgb.DMatrix(X_train, label=Y_train)
    test = xgb.DMatrix(X_test, label=Y_test)
    ```

3.  不使用 train 函数，而是使用以下代码执行 10 重交叉验证，并将结果存储在`model_metrics`数据帧中。for 循环遍历不同的树深度值，以找到最适合我们数据集的深度值。

    ```
    test_error = {}
    for i in range(20):
        param = {'max_depth':i, 'eta':0.1, 'silent':1, 'objective':'binary:hinge'}
        num_round = 50
        model_metrics = xgb.cv(param, train, num_round, nfold = 10)
        test_error[i] = model_metrics.iloc[-1]['test-error-mean']
    ```

4.  Visualize the results using Matplotlib.

    ```
    import matplotlib.pyplot as plt
    plt.scatter(test_error.keys(),test_error.values())
    plt.xlabel('Max Depth')
    plt.ylabel('Test Error')
    plt.show()
    ```

    ![Figure 6.14: Graph of max depth with test error](image/C13322_05_14.jpg)

    ###### 图 5.14:最大深度与测试误差的关系图

    从图中，我们了解到最大深度 9 最适合我们的数据集，因为它具有最低的测试误差。

5.  找到最佳的学习速度。运行这段代码需要一段时间，因为它迭代了大量的学习率，每轮 500 次。

    ```
    for i in range(1,100,5):
        param = {'max_depth':9, 'eta':0.001*i, 'silent':1, 'objective':'binary:hinge'}
        num_round = 500
        model_metrics = xgb.cv(param, train, num_round, nfold = 10)
        test_error[i] = model_metrics.iloc[-1]['test-error-mean']
    ```

6.  Visualize the results.

    ```
    lr = [0.001*(i) for i in test_error.keys()]
    plt.scatter(temp,test_error.values())
    plt.xlabel('Learning Rate')
    plt.ylabel('Error')
    plt.show()
    ```

    ![Figure 5.15: Graph of learning rate with test error](image/C13322_05_15.jpg)

    ###### 图 5.15:带有测试误差的学习率图表

    从该图中，我们可以看到，大约 0.01 的学习率最适合我们的模型，因为它具有最低的误差。

7.  Let us visualize the training and testing errors for each round for the learning rate 0.01.

    ```
    param = {'max_depth':9, 'eta':0.01, 'silent':1, 'objective':'binary:hinge'}
    num_round = 500
    model_metrics = xgb.cv(param, train, num_round, nfold = 10)
    plt.scatter(range(500),model_metrics['test-error-mean'], s = 0.7, label = 'Test Error')
    plt.scatter(range(500),model_metrics['train-error-mean'], s = 0.7, label = 'Train Error')
    plt.legend()
    plt.show()
    ```

    ![Figure 5.16: Graph of training and testing errors with respect to number of rounds
    ](image/C13322_05_16.jpg)

    ###### 图 5.16:关于回合数的训练和测试误差图

    #### 注意

    从这个图中，我们可以看到，我们在 490 左右得到的误差最小。这意味着当回合数在 490 左右时，我们的模型表现最佳。创建这条曲线有助于我们创建更精确的模型。

    要检查最小的错误，请使用以下代码:

    ```
    list(model_metrics['test-error-mean']).index(min(model_metrics['test-error-mean']))
    ```

8.  要理解这一点，请查看输出。

![Figure 6.17: Least error ](image/C13322_05_17.jpg)

###### 图 5.17:最小误差

#### 注意

最适合该数据集的最终模型参数:

最大深度= 9

Lea 学习率= 0.01

回合数= 496

## 保存和加载模型

掌握结构化数据的最后一点是保存和加载您已经训练和微调的模型的能力。每次我们需要预测时训练一个新的模型会浪费很多时间，所以能够保存一个训练好的模型对于数据科学家来说是必不可少的。保存的模型允许我们复制结果，并创建利用机器学习模型的应用和服务。步骤如下:

1.  要保存 XGBoost 模型，需要调用`save_model`函数。

    ```
    model.save_model('wholesale-model.model')
    ```

2.  To load a previously saved model, you have to call load_model on an initialized XGBoost variable.

    ```
    loaded_model = xgb.Booster({'nthread': 2})
    loaded_model.load_model('wholesale-model.model')
    ```

    #### 注意

    如果您让 XGBoost 访问它可以获得的所有线程，您的计算机在训练或预测时可能会变慢。

现在，您已经准备好开始使用 XGBoost 库对结构化数据集进行建模了！

### 练习 46:创建一个基于实时输入进行预测的 Python 脚本

在本练习中，我们将首先创建一个模型并保存它。然后，我们将创建一个 Python 脚本，该脚本将利用这个保存的模型对用户输入的数据执行预测。

1.  将活动 14 中的收入数据集作为熊猫数据框架加载。

    ```
    import pandas as pd
    import numpy as np
    data = pd.read_csv("../data/adult-data.csv", names=['age', 'workclass', 'education-num', 'occupation', 'capital-gain', 'capital-loss', 'hours-per-week', 'income'])
    ```

2.  去掉所有尾随空格。

    ```
    data[['workclass', 'occupation', 'income']] = data[['workclass', 'occupation', 'income']].apply(lambda x: x.str.strip())
    ```

3.  使用 scikit 将所有分类变量从字符串转换为整数。

    ```
    from sklearn.preprocessing import LabelEncoder
    from collections import defaultdict
    label_dict = defaultdict(LabelEncoder)
    data[['workclass', 'occupation', 'income']] = data[['workclass', 'occupation', 'income']].apply(lambda x: label_dict[x.name].fit_transform(x))
    ```

4.  将标签编码器保存在 pickle 文件中以备将来使用。pickle 文件存储 Python 对象，以便我们以后需要时可以访问它们。

    ```
    import pickle
    with open( 'income_labels.pkl', 'wb') as f:
            pickle.dump(label_dict, f, pickle.HIGHEST_PROTOCOL)
    ```

5.  将数据集拆分为培训和测试，并创建模型。
6.  将模型保存到文件中。

    ```
    model.save_model('income-model.model')
    ```

7.  在 Python 脚本中，加载模型和标注编码器。

    ```
    import xgboost as xgb
    loaded_model = xgb.Booster({'nthread': 8})
    loaded_model.load_model('income-model.model')
    def load_obj(file):
          with open(file + '.pkl', 'rb') as f:
                return pickle.load(f)
    label_dict = load_obj('income_labels')
    ```

8.  读取来自用户的输入。

    ```
    age = input("Please enter age: ")
    workclass = input("Please enter workclass: ")
    education_num = input("Please enter education_num: ")
    occupation = input("Please enter occupation: ")
    capital_gain = input("Please enter capital_gain: ")
    capital_loss = input("Please enter capital_loss: ")
    hours_per_week = input("Please enter hours_per_week: ")
    ```

9.  创建一个数据帧来存储这些数据。

    ```
    data_list = [age, workclass, education_num, occupation, capital_gain, capital_loss, hours_per_week]
    data = pd.DataFrame([data_list])
    data.columns = ['age', 'workclass', 'education-num', 'occupation', 'capital-gain', 'capital-loss', 'hours-per-week']
    ```

10.  预处理数据。

    ```
    data[['workclass', 'occupation']] = data[['workclass', 'occupation']].apply(lambda x: label_dict[x.name].transform(x))
    ```

11.  转换为 Dmatrix，并使用该模型执行预测。

    ```
    data = data.astype(int)
    data_xgb = xgb.DMatrix(data)
    pred = loaded_model.predict(data_xgb)
    ```

12.  Perform inverse transformation to get the results.

    ```
    income = label_dict['income'].inverse_transform([int(pred[0])])
    ```

    输出如下所示:

![Figure 5.18: Inverse transformation output](image/C13322_05_18.jpg)

###### 图 5.18:逆变换输出

#### 注意

确保您作为输入输入的值`workclass`和`occupation`存在于训练数据中，否则脚本将抛出错误。当`LabelEncoder`遇到一个以前没有见过的新值时，就会出现这个错误。

恭喜你！您构建了一个使用用户输入数据预测结果的脚本。现在，您可以将您的模型部署到任何您想部署的地方。

### 活动 15:预测客户流失

在本次活动中，我们将尝试预测客户是否会转向另一家电信提供商。数据来源于 IBM 样本数据集。让我们看看下面的场景:你在一家电信公司工作，最近，你的许多用户开始转向其他提供商。现在，为了能够给背叛客户降价，你需要在他们背叛之前预测哪个客户最有可能背叛。要做到这一点，你需要创建一个机器学习模型，预测哪个客户会叛逃。

1.  使用 pandas 加载 telecom churn ( `telco-churn.csv`)数据集()https://github . com/training bypackt/Data-Science-with-Python/tree/master/chapter 05/Data)。该数据集包含有关电信提供商客户的信息。数据集的原始来源位于:https://www . IBM . com/communities/analytics/Watson-analytics-blog/predictive-insights-in-the-telco-customer-churn-data-set/。它包含多个字段，如收费、任期和流信息，以及一个告诉我们客户是否搅动的变量。前几行应该是这样的:![](image/C13322_05_19.jpg)

    ###### 图 5.19:显示电信客户流失数据集前五个元素的屏幕截图

2.  删除不必要的变量。
3.  使用 scikit 将所有分类变量从字符串转换为整数。你可以使用下面的代码:`data.TotalCharges = pd.to_numeric(data.TotalCharges, errors='coerce')`
4.  修复加载熊猫时数据类型不匹配的问题。
5.  使用 XGBoost 库执行预测，并使用交叉验证执行参数调整，以将准确度提高到 80%以上。
6.  Save your model for future use.

    #### 注意

    这项活动的解决方案可在第 361 页找到。

## 神经网络

神经网络是数据科学家最常用的机器学习算法之一。在需要图像或数字媒体来找到解决方案的问题上，它一直优于传统的机器学习算法。在给定足够数据的情况下，它在结构化数据问题上优于传统的机器学习算法。具有两层以上的神经网络被称为深度神经网络，并且使用这些“深度”网络来解决问题的过程被称为深度学习。两种处理非结构化数据的神经网络主要有两种:一种是**卷积神经网络** ( **CNN** )可用于处理图像，一种是**递归神经网络** ( **RNN** )可用于处理时间序列和自然语言数据。我们会在*第六章*、*解码图像*和*第七章*、*处理人类语言*中多讲讲 CNN 和 RNNs。现在让我们看看一个普通的神经网络是如何工作的。在这一节中，我们将简要介绍神经网络的不同部分。我们将在接下来的章节中详细解释每个主题。

### 什么是神经网络？

神经网络的基本单元是神经元。神经网络的灵感来自生物大脑，这也是神经元这个名字的来源。神经网络中的所有连接就像大脑中的突触一样，可以将信息从一个神经元传递到另一个神经元。在神经网络中，输入信号的加权组合被聚合，然后输出信号在通过函数后向前传输。该函数是非线性激活函数，并且是神经元的激活阈值。多层这些相互连接的神经元形成了一个神经网络。只有神经网络的非输出层包括偏置单元。与每个神经元相关的权重以及这些偏差决定了整个网络的输出；因此，这些是我们在训练期间修改以适应数据的参数。

![Figure 5.20: Representation of single layer neural network](image/C13322_05_20.jpg)

###### 图 5.20:单层神经网络的表示

神经网络的第一层的节点数等于数据集中独立变量的数量。这一层因此被称为输入层，其后是多个隐藏层，其末端是输出层。输入层的每个神经元接受数据集的一个独立变量。输出层输出最终预测。如果是回归问题，这些输出可以是连续的(如 0.2，0.6，0.8)，如果是分类问题，这些输出可以是分类的(如 2，4，5)。神经网络的训练修改网络的权重和偏差以最小化误差，误差是期望值和输出值之间的差。权重与神经元的输入相乘，然后将偏差值添加到这些权重的组合中，以获得输出。

![Figure 5.21: Neuron output](image/C13322_05_21.jpg)

###### 图 5.21:神经元输出

这里， *y* 是神经元的输出， *x* 是输入， *w* 和 *b* 分别是权重和偏置， *f* 是激活函数，后面我们会详细介绍。

### 优化算法

为了最小化模型的误差，我们使用优化算法训练神经网络来最小化预定义的损失函数。这个优化算法有很多选择，你可以根据你的数据和模型选择一个。对于本书的大部分内容，我们将使用**随机梯度下降** ( **SGD** )，它在大多数情况下都工作得很好，但是我们将在需要时解释其他优化器。SGD 通过迭代找出梯度来工作，梯度是权重相对于误差的变化。在数学术语中，它是关于输入的偏导数。它找到梯度，这将有助于它最小化一个给定的函数，在我们的情况下，这是所谓的损失函数。随着我们越来越接近解决方案，这种梯度在数量上减少，从而防止我们超过最佳解决方案。

理解 SGD 最直观的方式就是下到谷底的动作。最初，我们走陡峭的下坡路，然后当我们接近底部时，坡度减小。

![Figure 5.22: Intuition of gradient descent (k represents magnitude of gradient)](image/C13322_05_22.jpg)

###### 图 5.22:梯度下降的直觉(k 代表梯度的大小)

### 超参数

决定训练一个模型所需时间的一个大参数被称为**学习率**，它本质上是我们执行下降所采取的步长。步长太小，模型需要很长时间才能达到最优解；太大，会超调最优解。为了规避这一点，我们从大的学习率开始，在几步之后降低学习率。这有助于我们更快地到达最小点，并且由于步长的减小，防止模型超过解。

接下来是权重的初始化。我们需要对神经网络的权重进行初始化，以获得一个起点，然后我们可以从该起点修改权重，以最小化误差。初始化在防止**消失**和**爆炸梯度**问题中起主要作用。

**消失梯度问题**指的是随着每一层的递减梯度，因为任何小于 1 的数的乘积甚至更小，所以在多层上，这个值变成 0。

**爆发梯度问题**当较大的误差梯度累积起来并导致模型发生非常大的更新时。如果南失去模型，这可能是一个问题。

使用 **Xavier 初始化**，我们可以防止这些问题，因为它在初始化权重时考虑了网络的大小。Xavier 初始化初始化权重，从以 0 为中心、具有标准偏差的截断正态分布绘制权重

![Figure 5.23: Xavier initialization](image/C13322_05_23.jpg)

###### 图 5.23:Xavier 初始化使用的标准偏差。

其中是该层的输入神经元的数量，yi 是该层的输出神经元的数量

这确保了即使网络中的层数非常大，输入和输出的方差也保持相同。

**损失函数**

另一个需要考虑的超参数是损失函数。根据问题的类型、分类或回归，使用不同的损失函数。对于分类，我们选择交叉熵和铰链等损失函数。对于回归，我们使用损失函数，如均方误差、平均绝对误差(MAE)和 Huber。不同的函数适用于不同的数据集。我们将在使用它们时仔细检查它们。

**激活功能**

创建神经网络层时，必须定义一个激活函数，这取决于该层是隐藏层还是输出层。在隐藏层的情况下，我们将使用 ReLU 或 tanh 激活函数。激活函数帮助神经网络模拟非线性函数。几乎没有现实生活中的情况可以用线性模型来解决。现在除此之外，不同的激活函数有不同的特性。Sigmoid 输出的值介于 0 和 1 之间，而 tanh 将输出集中在 0 附近，这样可以更好地学习。另一方面，ReLU 避免了消失梯度问题，并且计算效率高。这是一个 ReLU 图的表示。

![](image/C13322_05_24.jpg)

###### 图 5.24:ReLU 激活函数的表示

Softmax 输出概率，在执行多类分类时使用，而 sigmoid 输出 0 到 1 之间的值，仅用于二分类。线性激活主要用于解决回归问题的模型。下图显示了 sigmoid 激活函数的表示:

![Figure 5.25: Representation of sigmoid activation function](image/C13322_05_25.jpg)

###### 图 5.25:乙状结肠激活函数的表示

前一节有很多新的信息；如果你感到困惑，不要担心。我们将在余下的章节中实际应用所有这些概念，这将强化所有这些主题。

## Keras

Keras 是一个用 Python 编写的开源高级神经网络 API。它能够在 TensorFlow、微软认知工具包(CNTK)或 Theano 上运行。开发 Keras 是为了支持快速实验，从而帮助快速应用程序开发。使用 Keras，人们可以以尽可能少的延迟从想法到结果。由于巨大的社区支持，Keras 支持几乎所有与神经网络相关的最新数据科学模型。它包含常用构建块的多种实现，如层、批量规范化、丢弃、目标函数、激活函数和优化器。此外，Keras 允许用户为智能手机(Android 和 iOS)、网络或者为 **Java 虚拟机** ( **JVM** )创建模型。使用 Keras，您可以在 GPU 上训练您的模型，而无需更改任何代码。

鉴于 Keras 的所有这些特性，数据科学家必须学会如何使用该库的所有不同方面。作为一名数据科学家，掌握 Keras 的使用将极大地帮助你。为了展示 Keras 的强大功能，我们现在将安装它并创建一个单层神经网络模型。

#### 注意

你可以在这里阅读更多关于 Keras 的信息:https://keras.io/

### 练习 47:为 Python 安装 Keras 库并使用它来执行分类

在本练习中，我们将使用 Python 的 Keras 库对批发客户数据集(我们在*练习 44* 中使用过)执行分类。

1.  在您的虚拟环境中运行以下命令来安装 Keras。

    ```
    pip3 install keras
    ```

2.  从你的虚拟环境中打开 Jupyter 笔记本。
3.  导入 Keras 和其他所需的库。

    ```
    import pandas as pd
    from keras.models import Sequential
    from keras.layers import Dense
    import numpy as np
    from sklearn.metrics import accuracy_score
    ```

4.  Read the wholesale customer dataset using pandas and check to see if it was loaded successfully using the following command:

    ```
    data = pd.read_csv("data/wholesale-data.csv")
    data.head()
    ```

    输出应该如下所示:

    ![Figure 5.26: Screenshot showing first five elements of dataset](image/C13322_05_26.jpg)

    ###### 图 5.26:显示数据集前五个元素的屏幕截图

5.  将数据分割为要素和标签。

    ```
    X = data.copy()X.drop("Channel", inplace = True, axis = 1)Y = data.Channel
    ```

6.  创建训练集和测试集。

    ```
    X_train, X_test = X[:int(X.shape[0]*0.8)].values, X[int(X.shape[0]*0.8):].values Y_train, Y_test = Y[:int(Y.shape[0]*0.8)].values, Y[int(Y.shape[0]*0.8):].values
    ```

7.  Create the neural network model.

    ```
    model = Sequential()
    model.add(Dense(units=8, activation='relu', input_dim=7))
    model.add(Dense(units=16, activation='relu'))
    model.add(Dense(units=1, activation='sigmoid'))
    ```

    这里，我们创建一个四层网络，一个输入层，两个隐藏层，一个输出层。隐藏层具有 ReLU 激活，输出层具有 softmax 激活。

8.  Compile and train the model. We use the binary cross-entropy loss function, which is the same as the logloss we discussed before; we have chosen the optimizer to be stochastic gradient descent. We run the training for five epochs with a batch size of eight.

    ```
    model.compile(loss='binary_crossentropy',
                  optimizer='sgd',
                  metrics=['accuracy'])
    model.fit(X_train, Y_train, epochs=5, batch_size=8)
    ```

    #### 注意

    您将看到模型训练日志。Epoch 指的是训练迭代，352 指的是数据集的大小除以批量大小。在进度条之后，您可以看到一次迭代所用的时间。接下来，你可以看到训练每一批的平均时间。接下来是模型的损失，这里是二进制交叉熵损失，然后是迭代后的精度。其中一些术语是新的，但是我们将在下面的部分中理解它们。

    ![Figure 5.27: Screenshot of model training logs](image/C13322_05_27.jpg)

    ###### 图 5.27:模型训练日志的屏幕截图

9.  预测测试集的值。

    ```
    preds = model.predict(X_test, batch_size=128)
    ```

10.  Obtain the accuracy of the model.

    ```
    accuracy = accuracy_score(Y_test, preds.astype(int))
    print("Accuracy: %.2f%%" % (accuracy * 100.0))
    ```

    输出如下所示:

![Figure 5.28: Output accuracy](image/C13322_05_28.jpg)

###### 图 5.28:输出精度

恭喜你！你刚刚制作了你的第一个神经网络模型，准确率约为 81%，没有任何微调！您会注意到，与 XGBoost 相比，这个精度相当低。在接下来的几节中，您将了解如何提高这种准确性。准确度低的一个主要原因是数据的大小。一个神经网络模型要真正发光，它必须有一个大的数据集来训练；否则，它会过度拟合数据。

### Keras Library

Keras 支持模块化。所有初始化器、成本函数、优化器、层、正则化器和激活函数都是独立的模块，可用于任何类型的数据和网络架构。您会发现 Keras 中已经实现了几乎所有的最新功能。这允许代码的可重用性，并支持快速实验。作为一名数据科学家，您不会受到内置模块的限制；创建自己的定制模块并与其他内置模块一起使用是非常容易的。这使得研究成为可能，并有助于不同的用例。例如，您可能需要编写一个自定义的损失函数来最大化汽车销售量，赋予利润率较高的汽车更多的权重，从而获得更高的利润。

Keras 中定义了创建神经网络所需的所有不同种类的层。我们会在使用它们时进行调查。在 Keras 中创建神经模型有两种主要方法，顺序模型和函数 API。

**顺序**:**顺序模型**是一个线性的层叠。这是用 Keras 创建神经网络模型的最简单的方法。下面给出了该模型的一个片段:

```
model = Sequential()model.add(Dense(128, input_dim=784))model.add(Activation('relu'))
model.add(Dense(10))model.add(Activation('softmax'))
```

**功能 API** : **功能 API** 是复杂模型的必由之路。由于顺序模型的线性性质，不可能创建复杂的模型。functional API 允许您创建模型的多个部分，然后将它们合并在一起。函数式 API 中的相同模型如下所示:

```
inputs = Input(shape=(784,))
x = Dense(128, activation='relu')(inputs)prediction = Dense(10, activation='softmax')(x)model = Model(inputs=inputs, outputs=prediction)
```

Keras 的一个强大功能是回调。回调允许你在训练过程的任何阶段使用一个函数。事实证明，这对于在不同阶段获取统计数据和保存模型非常有用。它可用于对学习率应用自定义衰减，也可用于执行提前停止。

```
filepath="model-weights-{epoch:02d}-{val_loss:.2f}.hdf5"
model_ckpt = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')
callbacks = [model_ckpt]
```

要保存您在 Keras 上训练的模型，您只需使用以下代码行:

```
model.save('Path to model')
```

要从文件中加载模型，请使用以下代码:

```
keras.models.load_model('Path to model')
```

早期停止是一个有用的特性，可以使用回调来实现。训练模型时，提前停止有助于节省时间。如果指定度量的变化小于设置的阈值，则停止训练过程。

```
EarlyStopping(monitor='val_loss', min_delta=0.01, patience=5, verbose=1, mode='auto')
```

如果确认损失的变化在五个时期内小于 0.01，则上述回调停止训练。

#### 注意

总是使用`ModelCheckpoint`来存储模型状态。这对于大型数据集和大型网络尤为重要。

### 练习 48:使用神经网络预测鳄梨价格

让我们应用我们在这一部分学到的知识来创建一个优秀的神经网络模型，来预测不同种类鳄梨的价格。数据集(https://github . com/TrainingByPackt/Data-Science-with-Python/tree/master/chapter 05/Data)包含的信息包括农产品的平均价格、产量、鳄梨的产地以及所用袋子的尺寸。它也有一些未知的变量，可能有助于我们的模型。

#### 注意

原始来源地点:[www.hassavocadoboard.com/retail/volume-and-price-data](http://www.hassavocadoboard.com/retail/volume-and-price-data)

1.  导入 avocado 数据集并观察列。你会看到这样的东西:

    ```
    import pandas as pd
    import numpy as np
    data = pd.read_csv('data/avocado.csv')
    data.T
    ```

    ![Figure 5.29: Screenshot showing avocado dataset](image/C13322_05_29.jpg)

    ###### 图 5.29:显示鳄梨数据集的屏幕截图

2.  浏览数据，将日期列拆分为日和月。这将帮助我们抓住季节性，而忽略年份。现在，删除日期和未命名的列。

    ```
    data['Day'], data['Month'] = data.Date.str[:2], data.Date.str[3:5] 
    data = data.drop(['Unnamed: 0', 'Date'], axis = 1)
    ```

3.  使用`LabelEncoder`对分类变量进行编码，以便 Keras 可以使用它来训练模型。

    ```
    from sklearn.preprocessing import LabelEncoder
    from collections import defaultdict
    label_dict = defaultdict(LabelEncoder)
    data[['region', 'type', 'Day', 'Month', 'year']] = data[['region', 'type', 'Day', 'Month', 'year']].apply(lambda x: label_dict[x.name].fit_transform(x))
    ```

4.  将数据分成训练集和测试集。

    ```
    from sklearn.model_selection import train_test_split
    X = data
    y = X.pop('AveragePrice')
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=9)
    ```

5.  只要损失有所改善，就使用回调来保存模型，如果模型开始表现不佳，就提前停止模型。

    ```
    from keras.callbacks import ModelCheckpoint, EarlyStopping
    filepath="avocado-{epoch:02d}-{val_loss:.2f}.hdf5"
    model_ckpt = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')
    es = EarlyStopping(monitor='val_loss', min_delta=1, patience=5, verbose=1)
    callbacks = [model_ckpt, es]
    ```

6.  创建神经网络模型。这里，我们使用与之前相同的模型。

    ```
    from keras.models import Sequential
    from keras.layers import Dense
    model = Sequential()
    model.add(Dense(units=16, activation='relu', input_dim=13))
    model.add(Dense(units=8, activation='relu'))
    model.add(Dense(units=1, activation='linear'))
    model.compile(loss='mse', optimizer='adam')
    ```

7.  对模型进行训练和评估，得到模型的均方误差。

    ```
    model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs=40, batch_size=32)
    model.evaluate(X_test, y_test) 
    ```

8.  查看以下屏幕截图中的最终输出:

![Figure 5.30: MSE of model](image/C13322_05_30.jpg)

###### 图 5.30:模型的均方误差

恭喜你！您刚刚训练了您的神经网络，以在 avocado 数据集上获得合理的误差。上面显示的值是模型的均方误差。修改一些超参数，用剩下的数据，看看能不能得到更好的误差分。利用前面几节提供的信息。

#### 注意

MSE 的降低是有利的。最佳值将取决于具体情况。例如，在预测汽车速度时，小于 100 的值是理想的，而在预测一个国家的 GDP 时，1000 的 MSE 就足够了。

## 分类变量

分类变量的值可以用不同的类别表示。例如球的颜色、狗的品种和邮政编码。将这些分类变量映射到一个单独的维度会产生一种相互依赖的关系，这是不正确的。即使这些分类变量没有顺序或相关性，将它们作为单个特征输入到神经网络中也会使神经网络根据顺序在这些变量之间产生相关性，而在现实中，顺序并不意味着任何事情。在本节中，我们将了解解决这个问题和训练有效模型的方法。

### 一键编码

映射分类变量的最简单和最广泛使用的方法是使用一键编码。使用这种方法，我们将一个分类特征转换成与该特征中的类别数量相等的特征。

![Figure 5.31: Categorical feature conversion](image/C13322_05_31.jpg)

###### 图 5.31:分类特征转换

使用以下步骤将分类变量转换为一次性编码变量:

1.  如果数据表示为 int 以外的数据类型，则将数据转换为数字。有两种方法可以做到这一点
2.  可以直接用 sklearn 的`LabelEncoder`方法。
3.  Create bins to reduce the number of categories. The higher the number of categories, the more difficult it is for the model. You can choose an integer to represent each bin. Do keep in mind that doing this will lead to a loss in information and might result in a bad model. You can perform histogram binning using the following rule:

    如果分类列的数量少于 25，则使用 5 个箱。

    如果它在 25 和 100 之间，使用 n/5 个箱，其中 n 是分类列的数量，如果它大于 100，使用 10 * log (n)个箱。

    #### 注意

    您可以将频率小于 5%的类别合并为一个类别。

4.  使用 pandas 的`get_dummies`函数将步骤 1 中的数值数组转换成一个 hot vector。

![Figure 5.32: Output of get_dummies function](image/C13322_05_32.jpg)

###### 图 5.32:get _ dummies 函数的输出

一键编码不是使用分类数据的最佳方式有两个主要原因:

*   分类变量的不同值被假定为彼此完全独立。这导致关于它们之间关系的信息的丢失。
*   具有许多类别的分类变量导致计算非常昂贵的模型。更宽的数据集需要更多的数据点来构建有意义的模型。这就是众所周知的维数灾难。

为了解决这些问题，我们将使用实体嵌入。

### 实体嵌入

实体嵌入表示多维空间中的分类特征。这确保了网络学习特征的不同类别之间的正确关系。这个多维空间的维度并不代表任何特定的东西；它可以是模型认为适合学习的任何东西。例如，在一周中的几天的情况下，一个维度可以是该天是否是工作日，另一个维度可以是与工作日的距离。这种方法受到自然语言处理中用于学习单词和短语之间语义相似性的单词嵌入的启发。创建嵌入可以帮助教会神经网络星期五与星期三有什么不同，或者小狗和狗有什么不同。例如，一周中各天的四维嵌入矩阵如下所示:

![Figure 5.33: Four-dimensional embedding matrix
](image/C13322_05_33.jpg)

###### 图 5.33:四维嵌入矩阵

从上面的矩阵中，您可以看到嵌入学习了类别之间的依赖性:它知道星期六和星期天比星期四和星期五更相似，因为星期六和星期天的向量是相似的。当您的数据集中有许多分类变量时，实体嵌入会有很大的优势。要在 Keras 中创建实体嵌入，可以使用嵌入层。

#### 注意

总是尝试使用单词嵌入，因为它会给出最好的结果。

### 练习 49:使用实体嵌入预测鳄梨价格

让我们使用实体嵌入的知识，通过创建一个更好的神经网络模型来预测鳄梨价格。我们将使用之前的同一个 avocado 数据集。

1.  导入鳄梨价格数据集并检查是否有空值。将日期列拆分为月和日列。

    ```
    import pandas as pd
    import numpy as np
    data = pd.read_csv('data/avocado.csv')
    data['Day'], data['Month'] = data.Date.str[:2], data.Date.str[3:5]
    data = data.drop(['Unnamed: 0', 'Date'], axis = 1)
    data = data.dropna()
    ```

2.  对分类变量进行编码。

    ```
    from sklearn.preprocessing import LabelEncoder
    from collections import defaultdict
    label_dict = defaultdict(LabelEncoder)
    data[['region', 'type', 'Day', 'Month', 'year']] = data[['region', 'type', 'Day', 'Month', 'year']].apply(lambda x: label_dict[x.name].fit_transform(x))
    ```

3.  将数据分成训练集和测试集。

    ```
    from sklearn.model_selection import train_test_split
    X = data
    y = X.pop('AveragePrice')
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=9)
    ```

4.  创建一个字典，将分类列名映射到其中的唯一值。

    ```
    cat_cols_dict = {col: list(data[col].unique()) for col in ['region', 'type', 'Day', 'Month', 'year'] }
    ```

5.  Next, get the input data in the format that the embedding neural network will accept.

    ```
    train_input_list = []
    test_input_list = []
    for col in cat_cols_dict.keys():
        raw_values = np.unique(data[col])
        value_map = {}
        for i in range(len(raw_values)):
            value_map[raw_values[i]] = i       
        train_input_list.append(X_train[col].map(value_map).values)
        test_input_list.append(X_test[col].map(value_map).fillna(0).values)
    other_cols = [col for col in data.columns if (not col in cat_cols_dict.keys())]
    train_input_list.append(X_train[other_cols].values)
    test_input_list.append(X_test[other_cols].values)
    ```

    这里，我们正在做的是创建一个包含所有变量的数组列表。

6.  接下来，创建一个字典来存储嵌入层的输出尺寸。这是变量将被表示的值的数量。你必须通过反复试验得到正确的数字。

    ```
    cols_out_dict = {
        'region': 12, 
        'type': 1, 
        'Day': 10, 
        'Month': 3, 
        'year': 1
    }
    ```

7.  现在，为分类变量创建嵌入层。在循环的每次迭代中，我们为分类变量创建一个嵌入层。

    ```
    from keras.models import Model
    from keras.layers import Input, Dense, Concatenate, Reshape, Dropout
    from keras.layers.embeddings import Embedding
    inputs = []
    embeddings = []
    for col in cat_cols_dict.keys():

        inp = Input(shape=(1,), name = 'input_' + col)
        embedding = Embedding(cat_cols_dict[col], cols_out_dict[col], input_length=1, name = 'embedding_' + col)(inp)
        embedding = Reshape(target_shape=(cols_out_dict[col],))(embedding)
        inputs.append(inp)
        embeddings.append(embedding)
    ```

8.  现在，将连续变量添加到网络中，完成模型。

    ```
    input_numeric = Input(shape=(8,))
    embedding_numeric = Dense(16)(input_numeric) 
    inputs.append(input_numeric)
    embeddings.append(embedding_numeric)
    x = Concatenate()(embeddings)
    x = Dense(16, activation='relu')(x)
    x = Dense(4, activation='relu')(x)
    output = Dense(1, activation='linear')(x)
    model = Model(inputs, output)
    model.compile(loss='mse', optimizer='adam')
    ```

9.  使用 train_input_list 训练模型，该列表是我们在步骤 5 中为 50 个时期创建的。

    ```
    model.fit(train_input_list, y_train, validation_data = (test_input_list, y_test), epochs=50, batch_size=32)
    ```

10.  现在，从嵌入层获得权重来可视化嵌入。

    ```
    embedding_region = model.get_layer('embedding_region').get_weights()[0]
    ```

11.  Perform PCA and plot the output using the region labels (which you can get by performing inverse transform on the dictionary that we created earlier). PCA displays similar data points closer, by reducing the dimensionality to two dimensions. Here, we plot only the first 25 regions.

    如果你愿意，你可以把它们都画出来。

    ```
    import matplotlib.pyplot as plt
    from sklearn.decomposition import PCA
    pca = PCA(n_components=2)
    Y = pca.fit_transform(embedding_region[:25])
    plt.figure(figsize=(8,8))
    plt.scatter(-Y[:, 0], -Y[:, 1])
    for i, txt in enumerate((label_dict['region'].inverse_transform(cat_cols_dict['region']))[:25]):
        plt.annotate(txt, (-Y[i, 0],-Y[i, 1]), xytext = (-20, 8), textcoords = 'offset points')
    plt.show()
    ```

![Figure 5.34: Graphical representation of avocado growing region using entity embedding](image/C13322_05_34.jpg)

###### 图 5.34:使用实体嵌入的鳄梨生长区域的图形表示

恭喜你！您通过使用实体嵌入提高了模型的准确性。从嵌入图中可以看出，该模型能够计算出平均价格高低的区域。您可以绘制其他变量的嵌入图，以查看网络从数据中得出的关系。另外，尝试通过超参数调整来提高该模型的准确性。

### 活动 16:预测顾客的购买量

在本次活动中，我们将尝试预测顾客在某个产品类别上的消费金额。数据集(https://github . com/TrainingByPackt/Data-Science-with-Python/tree/master/chapter 05/Data)包含零售店中进行的交易。让我们来看看下面的场景:你在一家大型零售连锁店工作，想要预测哪类客户会在某个特定的产品类别上花多少钱。这样做将有助于您的一线员工向客户推荐合适的产品，从而提高销售额和客户满意度。为此，你需要创建一个预测交易购买价值的机器学习模型。

1.  Load the Black Friday dataset using pandas. This dataset is a collection of transactions made in a retail store. The information it contains is the age, city, marital status of the customer, product category of the item being bought, and bill amount. The first few rows should look like this:![Figure 5.35: Screenshot showing first five elements of Black Friday dataset ](image/C13322_05_35.jpg)

    ###### 图 5.35:显示黑色星期五数据集的前五个元素的屏幕截图

    删除不必要的变量和空值。拆下`Product_Category_2`和`Product_Category_3`柱。

2.  对所有分类变量进行编码。
3.  通过使用 Keras 库创建神经网络来执行预测。利用实体嵌入并执行超参数调整。
4.  Save your model for future use.

    #### 注意

    这项活动的解决方案可在第 364 页找到。

## 总结

在本章中，我们学习了如何创建高度精确的结构化数据模型，并了解了 XGBoost 是什么以及如何使用该库来训练模型，在开始之前，我们想知道什么是神经网络以及如何使用 Keras 库来训练模型。在学习了神经网络之后，我们开始处理分类数据。最后，我们学习了什么是交叉验证以及如何使用它。

现在你已经完成了这一章，你可以处理任何类型的结构化数据，并用它创建机器学习模型。在下一章中，您将学习如何为图像数据创建神经网络模型。