<title>C13322_06_Epub_Final_SW</title> <link href="css/epub.css" rel="stylesheet" type="text/css"> 

# *第六章*

# 解码图像

## 学习目标

本章结束时，您将能够:

*   创建可以将图像分类到不同类别的模型
*   使用 Keras 库为图像训练神经网络模型
*   在不同的商业场景中利用图像增强的概念
*   从图像中提取有意义的信息

本章将涵盖如何阅读和处理图像的各种概念。

## 简介

到目前为止，我们只处理数字和文本。在本章中，我们将学习如何使用机器学习来解码图像并提取有意义的信息，例如图像中存在的对象类型，或者图像中写入的数字。你有没有停下来想一想，我们的大脑是如何解读从眼睛接收到的图像的？经过数百万年的进化，我们的大脑已经变得非常高效和准确地从我们眼睛获得的图像中识别物体和模式。我们已经能够使用相机复制我们眼睛的功能，但让计算机识别图像中的模式和对象确实是一项艰巨的工作。与理解图像中存在的东西相关的领域被称为计算机视觉。在过去的几年里，计算机视觉领域见证了巨大的研究和进步。复杂神经网络(CNN)的引入和在 GPU 上训练神经网络的能力是这些突破中最大的。今天，CNN 被用于我们遇到计算机视觉问题的任何地方，例如，自动驾驶汽车，面部识别，物体检测，物体跟踪，以及创造完全自主的机器人。在这一章中，我们将了解这些细胞神经网络是如何工作的，以及与传统方法相比，它们有多大的改进。

## 图片

我们今天拥有的数码相机将图像存储为一个大的数字矩阵。这些就是我们所说的数字图像。这个矩阵上的单个数字指的是图像中的单个像素。个别数字指的是该像素的颜色强度。对于灰度图像，这些值从 0 到 255 不等，其中 0 表示黑色，255 表示白色。对于彩色图像，这个矩阵是三维的，其中每个维度都有红色、绿色和蓝色的值。矩阵中的值指的是各种颜色的强度。我们使用这些值作为我们的计算机视觉程序或数据科学模型的输入，以执行预测和识别。

现在，我们有两种方法来使用这些像素创建机器学习模型:

*   将单个像素作为不同的输入变量输入到神经网络
*   使用卷积神经网络

创建一个完全连接的神经网络，将单个像素值作为输入变量，这是目前对我们来说最简单和最直观的方法，因此我们将从创建这个模型开始。在下一节，我们将了解 CNN，看看它们在处理图像方面有多好。

### 练习 50:使用全连接神经网络对 MNIST 进行分类

在本练习中，我们将对**修改后的国家标准与技术研究所数据库** ( **MNIST** )数据集进行分类。MNIST 是一个手写数字的数据集，这些数字已被归一化以适合 28 x 28 像素的边界框。该数据集中有 60，000 幅训练图像和 10，000 幅测试图像。在全连接网络的情况下，我们将单个像素作为特征输入网络，然后将其训练为普通的神经网络，就像我们在*第 5 章*、*掌握结构化数据*中训练的第一个神经网络一样。

要完成本练习，请完成以下步骤:

1.  加载所需的库，如下图:

    ```
    import numpy as np
    import matplotlib.pyplot as plt
    from sklearn.preprocessing import LabelBinarizer
    from keras.datasets import mnist
    from keras.models import Sequential
    from keras.layers import Dense
    ```

2.  使用 Keras 库加载 MNIST 数据集:

    ```
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    ```

3.  From the shape of the dataset, you can figure out that the data is available in 2D format. The first element is the number of images available, whereas the next two elements are the width and height of the images:

    ```
    x_train.shape
    ```

    输出如下所示:

    ![Figure 6.1: Width and height of images
    ](image/C13322_06_01.jpg)

    ###### 图 6.1:图像的宽度和高度

4.  绘制第一幅图像，看看你正在处理哪种数据:

    ```
    plt.imshow(x_test[0], cmap=plt.get_cmap(‘gray'))
    plt.show()
    ```

    ![Figure 6.2: Sample image of the MNIST dataset
    ](image/C13322_06_02.jpg)

    ###### 图 6.2:MNIST 数据集的样本图像

5.  将 2D 数据转换为 1D 数据，以便我们的神经网络可以将其作为输入(28 x 28 像素= 784):

    ```
    x_train = x_train.reshape(60000, 784)
    x_test = x_test.reshape(10000, 784)
    ```

6.  将目标变量转换成一个热点向量，这样我们的网络就不会在不同的目标变量之间形成不必要的连接:

    ```
    label_binarizer = LabelBinarizer()
    label_binarizer.fit(range(10))
    y_train = label_binarizer.transform(y_train)
    y_test = label_binarizer.transform(y_test)
    ```

7.  创建模型。做一个小的两层网络；您可以尝试其他架构。您将在以下部分了解更多关于交叉熵损失的信息:

    ```
    model = Sequential()
    model.add(Dense(units=32, activation='relu', input_dim=784))
    model.add(Dense(units=32, activation='relu'))
    model.add(Dense(units=10, activation='softmax'))
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = [‘acc'])
    model.summary()
    ```

    ![Figure 6.3: Model architecture of the dense network
    ](image/C13322_06_03.jpg)

    ###### 图 6.3:密集网络的模型架构

8.  Train the model and check the final accuracy:

    ```
    model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=40, batch_size=32)
    score = model.evaluate(x_test, y_test)
    print(“Accuracy: {0:.2f}%”.format(score[1]*100))
    ```

    输出如下所示:

![Figure 6.4: Model accuracy
](image/C13322_06_04.jpg)

###### 图 6.4:模型准确性

恭喜你！现在，您已经创建了一个模型，它可以以 93.57%的准确率预测图像上的数字。您可以使用以下代码绘制不同的测试图像，并查看网络的结果。更改 image 变量的值以获得不同的图像:

```
image = 6
plt.imshow(x_test[image].reshape(28,28), 
cmap=plt.get_cmap(‘gray'))
plt.show()
y_pred = model.predict(x_test)
print(“Prediction: {0}”.format(np.argmax(y_pred[image])))
```

![Figure 6.5: An MNIST image with prediction from dense network
](image/C13322_06_05.jpg)

###### 图 6.5:带有密集网络预测的 MNIST 图像

您可以仅可视化不正确的预测，以了解模型的失败之处:

```
incorrect_indices = np.nonzero(np.argmax(y_pred,axis=1) != np.argmax(y_test,axis=1))[0]
image = 4
plt.imshow(x_test[incorrect_indices[image]].reshape(28,28), 
cmap=plt.get_cmap(‘gray'))
plt.show()
print(“Prediction: {0}”.format(np.argmax(y_pred[incorrect_indices[image]])))
```

![Figure 6.6: Incorrectly classified example from the dense network
](image/C13322_06_06.jpg)

###### 图 6.6:来自密集网络的错误分类示例

正如您在前面的截图中看到的，模型失败是因为我们预测类是 2，而正确的类是 3。

## 卷积神经网络

**卷积神经网络** ( **CNN** )是对具有卷积层的神经网络的称呼。这些卷积层在卷积滤波器的帮助下有效地处理原始图像的高维度。CNN 允许我们识别图像中高度复杂的模式，这对于简单的神经网络来说是不可能的。CNN 也可以用于自然语言处理。

CNN 的前几层是卷积的，网络对图像应用不同的过滤器来寻找图像中有用的模式；然后是池层，它有助于对卷积层的输出进行下采样。激活层控制信号从一层流向下一层，模拟我们大脑中的神经元。网络中最后几层是密集层；这些是我们在之前的练习中使用的相同图层。

### 卷积层

卷积层由多个过滤器组成，当它们在初始层中看到某个特征、边缘或颜色，并最终看到面、蜂窝和轮子时，它们会学习激活。这些滤镜就像我们都习以为常的 Instagram 滤镜一样。滤镜通过以某种方式改变像素来改变图像的外观。我们以检测水平边缘的滤镜为例。

![Figure 6.7: Horizontal edge detection filter
](image/C13322_06_07.jpg)

###### 图 6.7:水平边缘检测滤波器

正如您在前面的屏幕截图中看到的，过滤器将图像转换为另一个图像，该图像突出显示了水平线。为了得到变换，我们将图像的各个部分逐个乘以滤波器。首先，我们获取图像的左上角 3 x 3 横截面，并使用过滤器执行矩阵乘法，以获得变换的第一个左上角像素。然后我们将滤镜向右移动一个像素，得到转换的第二个像素，依此类推。该转换是一个新图像，它只突出显示了图像的水平线部分。滤波器参数的值，在这种情况下是 9，是卷积层在训练时学习的权重或参数。一些过滤器可能学会检测水平线、一些垂直线和一些 45 度角的线。随后的层学习更复杂的结构，如车轮或人脸的图案。

卷积层的一些超参数如下:

*   **过滤器**:这是网络每一层的过滤器数量。这个数字也反映了转换的维数，因为每个过滤器将产生一维的输出。
*   **滤波器大小**:这是网络将要学习的卷积滤波器的大小。这个超参数将决定输出变换的大小。
*   **Stride** :在前面的水平边缘示例中，我们每次都将滤镜移动一个像素。这就是跨步。它指的是过滤器每次通过时移动的量。这个超参数也决定了输出变换的大小。
*   **Padding**: This hyperparameter makes the network pad the image with zeros on all the sides. This helps preserve edge information in some cases and helps us keep the input and output of the same size.

    #### 注意

    如果您执行填充，那么您将获得与卷积运算的输出大小相同或更大的图像。如果不执行填充，图像将会缩小。

## 汇集层

**池层**缩小输入图像的大小，以减少网络中的计算量和参数。在卷积层之间周期性地插入池层，以控制过拟合。最常见的池变体是 2 x 2 最大池，步长为 2。该变体对输入执行下采样，以仅保留输出中四个像素的最大值。深度尺寸保持不变。

![Figure 6.8: Max pooling operation
](image/C13322_06_08.jpg)

###### 图 6.8:最大池操作

过去，我们也使用平均池，但是现在更经常使用最大池，因为它在实践中被证明效果更好。许多数据科学家不喜欢使用池化图层，只是因为池化操作会导致信息丢失。已经有一些关于这个主题的研究，并且已经发现没有池化层的简单架构有时优于最先进的模型。为了减小输入的大小，建议每隔一段时间在卷积层中使用更大的步长。

#### 注意

研究论文*力求简单:全卷积网络*评估了具有池层的模型，发现池层并不总是提高网络的性能，大多数情况下是在有足够数据可用的情况下。要了解更多信息，请阅读 https://arxiv.org/abs/1412.6806 的*力求简单:全卷积网*论文

## 亚当优化器

优化器在损失函数的帮助下更新权重。为优化器选择错误的优化器或错误的超参数会导致延迟找到问题的最佳解决方案。

Adam 这个名字来源于自适应矩估计。Adam 是专门为训练深度神经网络而设计的。Adam 的使用在数据科学社区中非常普遍，因为它可以快速接近最优解。因此，如果你想要快速收敛，使用 **Adam 优化器**。亚当并不总是导致最优解；在这种情况下，SGD with momentum 有助于实现最先进的结果。以下是参数:

*   **学习率**:这是优化器的步长。较大的值(0.2)导致较快的初始学习，而较小的值(0.00001)在训练期间减慢学习。
*   **Beta 1** :这是梯度平均估计值的指数衰减率。
*   **Beta 2** :这是梯度的无中心方差估计的指数衰减率。
*   **ε**:这是一个很小的数，防止被零除。

深度学习问题的一个很好的起点是学习率= 0.001，β1 = 0.9，β2 = 0.999，ε= 10-8。

#### 注意

欲了解更多信息，请阅读亚当论文:https://arxiv.org/abs/1412.6980v8

## 交叉熵损失

**交叉熵损失**在我们处理分类问题时使用，其中每个类别的输出是 0 到 1 之间的概率值。这里的损失随着模型偏离实际值而增加；它遵循负对数图。当模型预测的概率与实际值相差甚远时，这很有帮助。例如，如果真实标签的概率是 0.05，我们用巨大的损失惩罚模型。另一方面，如果真实标签的概率是 0.40，我们用较小的损失来惩罚它。

![Figure 6.9: Graph of log loss versus probability
](image/C13322_06_09.jpg)

###### 图 6.9:测井曲线损失与概率的关系图

上图显示，随着预测与真实标签的距离越来越远，损耗呈指数增长。交叉熵损失遵循的公式如下:

![Figure 6.10: Cross entropy loss formula
](image/C13322_06_10.jpg)

###### 图 6.10:交叉熵损失公式

*M* 是数据集中类的数量(MNIST 的情况下是 10)， *y* 是真实标签， *p* 是类的预测概率。我们更喜欢交叉熵损失进行分类，因为权重更新随着我们越来越接近真实情况而变得越来越小。交叉熵损失只惩罚正确类别的概率。

### 练习 51:使用 CNN 对 MNIST 进行分类

在本练习中，我们将使用 CNN 而不是在*练习 50* 中使用的全连接图层对**修改后的国家标准与技术研究所(MNIST** )数据集进行分类。我们将完整的图像作为输入提供给网络，并获得图像上的数字作为输出:

1.  使用 Keras 库加载 MNIST 数据集:

    ```
    from keras.datasets import mnist
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    ```

2.  将 2D 数据转换成只有一层的三维数据，这是 Keras 要求输入的方式:

    ```
    x_train = x_train.reshape(-1, 28, 28, 1)
    x_test = x_test.reshape(-1, 28, 28, 1)
    ```

3.  将目标变量转换成一个热点向量，这样我们的网络就不会在不同的目标变量之间形成不必要的连接:

    ```
    from sklearn.preprocessing import LabelBinarizer
    label_binarizer = LabelBinarizer()
    label_binarizer.fit(range(10))
    y_train = label_binarizer.transform(y_train)
    y_test = label_binarizer.transform(y_test)
    ```

4.  Create the model. Here, we make a small CNN. You can experiment with other architectures:

    ```
    from keras.models import Model, Sequential
    from keras.layers import Dense, Conv2D, MaxPool2D, Flatten
    model = Sequential()
    ```

    添加卷积层:

    ```
    model.add(Conv2D(32, kernel_size=3, 
    padding=”same”,input_shape=(28, 28, 1),    activation = ‘relu'))
    model.add(Conv2D(32, kernel_size=3, activation = ‘relu'))
    ```

    添加池层:

    ```
    model.add(MaxPool2D(pool_size=(2, 2)))
    ```

5.  将 2D 矩阵展平成 1D 向量:

    ```
    model.add(Flatten())
    ```

6.  Use dense layers as the final layers for the model:

    ```
    model.add(Dense(128, activation = “relu”))
    model.add(Dense(10, activation = “softmax”))
    model.compile(loss='categorical_crossentropy', optimizer='adam', 
    metrics = [‘acc'])
    model.summary()
    ```

    为了充分理解这一点，请看下面截图中的模型输出:

    ![Figure 6.11: Model architecture of the CNN
    ](image/C13322_06_11.jpg)

    ###### 图 6.11:CNN 的模型架构

7.  Train the model and check the final accuracy:

    ```
    model.fit(x_train, y_train, validation_data = (x_test, y_test), 
    epochs=10, batch_size=1024)
    score = model.evaluate(x_test, y_test)
    print(“Accuracy: {0:.2f}%”.format(score[1]*100))
    ```

    输出如下所示:

![Figure 6.12: Final model accuracy
](image/C13322_06_12.jpg)

###### 图 6.12:最终模型精度

恭喜你！现在，您已经创建了一个模型，它可以以 98.62%的准确率预测图像上的数字。您可以绘制不同的测试图像，并使用*练习 50* 中给出的代码查看您的网络结果。此外，画出不正确的预测，看看模型哪里出错了:

```
import numpy as np
import matplotlib.pyplot as plt
incorrect_indices = np.nonzero(np.argmax(y_pred,axis=1) != np.argmax(y_test,axis=1))[0]
image = 4
plt.imshow(x_test[incorrect_indices[image]].reshape(28,28), 
cmap=plt.get_cmap(‘gray'))
plt.show()
print(“Prediction: {0}”.format(np.argmax(y_pred[incorrect_indices[image]])))
```

![Figure 6.13: Incorrect prediction of the model; the true label is 2
](image/C13322_06_13.jpg)

###### 图 6.13:模型预测错误；真正的标签是 2

如您所见，该模型很难预测模糊的图像。你可以试验一下图层和超参数，看看你是否能得到更好的精度。如前一节所述，尝试用步幅更大的卷积层替换池层。

## 正规化

**正则化**是一种通过修改学习算法来帮助机器学习模型更好地泛化的技术。这有助于防止过度拟合，并帮助我们的模型更好地处理它在训练期间没有看到的数据。在本节中，我们将学习不同的正则化子。

### 脱落层

**Dropout** 是一种正则化技术，我们使用它来防止神经网络模型中的过度拟合。我们在训练时忽略从网络中随机选择的神经元。这防止了这些神经元的激活继续下去，并且权重更新在反向传播期间不应用于它们。神经元的权重被调整以识别特定的特征；邻近它们的神经元变得依赖于此，这可能导致过度拟合，因为这些神经元可以针对训练数据进行特殊化。当神经元被随机丢弃时，相邻的神经元介入并学习该表示，导致网络学习多个不同的表示。这使得网络更好地泛化，并防止模型过拟合。需要记住的一件重要事情是，在执行预测或测试模型时，不应使用下降图层。这将使模型丢失有价值的信息，并导致性能损失。Keras 会自己处理这件事。

使用 dropout 图层时，建议创建更大的网络，因为它为模型提供了更多的学习机会。我们通常使用 0.2 到 0.5 之间的退出概率。这个概率指的是神经元从训练中被丢弃的概率。发现在每个图层后放置一个漏失图层会产生良好的结果，因此您可以从在每个图层后放置概率为 0.2 的漏失图层开始，然后从那里进行微调。

要在 Keras 中创建概率为 0.5 的下降图层，可以使用以下函数:

```
keras.layers.Dropout(0.5)
```

![Figure 6.14: Visualizing dropout in a dense neural network
](image/C13322_06_14.jpg)

###### 图 6.14:可视化密集神经网络中的丢失

### L1 和 L2 正规化

**L2** 是最常见的正规化类型，其次是 **L1** 。这些正则化器通过向模型的损失添加一项来获得最终的成本函数。这个增加的项导致模型权重的降低。这反过来导致了一个模型，概括得很好。

L1 正则化的成本函数如下所示:

![Figure 6.15: Cost function of L1 regularization
](image/C13322_06_15.jpg)

###### 图 6.15:L1 正则化的成本函数

这里，λ是正则化参数。L1 正则化导致权重非常接近于零。这使得具有 L1 正则化的神经元变得仅依赖于最重要的输入，而忽略有噪声的输入。

L2 正则化的成本函数如下所示:

![Figure 6.16: Cost function of L2 regularization
](image/C13322_06_16.jpg)

###### 图 6.16:L2 正则化的成本函数

L2 正则化严重惩罚高权重向量，并优先考虑分散的权重。L2 正则化也称为权重衰减，因为它迫使网络的权重向零衰减，但与 L1 正则化不同，并不完全为零。我们可以把 L1 和 L2 结合起来，一起实施。要实现这些正则项，可以在 Keras 中使用以下函数:

```
keras.regularizers.l1(0.01)
keras.regularizers.l2(0.01)
keras.regularizers.l1_l2(l1=0.01, l2=0.01)
```

### 批量归一化

在*第 1 章*、*数据科学和数据预处理简介*中，我们学习了如何执行标准化，以及它如何帮助加快我们的机器学习模型的训练。这里，我们将把同样的标准化扩展到神经网络的各个层。**批量标准化**允许各层独立于其他层进行学习。它通过将一个图层的输入标准化为具有固定的平均值和方差来实现这一点；这防止了先前层的参数变化过多地影响该层的输入。也有轻微的正则化效果；与 dropout 非常相似，它可以防止过度拟合，但它是通过将噪声引入 mini 批处理的值来实现的。使用批处理规范化时，请确保使用较低的丢失率，因为丢失率会导致信息丢失。但是，不要删除 dropout 并完全依赖于批处理规范化，因为两者的结合被认为效果更好。当使用批量标准化时，可以使用更高的学习速率，因为它确保没有动作过高或过低。

![Figure 6.17: Batch normalization equation
](image/C13322_06_17.jpg)

###### 图 6.17:批量标准化方程

这里，(xi)是图层的输入，y 是归一化输入。μ是批次平均值，σ2 是批次的标准差。批量归一化引入了两个新的(x_i ) ̂the 损失。

要在 Keras 中创建批量归一化图层，可使用以下函数:

```
keras.layers.BatchNormalization()
```

### 练习 52:使用 CIFAR-10 图像通过正则化改进图像分类

在本练习中，我们将对加拿大高级研究所(CIFAR-10)数据集执行分类。它由 10 类 60，000 幅 32 x 32 的彩色图像组成。这 10 个不同的类代表了鸟、飞机、猫、汽车、青蛙、鹿、狗、卡车、船和马。它是机器学习研究中最广泛使用的数据集之一，主要在 CNN 领域。由于图像的低分辨率，可以在这些图像上更快地训练模型。我们将使用这个数据集来实现我们在上一节中学到的一些正则化技术:

#### 注意

要获取原始 CIFAR-10 文件和 CIFAR-100 数据集，请访问https://www.cs.toronto.edu/~kriz/cifar.html。

1.  使用 Keras 库加载 CIFAR-10 数据集:

    ```
    from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization
    from keras.datasets import cifar10
    (x_train, y_train), (x_test, y_test) = cifar10.load_data()
    ```

2.  Check the dimensions of the data:

    ```
    x_train.shape
    ```

    输出如下所示:

    ![Figure 6.18: Dimensions of x
    ](image/C13322_06_18.jpg)

    ###### 图 6.18:x 的尺寸

    类似尺寸，用于`y`:

    ```
    y_train.shape
    ```

    输出如下所示:

    ![Figure 6.19: Dimensions of y
    ](image/C13322_06_19.jpg)

    ###### 图 6.19:y 的尺寸

    由于这些是彩色图像，它们有三个通道。

3.  将数据转换成 Keras 要求的格式:

    ```
    x_train = x_train.reshape(-1, 32, 32, 3)
    x_test = x_test.reshape(-1, 32, 32, 3)
    ```

4.  将目标变量转换成一个热点向量，这样我们的网络就不会在不同的目标变量之间形成不必要的连接:

    ```
    from sklearn.preprocessing import LabelBinarizer
    label_binarizer = LabelBinarizer()
    label_binarizer.fit(range(10))
    y_train = label_binarizer.transform(y_train)
    y_test = label_binarizer.transform(y_test)
    ```

5.  Create the model. Here, we make a small CNN without regularization first:

    ```
    from keras.models import Sequential
    model = Sequential()
    ```

    添加卷积层:

    ```
    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32,32,3)))    
    model.add(Conv2D(32, (3, 3), activation='relu'))
    ```

    添加池层:

    ```
    model.add(MaxPool2D(pool_size=(2, 2)))
    ```

6.  将 2D 矩阵展平成 1D 向量:

    ```
    model.add(Flatten())
    ```

7.  使用致密层作为模型的最终层，编译模型:

    ```
    model.add(Dense(512, activation='relu'))
    model.add(Dense(10, activation='softmax'))
    model.compile(loss='categorical_crossentropy', optimizer='adam', 
    metrics = [‘acc'])
    ```

8.  训练模型并检查最终精度:

    ```
    model.fit(x_train, y_train, validation_data = (x_test, y_test), 
    epochs=10, batch_size=512)
    ```

9.  Now check the accuracy of the model:

    ```
    score = model.evaluate(x_test, y_test)
    print(“Accuracy: {0:.2f}%”.format(score[1]*100))
    ```

    输出如下所示:

    ![Figure 6.20: Accuracy of model
    ](image/C13322_06_20.jpg)

    ###### 图 6.20:模型的准确性

10.  Now create the same model, but with regularization. You can experiment with other architectures as well:

    ```
    model = Sequential()
    ```

    添加卷积层:

    ```
    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32,32,3)))    
    model.add(Conv2D(32, (3, 3), activation='relu'))   
    ```

    添加池层:

    ```
    model.add(MaxPool2D(pool_size=(2, 2)))
    ```

11.  添加批量标准化图层和一个删除图层:

    ```
    model.add(BatchNormalization())
    model.add(Dropout(0.10))
    ```

12.  将 2D 矩阵展平成 1D 向量:

    ```
    model.add(Flatten())
    ```

13.  使用密集图层作为模型的最终图层，编译模型:

    ```
    model.add(Dense(512, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(10, activation='softmax'))
    model.compile(loss='categorical_crossentropy', optimizer='adam', 
    metrics = [‘acc'])
    model.summary()
    ```

    ![Figure 6.21: Architecture of the CNN with regularization
    ](image/C13322_06_21.jpg)

    ###### 图 6.21:正则化美国有线新闻网；卷积神经网络的架构

14.  Train the model and check the final accuracy:

    ```
    model.fit(x_train, y_train, validation_data = (x_test, y_test), 
    epochs=10, batch_size=512)
    score = model.evaluate(x_test, y_test)
    print(“Accuracy: {0:.2f}%”.format(score[1]*100))
    ```

    输出如下所示:

![Figure 6.22: Final accuracy output
](image/C13322_06_22.jpg)

###### 图 6.22:最终精度输出

恭喜你！您利用正则化使您的模型比以前工作得更好。如果你看不到你的模型的改进，训练它更长的时间，所以设置它更多的时代。你还会看到，你可以训练更多的时代，而不用担心过度适应。

您可以绘制不同的测试图像，并使用*练习 50* 中给出的代码查看您的网络结果。此外，画出不正确的预测，看看模型哪里出错了:

```
import numpy as np
import matplotlib.pyplot as plt
y_pred = model.predict(x_test)
incorrect_indices = np.nonzero(np.argmax(y_pred,axis=1) != np.argmax(y_test,axis=1))[0]
labels = [‘airplane', ‘automobile', ‘bird', ‘cat', ‘deer', ‘dog', ‘frog', ‘horse', ‘ship', ‘truck']
image = 3
plt.imshow(x_test[incorrect_indices[image]].reshape(32,32,3))
plt.show()
print(“Prediction: {0}”.format(labels[np.argmax(y_pred[incorrect_indices[image]])]))
```

![Figure 6.23: Incorrect prediction of the model
](image/C13322_06_23.jpg)

###### 图 6.23:模型的不正确预测

如您所见，该模型很难预测模糊的图像。真正的标签是*马*。你可以试验一下图层和超参数，看看你是否能得到更好的精度。尝试使用正则化创建更复杂的模型，并训练它们更长时间。

## 图像数据预处理

在本节中，我们将介绍一些数据科学家可以用来预处理图像的技术。首先，我们看看图像标准化，然后我们学习如何将彩色图像转换成灰度图像。最后，我们看看如何将数据集中的所有图像放到相同的维度上。需要对图像进行预处理，因为数据集不包含相同大小的图像；我们需要将它们转换成标准尺寸，以便在它们身上训练机器学习模型。一些图像预处理技术有助于减少模型的训练时间，方法是使模型的重要特征更容易识别，或者像灰度图像那样减少维度。

### 正常化

在图像的情况下，像素的比例是相同的数量级，并且在 0 到 255 的范围内。因此，这个规范化步骤是可选的，但它可能有助于加快学习过程。再次重申，将数据居中并缩放到相同的顺序有助于网络，确保梯度不会失控。神经网络共享参数(神经元)。如果输入不按相同的顺序缩放，网络将很难学习。

### 转换成灰度

根据数据集的类型和您遇到的问题，您可以将图像从 RGB 转换为灰度。这有助于网络更快地工作，因为它需要学习的参数少得多。根据问题的类型，您可能不想这样做，因为这会导致图像颜色所提供的信息丢失。要将 RGB 图像转换为灰度图像，请使用**枕头**库:

```
from PIL import Image
image = Image.open(‘rgb.png').convert(‘LA')
image.save(‘greyscale.png')
```

![Figure 6.24: Image of a car converted to grayscale
](image/C13322_06_24.jpg)

###### 图 6.24:转换为灰度的汽车图像

### 将所有图像调整到相同的尺寸

使用现实生活中的数据集时，您经常会遇到一个重大挑战，即数据集中的所有影像大小并不相同。根据具体情况，您可以执行以下步骤之一来解决问题:

*   **Upsampling**: You can upsample smaller images to fix a specific size. If the aspect ratio doesn't match the size that you have decided upon, you can crop the image. There will be some loss of information, but you can get around this by taking different centers while cropping and introducing these new images to the dataset. This will make the model more robust. To do this, utilize the following code:

    ```
    from PIL import Image
    img = Image.open(‘img.jpg')
    scale_factor = 1.5
    new_img = img.resize((int(img.size[0]* scale_factor),int(img.size[1]* scale_factor)), Image.BICUBIC)
    ```

    `resize`函数的第二个参数是算法，它将用于获取调整后图像的新像素。双三次算法速度很快，是上采样的最佳像素重采样算法之一。

![Figure 7.25: Upsampled image of a car
](image/C13322_06_25.jpg)

###### 图 6.25:汽车的上采样图像

*   **Downsampling**: Similar to upsampling, you can perform downsampling on large images to make then smaller and then crop to fit the size that you have selected. You can use the following code to downsample images:

    ```
    scale_factor = 0.5
    new_img = img.resize(
    (int(img.size[0]* scale_factor ),
     int(img.size[1]* scale_factor)),
    Image.ANTIALIAS)
    ```

    如前所述，`resize`函数的第二个参数是用于获取调整后图像的新像素的算法。抗锯齿算法有助于平滑像素化图像。它比双三次更好，但速度要慢得多。抗锯齿是用于缩减采样的最佳像素重采样算法之一。

![Figure 6.26: Down sampled image of a car
](image/C13322_06_26.jpg)

###### 图 6.26:汽车的向下采样图像

*   **裁剪**:这是另一种让所有图像尺寸相同的方法，就是裁剪它们。如前所述，您可以使用不同的中心来防止信息丢失。你可以使用下面的代码来裁剪你的图片:

    ```
    area = (1000, 500, 2500, 2000)
    cropped_img = img.crop(area)
    ```

![Figure 6.27: Cropped image of a car
](image/C13322_06_27.jpg)

###### 图 6.27:汽车的裁剪图

*   **填充**:填充在图像周围添加一层 0 或 1，以增加图像的大小。要执行填充，请使用以下代码:

    ```
    size = (2000,2000)
    back = Image.new(“RGB”, size, “white”)
    offset = (250, 250)
    back.paste(cropped_img, offset)
    ```

![Figure 6.28: Padded image of a cropped car
](image/C13322_06_28.jpg)

###### 图 6.28:裁剪汽车的填充图像

### 其他有用的图像操作

**Pillow** 库有很多修改和创建新图像的功能。这些将有助于从我们现有的训练数据中创建新的图像。

要翻转图像，我们可以使用下面的代码:

```
img.transpose(Image.FLIP_LEFT_RIGHT)
```

![Figure 6.29: Flipped image of a cropped car
](image/C13322_06_29.jpg)

###### 图 6.29:裁剪汽车的翻转图像

要将图像旋转 45 度，我们可以使用以下代码:

```
img.rotate(45)
```

![Figure 6.30: The cropped car image rotated 45 degrees
](image/C13322_06_30.jpg)

###### 图 6.30:被裁剪的汽车图像旋转了 45 度

要将图像移动 1000 个像素，我们可以使用以下代码:

```
import PIL
width, height = img.size
image = PIL.ImageChops.offset(img, 1000, 0)
image.paste((0), (0, 0, 1000, height))
```

![Figure 6.31: Rotated image of the cropped car
](image/C13322_06_31.jpg)

###### 图 6.31:裁剪汽车的旋转图像

### 活动 17:预测一张图片是猫还是狗

在本活动中，我们将尝试预测所提供的图片是一只猫还是一只狗。来自微软的猫狗数据集(https://github . com/TrainingByPackt/Data-Science-with-Python/tree/master/chapter 06)包含了 25000 张猫狗的彩色图片。让我们看看下面的场景:你在一家兽医诊所工作，有两个兽医，一个专门研究狗，一个研究猫。你想通过判断下一个客户是狗还是猫来自动预约医生。为此，您需要创建一个 CNN 模型:

1.  加载狗和猫的数据集，并对图像进行预处理。
2.  使用图像文件名来查找每个图像的猫或狗标签。第一张图片应该是这样的:![Figure 6.32: First images of the dog and cat class
    ](image/C13322_06_32.jpg)

    ###### 图 6.32:狗和猫类的第一张图片

3.  得到要训练的正确形状的图像。
4.  Create a CNN that makes use of regularization.

    #### 注意

    这项活动的解决方案可在第 369 页找到。

您应该会发现这个模型的测试集准确率为 70.4%。训练集准确率真的很高，96 左右。这意味着模型已经开始过度拟合。作为一项练习，您可以改进模型以获得尽可能高的精确度。您可以使用之前练习中的代码绘制预测不正确的图像，以了解模型的性能:

```
import matplotlib.pyplot as plt
y_pred = model.predict(x_test)
incorrect_indices = np.nonzero(np.argmax(y_pred,axis=1) != np.argmax(y_test,axis=1))[0]
labels = [‘dog', ‘cat']
image = 5
plt.imshow(x_test[incorrect_indices[image]].reshape(50,50),  cmap=plt.get_cmap(‘gray'))
plt.show()
print(“Prediction: {0}”.format(labels[np.argmax(y_pred[incorrect_indices[image]])]))
```

![Figure 6.33: Incorrect prediction of a dog by the regularized CNN model
](image/C13322_06_33.jpg)

###### 图 6.33:正则化 CNN 模型对狗的错误预测

## 数据增强

在训练机器学习模型时，我们数据科学家经常会遇到类别不平衡和缺乏训练数据的问题。这导致了在现实场景中部署时性能不佳的次等模型。处理这些问题的一个简单方法是数据扩充。有多种方法来执行数据增强，例如旋转图像、移动对象、裁剪图像、剪切图像以使图像变形以及放大图像的一部分，还有更复杂的方法，例如使用生成式对抗网络(GANs)来生成新图像。gan 只是两个相互竞争的神经网络。生成器网络试图生成与现有图像相似的图像，而鉴别器网络试图确定该图像是生成的还是原始数据的一部分。在训练完成后，生成器网络能够创建不是原始数据的一部分但非常相似的图像，以至于它们可能被误认为是由摄像机实际捕获的图像。

#### 注意

你可以在这篇文章中了解更多关于甘斯:https://arxiv.org/abs/1406.2661.

![Figure 6.34: On the left is a fake image generated by a GAN, whereas the one on the right is an image of a real person
](image/C13322_06_34.jpg)

###### 图 6.34:左边是一个由 GAN 生成的假图像，而右边是一个真人的图像

#### 注意

学分:http://www.whichfaceisreal.com

回到执行图像增强的传统方法，我们执行前面提到的操作，例如翻转图像，然后在原始图像和变换后的图像上训练我们的模型。假设我们左边有一只猫的翻转图像:

![Figure 6.35: Normal picture of the cat on the right and flipped image on the left
](image/C13322_06_35.jpg)

###### 图 6.35:右边是猫的正常图片，左边是翻转的图片

现在，在这张左侧图像上训练的机器学习模型将很难识别右侧翻转的图像是猫的图像，因为它面向另一个方向。这是因为卷积层被训练来检测只向左看的猫的图像。它创造了关于身体不同特征位置的规则。

因此，我们在所有增强图像上训练我们的模型。数据扩充是从 CNN 模型中获得最佳结果的关键。我们利用 Keras 中的`ImageDataGenerator`类来轻松地执行图像放大。在下一节中，您将了解到关于生成器的更多信息。

## 发电机

在前一章中，我们讨论了由于 RAM 的限制，大数据集如何导致训练中的问题。当处理图像时，这个问题更严重。Keras 已经实现了生成器，可以帮助我们在进行训练时获得成批的输入图像及其相应的标签。这些生成器还可以帮助我们在使用图像进行训练之前对其进行数据扩充。首先，我们将看到如何利用`ImageDataGenerator`类为我们的模型生成增强图像。

为了实现数据扩充，我们只需要稍微修改一下我们的*练习 3* 代码。我们将用以下内容替换`model.fit()`:

```
BATCH_SIZE = 32
aug = ImageDataGenerator(rotation_range=20, 
width_shift_range=0.2, height_shift_range=0.2, 
shear_range=0.15, zoom_range=0.15,
horizontal_flip=True, vertical_flip=True, 
fill_mode=”nearest”)

log = model.fit_generator(
aug.flow(x_train, y_train, batch_size= BATCH_SIZE),
validation_data=( x_test, y_test), steps_per_epoch=len(x_train) // BATCH_SIZE, epochs=10)
```

现在让我们看看`ImageDataGenerator`实际上在做什么:

*   `rotation_range`:该参数定义了图像可以旋转的最大角度。这种旋转是随机的，可以是小于所述数量的任何值。这确保了没有两个图像是相同的。
*   `width_shift_range` / `height_shift_range`:该值定义了图像可以移动的量。如果该值小于 1，则假定该值是总宽度的一部分。如果大于 1，则取为像素。范围将在区间(`-shift_range`、`+ shift_range`)内。
*   `shear_range`:这是以度为单位的剪切角度(逆时针方向)。
*   `zoom_range`:此处的值可以是[ `lower_range`、`upper_range`，也可以是浮点数，在这种情况下，取值范围为[ `1-zoom_range`、`1+zoom_range` ]。这是随机缩放的范围。
*   `horizontal_flip` / `vertical_flip`:这里的 true 值使生成器随机水平或垂直翻转图像。
*   `fill_mode`: This helps us decide what to put in the whitespaces created by the rotation and searing process.

    `constant`:用常量值填充空白，常量值必须使用`cval`参数定义。

    `nearest`:用最近的像素填充空白。

    这造成了一种反射效果，很像一面镜子。

    `wrap`:这使得图像换行并填充空白。

生成器在遇到的所有图像上随机应用前面的操作。这确保了模型不会两次看到相同的图像，并减轻了过度拟合。当使用生成器时，我们必须使用`fit_generator()`函数而不是`fit()`函数。我们根据用于训练的空闲 RAM 的数量，向生成器传递一个合适的批处理大小。

默认的 Keras 生成器有一点内存开销；要消除这种情况，您可以创建自己的生成器。为此，您必须确保实现生成器的这四个部分:

1.  读取输入图像(或任何其他数据)。
2.  阅读或生成标签。
3.  Preprocess or augment the image.

    #### 注意

    确保随机放大图像。

4.  以 Keras 期望的形式生成输出。

下面是帮助您创建自己的生成器的示例代码:

```
def custom_image_generator(images, labels, batch_size = 128):    
    while True:
          # Randomly select images for the batch           batch_images = np.random.choice(images, 
                                     size = batch_size)          batch_input = []          batch_output = []           
          # Read image, perform preprocessing and get labels
          for image in batch_images:
               # Function that reads and returns the image
              input = get_input(image)
              # Function that gets the label of the image
                output = get_output(image,labels =labels)
              # Function that pre-processes and augments the image
                input = preprocess_image(input)
              batch_input += [input]              batch_output += [output]

          batch_x = np.array( batch_input )          batch_y = np.array( batch_output )          
            # Return a tuple of (images,labels) to feed the network           yield(batch_x, batch_y)
```

实施`get_input`、`get_output`和`preprocess_image`作为练习。

### 练习 53:使用图像增强对 CIFAR-10 图像进行分类

在本练习中，我们将对 CIFAR-10(加拿大高级研究所)数据集执行分类，类似于*练习 52* 。这里，我们将利用生成器来扩充训练数据。我们将随机旋转、移动和翻转图像:

1.  使用 Keras 库加载 CIFAR-10 数据集:

    ```
    from keras.datasets import cifar10
    (x_train, y_train), (x_test, y_test) = cifar10.load_data()
    ```

2.  将数据转换成 Keras 要求的格式:

    ```
    x_train = x_train.reshape(-1, 32, 32, 3)
    x_test = x_test.reshape(-1, 32, 32, 3)
    ```

3.  将目标变量转换成一个热点向量，这样我们的网络就不会在不同的目标变量之间形成不必要的连接:

    ```
    from sklearn.preprocessing import LabelBinarizer
    label_binarizer = LabelBinarizer()
    label_binarizer.fit(range(10))
    y_train = label_binarizer.transform(y_train)
    y_test = label_binarizer.transform(y_test)
    ```

4.  Create the model. We will use the network from *Exercise 3*:

    ```
    from keras.models import Sequential
    model = Sequential()
    ```

    添加卷积层:

    ```
    from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, BatchNormalization
    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32,32,3)))
    model.add(Conv2D(32, (3, 3), activation='relu'))
    ```

    添加池层:

    ```
    model.add(MaxPool2D(pool_size=(2, 2)))
    ```

    添加批处理规范化图层以及丢弃图层:

    ```
    model.add(BatchNormalization())
    model.add(Dropout(0.10))
    ```

5.  将 2D 矩阵展平成 1D 向量:

    ```
    model.add(Flatten())
    ```

6.  使用密集层作为模型的最终层:

    ```
    model.add(Dense(512, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(10, activation='softmax'))
    ```

7.  使用以下代码编译模型:

    ```
    model.compile(loss='categorical_crossentropy', optimizer='adam', 
    metrics = [‘acc'])
    ```

8.  创建数据生成器，并向其传递所需的数据增量:

    ```
    from keras.preprocessing.image import ImageDataGenerator
    datagen = ImageDataGenerator(
        rotation_range=45,
        width_shift_range=0.2,  
        height_shift_range=0.2,  
        horizontal_flip=True)
    ```

9.  训练模型:

    ```
    BATCH_SIZE = 128
    model_details = model.flow(datagen.flow(x_train, y_train, batch_size = BATCH_SIZE),
                        steps_per_epoch = len(x_train) // BATCH_SIZE, 
                        epochs = 10, 
                        validation_data= (x_test, y_test),
                        verbose=1)
    ```

10.  Check the final accuracy of the model:

    ```
    score = model.evaluate(x_test, y_test)
    print(“Accuracy: {0:.2f}%”.format(score[1]*100))
    ```

    输出如下所示:

![](image/C13322_06_36.jpg)

###### 图 6.36:模型精度输出

恭喜你！您已经利用数据扩充使您的模型能够识别更大范围的图像。你一定注意到你的模型的准确性下降了。这是因为我们训练模型的时期数量很少。我们使用数据增强的模型需要针对更多的时期进行训练。你还会看到，你可以训练更多的时代，而不用担心过度适应。这是因为每个历元，模型都会从数据集中看到一幅新图像。图像很少重复，如果有的话。如果你运行这个模型更多的时期，你肯定会看到改进。尝试更多架构和扩展。

这里你可以看到一个错误分类的图像。通过检查错误识别的图像，您可以衡量模型的性能，并找出它在哪里表现不佳。

```
y_pred = model.predict(x_test)
incorrect_indices = np.nonzero(np.argmax(y_pred,axis=1) != np.argmax(y_test,axis=1))[0]
labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
image = 2
plt.imshow(x_test[incorrect_indices[image]].reshape(32,32,3))
plt.show()
print("Prediction: {0}".format(labels[np.argmax(y_pred[incorrect_indices[image]])]))
```

请参见下面的截图来检查不正确的预测:

![Figure 6.37: Incorrect prediction from the CNN model that was trained on augmented data
](image/C13322_06_37.jpg)

###### 图 6.37:根据扩充数据训练的 CNN 模型的不正确预测

### 活动 18:识别和增强图像

在本活动中，我们将尝试预测一张图片是猫还是狗，就像在*活动 17* 中一样。然而，这一次我们将利用生成器来处理图像并对它们执行数据扩充，以获得更好的结果:

1.  创建函数来获取每个图像和每个图像标签。然后，创建一个函数来预处理加载的图像并扩充它们。最后，创建一个数据生成器(如**生成器**一节所示),利用上述函数在训练期间向 Keras 提供数据。
2.  加载将不被扩充的测试数据集。使用*活动 17 中的功能。*
3.  Create a CNN that will identify if the image provided is of a cat or a dog. Make sure to make use of regularization.

    #### 注意

    这项活动的解决方案可在第 373 页找到。

您应该会发现，该模型的测试集准确率约为 72%,比*活动 17* 中的模型有所改进。你会观察到训练准确率真的很高，在 98%左右。这意味着这个模型已经开始过度拟合，很像*活动 17* 中的那个。这可能是由于缺乏数据扩充。尝试更改数据扩充参数，以查看准确性是否有任何变化。或者，您可以修改神经网络的体系结构以获得更好的结果。您可以绘制预测不正确的图像，以了解模型的表现。

```
import matplotlib.pyplot as plt
y_pred = model.predict(validation_data[0])
incorrect_indices = np.nonzero(np.argmax(y_pred,axis=1) != np.argmax(validation_data[1],axis=1))[0]
labels = ['dog', 'cat']
image = 7
plt.imshow(validation_data[0][incorrect_indices[image]].reshape(50,50), cmap=plt.get_cmap('gray'))
plt.show()
print("Prediction: {0}".format(labels[np.argmax(y_pred[incorrect_indices[image]])]))
```

下面的屏幕截图显示了一个示例:

![Figure 6.38: Incorrect prediction of a cat by the data augmentation CNN model 
](image/C13322_06_38.jpg)

###### 图 6.38:数据扩充 CNN 模型对猫的错误预测

## 总结

在本章中，我们学习了什么是数字图像，以及如何用它们创建机器学习模型。然后，我们介绍了如何使用 Keras 库来训练图像的神经网络模型。我们还讨论了什么是正则化，如何将其用于神经网络，什么是图像增强，以及如何使用它是我们的重点。我们讨论了什么是 CNN 以及如何实现它们。最后，我们讨论了各种图像预处理技术。

现在您已经完成了本章，您将能够处理任何类型的数据来创建机器学习模型。在下一章，我们将学习如何处理人类语言。