

# 四、Streamlit 和机器学习

数据科学家发现自己处于一种非常常见的情况，即在模型创建过程的最后，不知道如何确切地说服非数据科学家他们的模型是有价值的。他们可能有来自他们的模型或者一些静态可视化的性能度量，但是没有简单的方法允许其他人与他们的模型交互。

在 Streamlit 之前，有几个其他的选择，最受欢迎的是在 Flask 或 Django 中创建一个成熟的应用，或者将他们的模型变成一个**应用编程接口** ( **API** )，并将开发人员引向它。这些都是很好的选择，但对于有价值的用例(如原型应用)来说，往往很耗时，而且不是最佳选择。

这里对团队的激励有点错位。一个数据科学家想要为他们的团队创建最好的模型，但是如果他们需要一两天(或者，如果他们有经验，几个小时)的工作来将他们的模型变成 Flask 或 Django 应用，那么在他们认为他们几乎完成建模过程之前，构建这个模型没有多大意义。Streamlit 的好处在于，它帮助我们将这一艰巨的过程转变为一种无摩擦的应用创建体验。在这一章中，我们将讨论如何在 Streamlit 中创建**机器学习** ( **ML** )原型，如何为你的 ML 应用添加用户交互，以及如何理解 ML 结果。

具体来说，本章涵盖以下主题:

*   标准 ML 工作流程
*   预测企鹅种类
*   在 Streamlit 中利用预先训练的 ML 模型
*   细流应用内的培训模型
*   了解 ML 结果

# 标准 ML 工作流程

创建使用 ML 的应用的第一步是 ML 模型本身。有几十个流行的工作流程来创建你自己的 ML 模型。很可能你已经有自己的了！这个过程有两个部分需要考虑:

*   最大似然模型的产生
*   ML 模型在生产中的应用

如果计划训练一次模型，然后在我们的 Streamlit 应用中使用该模型，最好的方法是首先在 Streamlit 外部(例如，在 Jupyter 笔记本或标准 Python 文件中)创建该模型，然后在应用中使用该模型。

如果计划使用用户输入在我们的应用中训练模型，那么我们不能再在 Streamlit 之外创建模型，而是需要在 Streamlit 应用中运行模型训练。

我们将从在 Streamlit 之外构建 ML 模型开始，然后继续在 Streamlit 应用内训练我们的模型。

# 预测企鹅种类

我们在本章中主要使用的数据集与我们在 [*第 1 章*](B16864_01_Final_VK_ePub.xhtml#_idTextAnchor014) 、*Streamlit 简介*中使用的帕尔默企鹅数据集相同。像往常一样，我们将创建一个新文件夹来存放我们新的 Streamlit 应用和附带的代码。下面的代码在我们的`streamlit_apps`文件夹中创建这个新文件夹，并从我们的`penguin_app`文件夹中复制数据。如果您还没有下载帕尔默企鹅数据，请按照 [*第二章*](B16864_02_Final_VK_ePub.xhtml#_idTextAnchor024) 、*上传、下载和操作数据*中*设置:帕尔默企鹅*部分的说明进行操作:

```py
mkdir penguin_ml
cp penguin_app/penguins.csv penguin_ml 
cd penguin_ml 
touch penguins_ml.py
touch penguins_streamlit.py
```

正如您在前面的代码中可能已经注意到的，这里有两个 Python 文件，一个用于创建 ML 模型(`penguins_ml.py`)，另一个用于创建 Streamlit 应用(`penguins_streamlit.py`)。我们将从`penguins_ml.py`文件开始，一旦我们有了满意的模型，我们将转移到`penguins_streamlit.py`文件。

注意

您也可以选择在 Jupyter 笔记本中创建模型，这种设计的可重复性较差(因为单元格可能会乱序运行)，但仍然非常受欢迎。

让我们让重新熟悉一下`penguins.csv`数据集。以下代码将读取数据集并打印出前五行:

```py
import pandas as pd 
penguin_df = pd.read_csv('penguins.csv')
print(penguin_df.head())
```

当我们在终端中运行我们的 Python 文件`penguins_ml.py`时，前面代码的输出将类似于下面的屏幕截图:

![Figure 4.1 – First five penguins
](img/B16864_04_01.jpg)

图 4.1-前五只企鹅

对于这个应用，我们将尝试创建一个应用，帮助野外的研究人员了解他们正在观察的企鹅种类。它将预测企鹅的种类，给定一些嘴、鳍和身体质量的测量，以及关于企鹅的性别和位置的知识。

下一部分并不是试图创造最好的 ML 模型，而只是为我们的 Streamlit 应用创建一个快速原型，我们可以迭代它。因此，在这种情况下，我们将删除具有空值的几行，并且不在我们的特性中使用`year`变量，因为它不适合我们的用例。我们将需要定义我们的特性和输出变量，并对我们的特性进行一次性编码(或者像 pandas 所说的那样，为我们的文本列创建虚拟变量)，并分解我们的输出变量(将其从字符串转换为数字)。下面的代码应该可以让我们的数据集更好地运行分类算法:

```py
import pandas as pd 
penguin_df = pd.read_csv('penguins.csv')
 penguin_df.dropna(inplace=True)
 output = penguin_df['species']
 features = penguin_df[['island', 'bill_length_mm', 'bill_depth_mm',
       'flipper_length_mm', 'body_mass_g', 'sex']]
 features = pd.get_dummies(features)
 print('Here are our output variables')
 print(output.head())
print('Here are our feature variables')
print(features.head())
```

现在，当我们再次运行我们的 Python 文件`penguins_ml.py`时，我们看到输出和特征变量被分开，如下面的屏幕截图所示:

![Figure 4.2 – Output variables
](img/B16864_04_02.jpg)

图 4.2-输出变量

现在，我们想使用我们数据的一个子集(在本例中为 80%)创建一个分类模型，并获得该模型的准确性。下面的代码使用一个随机森林模型运行这些步骤，但是如果您愿意，您可以使用其他分类算法。同样，这里的点是获得一个快速原型，展示给企鹅研究人员以获得反馈！

```py
import pandas as pd
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
penguin_df = pd.read_csv('penguins.csv')
penguin_df.dropna(inplace=True)
output = penguin_df['species']
features = penguin_df[['island', 'bill_length_mm', 'bill_depth_mm',
                       'flipper_length_mm', 'body_mass_g', 'sex']]
features = pd.get_dummies(features)
output, uniques = pd.factorize(output)
x_train, x_test, y_train, y_test = train_test_split(
    features, output, test_size=.8)
rfc = RandomForestClassifier(random_state=15)
rfc.fit(x_train, y_train)
y_pred = rfc.predict(x_test)
score = accuracy_score(y_pred, y_test)
print('Our accuracy score for this model is {}'.format(score))
```

我们现在有了一个很好的模型来预测企鹅的种类！我们在模型生成过程中的最后一步是保存这个模型中我们最需要的两个部分——模型本身和`uniques`变量，它将因式分解的输出变量映射到我们识别的物种名称。在前面的代码中，我们将添加几行代码，将这些对象保存为 pickle 文件(这些文件将一个 Python 对象转换为我们可以直接保存并从另一个 Python 文件(如我们的 Streamlit 应用)中轻松导入的对象)。更具体地说，`open()`函数创建两个 pickle 文件，`pickle.dump()`函数将我们的 Python 文件写入所述文件，`close()`函数关闭这些文件。`open()`函数中的`wb`代表*写入字节*，它告诉 Python 我们想要写入而不是读取这个文件:

```py
import pandas as pd
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import pickle
penguin_df = pd.read_csv('penguins.csv')
penguin_df.dropna(inplace=True)
output = penguin_df['species']
features = penguin_df[['island', 'bill_length_mm', 'bill_depth_mm',
                       'flipper_length_mm', 'body_mass_g', 'sex']]
features = pd.get_dummies(features)
output, uniques = pd.factorize(output)
x_train, x_test, y_train, y_test = train_test_split(
    features, output, test_size=.8)
rfc = RandomForestClassifier(random_state=15)
rfc.fit(x_train, y_train)
y_pred = rfc.predict(x_test)
score = accuracy_score(y_pred, y_test)
print('Our accuracy score for this model is {}'.format(score))
rf_pickle = open('random_forest_penguin.pickle', 'wb')
pickle.dump(rfc, rf_pickle)
rf_pickle.close()
output_pickle = open('output_penguin.pickle', 'wb')
pickle.dump(uniques, output_pickle)
output_pickle.close() 
```

在我们的`penguin_ml`文件夹中，我们现在又有了两个文件，一个名为`random_forest_penguin.pickle`的文件包含了我们的模型，另一个名为`output_penguin_.pickle`，它包含了企鹅种类和我们的模型输出之间的映射。这是它的`penguins_ml.py`功能！我们可以继续使用我们的 Streamlit 应用。

# 利用 Streamlit 中预先训练的 ML 模型

既然我们已经有了模型，我们希望将它(以及我们的映射函数)加载到 Streamlit 中。在我们之前创建的文件`penguins_streamlit.py`中，我们将使用下面的代码再次使用`pickle`库来加载我们的文件。我们使用与之前相同的函数，但是我们使用参数`rb`代替`wb`，它代表*读取字节*。为了确保这些是我们之前使用的相同的 Python 对象，我们将使用我们已经非常熟悉的`st.write()`函数来检查:

```py
import streamlit as st
import pickle
rf_pickle = open('random_forest_penguin.pickle', 'rb')
map_pickle = open('output_penguin.pickle', 'rb')
rfc = pickle.load(rf_pickle)
unique_penguin_mapping = pickle.load(map_pickle)
st.write(rfc)
st.write(unique_penguin_mapping)
```

与我们之前的【Streamlit 应用一样，我们在终端中运行下面的代码来运行我们的应用:

```py
streamlit run penguins_streamlit.py
```

我们现在有了随机森林分类器，以及企鹅地图！我们的下一步是添加 Streamlit 函数来获取用户输入。在我们的应用中，我们使用岛屿、喙长、喙深、鳍长、体重和性别来预测企鹅种类，因此我们需要从用户那里获得这些信息。对于 island 和 sex，我们知道哪些选项已经在我们的数据集中，并且希望避免解析用户文本，所以我们将使用`selectbox`。对于其他数据，我们只需要确保用户输入了一个正数，所以我们将使用`st.number_input()`函数，并使最小值为`0`。以下代码接收这些输入，并在我们的 Streamlit 应用上打印出来:

```py
import streamlit as st
import pickle
rf_pickle = open('random_forest_penguin.pickle', 'rb')
map_pickle = open('output_penguin.pickle', 'rb')
rfc = pickle.load(rf_pickle)
unique_penguin_mapping = pickle.load(map_pickle)
rf_pickle.close()
map_pickle.close()
island = st.selectbox('Penguin Island', options=[
                      'Biscoe', 'Dream', 'Torgerson'])
sex = st.selectbox('Sex', options=['Female', 'Male'])
bill_length = st.number_input('Bill Length (mm)', min_value=0)
bill_depth = st.number_input('Bill Depth (mm)', min_value=0)
flipper_length = st.number_input('Flipper Length (mm)', min_value=0)
body_mass = st.number_input('Body Mass (g)', min_value=0)
st.write('the user inputs are {}'.format(
    [island, sex, bill_length,
         bill_depth, flipper_length, body_mass]))
```

前面的代码应该会生成下面的 app。尝试一下，看看它是否能通过改变值来工作，看看输出是否也会改变。默认情况下，Streamlit 的设计使得每次更改值时，整个应用都会重新运行。下面的截图显示了应用的生活，我已经改变了一些价值。我们既可以用右手边的( **+** 和 **-** )按钮改变数值，也可以手动输入数值:

![Figure 4.3 – Model inputs
](img/B16864_04_03.jpg)

图 4.3–模型输入

现在我们有了所有的我们的投入，我们也有了我们的模型。下一步是将数据格式化为与预处理数据相同的格式，例如，我们的模型没有一个名为`sex`的变量，而是有两个名为`sex_female`和`sex_male`的变量。一旦我们的数据处于正确的状态，我们就可以调用`predict`函数，并将预测映射到我们的原始物种列表，以查看我们的模型如何运行。下面的代码正是这样做的，并且还向应用添加了一些基本的标题和说明，以使其更加可用。这个应用相当长，所以为了可读性，我将把它分成多个部分，首先为我们的应用添加说明和标题:

```py
import streamlit as st
import pickle
st.title('Penguin Classifier')
st.write("This app uses 6 inputs to predict the species of penguin using"
         "a model built on the Palmer's Penguin's dataset. Use the form below"
         " to get started!")
rf_pickle = open('random_forest_penguin.pickle', 'rb')
map_pickle = open('output_penguin.pickle', 'rb')
rfc = pickle.load(rf_pickle)
unique_penguin_mapping = pickle.load(map_pickle)
rf_pickle.close()
map_pickle.close()
```

我们现在有一个应用，上面有我们的标题和给用户的说明。下一步是像以前一样获取用户输入。我们还需要将我们的`sex`和`island`变量放入正确的格式中，如前所述:

```py
island = st.selectbox('Penguin Island', options=[
                      'Biscoe', 'Dream', 'Torgerson'])
sex = st.selectbox('Sex', options=['Female', 'Male'])
bill_length = st.number_input('Bill Length (mm)', min_value=0)
bill_depth = st.number_input('Bill Depth (mm)', min_value=0)
flipper_length = st.number_input('Flipper Length (mm)', min_value=0)
body_mass = st.number_input('Body Mass (g)', min_value=0)
island_biscoe, island_dream, island_torgerson = 0, 0, 0
if island == 'Biscoe':
    island_biscoe = 1
elif island == 'Dream':
    island_dream = 1
elif island == 'Torgerson':
    island_torgerson = 1
sex_female, sex_male = 0, 0
if sex == 'Female':
    sex_female = 1
elif sex == 'Male':
    sex_male = 1
```

我们所有的数据都是正确的格式！这里的最后一步是用我们的新数据在我们的模型上使用`predict()`函数，这是最后一节要处理的:

```py
new_prediction = rfc.predict([[bill_length, bill_depth, flipper_length,
                               body_mass, island_biscoe, island_dream,
                               island_torgerson, sex_female, sex_male]])
prediction_species = unique_penguin_mapping[new_prediction][0]
st.write('We predict your penguin is of the {} species'.format(prediction_species))
```

现在我们的应用应该看起来像下面的截图。我已经在输入中添加了一些示例值，但是你应该试着改变数据，看看你是否能改变物种！

![Figure 4.4 – Full Streamlit prediction
](img/B16864_04_04.jpg)

图 4.4-全流线预测

我们现在有一个完整的 Streamlit 应用，它利用我们预先训练的 ML 模型，接受用户输入，并输出预测。接下来，我们将讨论如何在 Streamlit 应用中直接训练模型！

# 【Streamlit 应用中的培训模型

通常，我们可能想要让用户输入改变我们的模型被训练的方式。我们可能想要接受来自用户的数据，或者询问用户他们想要使用什么功能，或者甚至允许用户挑选他们想要使用的机器学习算法的类型。所有这些选项在 Streamlit 中都是可行的，在本节中，我们将介绍使用用户输入来影响培训过程的基础知识。正如我们在上一节中所讨论的，如果一个模型只被训练一次，那么最好是在 Streamlit 之外训练模型，然后将模型导入到 Streamlit 中。但是，如果在我们的例子中，企鹅研究人员将数据存储在本地，或者不知道如何重新训练模型，但已经有了正确格式的数据，会怎么样呢？在这种情况下，我们可以添加`st.file_uploader()`选项，并为这些用户提供一个方法来输入他们自己的数据，并为他们部署一个定制模型，而无需编写任何代码。下面的代码将添加一个用户选项来接受数据，并将使用我们最初在`penguins_ml.py`中拥有的预处理/训练代码来为这个用户创建一个独特的模型。这里需要注意的是，只有当用户拥有与我们使用的格式和样式完全相同的数据时，这种方法才有效，这种情况不太可能发生。另一个潜在的附加功能是向用户显示该应用正确训练模型所需的数据格式。

```py
import streamlit as st
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import pickle
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
st.title('Penguin Classifier')
st.write("This app uses 6 inputs to predict the species of penguin using "
         "a model built on the Palmer's Penguin's dataset. Use the form below"
         " to get started!")
penguin_file = st.file_uploader('Upload your own penguin data')
```

第一个部分导入了我们需要的库，添加了标题——就像我们之前使用的一样，并添加了`file_uploader()`函数。然而，当用户还没有上传文件时，会发生什么呢？如果没有 penguin 文件，我们可以设置缺省值来加载我们的随机森林模型，如下一段代码所示:

```py
if penguin_file is None:
    rf_pickle = open('random_forest_penguin.pickle', 'rb')
    map_pickle = open('output_penguin.pickle', 'rb')
    rfc = pickle.load(rf_pickle)
    unique_penguin_mapping = pickle.load(map_pickle)
    rf_pickle.close()
    map_pickle.close()
```

我们需要解决的下一个问题是如何获取用户的数据，清洗这些数据，并基于这些数据训练一个模型。幸运的是，我们可以重用已经创建的模型训练代码，并将其放在下一个代码块的`else`语句中:

```py
else:
    penguin_df = pd.read_csv(penguin_file)
    penguin_df = penguin_df.dropna()
    output = penguin_df['species']
    features = penguin_df[['island', 'bill_length_mm', 'bill_depth_mm',
                           'flipper_length_mm', 'body_mass_g', 'sex']]
    features = pd.get_dummies(features)
    output, unique_penguin_mapping = pd.factorize(output)
    x_train, x_test, y_train, y_test = train_test_split(
        features, output, test_size=.8)
    rfc = RandomForestClassifier(random_state=15)
    rfc.fit(x_train, y_train)
    y_pred = rfc.predict(x_test)
    score = round(accuracy_score(y_pred, y_test), 2)
    st.write('We trained a Random Forest model on these data,'
             ' it has a score of {}! Use the '
             'inputs below to try out the model.'.format(score))
```

我们现在已经在应用中创建了我们的模型，需要从用户那里获得我们的预测输入。然而，这一次，我们可以在以前的基础上有所改进。截至目前，每次用户在我们的应用中更改输入，整个 Streamlit 应用都会重新运行。我们可以使用`st.form()`和`st.submit_form_button()`函数来包装其余的用户输入，并允许用户更改所有的输入，然后一次性提交整个表单，而不是多次提交:

```py
with st.form('user_inputs'):
island = st.selectbox('Penguin Island', options=[
                      'Biscoe', 'Dream', 'Torgerson'])
sex = st.selectbox('Sex', options=['Female', 'Male'])
bill_length = st.number_input('Bill Length (mm)', min_value=0)
bill_depth = st.number_input('Bill Depth (mm)', min_value=0)
flipper_length = st.number_input('Flipper Length (mm)', min_value=0)
body_mass = st.number_input('Body Mass (g)', min_value=0)
st.form_submit_button()
island_biscoe, island_dream, island_torgerson = 0, 0, 0
if island == 'Biscoe':
    island_biscoe = 1
elif island == 'Dream':
    island_dream = 1
elif island == 'Torgerson':
    island_torgerson = 1
sex_female, sex_male = 0, 0
if sex == 'Female':
    sex_female = 1
elif sex == 'Male':
    sex_male = 1
```

现在我们有了新表单的输入，我们需要创建我们的预测并将预测写给用户，如下一个块中的所示:

```py
new_prediction = rfc.predict([[bill_length, bill_depth, flipper_length,
                               body_mass, island_biscoe, island_dream,
                               island_torgerson, sex_female, sex_male]])
prediction_species = unique_penguin_mapping[new_prediction][0]
st.write('We predict your penguin is of the {} species'.format(prediction_species))
```

我们走吧！我们现在有一个 Streamlit 应用，允许用户输入自己的数据，并根据他们的数据训练一个模型，然后输出结果，如下一个截图所示:

![Figure 4.5 – Penguin classifier predictions
](img/B16864_04_05.jpg)

图 4.5–企鹅分类器预测

这里有潜在的改进，例如，通过使用缓存功能(在第二章 、*上传、下载和操作数据*中探讨)。像这种用户自带数据的应用很难构建，尤其是在没有通用数据格式的情况下。在撰写本文时，更常见的是看到展示令人印象深刻的 ML 模型和用例的 Streamlit 应用，而不是直接在应用中构建它们的应用(尤其是计算成本更高的模型训练)。正如我们之前提到的，Streamlit 开发人员通常会在要求用户以数据集的形式输入之前提供对所需数据格式的引用。然而，这种允许用户自带数据的选择是可行的，特别是允许快速迭代建模。

# 了解 ML 结果

到目前为止，我们的应用可能是有用的，但对于一个数据应用来说，仅仅显示结果往往不够好。我们还应该对他们为什么会得到这样的结果给出一些解释！为了做到这一点，我们可以在应用的输出中包含我们已经制作的部分，以帮助用户更好地理解模型。

首先，随机森林模型已经有一个内置的特征重要性方法，该方法是从组成随机森林的一组独立决策树中派生出来的。我们可以编辑我们的`penguins_ml.py`文件来绘制这个重要性，然后从我们的 Streamlit 应用中调用这个图像。我们也可以在我们的 Streamlit 应用中直接绘制这个图表，但是在`penguins_ml.py`中绘制一次这个图表比每次我们的 Streamlit 应用重新加载时(每次用户更改用户输入时)绘制更有效！).下面的代码编辑我们的`penguins_ml.py`文件，并添加特性重要性图，将其保存到我们的文件夹中。我们还调用了`tight_layout()`特性，它有助于更好地格式化我们的图表，并确保我们避免任何标签被剪掉。这组代码很长，文件的上半部分保持不变，所以只省略了关于库导入和数据清理的部分:

```py
x_train, x_test, y_train, y_test = train_test_split(
    features, output, test_size=.8)
rfc = RandomForestClassifier(random_state=15)
rfc.fit(x_train, y_train)
y_pred = rfc.predict(x_test)
score = accuracy_score(y_pred, y_test)
print('Our accuracy score for this model is {}'.format(score))
rf_pickle = open('random_forest_penguin.pickle', 'wb')
pickle.dump(rfc, rf_pickle)
rf_pickle.close()
output_pickle = open('output_penguin.pickle', 'wb')
pickle.dump(uniques, output_pickle)
output_pickle.close()
fig, ax = plt.subplots()
ax = sns.barplot(rfc.feature_importances_, features.columns)
plt.title('Which features are the most important for species prediction?')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.tight_layout()
fig.savefig('feature_importance.png')
```

现在，当我们重新运行`pengiuns_ml.py`时，我们应该会看到一个名为`feature_importance.png`的文件，我们可以从我们的 Streamlit 应用中调用它。让我们现在就做吧！我们可以使用`st.image()`功能让从我们的`png`加载一张图片，并打印到我们的企鹅应用上。以下代码将我们的图像添加到 Streamlit 应用中，并围绕我们所做的预测改进了我们的解释。由于这个代码块的长度，我们将只显示从我们开始使用用户数据进行预测的地方开始的新代码:

```py
new_prediction = rfc.predict([[bill_length, bill_depth, flipper_length,
                               body_mass, island_biscoe, island_dream,
                               island_torgerson, sex_female, sex_male]])
prediction_species = unique_penguin_mapping[new_prediction][0]
st.subheader("Predicting Your Penguin's Species:")
st.write('We predict your penguin is of the {} species'
         .format(prediction_species))
st.write('We used a machine learning (Random Forest) model to '
         'predict the species, the features used in this prediction '
         ' are ranked by relative importance below.')
st.image('feature_importance.png')
```

现在，您的 Streamlit 应用的底部应该看起来像下面的截图(注意:根据您的输入，您的字符串可能会略有不同)。

![Figure 4.6 – Feature importance screenshot
](img/B16864_04_06.jpg)

图 4.6–功能重要性截图

正如我们所见，根据我们的随机森林模型，喙长、喙深和鳍长是最重要的变量。解释我们的模型如何工作的最后一个选项是按物种绘制这些变量的分布，并绘制一些代表用户输入的垂直线。理想情况下，用户可以开始全面理解基础数据，因此也会理解来自模型的预测。为此，我们需要将数据导入到我们的 Streamlit 应用中，这是我们以前没有做过的。下面的代码导入了我们用来构建模型的企鹅数据，并绘制了三个直方图(分别代表*喙长*、*喙深*和*鳍长*)以及用户输入的垂直线，从模型解释部分开始:

```py
st.subheader("Predicting Your Penguin's Species:")
st.write('We predict your penguin is of the {} species'
         .format(prediction_species))
st.write('We used a machine learning (Random Forest) model to '
         'predict the species, the features used in this prediction '
         ' are ranked by relative importance below.')
st.image('feature_importance.png')
st.write('Below are the histograms for each continuous variable '
         'separated by penguin species. The vertical line '
         'represents your the inputted value.')
```

既然我们已经为直方图设置了应用，我们可以使用 Seaborn 可视化库中的`displot()`函数为我们最重要的变量创建三个直方图:

```py
fig, ax = plt.subplots()
ax = sns.displot(x=penguin_df['bill_length_mm'],
                 hue=penguin_df['species'])
plt.axvline(bill_length)
plt.title('Bill Length by Species')
st.pyplot(ax)
fig, ax = plt.subplots()
ax = sns.displot(x=penguin_df['bill_depth_mm'],
                 hue=penguin_df['species'])
plt.axvline(bill_depth)
plt.title('Bill Depth by Species')
st.pyplot(ax)
fig, ax = plt.subplots()
ax = sns.displot(x=penguin_df['flipper_length_mm'],
                 hue=penguin_df['species'])
plt.axvline(flipper_length)
plt.title('Flipper Length by Species')
st.pyplot(ax)
```

前面的代码应该创建下图所示的应用，这是我们的应用的最终形式。为了便于查看，我们将只显示第一个直方图:

![Figure 4.6 – Bill Length by Species
](img/B16864_04_07.jpg)

图 4.6–按物种划分的喙长

与往常一样，完整的最终代码可以在[https://github . com/tylerjrichards/Getting-Started-with-Streamlit-for-Data-Science](https://github.com/tylerjrichards/Getting-Started-with-Streamlit-for-Data-Science)找到。本节到此结束。我们现在已经创建了一个完全成型的 Streamlit 应用，它采用预先构建的模型和用户输入，并输出预测结果和对输出的解释。

# 总结

在这一章中，我们学习了一些 ML 基础知识:如何在 Streamlit 中使用预先构建的 ML 模型，如何在 Streamlit 中创建我们自己的模型，以及如何使用用户输入来理解和迭代 ML 模型。希望在这一章结束时，你能对每一个都感到满意。接下来，我们将使用 Streamlit 共享深入部署 Streamlit！