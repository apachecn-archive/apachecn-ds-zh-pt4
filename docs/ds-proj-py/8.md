

# 八、附录

# 1。数据探索和清理

## 活动 1.01:探索数据集中剩余的金融特征

**解决方案:**

在开始之前，按如下方式设置您的环境并加载到已清理的数据集中:

```
import pandas as pd
import matplotlib.pyplot as plt #import plotting package
#render plotting automatically
%matplotlib inline
import matplotlib as mpl #additional plotting functionality
mpl.rcParams['figure.dpi'] = 400 #high resolution figures
mpl.rcParams['font.size'] = 4 #font size for figures
from scipy import stats
import numpy as np
df = pd.read_csv('../../Data/Chapter_1_cleaned_data.csv')
```

1.  Create lists of feature names for the remaining financial features.

    这些分为两组，所以我们将像以前一样列出特性名称，以便一起分析它们。您可以使用以下代码来实现这一点:

    ```
    bill_feats = ['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', \
                  'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']
    pay_amt_feats = ['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', \
                     'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']
    ```

2.  Use `.describe()` to examine statistical summaries of the bill amount features. Reflect on what you see. Does it make sense?

    使用以下代码查看摘要:

    ```
    df[bill_feats].describe()
    ```

    输出应该如下所示:

    ![Figure 1.47: Statistical description of bill amounts for the past 6 months
    ](image/B16392_01_47.jpg)

    图 1.47:过去 6 个月账单金额的统计描述

    我们看到平均每个月的账单大概是 4 万到 5 万台币。我们鼓励您检查对当地货币的兑换率。比如 1 美元~= 30 台币。做换算，问问自己，这是合理的月供吗？我们也应该与客户确认这一点，但它似乎是合理的。

    我们还注意到有一些负的账单金额。这似乎是合理的，因为上个月的账单可能会超额支付，也许是因为预期购买会出现在本月的账单上。这种情况会使账户出现负余额，也就是说，账户持有人会得到一笔存款。

3.  Visualize the bill amount features using a 2 by 3 grid of histogram plots using the following code:

    ```
    df[bill_feats].hist(bins=20, layout=(2,3))
    ```

    图表应该是这样的:

    ![Figure 1.48: Histograms of bill amounts
    ](image/B16392_01_48.jpg)

    图 1.48:账单金额直方图

    图 1.48 中的直方图在几个方面有意义。大多数账户的账单金额相对较小。随着账单金额的增加，账户的数量逐渐减少。此外，账单金额的月与月分布也大致相似，因此我们没有注意到任何数据不一致的问题，就像我们使用支付状态功能时一样。该功能似乎通过了我们的数据质量检查。现在，我们将进入最后一组功能。

4.  Use the `.describe()` method to obtain a summary of the payment amount features using the following code:

    ```
    df[pay_amt_feats].describe()
    ```

    输出应该如下所示:

    ![Figure 1.49: Statistical description of bill payment amounts for the past 6 months
    ](image/B16392_01_49.jpg)

    图 1.49:过去 6 个月账单支付金额的统计描述

    平均付款金额大约比我们在前面的活动中总结的平均账单金额低一个数量级(10 的幂)。这意味着“一般情况”是一个账户每月都没有还清全部余额。根据我们对`PAY_1`特性的研究，这是有意义的，对于该特性，最普遍的值是 0(该账户至少支付了最低还款额，但没有付清全部余额)。没有负支出，这似乎也是对的。

5.  Plot a histogram of the bill payment features similar to the bill amount features, but also apply some rotation to the *x-axis* labels with the `xrot` keyword argument so that they don't overlap. Use the `xrot=<angle>` keyword argument to rotate the *x-axis* labels by a given angle in degrees using the following code:

    ```
    df[pay_amt_feats].hist(layout=(2,3), xrot=30)
    ```

    在我们的例子中，我们发现 30 度的旋转效果很好。情节应该是这样的:

    ![Figure 1.50: Histograms of raw payment amount data
    ](image/B16392_01_50.jpg)

    ``````

    图 1.50:原始支付金额数据的直方图

    快速浏览该图表明，这不是一个信息量很大的图形；在大多数直方图中只有一个柱具有显著的高度。这不是可视化这些数据的有效方法。看起来月支付金额主要在包括 0 的箱中。有多少实际上是 0？

6.  Use a Boolean mask to see how much of the payment amount data is exactly equal to 0 using the following code: Do this with the following code:

    ```
    pay_zero_mask = df[pay_amt_feats] == 0
    pay_zero_mask.sum()
    ```

    输出应该如下所示:

    ![Figure 1.51: Counts of bill payments equal to 0
    ](image/B16392_01_51.jpg)

    图 1.51:账单支付次数等于 0

    鉴于上一步中的直方图，这些数据有意义吗？

    这里的第一行创建了一个名为`pay_zero_mask`的新数据帧，它是一个根据支付金额是否等于 0 的`True`和`False`值的数据帧。第二行获取该数据帧的列和，将`True`解释为 1，将`False`解释为 0，因此列和表示对于每个特性有多少账户的值为 0。

    我们看到很大一部分，大约 20-25%的账户，在任何给定的月份中账单支付等于 0。但是，大部分账单支付都在 0 以上。那么，为什么我们在直方图中看不到它们呢？这是由于账单支付值的**范围**相对于大多数账单支付的值。

    在统计摘要中，我们可以看到一个月的最大账单支付通常比平均账单支付大 2 个数量级(100 倍)。看起来很可能只有少量的大额账单支付。但是，由于直方图的创建方式，使用大小相等的条柱，几乎所有数据都被集中到最小的条柱中，而较大的条柱几乎不可见，因为它们的帐户很少。我们需要一种策略来有效地可视化这些数据。

7.  Ignoring the payments of 0 using the mask you created in the previous step, use pandas' `.apply()` and NumPy's `np.log10()` method to plot histograms of logarithmic transformations of the non-zero payments. You can use `.apply()` to apply any function, including `log10`, to all the elements of a DataFrame. Use the following code for this:

    ```
    df[pay_amt_feats][~pay_zero_mask].apply(np.log10)\
                                     .hist(layout=(2,3))
    ```

    这是熊猫的一个比较高级的用法，如果你自己想不出来也不用担心。然而，开始了解如何用相对较少的代码在 pandas 中做很多事情是很好的。

    输出应该如下所示:

    ![Figure 1.52: Base-10 logs of non-zero bill payment amounts
    ](image/B16392_01_52.jpg)

图 1.52:非零账单支付金额的十进制日志

虽然我们可以尝试创建可变宽度的条块来更好地可视化支付金额，但一种更方便的方法是对数变换，即 **log transform** ，这种方法通常用于可视化，有时甚至用于建模，其中一些值的比例与大多数值的比例大不相同。我们使用了以 10 为底的对数变换。粗略地说，这个变换告诉我们一个值中零的数量。换句话说，至少 100 万美元但少于 1000 万美元的余额将具有至少 6 但少于 7 的对数变换，因为 106 = 1，000，000(反之 log10(1，000，000) = 6)，而 107 = 10，000，000。

为了将这种转换应用于我们的数据，首先，我们需要屏蔽掉零支付，因为`log10(0)`是未定义的(在这种情况下，另一种常见的方法是向所有值添加一个非常小的数字，例如 0.01，因此没有零)。我们用 Python 逻辑`not`操作符`~`和我们已经创建的零掩码完成了这项工作。然后我们使用 pandas `.apply()`方法，它将我们喜欢的任何函数应用于我们选择的数据。在这种情况下，我们希望应用由`np.log10`计算的以 10 为底的对数。最后，我们制作了这些值的直方图。

结果是更有效的数据可视化:值以更具信息性的方式分布在直方图区间中。我们可以看到，最常发生的账单支付在数千(`log10(1,000) = 3`)的范围内，这与我们在统计摘要中观察到的平均账单支付相匹配。有一些很小的账单支付，也有一些很大的。总的来说，账单支付的分布每月都很一致，所以我们看不出这个数据有任何潜在的问题。

# 2。Scikit 简介-学习和模型评估

## 活动 2.01:使用新功能进行逻辑回归，并创建精确召回曲线

**解决方案:**

1.  Use scikit-learn's `train_test_split` to make a new set of training and test data. This time, instead of `EDUCATION`, use `LIMIT_BAL`, the account's credit limit, as the feature.

    为此，请执行以下代码:

    ```
    X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split\
                                              (df['LIMIT_BAL']\
                                               .values\
                                               .reshape(-1,1),\
                                               df['default'\
                                                  'payment next'\
                                                  'month'].values,\
                                               test_size=0.2,\
                                               random_state=24))
    ```

    请注意，这里我们创建了新的训练和测试分割，使用了新的变量名。

2.  Train a logistic regression model using the training data from your split.

    下面的代码可以做到这一点:

    ```
    example_lr.fit(X_train_2, y_train_2)
    ```

    如果您在单个笔记本中运行整个章节，您可以重用之前使用的相同模型对象`example_lr`。你可以**重新训练**这个对象来学习这个新特性和响应之间的关系。如果您愿意，您甚至可以尝试不同的训练/测试分割，而无需创建新的模型对象。在这些场景中，现有的模型对象已经被就地更新**。**

***   Create the array of predicted probabilities for the test data.

    这一步的代码如下:

    ```
    y_test_2_pred_proba = example_lr.predict_proba(X_test_2)
    ```

    *   Calculate the ROC AUC using the predicted probabilities and the true labels of the test data. Compare this to the ROC AUC from using the `EDUCATION` feature.

    为此步骤运行以下代码:

    ```
    metrics.roc_auc_score(y_test_2, y_test_2_pred_proba[:,1])
    ```

    输出如下所示:

    ```
    0.6201990844642832
    ```

    请注意，我们对预测概率数组进行了索引，以便从第二列获得正类的预测概率。这与来自`EDUCATION`逻辑回归的 ROC AUC 相比如何？AUC 更高。这可能是因为现在我们在使用一个与账户财务状况(信用额度)有关系的特征，来预测与账户财务状况(是否会违约)相关的其他东西，而不是使用与财务不那么直接相关的东西。

    *   Plot the ROC curve.

    下面是实现这一点的代码；它类似于我们在前一个练习中使用的代码:

    ```
    fpr_2, tpr_2, thresholds_2 = metrics.roc_curve\
                                 (y_test_2, \
                                  y_test_2_pred_proba[:,1])
    plt.plot(fpr_2, tpr_2, '*-')
    plt.plot([0, 1], [0, 1], 'r--')
    plt.legend(['Logistic regression', 'Random chance'])
    plt.xlabel('FPR')
    plt.ylabel('TPR')
    plt.title('ROC curve for logistic regression with '\
              'LIMIT_BAL feature')
    ```

    该图应如下所示:

    ![Figure 2.30: ROC curve for the LIMIT_BAL logistic regression
    ](image/B16392_02_30.jpg)

    图 2.30:极限平衡逻辑回归的 ROC 曲线

    这看起来有点接近我们想要看到的 ROC 曲线:与仅使用`EDUCATION`的模型相比，它离随机机会线有点远。还要注意，在阈值范围内，成对的真阳性率和假阳性率的变化稍微平滑一些，这反映了`LIMIT_BAL`特征的大量不同值。

    *   Calculate the data for the precision-recall curve on the test data using scikit-learn's functionality.

    精确度通常与召回率一起考虑。我们可以使用`sklearn.metrics`中的`precision_recall_curve`来自动改变阈值，并计算每个阈值的精度和召回值对。下面是检索这些值的代码，类似于`roc_curve`:

    ```
    precision, recall, thresh_3 = metrics.precision_recall_curve\
                                  (y_test_2,\
                                   y_test_2_pred_proba[:,1])
    ```

    *   Plot the precision-recall curve using matplotlib: we can do this with the following code.

    请注意，我们将 recall 放在`x`轴上，将 precision 放在`y`轴上，并将轴的限制设置为范围[0，1]:

    ```
    plt.plot(recall, precision, '-x')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision and recall for the logistic'\
              'regression 'with LIMIT_BAL')
    plt.xlim([0, 1])
    plt.ylim([0, 1])
    ```

    ![Figure 2.31: Plot of the precision-recall curve
    ](image/B16392_02_31.jpg)

    图 2.31:精确度-召回率曲线图

    *   Use scikit-learn to calculate the area under the precision-recall curve.

    以下是代码:

    ```
    metrics.auc(recall, precision)
    ```

    您将获得以下输出:

    ```
    0.31566964427378624
    ```

    我们看到，精确度-召回曲线表明，精确度通常是相当低的这个模型；对于几乎所有的阈值范围，正确的肯定分类的精度或部分小于一半。我们可以计算精确-召回曲线下的面积，作为将该分类器与我们可能考虑的其他模型或特征集进行比较的方法。

    Scikit-learn 提供了使用梯形规则计算任何一组`x-y`数据的 AUC 的功能，您可能还记得微积分中的梯形规则:`metrics.auc`。我们使用这个功能来获得精确召回曲线下的面积。

    *   Now recalculate the ROC AUC, except this time do it for the training data. How is this different, conceptually and quantitatively, from your earlier calculation?

    首先，我们需要使用训练数据来计算预测概率，而不是测试数据。然后，我们可以使用训练数据标签计算 ROC AUC。代码如下:

    ```
    y_train_2_pred_proba = example_lr.predict_proba(X_train_2)
    metrics.roc_auc_score(y_train_2, y_train_2_pred_proba[:,1])
    ```

    您应该获得以下输出:

    ```
    0.6182918113358344
    ```** 

 **从数量上看，我们可以看到这个 AUC 与我们之前计算的测试数据 ROC AUC 并没有太大的不同。两者都在 0.62 左右。概念上，有什么区别？当我们在训练数据上计算这个度量时，我们测量的是模型预测“教导”模型如何进行预测的相同数据的技能。我们正在观察*模型与数据*的吻合程度。另一方面，测试数据度量指示模型以前没有“看到”的样本外数据的性能。如果这些分数之间存在很大差异(通常表现为训练分数高于测试分数),则表明尽管模型很好地拟合了数据，但训练模型并不能很好地推广到新的、看不见的数据。

在这种情况下，训练和测试分数是相似的，这意味着模型对样本外数据的处理与对模型训练中使用的相同数据的处理一样好。我们将在第四章*、*、*偏差方差权衡*中了解更多通过比较训练和测试分数获得的见解。

# 3。逻辑回归和特征探索的细节

## 活动 3.01:拟合逻辑回归模型并直接使用系数

**解决方案:**

前几个步骤类似于我们在之前的活动中所做的事情:

1.  以`PAY_1`和`LIMIT_BAL`为特征:

    ```
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(
        df[['PAY_1', 'LIMIT_BAL']].values,
        df['default payment next month'].values,
        test_size=0.2, random_state=24)
    ```

    创建一个训练/测试分割(80/20)
2.  导入`LogisticRegression`，使用默认选项，但是将解算器设置为`'liblinear'` :

    ```
    from sklearn.linear_model import LogisticRegression
    lr_model = LogisticRegression(solver='liblinear')
    ```

3.  对训练数据进行训练，并使用测试数据获得预测的类别以及类别概率:

    ```
    lr_model.fit(X_train, y_train)
    y_pred = lr_model.predict(X_test)
    y_pred_proba = lr_model.predict_proba(X_test)
    ```

4.  Pull out the coefficients and intercept from the trained model and manually calculate predicted probabilities. You'll need to add a column of ones to your features, to multiply by the intercept.

    首先，让我们使用水平堆叠创建一系列要素，并添加一列要素:

    ```
    ones_and_features = np.hstack\
                        ([np.ones((X_test.shape[0],1)), X_test])
    ```

    现在我们需要截距和系数，我们从 scikit-learn 输出中对它们进行整形和连接:

    ```
    intercept_and_coefs = np.concatenate\
                          ([lr_model.intercept_.reshape(1,1), \
                            lr_model.coef_], axis=1)
    ```

    要将截距和系数重复乘以`ones_and_features`的所有行，并对每一行求和(即找到线性组合)，您可以使用乘法和加法将这些全部写出。然而，使用点积要快得多:

    ```
    X_lin_comb = np.dot(intercept_and_coefs,\
                        np.transpose(ones_and_features))
    ```

    现在`X_lin_comb`有了我们需要传递给我们定义的 sigmoid 函数的参数，为了计算预测概率:

    ```
    y_pred_proba_manual = sigmoid(X_lin_comb)
    ```

5.  Using a threshold of `0.5`, manually calculate predicted classes. Compare this to the class predictions outputted by scikit-learn.

    人工预测的概率`y_pred_proba_manual`应该与`y_pred_proba`相同；我们马上检查一下。首先，手动预测具有阈值的类:

    ```
    y_pred_manual = y_pred_proba_manual >= 0.5
    ```

    这个数组的形状与`y_pred`不同，但是它应该包含相同的值。我们可以像这样检查两个数组的所有元素是否相等:

    ```
    np.array_equal(y_pred.reshape(1,-1), y_pred_manual)
    ```

    如果数组相等，这将返回一个逻辑`True`。

6.  Calculate ROC AUC using both scikit-learn's predicted probabilities and your manually predicted probabilities, and compare them.

    首先，导入以下内容:

    ```
    from sklearn.metrics import roc_auc_score
    ```

    然后，在两个版本上计算此指标，注意访问正确的列，或根据需要调整形状:

    ![Figure 3.37: Calculating the ROC AUC from predicted probabilities
    ](image/B16392_03_37.jpg)

图 3.37:根据预测概率计算 ROC AUC

事实上，AUC 是相同的。我们在这里做了什么？我们已经确认，从这个拟合的 scikit-learn 模型中，我们真正需要的是三个数字:截距和两个系数。一旦我们有了这些，我们就可以用几行代码和数学函数创建模型预测，这相当于从 scikit-learn 直接做出的预测。

这有助于确认您的理解，但除此之外，您为什么要这样做呢？我们将在最后一章讨论**模型部署**。但是，根据您的具体情况，在需要将新要素输入模型进行预测的环境中，您可能无法访问 Python。例如，您可能需要完全用 SQL 进行预测。虽然这通常是一种限制，但使用逻辑回归，您可以使用 SQL 中可用的数学函数来重新创建逻辑回归预测，只需将截距和系数复制并粘贴到 SQL 代码中的某个位置。点积可能不可用，但您可以使用乘法和加法来达到相同的目的。

那么，结果本身呢？我们在这里看到的是，我们可以稍微提高模型性能，超过我们以前的努力:仅使用`LIMIT_BAL`作为上一章活动中的一个特征，ROC AUC 为 0.62，而不是这里的 0.63。在下一章，我们将学习逻辑回归的高级技术，我们可以用它来进一步提高性能。

# 4。偏差方差权衡

## 活动 4.01:案例研究数据的交叉验证和特征工程

**解决方案:**

1.  Select out the features from the DataFrame of the case study data.

    您可以使用我们在本章中已经创建的特性名称列表，但是一定不要包含响应变量，这是一个非常好(但是完全不合适)的特性:

    ```
    features = features_response[:-1]
    X = df[features].values
    ```

2.  Make a training/test split using a random seed of 24:

    ```
    X_train, X_test, y_train, y_test = \
    train_test_split(X, df['default payment next month'].values,
                     test_size=0.2, random_state=24)
    ```

    我们将继续使用它，并将这个测试数据保留为不可见的测试集。通过指定随机种子，我们可以使用相同的训练数据，通过其他建模方法轻松创建单独的笔记本。

3.  实例化`MinMaxScaler`来缩放数据，如下面的代码所示:

    ```
    from sklearn.preprocessing import MinMaxScaler
    min_max_sc = MinMaxScaler()
    ```

4.  用`saga`解算器实例化一个逻辑回归模型，L1 惩罚，并将`max_iter`设置为`1000`，因为我们希望让解算器有足够的迭代次数来找到一个好的解:

    ```
    lr = LogisticRegression(solver='saga', penalty='l1',
                            max_iter=1000)
    ```

5.  导入`Pipeline`类，并使用 scaler 和逻辑回归模型创建一个管道，对步骤分别使用名称`'scaler'`和`'model'`:

    ```
    from sklearn.pipeline import Pipeline
    scale_lr_pipeline = Pipeline(
        steps=[('scaler', min_max_sc), ('model', lr)])
    ```

6.  使用`get_params`和`set_params`方法查看如何从管道的每个阶段查看参数并更改它们(在笔记本的单独单元格中执行下面的每一行并观察输出):

    ```
    scale_lr_pipeline.get_params()
    scale_lr_pipeline.get_params()['model__C']
    scale_lr_pipeline.set_params(model__C = 2)
    ```

7.  创建一个更小范围的 *C* 值来进行交叉验证测试，因为这些模型将需要更长的时间来训练，并使用比我们之前的练习更多的数据进行测试；我们推荐*C =【10*2*，10，1，10* -1 *，10* -2 *，10*-3*:

    ```
    C_val_exponents = np.linspace(2,-3,6)
    C_vals = np.float(10)**C_val_exponents
    ```* 
**   Make a new version of the `cross_val_C_search` function, called `cross_val_C_search_pipe`. Instead of the `model` argument, this function will take a `pipeline` argument. The changes inside the function will be to set the *C* value using `set_params(model__C = <value you want to test>)` on the pipeline, replacing the model with the pipeline for the `fit` and `predict_proba` methods, and accessing the *C* value using `pipeline.get_params()['model__C']` for the printed status update.

    这些变化如下:

    ```
    def cross_val_C_search_pipe(k_folds, C_vals, pipeline, X, Y):
    ##[…]
    pipeline.set_params(model__C = C_vals[c_val_counter])
    ##[…]
    pipeline.fit(X_cv_train, y_cv_train)
    ##[…]
    y_cv_train_predict_proba = pipeline.predict_proba(X_cv_train)
    ##[…]
    y_cv_test_predict_proba = pipeline.predict_proba(X_cv_test)
    ##[…]
    print('Done with C = {}'.format(pipeline.get_params()\
                                    ['model__C']))
    ```

    注意

    关于完整的代码，请参考[https://packt.link/AsQmK](https://packt.link/AsQmK)。

    *   Run this function as in the previous exercise, but using the new range of *C* values, the pipeline you created, and the features and response variable from the training split of the case study data. You may see warnings here, or in later steps, regarding the non-convergence of the solver; you could experiment with the `tol` or `max_iter` options to try and achieve convergence, although the results you obtain with `max_iter = 1000` are likely to be sufficient. Here is the code to do this:

    ```
    cv_train_roc_auc, cv_test_roc_auc, cv_test_roc = \
    cross_val_C_search_pipe(k_folds, C_vals, scale_lr_pipeline,
                            X_train, y_train)
    ```

    您将获得以下输出:

    ```
    Done with C = 100.0
    Done with C = 10.0
    Done with C = 1.0
    Done with C = 0.1
    Done with C = 0.01
    Done with C = 0.001
    ```

    *   Plot the average training and test ROC AUC across folds, for each *C* value, using the following code:

    ```
    plt.plot(C_val_exponents, np.mean(cv_train_roc_auc, axis=0),
             '-o', label='Average training score')
    plt.plot(C_val_exponents, np.mean(cv_test_roc_auc, axis=0),
             '-x', label='Average testing score')
    plt.ylabel('ROC AUC')
    plt.xlabel('log$_{10}$(C)')
    plt.legend()
    plt.title('Cross-validation on Case Study problem')
    ```

    您将获得以下输出:

    ![Figure 4.25: Cross-validation test performance
    ](image/B16392_04_25.jpg)

    图 4.25:交叉验证测试性能

    您应该注意到，正则化在这里并没有带来太多的好处，这是可以预料的:对于较低的 *C* 值，对应于更强的正则化，模型测试(以及训练)性能会降低。虽然我们能够通过使用所有可用的功能来提高模型性能，但似乎没有过度拟合。反而是培训和考试成绩差不多。我们不是过度适应，而是可能适应不足。让我们尝试设计一些交互功能，看看它们能否提高性能。

    *   Create interaction features for the case study data and confirm that the number of new features makes sense using the following code:

    ```
    from sklearn.preprocessing import PolynomialFeatures
    make_interactions = PolynomialFeatures(degree=2,
                                           interaction_only=True,
                                           include_bias=False)
    X_interact = make_interactions.fit_transform(X)
    X_train, X_test, y_train, y_test = train_test_split(
        X_interact, df['default payment next month'].values,
        test_size=0.2, random_state=24)
    print(X_train.shape)
    print(X_test.shape)
    ```

    您将获得以下输出:

    ```
    (21331, 153)
    (5333, 153)
    ```

    由此您应该看到新的特性数是 153，即*17+" 17 choose 2 " = 17+136 = 153*。*“17 选 2”*部分来自于从 17 个原始特征中选择 2 个特征的所有可能组合进行交互。

    *   Repeat the cross-validation procedure and observe the model performance when using interaction features; that is, repeat *steps 9* and *10*. Note that this will take substantially more time, due to the larger number of features, but it will probably take less than 10 minutes.

    您将获得以下输出:

    ![Figure 4.26: Improved cross-validation test performance from adding interaction features
    ](image/B16392_04_26.jpg)*

 *图 4.26:通过添加交互特性来提高交叉验证测试的性能

那么，平均交叉验证测试性能是否随着交互特性而提高？正规化有用吗？

设计相互作用特征将最佳模型测试分数增加到大约 *ROC AUC = 0.74* 平均穿过褶皱，从不包括相互作用的大约 0.72。这些分数发生在 *C = 100* ，也就是说，正则化可以忽略不计。在具有交互的模型的训练分数与测试分数的关系图上，您可以看到训练分数比测试分数高一点，因此可以说存在一定程度的过度拟合。然而，我们不能通过正则化来增加测试分数，所以这可能不是过度拟合的问题实例。在大多数情况下，产生最高测试分数的策略就是最佳策略。

总之，使用逻辑回归模型，增加交互作用特征改善了交叉验证性能，正则化似乎在这一点上对案例研究没有用。我们将保留拟合所有训练数据的步骤，以便稍后在交叉验证中尝试其他模型以找到最佳模型时使用。

# 5。决策树和随机森林

## 活动 5.01:使用随机森林进行交叉验证网格搜索

**解决方案:**

1.  Create a dictionary representing the grid for the `max_depth` and `n_estimators` hyperparameters that will be searched. Include depths of 3, 6, 9, and 12, and 10, 50, 100, and 200 trees. Leave the other hyperparameters at their defaults. Create the dictionary using this code:

    ```
    rf_params = {'max_depth':[3, 6, 9, 12],
                 'n_estimators':[10, 50, 100, 200]}
    ```

    注意

    还有许多其他可能的超参数可供搜索。特别是，随机森林的 scikit-learn 文档指出“使用这些方法时要调整的主要参数是`n_estimators`和`max_features`”,并且“对于分类任务，经验上好的默认值是……`max_features=sqrt(n_features)`”

    来源:https://sci kit-learn . org/stable/modules/ensemble . html # parameters

    出于本书的目的，为了缩短运行时间，我们将使用`max_features='auto'`(等于`sqrt(n_features)`)并将我们的探索限于`max_depth`和`n_estimators`。在现实世界中，您应该根据您能够负担的计算时间来探索其他超参数。请记住，为了在特别大的参数空间中进行搜索，您可以使用`RandomizedSearchCV`来避免对网格中超参数的每个组合进行穷举计算。

2.  使用本章之前使用的相同选项实例化一个`GridSearchCV`对象，但是使用在步骤 1 中创建的超参数字典。设置`verbose=2`查看每次拟合的输出。您可以重用我们一直在使用的同一个随机森林模型对象`rf`，或者创建一个新的。创建一个新的随机森林对象，并使用下面的代码实例化`GridSearchCV`类:

    ```
    rf = RandomForestClassifier(n_estimators=10,\
                                criterion='gini',\
                                max_depth=3,\
                                min_samples_split=2,\
                                min_samples_leaf=1,\
                                min_weight_fraction_leaf=0.0,\
                                max_features='auto',\
                                max_leaf_nodes=None,\
                                min_impurity_decrease=0.0,\
                                min_impurity_split=None,\
                                bootstrap=True,\
                                oob_score=False,\
                                n_jobs=None,
                                random_state=4,\
                                verbose=0,\
                                warm_start=False,\
                                class_weight=None)
    cv_rf = GridSearchCV(rf, param_grid=rf_params,\
                         scoring='roc_auc',\
                         n_jobs=-1,\
                         refit=True,\
                         cv=4,\
                         verbose=2,\
                         error_score=np.nan,\
                         return_train_score=True)
    ```

3.  Fit the `GridSearchCV` object on the training data. Perform the grid search using this code:

    ```
    cv_rf.fit(X_train, y_train)
    ```

    因为我们选择了`verbose=2`选项，所以你会在笔记本上看到一个比较大的输出量。对于每个超参数组合和每个折叠，在拟合和测试时都会有输出。以下是最初的几行输出:

    ![Figure 5.22: The verbose output from cross-validation
    ](image/B16392_05_22.jpg)

    图 5.22:交叉验证的详细输出

    虽然对于较短的交叉验证过程，没有必要看到所有这些输出，但对于较长的过程，看到交叉验证正在工作，并让您了解各种超参数组合的拟合时间，这是令人放心的。如果事情花费的时间太长，您可能希望通过按下笔记本顶部的 stop 按钮(正方形)来中断内核，并选择运行时间更短的超参数，或者使用一组更有限的超参数。

    完成所有这些后，您应该会看到以下输出:

    ![Figure 5.22: The cross-validation output upon completion
    ](image/B16392_05_23.jpg)

    图 5.23:完成后的交叉验证输出

    运行此交叉验证作业大约需要 2 分钟。随着您的工作增多，您可能希望使用`n_jobs`参数探索并行处理，看看是否有可能加快搜索速度。使用`n_jobs=-1`进行并行处理，您应该能够获得比串行处理更短的运行时间。然而，通过并行处理，你将无法看到每个单独模型拟合操作的输出，如图*图 5.23* 所示。

4.  将网格搜索的结果放入熊猫数据框中。使用此代码将结果放入数据帧:

    ```
    cv_rf_results_df = pd.DataFrame(cv_rf.cv_results_)
    ```

5.  Create a `pcolormesh` visualization of the mean testing score for each combination of hyperparameters. Here is the code to create a mesh graph of cross-validation results. It's similar to the example graph that we created previously, but with annotation that is specific to the cross-validation we performed here:

    ```
    ax_rf = plt.axes()
    pcolor_graph = ax_rf.pcolormesh\
                   (xx_rf, yy_rf,\
                    cv_rf_results_df['mean_test_score']\
                    .values.reshape((4,4)), cmap=cm_rf)
    plt.colorbar(pcolor_graph, label='Average testing ROC AUC')
    ax_rf.set_aspect('equal')
    ax_rf.set_xticks([0.5, 1.5, 2.5, 3.5])
    ax_rf.set_yticks([0.5, 1.5, 2.5, 3.5])
    ax_rf.set_xticklabels\
    ([str(tick_label) for tick_label in rf_params['n_estimators']])
    ax_rf.set_yticklabels\
    ([str(tick_label) for tick_label in rf_params['max_depth']])
    ax_rf.set_xlabel('Number of trees')
    ax_rf.set_ylabel('Maximum depth')
    ```

    与我们之前的例子的主要变化是，我们绘制的不是从 1 到 16 的整数，而是我们已经检索并使用`cv_rf_results_df['mean_test_score'].values.reshape((4,4))`整形的平均测试分数。这里的另一个新东西是，我们使用列表理解，基于网格中超参数的数值，为刻度标签创建字符串列表。我们从我们定义的字典中访问它们，然后将它们分别转换成列表理解中的`str`(字符串)数据类型，例如`ax_rf.set_xticklabels([str(tick_label) for tick_label in rf_params['n_estimators']])`。我们已经使用`set_xticks`将记号位置设置到我们想要的位置。同样，我们使用`ax_rf.set_aspect('equal')`制作一个正方形的图形。该图应该如下所示:

    ![Figure 5.24: Results of cross-validation of a random forest 
    over a grid with two hyperparameters
    ](image/B16392_05_24.jpg)

    图 5.24:带有两个超参数的网格上随机森林的交叉验证结果

6.  Conclude which set of hyperparameters to use.

    从网格搜索中我们能得出什么结论？使用深度超过 3 的树当然有优势。在我们尝试的参数组合中，有 200 棵树的`max_depth=9`产生了最好的平均测试分数，您可以在数据框架中查找并确认 ROC AUC = 0.776。

    这是迄今为止我们所有努力中找到的最好的模型。

    在现实世界中，我们可能会进行更彻底的搜索。一些好的下一步将是尝试更多的树，而不是花更多的时间用`n_estimators` < 200，因为我们知道我们需要至少 200 棵树来获得最佳性能。你可以搜索一个更细粒度的空间`max_depth`，而不是像我们在这里所做的那样跳过 3s，并尝试其他几个超参数，如`max_features`。然而，出于我们的目的，我们将假设我们已经找到了这里的最佳超参数，并继续前进..

# 6。梯度提升、XGBoost 和 SHAP 值

## 活动 6.01:用 XGBoost 对案例研究数据建模，用 SHAP 解释模型

**解决方案:**

在本活动中，我们将利用本章中学到的合成数据集，并将其应用于案例研究数据。我们将了解 XGBoost 模型在验证集上的表现，并使用 SHAP 值解释模型预测。我们已经为该活动准备了数据集，替换了先前忽略的`PAY_1`特征中有缺失值的样本，同时为没有缺失值的样本保持相同的训练/测试分割。您可以在本次活动笔记本的附录中看到这些数据是如何准备的。

1.  加载为此练习准备的案例研究数据。文件路径为`../../Data/Activity_6_01_data.pkl`，变量为:`features_response, X_train_all, y_train_all, X_test_all, y_test_all` :

    ```
    with open('../../Data/Activity_6_01_data.pkl', 'rb') as f:
        features_response, X_train_all, y_train_all, X_test_all,\
        y_test_all = pickle.load(f)
    ```

2.  定义一个验证集来训练提前停止的 XG boost:

    ```
    from sklearn.model_selection import train_test_split
    X_train_2, X_val_2, y_train_2, y_val_2 = \
    train_test_split(X_train_all, y_train_all,\
                     test_size=0.2, random_state=24)
    ```

3.  实例化 XGBoost 模型。我们将使用`lossguide`增长策略，并检查几个`max_leaves` :

    ```
    xgb_model_4 = xgb.XGBClassifier(
        n_estimators=1000,
        max_depth=0,
        learning_rate=0.1,
        verbosity=1,
        objective='binary:logistic',
        use_label_encoder=False,
        n_jobs=-1,
        tree_method='hist',
        grow_policy='lossguide')
    ```

    值的验证集性能
4.  从 5 到 200 搜索`max_leaves`的值，以 5 为单位计数:

    ```
    max_leaves_values = list(range(5,205,5))
    ```

5.  创建提前停止的评估集:

    ```
    eval_set_2 = [(X_train_2, y_train_2), (X_val_2, y_val_2)]
    ```

6.  使用与*练习 6.01:调整 XGBoost 超参数的随机网格搜索* :

    ```
    %%time
    val_aucs = []
    for max_leaves in max_leaves_values:
        #Set parameter and fit model
        xgb_model_4.set_params(**{'max_leaves':max_leaves})
        xgb_model_4.fit(X_train_2, y_train_2,\
                        eval_set=eval_set_2,\
                        eval_metric='auc',\
                        verbose=False,\
                        early_stopping_rounds=30)
        #Get validation score
        val_set_pred_proba = xgb_model_4.predict_proba(X_val_2)[:,1]
        val_aucs.append(roc_auc_score(y_val_2, val_set_pred_proba))
    ```

    中相同的技术，遍历超参数值并创建 ROC AUCs 验证列表
7.  Create a data frame of the hyperparameter search results and plot the validation AUC against `max_leaves`:

    ```
    max_leaves_df_2 = \
    pd.DataFrame({'Max leaves':max_leaves_values,\
                  'Validation AUC':val_aucs})
    mpl.rcParams['figure.dpi'] = 400
    max_leaves_df_2.set_index('Max leaves').plot()
    ```

    情节应该是这样的:

    ![Figure 6.15: Validation AUC versus max_leaves for the case study data
    ](image/B16392_06_15.jpg)

    图 6.15:案例研究数据的验证 AUC 与`max_leaves`

    尽管这种关系有些混乱，但我们发现，一般而言，`max_leaves`值越低，验证集 ROC AUC 越高。这是因为通过允许更少的叶子来限制树的复杂性导致更少的过度拟合，并且增加了验证集分数。

8.  Observe the number of `max_leaves` corresponding to the highest ROC AUC on the validation set:

    ```
    max_auc_2 = max_leaves_df_2['Validation AUC'].max()
    max_auc_2
    max_ix_2 = max_leaves_df_2['Validation AUC'] == max_auc_2
    max_leaves_df_2[max_ix_2]
    ```

    结果应该如下所示:

    ![Figure 6.16: Optimal max_leaves and validation set AUC for the case study data
    ](image/B16392_06_16.jpg)

    图 6.16:案例研究数据的最佳`max_leaves`和验证集 AUC

    我们希望根据我们之前对案例研究数据建模的努力来解释这些结果。这不是一个完美的比较，因为这里我们在训练和验证数据中有缺失值，而以前我们忽略了它们，这里我们只有一个验证集，而不是以前使用的 k-folds 交叉验证(尽管感兴趣的读者可以尝试在 XGBoost 中使用 k-folds 交叉验证进行多次训练/验证分割，并提前停止)。

    然而，即使考虑到这些限制，这里的验证结果应该提供一个样本外性能的度量，类似于我们之前执行的 k 倍交叉验证。我们注意到，这里的验证 ROC AUC 0.779 比之前在*活动 5.01* 、*使用随机森林的交叉验证网格搜索*、*第 5 章决策树和随机森林*中使用随机森林获得的 0.776 稍高。这些验证分数非常相似，在实践中使用其中任何一个模型都是可行的。我们现在将继续使用 XGBoost 模型。

9.  用最佳超参数改装 XGBoost 模型:

    ```
    xgb_model_4.set_params(**{'max_leaves':40})
    xgb_model_4.fit(X_train_2, y_train_2, eval_set=eval_set_2,
                    eval_metric='auc',
                    verbose=False, early_stopping_rounds=30)
    ```

10.  这样我们就可以检查验证集的 SHAP 值，制作这个数据的数据框架:

    ```
    X_val_2_df = pd.DataFrame(data=X_val_2,
                              columns=features_response[:-1])
    ```

11.  Create an SHAP explainer for our new model using the validation data as the background dataset, obtain the SHAP values, and make a summary plot:

    ```
    explainer_2 = shap.explainers.Tree(xgb_model_4, data=X_val_2_df)
    shap_values_2 = explainer_2(X_val_2_df)
    mpl.rcParams['figure.dpi'] = 75
    shap.summary_plot(shap_values_2.values, X_val_2_df)
    ```

    情节应该是这样的:

    ![Figure 6.17: SHAP values for the XGBoost model of the case study data on the validation set
    ](image/B16392_06_17.jpg)

    图 6.17:验证集上案例研究数据的 XGBoost 模型的 SHAP 值

    从*图 6.17* 中，我们可以看到 XGBoost 模型中最重要的特征与我们在*第五章*、*决策树和随机森林* ( *图 5.15* )中探讨的随机森林模型中的特征有些不同。不再是最重要的特征，尽管它仍然排在第三位。`LIMIT_BAL`，借款人的信用额度，现在是最重要的特征。作为一个重要特征，这是有意义的，因为贷款人可能会根据借款人的风险程度来设定信贷限额，因此它应该是违约风险的一个很好的预测指标。

    让我们探索一下`LIMIT_BAL`是否有任何有趣的 SHAP 与其他功能的互动。我们可以让`shap`包通过不索引颜色参数的 explainer 对象来选择交互最多的特性，而不是指定散点图的颜色。

12.  Make a scatter plot of `LIMIT_BAL` SHAP values, colored by the feature with the strongest interaction:

    ```
    shap.plots.scatter(shap_values_2[:,'LIMIT_BAL'],
                       color=shap_values_2)
    ```

    情节应该是这样的:

    ![Figure 6.18: Scatter plot of SHAP values of LIMIT_BAL and the 
    feature with the strongest interaction
    ](image/B16392_06_18.jpg)

    图 6.18:`LIMIT_BAL`和具有最强相互作用的特征的 SHAP 值散点图

    `BILL_AMT2`，前两个月的账单金额，与`LIMIT_BAL`的交互最强。我们可以看到，对于大多数`LIMIT_BAL`值，如果账单特别高，这将导致更积极的 SHAP 值，这意味着违约风险增加。通过注意大多数最红的彩色点出现在图 6.18 中*点带的顶部，可以观察到这一点。这具有直观的意义:即使借款人获得了很高的信用额度，如果他们的账单变得非常大，这可能意味着违约风险增加。*

    最后，我们将保存模型以及培训和测试数据，用于分析并交付给我们的业务合作伙伴。我们使用 Python 的`pickle`功能来实现这一点。

13.  将训练好的模型与训练和测试数据一起保存到一个文件:

    ```
    with open('../Data/xgb_model_w_data.pkl', 'wb') as f:
        pickle.dump([X_train_all, y_train_all,\
                     X_test_all, y_test_all,\
                     xgb_model_4], f)
    ```

# 7 .。测试集分析、财务洞察和向客户交付

## 活动 7.01:获得财务洞察力

**解决方案:**

1.  Using the testing set, calculate the cost of all defaults if there were no counseling program.

    使用此代码进行计算:

    ```
    cost_of_defaults = np.sum(y_test_all * X_test_all[:,5])
    cost_of_defaults 
    ```

    输出应该是这样的:

    ```
    60587763.0
    ```

2.  Calculate by what percent the cost of defaults can be decreased by the counseling program.

    违约成本的潜在下降是咨询计划的最大可能净节约，除以没有计划时所有违约的成本:

    ```
    net_savings[max_savings_ix]/cost_of_defaults
    ```

    输出应该是这样的:

    ```
    0.2214260658542551
    ```

    结果表明，在预测模型的指导下，我们可以使用咨询计划将违约成本降低 22%。

3.  Calculate the net savings per account (considering all accounts it might be possible to counsel, in other words relative to the whole test set) at the optimal threshold.

    使用此代码进行计算:

    ```
    net_savings[max_savings_ix]/len(y_test_all)
    ```

    输出应该如下所示:

    ```
    2259.2977433479286
    ```

    类似这样的结果有助于客户将他们通过咨询项目可能节省的潜在金额扩大到他们所服务的尽可能多的账户。

4.  Plot the net savings per account against the cost of counseling per account for each threshold.

    使用以下代码创建绘图:

    ```
    plt.plot(total_cost/len(y_test_all),
             net_savings/len(y_test_all))
    plt.xlabel\
    ('Upfront investment: cost of counselings per account (NT$)')
    plt.ylabel('Net savings per account (NT$)')
    ```

    结果图应该如下所示:

    ![Figure 7.14: The initial cost of the counseling program needed 
    to achieve a given amount of savings
    ](image/B16392_07_14.jpg)

    图 7.14:实现一定数量的储蓄所需的咨询项目的初始成本

    这表明客户在一个给定的月里需要为咨询项目预算多少钱，以达到给定的储蓄金额。看起来最大的收益可以通过每个账户高达 1300 元新台币的预算来创造(你可以使用`np.argmax`找到与最大净储蓄相对应的准确预算金额)。然而，前期投资在新台币 1000 元至 2000 元之间的净储蓄相对持平，超出该范围则更低。客户实际上可能没有能力为这个项目做这么多预算。然而，如果需要的话，这个图表给了他们支持更大预算的证据。

    这个结果与我们上一个练习中的图形相对应。尽管我们已经展示了最佳阈值是 0.36，但是对于客户来说，使用更高的阈值(高达约 0.5)可能是没问题的，从而做出更少的正面预测，向更少的账户持有人提供咨询，并且具有更小的前期项目成本。*图 7.14* 显示了每个账户的成本和净节省。

5.  Plot the fraction of accounts predicted as positive (this is called the "flag rate") at each threshold.

    使用此代码绘制标志速率与阈值的关系:

    ```
    plt.plot(thresholds, n_pos_pred/len(y_test_all))
    plt.ylabel('Flag rate')
    plt.xlabel('Threshold')
    ```

    该图应如下所示:

    ![Figure 7.15: Flag rate against threshold for the credit counseling program
    ](image/B16392_07_15.jpg)

    图 7.15:信贷咨询计划的标志利率与阈值

    该图显示了预测违约的人数比例，因此在每个阈值都将推荐外联。似乎在最佳阈值 0.36，只有大约 20%的帐户将被标记为咨询。这显示了如何使用一个模型来优先考虑客户咨询可以帮助集中在正确的客户和减少资源浪费。更高的阈值可能会导致接近最佳的节省，如图*图 7.12* ( *第 7 章*、*测试集分析、财务洞察和向客户交付*)所示，从而导致更低的标记率。

6.  Plot a precision-recall curve for the testing data using the following code:

    ```
    plt.plot(n_true_pos/sum(y_test_all),\
             np.divide(n_true_pos, n_pos_pred)) 
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    ```

    情节应该是这样的:

    ![Figure 7.16: Precision-recall curve
    ](image/B16392_07_16.jpg)

    图 7.16:精确召回曲线

    *图 7.16* 显示，为了开始获得远高于 0 的真实肯定率(即召回率)，我们需要接受大约 0.8 或更低的精度。

    精确度和召回率与项目的成本和节约有着直接的联系:我们的预测越精确，由于不正确的模型预测而浪费在咨询上的钱就越少。召回率越高，我们就能通过成功识别违约账户来节省越多的资金。将此步骤中的代码与上一个练习中用于计算成本和节约的代码进行比较，可以看出这一点。

    要了解精确度和召回率与用于定义正面和负面预测的阈值之间的关系，将它们分别绘制出来可能会有所帮助。

7.  Plot precision and recall separately on the *y*-axis against threshold on the *x*-axis.

    使用以下代码生成绘图:

    ```
    plt.plot(thresholds, np.divide(n_true_pos, n_pos_pred),
             label='Precision')
    plt.plot(thresholds, n_true_pos/sum(y_test_all),
             label='Recall')
    plt.xlabel('Threshold')
    plt.legend()
    ```

    该图应如下所示:

    ![Figure 7.17: Precision and recall plotted separately against the threshold
    ](image/B16392_07_17.jpg)

图 7.17:精确度和召回率分别与阈值相对应

这个图解释了为什么最佳阈值是 0.36。虽然最佳阈值也取决于成本和节省的财务分析，但我们可以在这里看到，精确度初始增加的最陡部分，它代表积极预测的正确性，因此是模型指导咨询的成本效益如何的度量，发生在大约 0.36 的阈值。*** ***

## 嘿！

我是这本书的作者斯蒂芬·克劳斯曼。我真的希望你喜欢读我的书，并发现它很有用。

这对我(和其他潜在的读者)真的很有帮助！)如果你可以在亚马逊上留下评论，分享你对 Python 、*第二版*的*数据科学项目的想法。*

去链接[https://packt.link/r/1800564481](https://packt.link/r/1800564481)。

运筹学

扫描二维码留下你的评论。

![Barcode
](image/Barcode.jpg)

你的评论将有助于我了解这本书哪些地方做得很好，哪些地方可以在未来的版本中改进，所以非常感谢。

最美好的祝愿，

斯蒂芬·克洛特曼***