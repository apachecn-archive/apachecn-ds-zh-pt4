

# 二、ScikitLearn 简介和模型评估

概观

在探索了案例研究数据的响应变量之后，本章通过逻辑和线性回归的简单用例，介绍了 scikit-learn 用于训练模型和进行预测的核心功能。二元分类模型的评估指标，包括**真阳性率和假阳性率**、**混淆矩阵**、**接收器操作特性** ( **ROC** ) **曲线**和**精确召回曲线**，均从头开始演示，并使用方便的 scikit-learn 功能。本章结束时，你将能够使用 scikit-learn 建立和评估二元分类模型。

# 简介

在前一章中，您熟悉了基本的 Python，然后了解了用于数据探索的 pandas 工具。使用 Python 和 pandas，您可以执行诸如加载数据集、验证数据完整性以及对数据中的要素或独立变量执行探索性分析等操作。

在本章中，我们将通过检查响应变量来完成对数据的探索。在我们得出数据是高质量且有意义的结论后，我们将准备好继续开发机器学习模型。我们将从 scikit-learn 开始，这是 Python 语言中最流行的机器学习包之一。在下一章学习数学模型如何工作的细节之前，这里我们将开始熟悉在 scikit-learn 中使用它们的语法。

我们还将学习一些回答“这个模型好不好”这个问题的常用技巧有许多可能的方法来进行模型评估。对于业务应用程序，通过财务分析来确定一个模型能够创造的价值，是了解您的工作的潜在影响的一个重要方法。通常，最好在一开始就确定项目的商业机会。然而，由于本书的重点是机器学习和预测建模，我们将在最后一章演示财务分析。

有几个重要的模型评估标准被认为是数据科学和机器学习中的标准知识。我们将在这里讨论一些最广泛使用的分类模型性能指标。

# 探索响应变量，结束初步探索

我们现在已经浏览了所有的**特性**以查看是否有数据丢失，并对它们进行了一般性的检查。这些特征很重要，因为它们构成了我们机器学习算法的**输入**。在模型的另一边是**输出**，它是对**响应变量**的预测。对于我们的问题，这是一个二进制标志，表示一个信用账户下个月是否会违约。

案例研究项目的关键任务是为这个目标提出一个预测模型。由于响应变量是一个是/否标志，这个问题被称为一个**二元分类**任务。在我们标记的数据中，违约(即`'default payment next month'` `= 1`)的样本(账户)被称为属于**正类**，而不属于**负类**。

关于二元分类问题的反应，要检查的主要信息是:阳性类别的比例是多少？这是一个简单的检查。

在我们执行这个检查之前，我们用下面的代码加载我们需要的包:

```py
import numpy as np #numerical computation
import pandas as pd #data wrangling
import matplotlib.pyplot as plt #plotting package
#Next line helps with rendering plots
%matplotlib inline
import matplotlib as mpl #add'l plotting functionality
mpl.rcParams['figure.dpi'] = 400 #high res figures
```

现在，我们像这样加载案例研究数据的清理版本:

```py
df = pd.read_csv('../../Data/Chapter_1_cleaned_data.csv')
```

注意

作为您在第 1 章、*数据探索和清理*中工作的结果，清理后的数据集应该已经保存。如果您将上述代码片段中已清理数据保存在不同的位置，则该数据的路径可能会有所不同。

现在，为了找到正类的比例，我们需要做的就是得到整个数据集上响应变量的平均值。这就有了违约率的解释。检查每个类的样本数量也是值得的，在熊猫中使用`groupby`和`count`。这在下面的截图中有所呈现:

![Figure 2.1: Class balance of the response variable
](image/B16925_02_01.jpg)

图 2.1:响应变量的类别平衡

由于目标变量是`1`或`0`，取该列的平均值表示违约账户的比例:22%。样本在正类中的比例(默认值= 1)，也称为该类的**类分数**，是一个重要的统计数据。在二元分类中，数据集被描述为**平衡**或**不平衡**:正负类的比例是否相等？大多数机器学习分类模型被设计成处理平衡的数据:类之间 50/50 的分割。

然而，在实践中，真实数据很少是平衡的。因此，有几种方法适用于处理不平衡数据。其中包括以下内容:

*   **欠采样**多数类:从多数类中随机丢弃样本，直到类分数相等，或者至少不那么不平衡。
*   **过采样**少数类:随机添加少数类的重复样本，以达到同样的目的。
*   **加权样本**:这种方法是作为训练步骤的一部分执行的，因此在训练好的模型中，少数类总体上具有与多数类一样多的“重点”。其效果类似于过采样。
*   更复杂的方法，比如**合成少数过采样技术** ( **SMOTE** )。

虽然我们的数据严格来说并不均衡，但我们也注意到，22%的正类分数也并不特别不平衡。一些领域，如欺诈检测，通常处理小得多的正类分数:大约 1%或更少。这是因为“坏演员”的比例相对于交易总人口来说相当小；同时，如果可能的话，能够识别它们是很重要的。对于像这样的问题，更有可能的是，使用一种方法来解决类不平衡会导致更好的结果。

既然我们已经研究了响应变量，我们已经完成了最初的数据研究。然而，数据探索应该被认为是一项持续的任务，在任何项目中您都应该牢记在心。当您创建模型并生成新的结果时，最好考虑这些结果对数据意味着什么，这通常需要快速迭代到探索阶段。一种特别有用的探索，通常也是在建模之前进行的，是检查特征和响应之间的关系。我们在*第 1 章*、*数据探索和清理*中给出了一个预览，当时我们按`EDUCATION`特征分组并检查响应变量的平均值。我们以后还会做更多的工作。然而，这更多的是建立一个模型，而不是检查数据的内在质量。

对我们刚刚完成的所有数据的初步阅读是在项目开始时打下的重要基础。当您这样做时，您应该问自己以下问题:

*   Is the data **complete**?

    是否有缺失值或其他异常？

*   Is the data **consistent**?

    分布是否随时间变化，如果是，这是预期的吗？

*   Does the data **make sense**?

    特性的值是否符合它们在数据字典中的定义？

后两个问题帮助你确定你认为数据是否**正确**。如果任何一个问题的答案是“不”，那么这个问题应该在继续项目之前解决。

此外，如果您想到任何可能有帮助且有可能获得的替代或附加数据，现在将是在项目生命周期中用这些数据扩充数据集的好时机。这方面的例子可能包括邮政编码级别的人口统计数据，如果您有与帐户相关联的地址，您可以将这些数据**加入到您的数据集。我们没有这些用于案例研究的数据，我们决定利用现有的数据继续这个项目。**

# sci kit 简介-了解

虽然 pandas 将为您节省大量加载、检查和清理数据的时间，但使您能够进行预测建模的机器学习算法位于其他包中。Scikit-learn 是 Python 的一个基础机器学习包，包含许多有用的算法，也影响了 Python 中其他机器学习库的设计和语法。为此，我们关注 sci kit——学习在预测建模实践中发展技能。虽然任何一个包都不可能提供所有的东西，但 scikit-learn 在适应分类、回归和无监督学习的各种经典方法方面非常接近。然而，它没有为一些更近的进步提供太多功能，如深度学习。

以下是您应该了解的几个其他相关软件包:

**轨道**:

*   到目前为止，我们使用的大多数软件包，如 NumPy 和 pandas，实际上都是 SciPy 生态系统的一部分。
*   SciPy 为线性回归和线性编程等经典方法提供了轻量级函数。

**状态模型**:

*   更面向统计，对于熟悉 R 的用户来说可能更舒服
*   可以得到回归系数的 p 值和置信区间
*   时间序列模型的能力，如 ARIMA

**XGBoost 和 LightGBM** :

*   提供一套通常优于随机森林的最先进的集合模型。我们将在*第 6 章*、*梯度提升、SHAP 值以及处理缺失数据*中了解 XGBoost。

**TensorFlow, Keras, and PyTorch** :

*   深度学习能力

有许多其他的 Python 包可能会派上用场，但是这让您对那里有什么有一个概念。

Scikit-learn 为各种任务提供了大量不同的模型，但是方便的是，使用它们的语法是一致的。在本节中，我们将使用一个**逻辑回归**模型来说明模型语法。逻辑回归，尽管它的名字，实际上是一个分类模型。这是最简单的分类模型之一，因此也是最重要的分类模型。在下一章中，我们将讨论逻辑回归如何工作的数学细节。在那之前，你可以简单地把它想象成一个黑匣子，可以从标记的数据中学习，然后做出预测。

从第一章开始，您应该熟悉在标记数据上训练算法的概念，以便您可以使用这个训练的模型来对新数据进行预测。Scikit-learn 将这些核心功能封装在用于训练模型的`.fit`方法和用于进行预测的`.predict`方法中。由于一致的语法，您可以在任何 scikit-learn 模型上调用`.fit`和`.predict`，从线性回归到分类树。

第一步是选择一些模型，在这个例子中是逻辑回归模型，并从 scikit-learn 提供的**类**中实例化它。在 Python 中，类是创建对象的模板，对象是函数(如`.fit`)和数据(如从模型拟合过程中获得的信息)的集合。当您从 scikit-learn 实例化一个模型类时，您将获得 scikit-learn 提供给您的模型蓝图，并从中创建一个有用的**对象**。您可以在您的数据上训练此对象，然后将其保存到磁盘供以后使用。以下代码片段可用于执行此任务。第一步是导入类:

```py
from sklearn.linear_model import LogisticRegression
```

将类实例化为对象的代码如下:

```py
my_lr = LogisticRegression()
```

该对象现在是我们工作区中的一个变量。我们可以使用下面的代码来检查它:

```py
my_lr
```

这将产生以下输出:

```py
LogisticRegression()
```

注意，创建模型对象的行为本质上不涉及什么是逻辑回归或者它如何工作的知识。虽然我们在创建逻辑回归模型对象时没有选择任何特定的选项，但是我们现在实际上使用了许多默认选项来描述模型的形成和训练。实际上，这些是我们在没有意识到的情况下对模型实现的细节所做的选择。像 scikit-learn 这样一个易于使用的软件包的危险在于，它有可能模糊你的这些选择。然而，任何时候你使用像 scikit-learn 模型一样为你准备的机器学习模型，你的首要工作是理解所有可用的选项。这种情况下的最佳实践是在创建对象时显式地为模型提供每个关键字参数。即使你只是选择了所有的默认选项，这也有助于提高你对所做选择的意识。

我们稍后将回顾这些选择的解释，但是现在这里是用所有默认选项实例化逻辑回归模型的代码:

```py
my_new_lr = LogisticRegression(penalty='l2', dual=False,\
                               tol=0.0001, C=1.0,\
                               fit_intercept=True,\
                               intercept_scaling=1,\
                               class_weight=None,\
                               random_state=None,\
                               solver='lbfgs',\
                               max_iter=100,\
                               multi_class='auto',\
                               verbose=0, warm_start=False,\
                               n_jobs=None, l1_ratio=None)
```

尽管我们在`my_new_lr`中创建的对象与`my_lr`相同，但当你开始学习不同种类的模型时，这样明确的描述尤其有用。一旦你感觉更舒服了，你可能希望用默认选项进行实例化，然后根据需要进行修改。在这里，我们展示如何做到这一点。以下代码设置了两个选项，并显示了模型对象的当前状态:

```py
my_new_lr.C = 0.1
my_new_lr.solver = 'liblinear'
my_new_lr
```

这会产生以下结果:

```py
Out[11]:LogisticRegression(C=0.1, solver='liblinear')
```

请注意，只显示我们根据默认值更新的选项。这里，我们取了模型的一个所谓的**超参数**，`C`，并将其从默认值`1`更新为`0.1`。我们还指定了一个求解器。目前，只要理解超参数是在将模型拟合到数据之前提供给模型的选项就足够了。这些选项指定了模型的训练方式。稍后，我们将详细解释所有选项是什么，以及如何有效地为它们选择值。

为了说明核心功能，我们将把这种近乎默认的逻辑回归用于一些数据。监督学习算法依赖于标记数据。这意味着我们既需要通常包含在名为`X`的变量中的特性，也需要名为`y`的变量中的相应响应。我们将从数据集中借用一个特征的前 10 个样本和响应来说明:

```py
X = df['EDUCATION'][0:10].values.reshape(-1,1)
X
```

这将显示前 10 个样本的`EDUCATION`特性值:

![Figure 2.2: First 10 values of a feature
](image/B16925_02_02.jpg)

图 2.2:特性的前 10 个值

响应变量的相应前 10 个值可以如下获得:

```py
y = df['default payment next month'][0:10].values
y
```

以下是输出:

```py
Out[13]: array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0])
```

这里，我们从我们的数据框架中选择了几个系列(即列):我们已经讨论过的`EDUCATION`特性和响应变量。然后我们选择每个数组的前 10 个元素，最后使用`.values`方法返回 NumPy 数组。还要注意，我们使用了`.reshape`方法来重塑特征。Scikit-learn 预计特征数组的第一维(即行数)将等于样本数，因此我们需要为`X`进行整形，而不是为`y`。`.reshape`的第一个位置参数中的`–1`表示根据输入的数据量，使输出数组的形状在该维度上具有灵活性。由于本例中只有一个特性，我们将列数指定为第二个参数`1`，并让`–1`参数指示数组应该在第一维上“填充”容纳数据所需的尽可能多的元素，在本例中是 10 个元素。请注意，虽然我们已经将数据提取到 NumPy 数组中以展示如何做到这一点，但也可以使用 pandas 系列作为 scikit-learn 的直接输入。

现在让我们用这些数据来拟合我们的逻辑回归。这只用一行代码就完成了:

```py
my_new_lr.fit(X, y)
```

以下是输出:

```py
Out[14]:LogisticRegression(C=0.1, solver='liblinear')
```

这就是全部了。一旦准备好数据并指定了模型，拟合模型几乎就像是事后的想法。当然，我们现在忽略了所有重要的选项和它们的含义。但是，从技术上讲，根据代码拟合一个模型是非常容易的。您可以看到该单元格的输出只是打印了我们已经看到的相同选项。虽然拟合过程除了这个输出之外没有返回任何东西，但是发生了一个非常重要的变化。`my_new_lr`模型对象现在是一个经过训练的模型。我们说这个变化发生在**位置**，因为没有创建新的对象；现有对象`my_new_lr`已被修改。这类似于就地修改数据帧。我们现在可以使用我们训练好的模型，使用新样本的特征进行预测，这是该模型以前从未“见过”的。让我们试试`EDUCATION`特性的下 10 行。

我们可以使用一个新变量`new_X`来选择和查看这些特性:

```py
new_X = df['EDUCATION'][10:20].values.reshape(-1,1)
new_X
```

![Figure 2.3: New features to make predictions for
](image/B16925_02_03.jpg)

图 2.3:要预测的新特性

预测是这样完成的:

```py
my_new_lr.predict(new_X)
```

以下是输出:

```py
array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
```

我们还可以查看与这些预测相对应的真实值，因为这些数据被标记为:

```py
df['default payment next month'][10:20].values
```

以下是输出:

```py
Out[17]:array([0, 0, 0, 1, 0, 0, 1, 0, 0, 0])
```

在这里，我们举例说明了几件事。在获得新的特征值之后，我们已经对训练好的模型调用了`.predict`方法。注意，这个方法的唯一参数是一组特性，也就是我们称之为`new_X`的“X”。

我们的小模特表现如何？我们可能会天真地观察到，由于模型预测全是 0，而 80%的真实标签是 0，所以我们有 80%的时间是正确的，这似乎相当不错。另一方面，我们完全没有成功预测任何 1。所以，如果这些是重要的，我们实际上做得不是很好。虽然这只是一个让您熟悉 scikit-learn 如何工作的示例，但对于这个问题，考虑一下“好的”预测可能是什么样子是值得的。我们将很快进入评估模型预测能力的细节。现在，祝贺你自己已经接触了一些真实的数据，并拟合了你的第一个机器学习模型。

## 生成合成数据

在下面的练习中，您将独自完成模型拟合过程。我们将使用线性回归来推动这一过程，线性回归是最著名的数学模型之一，它应该为基础统计学所熟悉。它也被称为最佳拟合线。如果您不知道它是什么，您可以参考基本的统计资料，尽管这里的目的是说明 sci-kit learn 中模型拟合的机制，而不是详细理解模型。我们将在本书后面的其他数学模型中研究这一点，我们将应用于案例研究，如逻辑回归。为了有数据可用，你将生成你自己的**合成数据**。合成数据是一种有价值的学习工具，用于探索模型、阐释数学概念以及进行思维实验来测试各种想法。为了制作合成数据，我们将在这里再次说明如何使用 NumPy 的`random`库来生成随机数，以及如何使用 matplotlib 的`scatter`和`plot`函数来创建散点图和线图。在本练习中，我们将使用 scikit-learn 进行线性回归部分。

首先，我们使用 NumPy 创建一个特征值的一维数组`X`，它由 1，000 个 0 到 10 之间的随机实数(换句话说，不仅仅是整数，还有小数)组成。我们再次为随机数发生器使用一个**种子**。接下来，我们使用来自均匀分布的`default_rng`(随机数生成器)的`.uniform`方法:同样有可能在`low`(包含)和`high`(不包含)之间选择任意数字，并且将返回您指定的任意`size`的数组。我们创建一个包含 1，000 个元素的一维数组(即向量)，然后检查前 10 个元素。所有这些都可以使用下面的代码来完成:

```py
from numpy.random import default_rng
rg = default_rng(12345)
X = rg.uniform(low=0.0, high=10.0, size=(1000,))
X[0:10]
```

输出应该如下所示:

![Figure 2.4: Creating random, uniformly distributed numbers with NumPy
](image/B16925_02_04.jpg)

图 2.4:用 NumPy 创建随机的、均匀分布的数字

## 线性回归的数据

现在我们需要一个响应变量。在本例中，我们将生成遵循线性回归假设的数据:数据将显示相对于要素的线性趋势，但具有正态分布的误差:

![Figure 2.5: Linear equation with Gaussian noise
](image/B16925_02_05.jpg)

图 2.5:带有高斯噪声的线性方程

这里， *a* 是斜率， *b* 是截距，高斯噪声的均值为，标准差为 *σ* 。为了编写代码来实现这一点，我们需要生成一个相应的响应向量`y`，计算方法是斜率乘以特征数组`X`，加上一些高斯噪声(再次使用 NumPy)和一个截距。噪声将是 1000 个数据点的阵列，其形状(`size`)与特征阵列`X`相同，其中噪声的平均值(`loc`)为 0，标准偏差(`scale`)为 1。这将为我们的线性数据增加一点“扩散”:

```py
slope = 0.25
intercept = -1.25
y = slope * X + rg.normal(loc=0.0, scale=1.0, size=(1000,))\
          + intercept
```

现在我们想把这些数据可视化。我们将使用 matplotlib 绘制`y`与特征`X`的散点图。首先，我们使用`.rcParams`来设置分辨率(`dpi` =每英寸点数)，以获得清晰的图像。然后我们用`plt.scatter`创建散点图，其中`X`和`y`分别是前两个参数，`s`参数指定了点的大小。

此代码可用于绘图:

```py
mpl.rcParams['figure.dpi'] = 400
plt.scatter(X,y,s=1)
plt.xlabel('X')
plt.ylabel('y')
```

执行完这些单元格后，您应该会在笔记本中看到类似这样的内容:

![Figure 2.6: Plot the noisy linear relationship
](image/B16925_02_06.jpg)

图 2.6:绘制噪声线性关系

看起来像一些嘈杂的线性数据，就像我们希望的那样。现在我们来建模。

注意

如果你正在阅读这本书的印刷版本，你可以通过访问以下链接下载并浏览本章中一些图片的彩色版本:[https://packt.link/0dbUp](https://packt.link/0dbUp)。

## 练习 2.01:sci kit-Learn 中的线性回归

在本练习中，我们将利用刚刚生成的合成数据，使用 scikit-learn 确定最佳拟合线或线性回归。第一步是从 scikit-learn 导入一个线性回归模型类，并从中创建一个对象。导入类似于我们之前使用的`LogisticRegression`类。与任何模型类一样，您应该观察所有的默认选项是什么。注意，对于线性回归，没有多少选项可以指定:在本练习中，您将使用默认值。默认设置包括`fit_intercept=True`，这意味着回归模型将包括截距项。这当然是合适的，因为我们在合成数据中添加了一个截距。执行以下步骤来完成练习，注意必须首先在同一个笔记本(如 GitHub 所示)中运行前一节中为线性回归创建数据的代码:

注意

这个练习的 Jupyter 笔记本可以在这里找到:[https://packt.link/IaoyM](https://packt.link/IaoyM)。

1.  Execute this code to import the linear regression model class and instantiate it with all the default options:

    ```py
    from sklearn.linear_model import LinearRegression
    lin_reg = LinearRegression(fit_intercept=True, normalize=False,\
                               copy_X=True, n_jobs=None)
    lin_reg	
    ```

    您应该会看到以下输出:

    ```py
    Out[11]:LinearRegression()
    ```

    因为我们使用了所有的默认值，所以没有显示任何选项。现在，我们可以使用我们的合成数据来拟合模型，记住要重塑特征数组(就像我们之前做的那样)，以便样本沿着第一维。拟合线性回归模型后，我们检查包含拟合模型截距的`lin_reg.intercept_`，以及包含斜率的`lin_reg.coef_`。

2.  Run this code to fit the model and examine the coefficients:

    ```py
    lin_reg.fit(X.reshape(-1,1), y)
    print(lin_reg.intercept_)
    print(lin_reg.coef_)
    ```

    您应该会看到截距和斜率的输出:

    ```py
    -1.2522197212675905
    [0.25711689]
    ```

    我们再次看到，一旦准备好数据并决定了模型的选项，在 scikit-learn 中实际拟合模型是一个简单的过程。这是因为确定模型参数的所有算法工作都是从用户那里抽象出来的。我们将在后面讨论这个过程，因为我们将在案例研究数据中使用逻辑回归模型。

    我们拟合的模型的斜率和截距如何？

    这些数字相当接近我们在创建模型时指出的斜率和截距。然而，由于随机噪声，它们只是近似值。

    最后，我们可以使用模型对特征值进行预测。在这里，我们使用用于拟合模型的相同数据来做这件事:特征数组，`X`。我们将它的输出捕获为一个变量，`y_pred`。这与图 2.7 中*所示的例子非常相似，只是这里我们对用于拟合模型的相同数据进行预测(之前，我们对不同数据进行预测)，并且我们将`.predict`方法的输出放入一个变量中。*

3.  Run this code to make predictions:

    ```py
    y_pred = lin_reg.predict(X.reshape(-1,1))
    ```

    我们可以绘制预测值`y_pred`与特征`X`的关系，作为特征和响应数据散点图的线图，就像我们在*图 2.6* 中所做的那样。这里，我们添加了`plt.plot`，默认情况下它会生成一个线形图，来绘制模型训练数据的特征和模型预测响应值。请注意，在对`plt.plot`的调用中，我们在`X`和`y`数据后跟随了`'r'`。此关键字参数使线条变为红色，是绘图格式的速记语法的一部分。

4.  This code can be used to plot the raw data, as well as the fitted model predictions on this data:

    ```py
    plt.scatter(X,y,s=1)
    plt.plot(X,y_pred,'r')
    plt.xlabel('X')
    plt.ylabel('y')
    ```

    在执行这个单元格之后，您应该会看到类似这样的内容:

    ![Figure 2.7: Plotting the data and the regression line
    ](image/B16925_02_07.jpg)

图 2.7:绘制数据和回归线

正如所料，该图看起来像一条最佳拟合线。

在本练习中，与我们使用逻辑回归调用`.predict`不同，我们对用于训练模型的相同数据`X`进行了预测。这是一个重要的区别。在这里，我们看到了模型如何“适应”它所训练的相同数据，我们之前检查了新的、看不见的数据上的模型预测。在机器学习中，我们通常关注预测能力:我们希望模型能够帮助我们了解未来场景的可能结果。然而，事实证明，对用于拟合模型的**训练数据**和未用于拟合模型的**测试数据**的模型预测，对于理解模型的工作是很重要的。我们将在第 4 章*、*、*偏差方差权衡*中正式阐述这些概念，届时我们将讨论**偏差方差权衡**。

# 为二进制分类建立性能指标模型

在我们开始认真构建预测模型之前，我们想知道一旦我们创建了一个模型，我们如何确定它在某种意义上是否是“好”的。正如你所想象的，这个问题受到了研究者和实践者的广泛关注。因此，有各种各样的模型性能指标可供选择。

注意

要了解选项的范围，请查看 scikit-learn 模型评估页面:[https://sci kit-learn . org/stable/modules/model _ evaluation . html # model-evaluation](https://scikit-learn.org/stable/modules/model_evaluation.html#model-evaluation)。

当选择模型性能指标来评估模型的预测质量时，记住两点很重要。

**问题指标的适当性**

度量标准通常只为特定类别的问题定义，例如分类或回归。对于二元分类问题，有几个度量标准来表征模型回答的是或否问题的正确性。这里的一个额外的细节层次是模型对每一个类的正确频率，积极类和消极类。我们将在这里详细讨论这些指标。另一方面，回归度量旨在衡量预测与目标数量的接近程度。如果我们试图预测一所房子的价格，我们有多接近？我们是否系统地高估或低估了？我们是不是搞错了越贵的房子，却搞错了越便宜的房子？有许多可能的方法来查看回归度量。

**该指标是否回答了业务问题？**

无论您正在处理哪一类问题，都会有许多度量标准可供选择。哪一个是正确的？即使这样，你如何知道一个模型在度量上是否“足够好”呢？在某种程度上，这是一个主观的问题。然而，当我们考虑模型的目标是什么时，我们可以是客观的。在商业环境中，典型的目标是增加利润或减少损失。最终，您需要统一您的业务问题，这通常以某种方式与金钱相关，以及您将用来判断您的模型的度量标准。

例如，在我们的信用违约问题中，是否存在与不能正确识别将违约的账户相关联的特别高的成本？这比潜在的错误分类一些不会违约的账户更重要吗？

在本书的后面，我们将在我们的问题中引入正确和错误分类的相对成本和收益的概念，并进行财务分析。首先，我们将向您介绍用于评估二元分类模型预测质量的最常用指标，我们需要为我们的案例研究构建这类模型。

## 拆分数据:训练集和测试集

在本章的 scikit-learn 介绍中，我们介绍了使用经过训练的模型对该模型以前从未“见过”的新数据进行预测的概念。事实证明，这是预测建模中的一个基本概念。在我们寻求创建一个具有预测能力的模型的过程中，我们需要某种方法来衡量该模型对不适合该模型的数据进行预测的能力。这是因为在拟合模型时，模型在学习用于拟合的特定标记数据集的特征和响应之间的关系时变得“专门化”。虽然这很好，但最终我们希望能够使用该模型对新的、未知的数据做出准确的预测，因为我们不知道这些标签的真实价值。

例如，在我们的案例研究中，一旦我们将训练好的模型交付给我们的客户，他们就会生成一个新的像我们现在这样的特征数据集，除了不是从 4 月到 9 月，而是从 5 月到 10 月。我们的客户将使用具有这些特征的模型来预测账户是否会在 11 月违约。

为了了解我们的模型能在多大程度上预测哪些账户将在 11 月份实际违约(要到 12 月份才能知道)，我们可以使用当前的数据集，并保留一些来自模型训练过程的数据，这些数据带有已知的标签。该数据被称为**测试数据**，也可以被称为**样本外数据**，因为它由未用于训练模型的样本组成。那些用来训练模型的样本叫做**训练数据**。通过展示一组测试数据，我们可以了解模型在用于预期目的时的表现，从而对模型训练期间未包含的样本进行预测。在本章中，我们将创建一个示例训练/测试分割来说明不同的二进制分类指标。

我们将使用 scikit 的便利的`train_test_split`功能——学习分割数据，以便 80%将用于训练，保留 20%用于测试。这些百分比是进行这种分割的常用方法；通常，您需要足够的训练数据，以使算法能够从代表性的数据样本中充分“学习”。然而，这些百分比并不是一成不变的。如果您有大量的样本，您可能不需要很大百分比的训练数据，因为您将能够以较低的百分比获得相当大的代表性训练集。我们鼓励您尝试不同的尺寸，看看效果如何。此外，请注意，就有效训练模型所需的数据量而言，每个问题都是不同的。对于调整训练集和测试集的大小，没有硬性的规则。

对于我们的 80/20 分割，我们可以使用以下代码片段所示的代码:

```py
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split\
                                   (df['EDUCATION']\
                                    .values.reshape(-1,1),\
                                    df['default payment\
                                       ' next month']\
                                    .values, test_size=0.2,\
                                    random_state=24)
```

请注意，我们已经将`test_size`设置为`0.2`，即 20%。训练数据的大小将自动设置为余数，即 80%。让我们检查一下我们的训练和测试数据的形状，看看它们是否符合预期，如下面的输出所示:

![Figure 2.8: Shape of training and test sets
](image/B16925_02_08.jpg)

图 2.8:训练集和测试集的形状

您应该自己确认定型集和测试集中的样本数(行)是否符合 80/20 的划分。

在进行训练/测试分割时，我们还设置了`random_state`参数，这是一个随机数种子。使用此参数可以在笔记本电脑的运行中实现一致的训练/测试分割。否则，每次运行代码时，随机分割过程将选择不同的 20%的数据进行测试。

`train_test_split`的第一个参数是特性，在本例中只是`EDUCATION`，第二个参数是响应。有四个输出:分别是训练集和测试集中样本的特征，以及伴随这些特征集的相应响应变量。这个函数所做的只是从数据集中随机选择 20%的行索引，并将这些特性和响应作为测试数据，剩下的用于训练。既然我们已经有了训练和测试数据，那么最好确保这些数据集之间的数据性质是相同的。特别是正类的分数是否相似？您可以在以下输出中观察到这一点:

![Figure 2.9: Class fractions in training and test data
](image/B16925_02_09.jpg)

图 2.9:训练和测试数据中的类分数

训练和测试数据中的正类分数都约为 22%。这很好，因为我们可以说训练集是测试集的代表。在这种情况下，由于我们有一个相当大的数据集，有数万个样本，并且类不是太不平衡，我们不必采取预防措施来确保这种情况发生。

但是，您可以想象，如果数据集更小，并且阳性类非常少，则训练集和测试集之间的类分数可能会明显不同，或者更糟的是，测试集中可能根本没有阳性样本。为了防止这种情况，您可以使用**分层抽样**，关键字参数`stratify`为`train_test_split`。该过程还将数据随机分成训练集和测试集，但保证类分数相等或非常相似。

注意

**超时测试**

如果您的数据包含跨越很长一段时间的特征和响应，那么尝试将您的训练/测试按时间划分是一个很好的做法。例如，如果您有两年的数据以及每个月的特征和响应，您可能希望尝试按顺序对 12 个月的数据训练模型，并在下个月或下个月进行测试，这取决于何时使用模型在操作上是可行的。你可以重复这个过程，直到你收集完所有的数据，得到几个不同的测试分数。这将为您提供对模型性能的有用见解，因为它模拟了模型在部署时将面临的实际条件:根据旧功能和响应训练的模型将用于对新数据进行预测。在案例研究中，响应仅来自一个时间点(一个月内的信用违约)，因此这不是一个选项。

## 分类准确度

现在，我们继续拟合一个示例模型来说明二进制分类度量。我们将继续使用接近默认选项的逻辑回归，选择我们在*第 1 章、* *数据探索和清理*中演示的相同选项:

![Figure 2.10: Loading the model class and creating a model object
](image/B16925_02_10.jpg)

图 2.10:加载模型类并创建模型对象

现在，我们继续训练模型，正如你可能想象的那样，使用来自我们训练集的标记数据。我们立即着手使用训练好的模型对来自保留测试集的样本的特征进行预测:

![Figure 2.11: Training a model and making predictions on the test set
](image/B16925_02_11.jpg)

图 2.11:训练模型并对测试集进行预测

我们将测试集的模型预测标签存储在一个名为`y_pred`的变量中。我们现在应该如何评估这些预测的质量？在`y_test`变量中，我们有真正的标签。首先，我们将计算可能是所有二进制分类度量中最简单的:**准确度**。准确度被定义为被正确分类的样本的比例。

计算准确度的一种方法是创建一个逻辑掩码，每当预测标签等于实际标签时，该掩码为`True`，否则为`False`。然后我们可以取这个掩码的平均值，它将把`True`解释为 1，把`False`解释为 0，给我们正确分类的比例:

![Figure 2.12: Calculating classification accuracy with a logical mask
](image/B16925_02_12.jpg)

图 2.12:使用逻辑掩码计算分类准确度

这表明该模型在 78%的情况下是正确的。虽然这是一个非常简单的计算，但实际上使用 scikit-learn 的便利有更简单的方法来计算精度。一种方法是使用训练好的模型的`.score`方法，传递测试数据的特征来进行预测，以及测试标签。这种方法在一个步骤中完成预测，然后执行我们之前执行的相同计算。或者，我们可以导入 scikit-learn 的`metrics`库，其中包含许多模型性能指标，例如`accuracy_score`。为此，我们传递真实标签和预测标签:

![Figure 2.13: Calculating classification accuracy with scikit-learn
](image/B16925_02_13.jpg)

图 2.13:使用 scikit-learn 计算分类准确度

这些都给出了相同的结果，这是应该的。现在我们知道了模型有多精确，我们如何解释这个指标呢？表面上看，78%的准确率听起来不错。我们的大部分预测都是正确的。然而，对二元分类准确性的一个重要测试是将事物与一个非常简单的假设模型进行比较，该模型只进行一次预测:这个假设模型预测每个样本的多数类，不管特征是什么。虽然在实践中这个模型是无用的，但它提供了一个重要的极端情况来比较我们的训练模型的准确性。这种极端情况有时被称为零模型。

想想这样一个空模型的精确度会是多少。在我们的数据集中，我们知道大约 22%的样本是阳性的。所以，负类是多数类，剩下 78%的样本。因此，该数据集的空模型(总是预测多数否定类)在 78%的情况下是正确的。现在，当我们将这里的训练模型与这样的零模型进行比较时，很明显，78%的准确度实际上不是很有用。我们可以用一个不关注特征的模型得到同样的精度。

虽然我们可以根据多数类零模型来解释准确性，但还有其他二进制分类度量来更深入地研究该模型分别对阴性和阳性样本的表现。

## 真阳性率、假阳性率和混淆矩阵

在二进制分类中，只需要考虑两个标签:阳性和阴性。作为一种比跨所有样本的预测准确性更能描述模型性能的方式，我们也可以只查看那些具有正标签的样本的准确性。我们成功预测为阳性的比例称为**真阳性率** ( **TPR** )。如果我们说 **P** 是测试数据中**阳性类**的样本数，而 **TP** 是**真阳性**的数目，定义为模型预测为阳性的阳性样本数，那么 TPR 如下:

![Figure 2.14: TPR equation
](image/B16925_02_14.jpg)

图 2.14: TPR 方程

真阳性率的另一面是**假阴性率** ( **FNR** )。这是我们错误预测为阴性的阳性测试样本的比例。这种误差被称为**假阴性** ( **FN** )并且**假阴性率** ( **FNR** )计算如下:

![Figure 2.15: FNR equation
](image/B16925_02_15.jpg)

图 2.15: FNR 方程

由于所有阳性样本要么被正确预测，要么被错误预测，所以真阳性样本数和假阴性样本数之和等于阳性样本总数。从数学上讲， *P = TP + FN* ，因此，使用 TPR 和 FNR 的定义，我们有以下公式:

![Figure 2.16: The relation between the TPR and FNR
](image/B16925_02_16.jpg)

图 2.16:TPR 和 FNR 之间的关系

由于 TPR 和 FNR 之和为 1，因此只需计算其中一个就足够了。

与 TPR 和 FNR 类似的还有**真阴性率** ( **TNR** )和**假阳性率** ( **FPR** )。如果 **N** 为**阴性**样本数，则**真阴性**样本数之和( **TN** )为正确预测的样本数，而**假阳性** ( **FP** )样本数之和为错误预测为阳性的样本数:

![Figure 2.17: TNR equation
](image/B16925_02_17.jpg)

图 2.17: TNR 方程

![Figure 2.18: FPR equation
](image/B16925_02_18.jpg)

图 2.18: FPR 方程

![Figure 2.19: Relation between the TNR and FPR
](image/B16925_02_19.jpg)

图 2.19:TNR 和 FPR 之间的关系

真假阳性和阴性可以方便地总结在一个叫做**混淆矩阵**的表格中。二元分类问题的混淆矩阵是 2×2 矩阵，其中真实类别沿着一个轴，而预测类别沿着另一个轴。混淆矩阵快速总结了有多少真的和假的阳性和阴性:

![Figure 2.20: The confusion matrix for binary classification
](image/B16925_02_20.jpg)

图 2.20:二元分类的混淆矩阵

由于我们希望做出正确的分类，所以我们希望混淆矩阵的**对角线**条目(即沿着从左上到右下的对角线的条目:TN 和 TP)相对较大，而非对角线相对较小，因为这些代表不正确的分类。通过将对角线上的条目(正确的预测)相加，然后除以所有预测的总数，可以从混淆矩阵中计算出准确度。

## 练习 2.02:用 Python 计算真假正负率和混淆矩阵

在本练习中，我们将使用之前创建的逻辑回归模型中的测试数据和模型预测，仅使用`EDUCATION`特性。我们将说明如何手动计算真和假的正和负比率，以及混淆矩阵所需的真和假的正和负的数量。然后我们将展示用 scikit-learn 计算混淆矩阵的快速方法。执行以下步骤来完成这个练习，注意在做这个练习之前必须运行前一节中的一些代码(如 GitHub 上所示):

注意

这个练习的 Jupyter 笔记本可以在这里找到:[https://packt.link/S02kz](https://packt.link/S02kz)。

1.  Run this code to calculate the number of positive samples:

    ```py
    P = sum(y_test)
    P
    ```

    输出应该如下所示:

    ```py
    1155
    ```

    现在我们需要真阳性的数量。这些样本的真实标签为 1，预测也为 1。我们可以用一个逻辑掩码来识别这些样本，这些样本是正的(`y_test==1` ) **、** ( `&`是 Python 中的逻辑**和**运算符)，具有正预测(`y_pred==1`)。

2.  Use this code to calculate the number of true positives:

    ```py
    TP = sum( (y_test==1) & (y_pred==1) )
    TP
    ```

    以下是输出:

    ```py
    0
    ```

    真正的阳性率是真正的阳性与阳性的比例，当然这里是 0。

3.  Run the following code to obtain the TPR:

    ```py
    TPR = TP/P
    TPR
    ```

    您将获得以下输出:

    ```py
    0.0
    ```

    同样，我们可以识别假阴性。

4.  Calculate the number of false negatives with this code:

    ```py
    FN = sum( (y_test==1) & (y_pred==0) )
    FN
    ```

    这应该会输出以下内容:1155

    我们也想要 FNR。

5.  Calculate the FNR with this code:

    ```py
    FNR = FN/P
    FNR
    ```

    这将输出以下内容:

    ```py
    1.0
    ```

    **我们从真阳性率和假阴性率中学到了什么？**

    首先，我们可以确认它们的总和为 1。这个事实很容易看出，因为 TPR = 0，FPR = 1。关于我们的模型，这告诉了我们什么？在测试集上，至少对于阳性样本，该模型实际上充当了多数类无效模型。每个阳性样本都被预测为阴性，所以没有一个样本被正确预测。

6.  Let's find the TNR and FPR of our test data. Since these calculations are very similar to those we looked at previously, we show them all at once and illustrate a new Python function:![Figure 2.21: Calculating true negative and false positive rates and printing them
    ](image/B16925_02_21.jpg)

    图 2.21:计算真阴性和假阳性率并打印出来

    除了以与我们之前使用 TPR 和 FNR 类似的方式计算 TNR 和 FPR 之外，我们还演示了 Python 中的`print`函数以及用于字符串的`.format`方法，该方法允许在用花括号`{}`标记的位置替换变量。格式化数字有一系列选项，例如包括一定数量的小数位。

    注意

    更多详情，请参考[https://docs.python.org/3/tutorial/inputoutput.html](https://docs.python.org/3/tutorial/inputoutput.html)。

    现在，我们在这里学到了什么？事实上，我们的模型在所有样本中，无论是正样本还是负样本，都表现得与多数类零模型完全一样。很明显我们需要一个更好的模型。

    虽然我们在本练习中已经手动计算了混淆矩阵的所有条目，但在 scikit-learn 中有一种快速的方法可以做到这一点。注意，在 scikit-learn 中，真实类别沿着混淆矩阵的纵轴，而预测类别沿着混淆矩阵的横轴，正如我们之前所介绍的。

7.  Create a confusion matrix in scikit-learn with this code:

    ```py
    metrics.confusion_matrix(y_test, y_pred)
    ```

    您将获得以下输出:

    ![Figure 2.22: The confusion matrix for our example model
    ](image/B16925_02_22.jpg)

图 2.22:我们的示例模型的混淆矩阵

计算 TPR、FNR、TNR 和 FPR 所需的所有信息都包含在混淆矩阵中。我们还注意到，可以从混淆矩阵中导出更多的分类度量。事实上，其中一些实际上是我们在这里已经检查过的同义词。例如，TPR 也被称为**召回**和**灵敏度**。除了召回，另一个经常用于二进制分类的度量是**精度**:这是正确的肯定预测的比例(相对于正确预测的肯定样本的比例)。我们将在本章的活动中获得更多精确的经验。

注意

**多类分类**

我们的案例研究涉及一个二元分类问题，只有两种可能的结果:账户违约或不违约。机器学习分类问题的另一个重要类型是多类分类。在多类分类中，有几种可能的互斥结果。一个经典的例子是手写数字的图像识别；手写数字只能是 0，1，2，… 9 中的一个。虽然多类分类超出了本书的范围，但是我们现在学习的二元分类的度量可以扩展到多类设置。

## 发现预测概率:逻辑回归是如何预测的？

现在，我们已经熟悉了准确性、真假阳性和阴性以及混淆矩阵，我们可以探索使用逻辑回归的新方法来了解更高级的二进制分类指标。到目前为止，我们只将逻辑回归视为一个“黑盒”，它可以从标记的训练数据中学习，然后对新特征进行二元预测。虽然我们将在本书的后面详细了解逻辑回归的工作原理，但我们现在可以开始窥视黑盒内部了。

关于逻辑回归如何工作，需要理解的一点是，原始预测——换句话说，定义逻辑回归的数学方程的直接输出——不是二元标签。它们实际上是从 0 到 1 范围内的**概率**(尽管，从技术上来说，这个等式从不允许概率恰好等于 0 或 1，我们将在后面看到)。这些概率只能通过使用一个**阈值**转换成二元预测。阈值是一种概率，高于该值时，预测被宣布为正，低于该值时，预测为负。scikit-learn 中的阈值是 0.5。这意味着任何预测概率至少为 0.5 的样本被识别为阳性，而任何预测概率<为 0.5 的样本被判定为阴性。然而，我们可以随意使用任何阈值。事实上，选择阈值是逻辑回归的关键灵活性之一，其他估计类成员概率的机器学习分类算法也是如此。

## 练习 2.03:从训练好的逻辑回归模型中获得预测概率

在下面的练习中，我们将熟悉逻辑回归的预测概率，以及如何从 scikit-learn 模型中获得它们。

通过进一步检查我们在本章前面训练的逻辑回归模型对象上可用的方法，我们可以开始发现预测的概率。回想一下，以前，一旦我们训练了模型，我们就可以使用新样本的特征值进行二元预测，方法是将这些值传递给训练模型的`.predict`方法。这些预测是基于阈值为 0.5 的假设。

然而，我们可以使用`.predict_proba`方法直接访问这些样本的预测概率。执行以下步骤来完成练习，请记住，如果您要创建一个新笔记本，您将需要重新创建本章之前培训的相同模型:

注意

这个练习的 Jupyter 笔记本可以在这里找到:[https://packt.link/yDyQn](https://packt.link/yDyQn)。笔记本包含训练模型的先决步骤，应该在此处显示的第一步之前执行。

1.  Obtain the predicted probabilities for the test samples using this code:

    ```py
    y_pred_proba = example_lr.predict_proba(X_test)
    y_pred_proba
    ```

    输出应该如下所示:

    ![Figure 2.23: Predicted probabilities of the test data](image/B16925_02_23.jpg)

    图 2.23:测试数据的预测概率

    我们在这个输出中看到，我们已经存储在`y_pred_proba`中，有两列。这是因为在我们的分类问题中有两类:负面和正面。假设阴性标签编码为 0，阳性标签编码为 1，就像我们的数据一样，scikit-learn 会将阴性类别成员的概率报告为第一列，将阳性类别成员的概率报告为第二列。

    因为这两个类别是互斥的，并且是唯一的选项，所以对于每个样本，这两个类别的预测概率之和应该等于 1。我们来确认一下。

    首先，我们可以在第一维(列)上使用`np.sum`来计算每个样本的概率之和。

2.  Calculate the sum of predicted probabilities for each sample with this code:

    ```py
    prob_sum = np.sum(y_pred_proba,1)
    prob_sum
    ```

    输出如下所示:

    ```py
    array([1., 1., 1., ..., 1., 1., 1.])
    ```

    它看起来肯定全是 1。我们应该检查结果是否与测试数据标签数组的形状相同。

3.  Check the array shape with this code:

    ```py
    prob_sum.shape
    ```

    这将输出以下内容:

    ```py
    (5333,)
    ```

    好；这是预期的形状。现在，检查每个值是否为 1。我们使用`np.unique`来显示这个数组的所有独特元素。这类似于 SQL 中的`DISTINCT`。如果所有的概率和确实都是 1，那么概率数组应该只有一个唯一的元素:1。

4.  Show all unique array elements with this code:

    ```py
    np.unique(prob_sum)
    ```

    这将输出以下内容:

    ```py
    array([1.])
    ```

    在确认了我们对预测概率的信念之后，我们注意到由于类概率总和为 1，所以只考虑第二列就足够了，即正类成员的预测概率。让我们把它们放在一个数组里。

5.  Run this code to put the second column of the predicted probabilities array (predicted probability of membership in the positive class) in an array:

    ```py
    pos_proba = y_pred_proba[:,1]
    pos_proba
    ```

    输出应该如下所示:

    ![Figure 2.24: Predicted probabilities of positive class membership
    ](image/B16925_02_24.jpg)

    图 2.24:正类成员的预测概率

    这些概率看起来像什么？找出答案的一个方法，也是对模型输出的一个很好的诊断，是绘制预测的概率。直方图是一种自然的方法，为此我们可以使用 matplotlib 函数`hist()`。请注意，如果您执行一个只有直方图函数的单元格，您将得到在绘图之前返回的 NumPy 直方图函数的输出。这包括每个箱中的样本数量以及箱边缘的位置。

6.  Execute this code to see histogram output and an unformatted plot (not shown here):

    ```py
    plt.hist(pos_proba)
    ```

    输出如下所示:

    ![Figure 2.25: Details of histogram calculation
    ](image/B16925_02_25.jpg)

    图 2.25:直方图计算的细节

    这可能是对你有用的信息，也可以直接从`np.histogram()`函数中获得。然而，这里我们主要对情节感兴趣，所以我们调整了字体大小并添加了一些轴标签。

7.  Run this code for a formatted histogram plot of predicted probabilities:

    ```py
    mpl.rcParams['font.size'] = 12
    plt.hist(pos_proba)
    plt.xlabel('Predicted probability of positive class '\
               'for test data')
    plt.ylabel('Number of samples')
    ```

    情节应该是这样的:

    ![Figure 2.26: Histogram plot of predicted probabilities
    ](image/B16925_02_26.jpg)

    图 2.26:预测概率的直方图

    请注意，在概率直方图中，实际上只有四个箱中有样本，并且它们之间相隔相当远。这是因为`EDUCATION`特性只有四个唯一的值，这是我们的示例模型中唯一的特性。

    另外，注意所有的预测概率都低于 0.5。这就是使用 0.5 阈值预测每个样本为阴性的原因。我们可以想象，如果我们把阈值设在 0.5 以下，我们会得到不同的结果。例如，如果我们将阈值设置为 0.25，则图 2.26 中*最右边的最小容器中的所有样本都将被分类为阳性，因为所有这些样本的预测概率都高于 0.25。如果我们能看到这些样本中有多少实际上有阳性标记，这将对我们有所帮助。然后，我们可以通过将最右侧箱中的样本分类为阳性，来查看将阈值向下移动到 0.25 是否会提高分类器的性能。*

    事实上，我们可以使用**堆叠直方图**很容易地形象化这一点。这看起来很像*图 2.27* 中的直方图，除了负样本和正样本的颜色不同。首先，我们需要区分预测概率中的正样本和负样本。我们可以通过用逻辑掩码索引我们的预测概率数组来做到这一点；首先获取阳性样本，这里为`y_test == 1`，然后获取阴性样本，这里为`y_test == 0`。

8.  Isolate the predicted probabilities for positive and negative samples with this code:

    ```py
    pos_sample_pos_proba = pos_proba[y_test==1]
    neg_sample_pos_proba = pos_proba[y_test==0]
    ```

    现在我们想把这些绘制成一个堆积直方图。该代码类似于我们已经创建的直方图，除了我们将传递一个要绘制的数组列表，这是我们刚刚创建的正样本和负样本的概率数组，以及一个指示我们希望条形图堆叠而不是并排绘制的关键字。我们还将创建一个图例，以便在图上可以清楚地识别颜色。

9.  Plot a stacked histogram using this code:

    ```py
    plt.hist([pos_sample_pos_proba, neg_sample_pos_proba],\
              histtype='barstacked')
    plt.legend(['Positive samples', 'Negative samples'])
    plt.xlabel('Predicted probability of positive class')
    plt.ylabel('Number of samples')
    ```

    情节应该是这样的:

    ![Figure 2.27: Stacked histogram of predicted probabilities by class
    ](image/B16925_02_27.jpg)

图 2.27:分类预测概率的堆积直方图

该图向我们展示了每个预测概率的样本的真实标签。现在我们可以考虑将阈值降低到 0.25 会有什么影响。花点时间想想这意味着什么，记住任何预测概率达到或超过阈值的样本都将被归类为阳性。

由于在图 2.28 右侧的小容器中几乎所有的样本都是负样本，如果我们将阈值降低到 0.25，我们会错误地将这些样本归类为正样本，并增加我们的 FPR。与此同时，我们仍然无法正确地对许多阳性样本进行分类，因此我们的 TPR 根本不会增加太多。进行这种更改似乎会降低模型的准确性。

## 受试者工作特征(ROC)曲线

决定分类器的阈值是一个寻找“最佳点”的问题，在这个点上我们可以成功地恢复足够的真阳性，而不会导致太多的假阳性。随着门槛越来越低，两者都会更多。一个好的分类器将能够捕获更多的真阳性，而不会以大量的假阳性为代价。根据之前练习的预测概率，进一步降低阈值会有什么影响？原来在机器学习中有一个经典的可视化方法，有一个相应的度量可以帮助回答这类问题。

**接收器工作特性** ( **ROC** )曲线是一对 TPR(*y 轴*)和 FPR(*x 轴*)的曲线图，这是将阈值从 1 一直降低到 0 的结果。您可以想象，如果阈值为 1，则没有阳性预测，因为逻辑回归仅预测严格介于 0 和 1 之间的概率(不包括终点)。因为没有正面预测，TPR 和 FPR 都是 0，所以 ROC 曲线从(0，0)开始。随着阈值的降低，TPR 将开始增加，如果它是一个好的分类器，希望比 FPR 更快。最终，当阈值一直降低到 0 时，每个样本都被预测为阳性，包括实际上为阳性的所有样本，但也包括实际上为阴性的所有样本。这意味着 TPR 是 1，但是 FPR 也是 1。在这两个极端之间是您可能想要设置阈值的合理选择，这取决于针对所考虑的特定问题的真和假肯定和否定的相对成本和收益。通过这种方式，可以全面了解分类器在所有不同阈值下的性能，以决定使用哪一个阈值。

我们可以编写代码，通过使用预测概率并将阈值从 1 变到 0 来确定 ROC 曲线的 TPR 和 FPR。相反，我们将使用 scikit-learn 的便利功能，它将真实标签和预测概率作为输入，并返回 TPR、FPR 和导致它们的阈值的数组。然后，我们将绘制 TPR 与 FPR 的关系图，以显示 ROC 曲线。运行此代码，使用 scikit-learn 为 ROC 曲线生成 TPR 和 FPR 数组，如果需要，导入`metrics`模块:

```py
from sklearn import metrics
fpr, tpr, thresholds = metrics.roc_curve(y_test, pos_proba)
```

现在我们需要制作一个情节。我们将使用`plt.plot`，它将使用第一个参数作为 *x* 值(FPRs ),第二个参数作为 *y* 值(TPRs ),以及简写的`'*-'`,用星形符号表示数据点所在的线图。我们添加一个从(0，0)到(1，1)的直线图，它将以红色(`'r'`)和虚线(`'--'`)出现。我们还为该图赋予了一个图例(我们稍后将对此进行解释)，以及轴标签和标题。该代码生成 ROC 图:

```py
plt.plot(fpr, tpr, '*-')
plt.plot([0, 1], [0, 1], 'r--')
plt.legend(['Logistic regression', 'Random chance'])
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.title('ROC curve')
```

情节应该是这样的:

![Figure 2.28: ROC curve for our logistic regression, with a line 
of random chance shown for comparison
](image/B16925_02_28.jpg)

图 2.28:我们逻辑回归的 ROC 曲线，显示了一条随机机会线用于比较

我们从 ROC 曲线中学到了什么？我们可以看到，它从(0，0)开始，阈值足够高，因此没有肯定的分类。然后，正如我们先前在将阈值降低到大约 0.25 时所想象的那样，首先发生的是 FPR 增加，但是 TPR 增加很少。继续降低阈值的结果是，图 2.28 中*的堆积直方图中的其他条柱将被包含为阳性分类，这些结果由线条上的后续点显示。我们可以通过检查阈值阵列来查看导致这些比率的阈值，这不是该图的一部分。使用以下代码查看用于计算 ROC 曲线的阈值:*

```py
thresholds
```

输出应该如下所示:

```py
array([1.2549944 , 0.2549944 , 0.24007604, 0.22576598, 0.21207085]) 
```

请注意，第一个阈值实际上大于 1；实际上，它只是需要一个足够高的阈值，以至于没有积极的分类。

现在考虑一个“好的”ROC 曲线会是什么样子。当我们降低阈值时，我们希望看到 TPR 增加，这意味着我们的分类器在正确识别阳性样本方面做得很好。同时，理想情况下，FPR 不应该增加那么多。一个有效分类器的 ROC 曲线应该紧挨着图的左上角:高 TPR，低 FPR。你可以想象一个完美的分类器将得到 TPR 为 1(恢复所有的阳性样本)和 FPR 为 0，并显示为一种从(0，0)开始，向上到(0，1)并在(1，1)结束的正方形。虽然在实践中这种性能是极不可能的，但它给了我们一个极限情况。

进一步考虑这种分类器的曲线(AUC) 下的**面积是多少，如果你学过微积分的话，请记住它。完美分类器的 AUC 将是 1，因为曲线的形状将是单位区间[0，1]上的正方形。**

另一方面，在我们的图中标记为“随机机会”的线是 ROC 曲线，理论上是通过投掷无偏硬币作为分类器得到的:获得真阳性和假阳性的可能性一样大，所以降低阈值会以相等的比例引入更多的两者，TPR 和 FPR 以相同的速度增加。在这个 ROC 下的 AUC 将是完美分类器的一半，正如你在图中看到的，将是 0.5。

因此，总的来说，ROC AUC 将在 0.5 和 1 之间(尽管低于 0.5 的值在技术上是可能的)。接近 0.5 的值表示该模型作为分类器比随机机会(抛硬币)好不了多少，而接近 1 的值表示性能更好。 **ROC AUC** 是分类器质量的关键指标，广泛用于机器学习。ROC AUC 也可称为 **C 统计**(一致性统计)。

作为如此重要的指标，scikit-learn 提供了一种计算 ROC AUC 的简便方法。让我们看看逻辑回归分类器的 ROC AUC 是什么，在这里我们可以传递与传递给`roc_curve`函数相同的信息。用以下代码计算 ROC 曲线下的面积:

```py
metrics.roc_auc_score(y_test, pos_proba)
```

并观察输出:

```py
0.5434650477972642
```

逻辑回归的 ROC AUC 非常接近 0.5，这意味着它不是一个非常有效的分类器。这并不奇怪，考虑到我们没有花费精力去确定候选池中的哪些特性在这一点上实际上是有用的。我们刚刚习惯了模型拟合语法，并学习了使用一个只包含`EDUCATION`特性的简单模型来计算模型质量度量的方法。随后，通过考虑其他特征，我们有望获得更高的 ROC AUC。

注意

ROC 曲线:这个名字是怎么来的？

在第二次世界大战期间，对雷达接收机操作员的评估是基于他们判断出现在他们雷达屏幕上的东西实际上是否是敌机的能力。这些决定涉及到与我们对二元分类感兴趣的相同的真、假阳性和假阴性的概念。ROC 曲线被设计为一种测量雷达接收设备操作员效率的方法。

## 精度

在开始活动之前，我们将考虑之前简要介绍的分类度量:**精度**。像 ROC 曲线一样，这种诊断在阈值范围内是有用的。精度定义如下:

![Figure 2.29: Precision equation
](image/B16925_02_29.jpg)

图 2.29:精度方程

考虑对此的解释，在预测概率范围内改变阈值，就像我们对 ROC 曲线所做的那样。在高阈值时，预测为阳性的样本相对较少。随着我们降低门槛，越来越多的人会被预测为阳性。我们的希望是，随着我们这样做，真阳性的数量比假阳性的数量增加得更快，正如我们在 ROC 曲线上看到的那样。精度查看真阳性的数量与真阳性和假阳性之和的比率。想想这里的分母:真阳性和假阳性之和是多少？

这个总数实际上是肯定预测的总数，因为所有的肯定预测要么是正确的，要么是错误的。因此，精度衡量的是正确的正面预测与所有正面预测的比率。因此，它也被称为**阳性预测值**。如果阳性样本很少，precision 比 ROC AUC 对分类器的质量给出了更关键的评估。与 ROC 曲线一样，scikit 中有一个方便的函数——学习在一个阈值范围内计算精度和召回率(也称为 TPR):`metrics.precision_recall_curve`。精度和召回率通常一起绘制，以评估正面预测的质量，直到有多少部分是正确的，同时考虑正面 a 类模型能够识别多少部分。我们将在下面的活动中绘制一条精确回忆曲线。

为什么精度可能是分类器性能的有用度量？想象一下，对于每一个积极的模型预测，您都将采取一些昂贵的行动，例如对被自动化过程标记为不适当的内容进行耗时的审查。假阳性会浪费人类审查员的宝贵时间。您会希望确保您对哪些内容接受了详细审查做出了正确的决定。在这种情况下，精度可能是一个很好的度量标准。

## 活动 2.01:使用新功能进行逻辑回归，并创建精确召回曲线

在本活动中，您将使用除`EDUCATION`之外的一个特性来训练一个逻辑回归模型。然后，您将以图形方式评估精确度和召回率之间的权衡，并计算精确度-召回率曲线下的面积。您还将计算训练集和测试集的 ROC AUC，并对它们进行比较。

执行以下步骤来完成活动:

注意

这个活动的代码和结果输出已经加载到一个 Jupyter 笔记本中，可以在这里找到:[https://packt.link/SvAOD](https://packt.link/SvAOD)。

1.  使用 scikit-learn 的`train_test_split`制作一组新的训练和测试数据。这一次，使用账户的信用限额`LIMIT_BAL`作为特征，而不是`EDUCATION`。
2.  使用来自拆分的训练数据来训练逻辑回归模型。
3.  为测试数据创建预测概率数组。
4.  使用预测概率和测试数据的真实标签计算 ROC AUC。将其与使用`EDUCATION`功能获得的 ROC AUC 进行比较。
5.  绘制 ROC 曲线。
6.  使用 scikit-learn 的功能计算测试数据上的**精确召回曲线**的数据。
7.  使用 matplotlib 绘制精度-召回曲线。
8.  使用 scikit-learn 计算精确召回曲线下的面积。您应该得到大约为 0.315 的值。
9.  Now recalculate the ROC AUC, except this time do it for the training data. How is this different, conceptually and quantitatively, from your earlier calculation?

    注意

    包含 Python 代码解决方案的 Jupyter 笔记本可以在这里找到:[https://packt.link/SvAOD](https://packt.link/SvAOD)。通过[链接](B16925_Solution_ePub.xhtml#_idTextAnchor151)可以找到该活动的详细分步解决方案。

# 总结

在本章中，我们通过检查响应变量完成了对案例研究数据的初步探索。一旦我们对数据集的完整性和正确性有了信心，我们就准备探索特征和反应之间的关系，并建立模型。

本章的大部分时间我们都在习惯 scikit 中的模型拟合——在技术、编码级别学习，并学习可以用于案例研究的二进制分类问题的度量标准。当尝试不同的特性集和不同种类的模型时，您将需要某种方法来判断一种方法是否比另一种更好。因此，你需要使用像我们在本章中学到的模型性能度量。

虽然准确性是一个熟悉和直观的度量标准，即正确分类的百分比，但我们知道了为什么它可能无法对分类器的性能进行有用的评估。我们学习了如何使用多数类空模型来判断准确率是真的好，还是不比简单预测所有样本的最常见类好。当数据不平衡时，准确性通常不是判断分类器的最佳方式。

为了对一个模型的表现有更细致的了解，有必要区分积极和消极的类别，并独立评估它们的准确性。从真和假的肯定和否定分类的结果计数(可以在混淆矩阵中总结)中，我们可以导出几个其他度量:真和假的肯定和否定率。将真假阳性和阴性与预测概率和可变预测阈值的概念相结合，我们可以使用 ROC 曲线、精确召回曲线和这些曲线下的面积来进一步表征分类器的有用性。

有了这些工具，你就可以很好地回答关于二元分类器在你可能工作的任何领域中的性能的一般问题。在本书的后面，我们将了解通过将成本和收益与真的和假的肯定和否定联系起来来评估模型性能的特定于应用程序的方法。在此之前，从下一章开始，我们将开始学习可能是最流行和最简单的分类模型背后的细节:**逻辑回归**。