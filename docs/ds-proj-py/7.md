

# 7 .。测试集分析、财务洞察和向客户交付

概观

本章介绍了几种用于分析模型测试集的技术，以获得对未来可能的模型性能的洞察。这些技术包括我们已经计算过的相同模型性能指标，如 ROC AUC，以及新类型的可视化，如通过预测概率的箱倾斜违约风险和预测概率的校准。读完这一章，你将能够弥合机器学习的理论指标和商业世界的财务指标之间的差距。您将能够在评估模型的财务影响时确定关键的见解，并就如何实现这种影响向客户提供指导。最后，我们讨论了交付和部署模型时需要考虑的关键因素，例如交付的格式以及在使用模型时监控模型的方式。

# 简介

在上一章中，我们使用 XGBoost 将模型性能提升到了前所未有的高度，并学习了如何使用 SHAP 值解释模型预测。现在，我们将认为模型构建已经完成，并在将模型交付给客户之前解决需要注意的剩余问题。本章的关键要素是测试集的分析，包括财务分析，以及向希望在现实世界中使用模型的客户交付模型时要考虑的事情。

我们查看测试集，以了解模型在未来的表现如何。通过计算我们已经知道的指标，如 ROC AUC，但现在在测试集上，我们可以确信我们的模型将对新数据有用。我们还将学习一些直观的方法来可视化模型的能力，将客户分组到不同的违约风险水平，例如十分位数图。

您的客户可能会感谢您在创建更准确的模型或 ROC AUC 更高的模型方面所做的努力。然而，他们肯定会感谢理解该模型可以帮助他们赚多少钱或节省多少钱，并且可能会很乐意接受关于如何最大化该模型在这方面的潜力的具体指导。测试集的财务分析可以模拟基于模型的策略的不同场景，并帮助客户选择适合他们的策略。

在完成财务分析之后，我们将讨论如何交付一个模型供客户使用，以及如何监控其性能。

# 建模结果回顾

为了开发一个二元分类模型来满足我们客户的业务需求，我们现在已经尝试了几种建模技术，并取得了不同程度的成功。最后，我们希望选择性能最佳的型号来做进一步的分析并展示给我们的客户。然而，交流我们探索的其他选项也是很好的，展示一个经过彻底研究的项目。

在这里，我们回顾我们为案例研究问题尝试的不同模型、我们需要调整的超参数以及交叉验证的结果，或者 XGBoost 案例中的验证集。我们只包括我们使用所有可能的特性所做的工作，而不包括我们只使用一两个特性的早期探索模型:

![Figure 7.1: Summary of modeling activities with case study data
](image/B16392_07_01.jpg)

图 7.1:使用案例研究数据的建模活动总结

当向客户展示结果时，您应该准备好向所有技术熟悉程度的业务合作伙伴解释这些结果，包括那些几乎没有技术背景的合作伙伴。例如，业务合作伙伴可能不理解 ROC AUC 度量的推导过程；然而，这是一个重要的概念，因为它是我们用来评估模型的主要性能指标。你可能需要解释这是一个可以在 0.5 和 1 之间变化的度量，并对这些限制给出直观的解释:0.5 不比抛硬币好，1 是完美的，这基本上是无法实现的。

我们的结果介于两者之间，用我们开发的最佳模型接近 0.78。虽然给定模型的 ROC AUC 本身不一定有意义，但图 7.1 显示我们已经尝试了几种方法，并取得了比最初尝试更好的性能。最后，对于像案例研究这样的业务应用程序，如果可能的话，ROC AUC 这样的抽象模型性能指标应该附有财务分析。我们将在本章后面探讨这一点。

注:关于解释 ROC AUC

ROC AUC 评分的一个有趣解释是，对于两个样本，一个具有阳性结果，一个具有阴性结果，阳性样本的预测概率高于阴性样本。换句话说，对于正在评估的数据集中所有可能的阳性和阴性样本对，阳性样本比阴性样本具有更高模型预测的配对比例等于 ROC AUC。

从*图 7.1* 中，我们可以看到，对于案例研究，我们在创建更复杂的**模型**时所做的努力，无论是通过在简单的逻辑回归中添加新功能，还是通过创建决策树集合，都产生了更好的模型性能。特别是，随机森林和 XGBoost 模型表现相似，尽管这些验证分数在技术上不可直接比较，因为在随机森林的情况下，我们排除了缺失值并使用了 4 重交叉验证，而对于 XGBoost，缺失值被包括在内，并且只有一个用于早期停止的验证集。然而，*图 7.1* 表明 XGBoost 或 random forest 可能是最佳选择。我们将继续使用 XGBoost 模型。

既然我们已经决定了我们将交付哪个模型，那么考虑一下我们在模型开发过程中可能已经尝试过的额外的事情是很好的。这些概念不会在本书中探讨，但是你可以自己尝试一下。

## 特色工程

我们简单提到的另一种提高模型性能的方法是**特征工程**。虽然我们使用 scikit-learn 的自动化功能设计功能来制作交互功能，但您也可以从现有功能中手动设计功能。例如，信用帐户使用了其信用限额的很大一部分，这可能被认为是特别有风险的。我们的功能中有关于信用额度的信息，也有过去账单的金额。事实上，我们在*活动 6.01* 、*中训练的 XGBoost 模型中最重要的特性是信用额度特性`LIMIT_BAL`。与此交互最强的特性是两个月前的账单金额。虽然 XGBoost 可以找到这样的交互，并在某种程度上对它们进行建模，但我们也可以设计一个新的特性:过去每月的账单金额与信用限额的比率，假设账单金额是帐户的余额。这种对**信用利用率**的测量可能是一种更强的特性，并且当以这种方式计算时，比单独为模型提供信用限额和每月账单金额会产生更好的模型性能。*

特征工程可能采取操纵现有特征以制造新特征的形式，如在前面的例子中，或者它可能涉及引入全新的数据源并利用它们创建特征。

新功能的灵感可能来自领域知识:与你的业务伙伴就他们认为好的功能进行对话会非常有帮助，特别是如果他们比你对你的应用程序有更多的领域知识。检查现有功能的交互也可以是假设新功能的一种方式，例如我们如何在*活动 6.01* 、*中看到似乎与信用利用有关的交互，用 XGBoost 对案例研究数据建模，用 SHAP* 解释模型。

## 集合多个模型

在为案例研究项目选择最终的交付模型时，交付 random forest 或 XGBoost 可能都没问题。机器学习中另一种常用的方法是**集成**多个模型。这意味着组合不同模型的预测，类似于 random forest 和 XGBoost 如何组合许多决策树。但在这种情况下，组合模型预测的方式取决于数据科学家。创建模型集合的一个简单方法是取它们预测的平均值。

当存在多个模型时，通常会进行集成，这些模型可能是不同种类的模型，或者是具有不同特征的模型，它们都具有良好的性能。在我们的例子中，使用来自随机森林和 XGBoost 的平均预测可能比任何一个单独的模型都有更好的性能。为了探究这一点，我们可以在一个验证集上比较性能，例如，在 XGBoost 中用于提前停止的验证集。

## 不同的建模技术

根据你在一个项目上有多少时间以及你在不同建模技术上的专业知识，你会想尝试尽可能多的方法。更先进的方法，如用于分类的神经网络，可能在这个问题上产生改进的性能。我们鼓励你继续学习，学习如何使用这些模型。然而，对于表格数据，比如我们在案例研究中所用的表格数据，XGBoost 是一个很好的事实上的选择，即使不是所有方法中性能最好的，也可能提供出色的性能。

## 平衡类

请注意，我们没有解决响应变量中的类别不平衡问题。鼓励您尝试使用 scikit-learn 中的`class_weight='balanced'`选项或使用 XGBoost 中的`scale_pos_weight`超参数来拟合模型，以查看效果。

虽然这些是进一步模型开发的有趣途径，但是对于本书来说，我们已经完成了模型构建。我们将继续在测试集上检查 XGBoost 模型的性能。

# 在测试集上模拟性能

从验证集中，我们已经对 XGBoost 模型的样本外性能有了一些概念。但是，通过提前停止，验证集被用于模型拟合。我们可以对预期的未来绩效做出的最严格的估计，应该使用根本没有用于模型拟合的数据来创建。这就是在模型构建过程中保留测试数据集的原因。

你可能会注意到，我们已经在一定程度上检查了测试集，例如，在第一章评估数据质量和进行数据清理时。预测建模的黄金标准是在项目的最开始留出一个测试集，在模型完成之前根本不检查它。这是确保在模型开发过程中没有来自测试集的知识“泄露”到训练集中的最简单的方法。当这种情况发生时，它打开了测试集不再是未来未知数据的现实表示的可能性。然而，有时一起探索和清理所有数据是很方便的，正如我们所做的那样。如果测试数据与其他数据具有相同的质量问题，那么就不会有泄漏。当您决定使用哪些特性、适合不同的模型以及比较它们的性能时，确保您不是在看测试集是最重要的。

我们从加载来自*活动 6.01* 、*的训练模型开始测试集检查，用 XGBoost 建模案例研究数据，用 SHAP* 解释模型，以及训练和测试数据和特性名称，使用 Python 的`pickle`:

```
with open('../../Data/xgb_model_w_data.pkl', 'rb') as f:
    features_response, X_train_all, y_train_all, X_test_all,\
    y_test_all, xgb_model_4 = pickle.load(f)
```

将这些变量加载到笔记本中，我们就可以对测试集进行预测和分析。首先获得测试集的预测概率:

```
test_set_pred_proba = xgb_model_4.predict_proba(X_test_all)[:,1]
```

现在从 scikit-learn 导入 ROC AUC 计算例程，用它来计算测试集的这个指标，并显示它:

```
from sklearn.metrics import roc_auc_score
test_auc = roc_auc_score(y_test_all, test_set_pred_proba)
test_auc
```

结果应该如下所示:

```
0.7735528979671706
```

测试集上的 ROC AUC 0.774 比我们在 XGBoost 模型的验证集上看到的 0.779 低一点；然而，它并没有很大的不同。由于模型拟合过程优化了模型在验证集上的性能，所以看到新数据的性能有所下降并不完全令人惊讶。总体而言，测试性能符合预期，我们可以认为该模型在 ROC AUC 指标方面测试成功。

虽然我们不会在这里这样做，但在交付一个训练好的模型之前，最后一步可能是让它适合所有可用的数据，包括看不见的测试集。这可以通过连接训练和测试数据特征(`X_train_all`、`X_test_all`)和标签(`y_train_all`、`y_test_all`)，并使用它们来拟合新的模型来完成，或许通过定义用于提前停止的新的验证集或使用当前的测试集来实现该目的。这种方法的动机是机器学习模型在更多数据上训练时通常表现更好。不利的一面是，由于在这些情况下没有看不见的测试集，最终的模型可能被认为是未经测试的。

数据科学家对使用哪种方法有不同的看法:只使用看不见的测试集进行模型评估，还是在过程中的所有先前步骤完成后，使用尽可能多的数据(包括测试集)来训练最终模型。一个考虑因素是模型是否会受益于更多数据的训练。这可以通过构建**学习曲线**来确定。虽然我们不会在这里说明这一点，但学习曲线背后的概念是在连续增加的数据量上训练模型，并在相同的验证集上计算验证分数。例如，如果您有 10，000 个训练样本，您可以留出 500 个作为验证集，然后在前 1，000 个样本上训练模型，然后是前 2，000 个样本，依此类推，直到不在验证集中的所有 9，500 个样本。如果对更多数据的训练持续增加验证分数，甚至达到使用所有可用数据的程度，这是一个信号，表明对比训练集中更多的数据进行训练将是有益的。然而，如果模型性能在某个点开始变得平稳，并且额外的数据似乎不会创建一个更高性能的模型，您可能不需要这样做。学习曲线可以指导测试集采用哪种方法，以及项目中是否需要更多的数据。

出于案例研究的目的，我们将假设我们不会从使用测试集改装模型中获得任何好处。因此，我们现在主要关注的是向客户展示模型，帮助他们设计一个策略来使用它来满足他们的业务目标，并提供如何随着时间的推移监控模型性能的指导。

## 预测概率分布及十分位数图

ROC AUC 指标很有帮助，因为它提供了一个概括数据集模型性能的数字。然而，查看不同人群子集的模型性能也是很有见地的。将总体分成子集的一种方法是使用模型预测本身。使用测试集，我们可以用直方图可视化预测的概率:

```
mpl.rcParams['figure.dpi'] = 400
plt.hist(test_set_pred_proba, bins=50)
plt.xlabel('Predicted probability')
plt.ylabel('Number of samples')
```

该代码应产生以下图形:

![Figure 7.2: Distribution of predicted probabilities for the test set
](image/B16392_07_02.jpg)

图 7.2:测试集的预测概率分布

测试集的预测概率直方图显示，大多数预测都聚集在范围`[0, 0.2]`内。换句话说，根据该模型，大多数借款人的违约几率在 0%到 20%之间。然而，似乎有一小部分借款人风险较高，集中在 0.7 附近。

检查不同预测违约风险区域的模型性能的直观方法是创建一个十分位数图表，该图表根据预测概率的十分位数将借款人分组。在每个十分位数内，我们可以计算出真实的违约率。我们预计违约率将从最低预测值稳步上升至最高值。

我们可以像在*练习 6.01* 、*中一样计算十分位数，使用 pandas 的`qcut`:*

```
deciles, decile_bin_edges = pd.qcut(x=test_set_pred_proba,\
                                    q=10,\
                                    retbins=True)
```

这里我们分割测试集的预测概率，用关键字参数`x`提供。我们希望将它们分成 10 个大小相等的箱，预测概率的底部 10%在第一个箱中，依此类推，因此我们表示我们想要`q=10`个分位数。但是，您可以拆分成任意数量的箱，例如 20 个(五分位数)或 5 个(五分位数)。因为我们指定了`retbins=True`，所以 bin 边缘在`decile_bin_edges`变量中返回，而十分位数标签系列在`deciles`中。我们可以检查创建 10 个箱所需的 11 个箱边:

```
decile_bin_edges
```

应该会产生这样的结果:

```
array([0.02213463, 0.06000734, 0.08155108, 0.10424594, 0.12708404,
       0.15019046, 0.18111563, 0.23032923, 0.32210371, 0.52585585,
       0.89491451])
```

为了利用`decile`系列，我们可以将它与测试集的真实标签和预测概率组合成一个数据框架:

```
test_set_df = pd.DataFrame({'Predicted probability':test_set_pred_proba,\
                            'Prediction decile':deciles,\
                            'Outcome':y_test_all})
test_set_df.head()
```

数据帧的前几行应该如下所示:

![Figure 7.3: DataFrame with predicted probabilities and deciles
](image/B16392_07_03.jpg)

图 7.3:带有预测概率和十分位数的数据框架

在数据框中，我们可以看到每个样本都标有一个十分位数，用包含预测概率的十分位数的边缘来表示。结果显示了真正的标签。我们想要在十分位数图表中显示的是十分位数区间内的真实违约率。为此，我们可以利用熊猫的能力。首先，我们创建一个`groupby`对象，通过在`decile`列上分组我们的数据帧:

```
test_set_gr = test_set_df.groupby('Prediction decile')
```

`groupby`对象可以由其他列聚合。特别是，这里我们对十分位数范围内的违约率感兴趣，这是`outcome`变量的平均值。我们还计算每个箱中数据的数量。由于分位数(如十分位数)将人口分组到大小相等的箱中，因此我们期望计数相同或相似:

```
gr_df = test_set_gr.agg({'Outcome':['count', 'mean']})
```

检查我们的分组数据帧:

![Figure 7.4: Default rate in deciles of predicted probability on the test set
](image/B16392_07_04.jpg)

图 7.4:测试集上预测概率的十分位数的违约率

在*图 7.4* 中，我们可以看到，实际上所有箱中的计数几乎相等。我们还可以看出，真实违约率随着十分位数的增加而增加，正如我们所希望和预期的那样，因为我们知道我们的模型具有良好的性能。在可视化数据之前，值得注意的是这个数据帧有一种特殊的列索引，称为 **multiindex** 。注意，有两行文本描述了这些列，一个顶级索引只包含一个标签`Outcome`，另一个二级索引包含标签`count`和`mean`。访问具有多索引的数据帧中的数据比我们之前使用的数据帧稍微复杂一些。我们可以按如下方式显示列索引:

```
gr_df.columns
```

这将产生以下结果:

```
MultiIndex([('Outcome', 'count'),
            ('Outcome',  'mean')],
           )
```

这里我们可以看到，要从多索引中访问一个列，我们需要使用元组来指定索引的每个级别，例如，`gr_df[('Outcome','count')]`。虽然这里 MultiIndex 并不是真正必要的，因为我们只做了一个列的聚合(`Outcome`)，但是当有多个列的聚合时，它会派上用场。

现在，我们想创建一个可视化，显示模型预测如何做好宁滨借款人分组与持续增加的违约风险。我们将显示每个仓位的计数，以及每个仓位的违约风险。因为这些列的标度不同，计数以百计，风险在 0 到 1 之间，所以我们应该使用双 *y* 轴图。为了对绘图外观有更多的控制，我们将使用 Matplotlib 函数创建这个绘图，而不是通过 pandas。首先，我们创建每个箱中样本大小的图，为了清晰起见，用与图相同的颜色标记 *y* 轴刻度。如果你阅读的是黑白的，请查看 GitHub 上的笔记本，因为颜色对这个情节很重要。这段代码应该与下一个代码在同一个单元格中运行。在这里，我们创建一组轴，然后向其中添加一个绘图以及一些格式和注释:

```
ax_1 = plt.axes()
color_1 = 'tab:blue'
gr_df[('Outcome', 'count')].plot.bar(ax=ax_1, color=color_1)
ax_1.set_ylabel('Count of observations', color=color_1)
ax_1.tick_params(axis='y', labelcolor=color_1)
ax_1.tick_params(axis='x', labelrotation = 45)
```

请注意，我们正在为样本大小创建一个`bar`图。我们想要添加一个线图，在右边的 *y* 轴上显示每个 bin 中的默认比率，但与现有图的 *x* 轴相同。Matplotlib 为此提供了一个名为`twinx`的方法，可以在一个`axes`对象上调用该方法来返回一个共享同一 *x* 轴的新 axes 对象。我们采取类似的步骤，然后绘制默认利率并进行注释:

```
ax_2 = ax_1.twinx()
color_2 = 'tab:red'
gr_df[('Outcome', 'mean')].plot(ax=ax_2, color=color_2)
ax_2.set_ylabel('Default rate', color=color_2)
ax_2.tick_params(axis='y', labelcolor=color_2)
```

在一个代码单元中运行前面的两个代码片段后，应该会出现下面的图:

![Figure 7.5: Default rate according to model prediction decile
](image/B16392_07_05.jpg)

图 7.5:根据模型预测十分位数的违约率

*图 7.5* 包含的信息与*图 7.4* 中数据框显示的信息相同，但呈现方式更好。很明显，违约风险随着每十分位数的增加而增加，风险最高的 10%借款人的违约率接近 70%，但风险最低的低于 10%。当一个模型能够有效地区分违约风险持续增加的借款人群体时，这个模型被称为**倾斜**被检验的人群。还要注意的是，违约率在最低的 5 到 7 个十分位数之间相对平稳，这可能是因为这些观察结果大多集中在预测风险的范围[0，0.2]内，如图 7.2 中的直方图所示。

从倾斜违约风险的角度来看，将测试集分成相同人口的十分位数是检验模型性能的一种方式。然而，客户可能有兴趣查看不同组的违约率，例如等间隔仓(例如，将预测范围[0，0.2]，[0.2，0.4]等中的所有观察值宁滨在一起，而不考虑每个仓中的样本大小)，或一些其他方式。在下面的练习中，你将探索如何在熊猫身上轻松做到这一点。

在下面的练习中，我们将利用几个统计概念来帮助创建误差线，包括我们之前了解过的平均值的**标准误差，以及二项式分布**的**正态近似。**

我们从*第五章*、*决策树和随机森林*中得知，我们可以将样本均值的方差估计为![1](image/B16925_06_Equation1.png)，其中 *n* 是样本大小，![2](image/B16925_06_Equation2.png)是理论上较大总体的未观测方差。虽然我们不知道![3](image/B16925_06_Equation3.png)，但是可以通过我们观察到的样本的方差来估计。对于二元变量，样本方差可以计算为 *p(1-p)* ，其中 *p* 是成功的比例，或者是案例研究的默认值。给定上面样本均值方差的公式，我们可以代入观察到的方差，然后求平方根得到均值的标准差:![4](image/B16925_06_Equation4.png)。在某些情况下，该公式也被称为二项式分布的正态近似。下面我们将使用它在不同模型预测区间的违约率等间隔图上创建误差线。关于这些概念的更多细节，我们鼓励你查阅统计学教科书。

## 练习 7.01:等间隔图表

在本练习中，您将制作一个类似于*图 7.5* 所示的图表；然而，您将使用预测概率的相等间隔，而不是将测试集分割成预测概率的相等人口十分位数。如果业务合作伙伴希望考虑使用特定得分范围的潜在基于模型的策略，指定间隔可能会有所帮助。您可以使用 pandas `cut`来创建等间隔面元，或者使用面元边缘的阵列来定制面元，类似于您如何使用`qcut`来创建分位数标签:

注意

你可以在 https://packt.link/4Ev3n 找到这个练习的 Jupyter 笔记本。

1.  Create the series of equal-interval labels, for 5 bins, using the following code:

    ```
    equal_intervals, equal_interval_bin_edges = \
        pd.cut(x=test_set_pred_proba,\
               bins=5,\
               retbins=True)
    ```

    注意，这类似于对`qcut`的调用，除了在这里用`cut`我们可以通过向`bins`参数提供一个整数来表示我们想要多少个等间隔的仓。您还可以为此参数提供一个数组，以指定自定义容器的容器边缘。

2.  Examine the equal-interval bin edges with this code:

    ```
    equal_interval_bin_edges
    ```

    结果应该如下所示:

    ```
    array([0.02126185, 0.1966906 , 0.37124658, 0.54580256, 0.72035853,
           0.89491451])
    ```

    您可以通过从第一个到倒数第二个项目的子数组中减去从第二个开始到最后的子数组，来确认这些条块边缘之间的间隔相等。

3.  Check the intervals between bin edges like this:

    ```
    equal_interval_bin_edges[1:] - equal_interval_bin_edges[:-1]
    ```

    结果应该是这样的:

    ```
    array([0.17542876, 0.17455598, 0.17455598, 0.17455598, 0.17455598])
    ```

    您可以看到，箱子边缘之间的距离大致相等。第一个箱边缘比最小预测概率小一点，您可以自己确认。

    为了创建一个类似于*图 7.5* 的图，首先我们需要将 bin 标签和响应变量放在一个数据帧中，就像我们之前对十分位数标签所做的那样。我们也将预测的概率放在数据框中以供参考。

4.  Make a DataFrame of predicted probabilities, bin labels, and the response variable for the test set like this:

    ```
    test_set_bins_df =\
    pd.DataFrame({'Predicted probability':test_set_pred_proba,\
                  'Prediction bin':equal_intervals,\
                  'Outcome':y_test_all})
    test_set_bins_df.head()
    ```

    结果应该如下所示:

    ![Figure 7.6: DataFrame with equal-interval bins
    ](image/B16392_07_06.jpg)

    图 7.6:具有等间隔条柱的数据帧

    我们可以使用这个数据帧按照 bin 标签进行分组，然后获得我们感兴趣的指标:代表默认速率和每个 bin 中的样本数的聚合。

5.  Group by the bin label and calculate the default rate and sample count within bins with this code:

    ```
    test_set_equal_gr = test_set_bins_df.groupby('Prediction bin')
    gr_eq_df = test_set_equal_gr.agg({'Outcome':['count', 'mean']})
    gr_eq_df
    ```

    生成的数据帧应该如下所示:

    ![Figure 7.7: Grouped data for five equal-interval bins
    ](image/B16392_07_07.jpg)

    图 7.7:五个等间隔箱的分组数据

    注意，这里与分位数不同，每个箱中有不同数量的样本。违约率似乎以一致的方式在各仓位间增加。让我们绘制这个数据帧，创建一个类似于*图 7.5* 的可视化。

    在创建此可视化之前，为了考虑到违约率的估计值对于较高的预测概率可能不太稳健，由于这些范围内的样本量减少，我们将计算违约率的标准误差。

6.  Calculate the standard errors of the default rates within bins using this code:

    ```
    p = gr_eq_df[('Outcome', 'mean')].values
    n = gr_eq_df[('Outcome', 'count')].values
    std_err = np.sqrt(p * (1-p) / n)
    std_err
    ```

    结果应该如下所示:

    ```
    array([0.00506582, 0.01258848, 0.02528987, 0.02762643, 0.02683029])
    ```

    请注意，对于分数范围较高且样本较少的条柱，标准误差较大。将这些标准误差与默认汇率可视化会很有帮助。

7.  Use this code to create an equal-interval plot of default rate and sample size. The code is very similar to that needed for *Figure 7.5*, except here we include error bars on the default rate plot using the `yerr` keyword and the results from the previous step:

    ```
    ax_1 = plt.axes()
    color_1 = 'tab:blue'
    gr_eq_df[('Outcome', 'count')].plot.bar(ax=ax_1, color=color_1)
    ax_1.set_ylabel('Count of observations', color=color_1)
    ax_1.tick_params(axis='y', labelcolor=color_1)
    ax_1.tick_params(axis='x', labelrotation = 45)
    ax_2 = ax_1.twinx()
    color_2 = 'tab:red'
    gr_eq_df[('Outcome', 'mean')].plot(ax=ax_2, color=color_2,
                                       yerr=std_err)
    ax_2.set_ylabel('Default rate', color=color_2)
    ax_2.tick_params(axis='y', labelcolor=color_2)
    ```

    结果应该是这样的:

    ![Figure 7.8: Plot of default rate and sample count for equal-interval bins
    ](image/B16392_07_08.jpg)

图 7.8:等间隔箱的默认速率和样本计数图

我们可以在*图 7.8* 中看到，与分位数方法相比，不同箱中的样本数量差异很大。虽然在较高分数仓中有相对较少的样本，导致较大的标准误差，但与违约率从较低分数仓向较高分数仓增加的总体趋势相比，违约率图上的误差条仍然较小，因此我们可以对这一趋势充满信心。

## 预测概率的校准

*图 7.8* 的一个有趣的特征是，违约率的线图从一个仓位到另一个仓位增加了大致相同的量。与*图 7.5* 中的十分位数图形成对比，在该图中，违约率开始缓慢上升，然后上升得更快。还要注意，默认利率似乎大致是每个仓位的预测概率边缘的中点。这意味着默认比率类似于每个箱中的平均模型预测。换句话说，正如 ROC AUC 所量化的，我们的模型似乎不仅有效地将借款人从低到高的违约风险进行了排序，而且似乎还准确地预测了违约概率。

测量预测概率与实际概率的接近程度是**校准** **概率**的目标。概率校准的标准测量遵循上述概念，称为**预期校准误差** ( **ECE** )，定义为

![Figure 7.9: Expected Calibration Error
](image/B16392_07_09.jpg)

图 7.9:预期校准误差

其中，索引 *i* 的范围从 1 到箱数( *N* )， *F* i 是落入箱 *i* ， *o* i 是箱 *i* 中样本为正的部分(即，对于案例研究，违约者)，而 *e* i 是箱 *i 内预测概率的平均值*

我们可以使用非常类似于*图 7.4* 中所示的数据框架来计算测试集十分位数区间内预测概率的 ECE，这是创建十分位数图表所需要的。我们需要的唯一加法是每个箱中的平均预测概率。创建这样一个数据帧，如下所示:

```
cal_df = test_set_gr.agg({'Outcome':['count', 'mean'],\
                          'Predicted probability':'mean'})
cal_df
```

输出数据帧应该如下所示:

![Figure 7.10: DataFrame for calculating the ECE metric
](image/B16392_07_10.jpg)

图 7.10:计算 ECE 指标的数据框架

为了方便起见，让我们为`F`定义一个变量，它是每个箱中样本的分数。这是来自上述数据帧的每个箱中的计数除以样本总数，取自测试集的响应变量的形状:

```
F = cal_df[('Outcome', 'count')].values/y_test_all.shape[0]
F
```

输出应该是这样的:

```
array([0.10003368, 0.10003368, 0.10003368, 0.09986527, 0.10003368,
       0.10003368, 0.09986527, 0.10003368, 0.10003368, 0.10003368])
```

因此，每个箱有大约 10%的样本。当然，这是意料之中的，因为箱是使用分位数方法创建的。然而，对于其他分组，分组中的样本大小可能不相等。现在让我们用代码实现 ECE 的公式来计算这个指标:

```
ECE = np.sum(
    F
    * np.abs(
             cal_df[('Outcome', 'mean')]
             - cal_df[('Predicted probability', 'mean')]))
ECE
```

输出应该是这样的:

```
0.008144502190176022
```

这个数字代表我们最终模型在测试集上的 ECE。这个数字本身并不那么有意义。然而，在模型投入生产并在现实世界中使用之后，可以随着时间的推移对这样的指标进行监控。如果 ECE 开始增加，这是模型校准程度降低的迹象，可能需要重新训练，或者对输出应用校准程序。

检查测试集预测概率校准的一种更直观的方法是绘制 ECE 所需的成分，特别是响应变量的真实违约率，与每个箱中模型预测的平均值相对比。对此，我们添加一条 1-1 线，代表完美校准，作为参考点:

```
ax = plt.axes()
ax.plot([0, 0.8], [0, 0.8], 'k--', linewidth=1,
        label='Perfect calibration')
ax.plot(cal_df[('Outcome', 'mean')],\
        cal_df[('Predicted probability', 'mean')],\
        marker='x',\
        label='Model calibration on test set')
ax.set_xlabel('True default rate in bin')
ax.set_ylabel('Average model prediction in bin')
ax.legend()
```

结果图应该如下所示:

![Figure 7.11: Calibration plot for predicted probabilities
](image/B16392_07_11.jpg)

图 7.11:预测概率的校准图

*图 7.11* 显示，模型预测的概率非常接近真实的违约率，因此模型看起来校准良好。为了获得更多的见解，您可以尝试自己在该图中添加误差线作为练习。还要注意，scikit-learn 提供了一个函数，用于计算创建*图 7.11* : `sklearn.calibration.calibration_curve`所需的信息。但是，该函数不会返回每个箱中的样本大小。

概率校准需要注意的另一点是，一些处理类不平衡的方法(如过采样或欠采样)会改变训练数据集中的类分数，这将影响预测的概率，并可能使它们不太准确。不过，根据客户的需求，与该模型根据借款人的违约风险(由 ROC AUC 衡量)对其进行评级的能力相比，这可能并不那么重要。

# 财务分析

到目前为止，我们计算的模型性能指标是基于可以应用于分析任何分类模型的抽象度量:模型的准确性，模型在不同阈值(ROC AUC)下识别真阳性相对于假阳性的熟练程度，阳性预测的正确性(精度)，或直观度量，如倾斜风险。这些指标对于理解模型的基本工作非常重要，并且在机器学习社区中被广泛使用，因此理解它们非常重要。然而，对于一个模型到业务用例的应用，我们不能总是直接使用这样的性能度量来创建一个关于如何使用模型来指导业务决策的策略，或者计算出一个模型期望创建多少价值。为了更进一步，将预测概率和阈值的数学世界与成本和收益的商业世界联系起来，通常需要某种财务分析。

为了帮助客户进行这种分析，数据科学家需要根据模型做出的预测，了解可能会采取何种决策和行动。这应该是与客户谈话的主题，最好是在项目生命周期的早期。我们把它留到了本书的结尾，这样我们就可以对什么是预测建模以及它是如何工作的有一个基本的了解。然而，在项目开始时了解模型使用的业务环境，允许您根据价值的创造来设定模型性能的目标，您可以在整个项目中跟踪它，就像我们跟踪我们构建的不同模型的 ROC AUC 一样。将模型性能指标转化为财务术语是本节的主题。

对于案例研究中的二元分类模型，数据科学家需要知道以下几个问题的答案，以帮助客户了解如何使用该模型:

*   客户希望使用模型来帮助他们做出什么样的决策？
*   如何使用二元分类模型的预测概率来帮助做出这些决定？
*   它们是肯定/否定的决定吗？如果是这样，那么选择预测概率的单个阈值就足够了。
*   根据模型结果，是否将决定两个以上的活动级别？如果是这样的话，那么选择两个或更多的阈值，例如，将预测分为低、中、高风险，可能是解决方案。例如，低于 0.5 的预测概率可以被认为是低风险，介于 0.5 和 0.75 之间的预测概率是中等风险，高于 0.75 的预测概率是高风险。
*   根据模型指导，采取所有可用的不同行动方案的成本是多少？
*   由于模型指导而采取的成功行动的潜在好处是什么？

## 与客户的金融对话

我们向案例研究客户询问上述要点，并了解到以下情况:对于违约风险高的信用账户，客户正在设计一个新的计划，为账户持有人提供个性化咨询，鼓励他们按时支付账单，或者在无法支付时提供替代支付选项。信贷咨询由在呼叫中心工作的训练有素的客户服务代表进行。每次咨询的费用是新台币 7，500 元，一次咨询的预期成功率是 70%，这意味着平均 70%的电话咨询接收者将按时支付账单，或做出债权人可以接受的替代安排。成功咨询的潜在好处是，如果咨询的结果是一个账户将要违约，但没有违约，那么这个账户每月的账单金额将会变成储蓄。目前，拖欠账户的月账单被报告为损失。

在与客户进行了前面的对话之后，我们就有了进行财务分析所需的材料。客户希望我们帮助他们决定联系哪些成员并提供信用咨询。如果我们能帮助他们缩小需要咨询的人的范围，我们就能通过避免不必要的和昂贵的联系来帮助他们省钱。客户有限的咨询资源将更恰当地花在违约风险较高的账户上。由于防止了违约，这将创造更大的节约。此外，客户让我们知道我们的分析可以帮助他们申请咨询项目的预算，如果我们能让他们知道提供多少次咨询是值得的。

当我们继续进行财务分析时，我们看到该模型将帮助客户在逐个账户的基础上做出的决定是一个是/否的决定:是否向给定账户的持有人提供咨询。因此，我们的分析应该集中在找到一个适当的预测概率阈值，据此我们可以将我们的账户分为两组:将接受咨询的高风险账户和不接受咨询的低风险账户。

## 练习 7.02:描述成本和节约的特征

模型输出和客户将做出的商业决策之间的联系归结为选择预测概率的阈值。因此，在本练习中，我们将描述咨询计划的预期成本，即提供个别咨询服务的成本，以及在一系列阈值下防止违约的预期节省。在每个阈值上有不同的成本和节省，因为每个阈值预计会导致不同数量的肯定预测，以及这些预测中不同数量的真肯定。第一步是创建一个潜在阈值数组。我们将使用 0 到 1，增量为 0.01。执行以下步骤来完成练习:

注意

这个练习的 Jupyter 笔记本可以在这里找到:[https://packt.link/yiMEr](https://packt.link/yiMEr)。根据本章之前的结果，为本次练习准备数据的其他步骤已添加到笔记本中。在执行本练习之前，请确保执行笔记本中显示的先决条件步骤。

1.  Create a range of thresholds to calculate expected costs and benefits of counseling with this code:

    ```
    thresholds = np.linspace(0, 1, 101)
    ```

    这将在 0 和 1 之间创建 101 个线性间隔的点，包括 0 和 1。

    现在，我们需要知道防止违约可能带来的节约。为了精确计算，我们需要知道下个月的月账单。但是，客户通知我们，在他们需要创建要联系的账户持有人名单时，这将是不可用的。因此，为了估计潜在的节省，我们将使用最近的月度账单。

    我们将使用测试数据来创建此分析，因为这提供了一个在我们将模型交付给客户后将如何使用该模型的模拟:在未用于模型培训的新帐户上。

2.  Confirm the index of the testing data features array that corresponds to the most recent month's bill:

    ```
    features_response[5]
    ```

    输出应该是这样的:

    ```
    'BILL_AMT1'
    ```

    索引 5 是最近几个月的账单，我们稍后会用到。

3.  Store the cost of counseling in a variable to use for analysis:

    ```
    cost_per_counseling = 7500
    ```

    我们也从客户那里了解到咨询项目并不是 100%有效。我们应该在分析中考虑到这一点。

4.  Store the effectiveness rate the client gave us for use in analysis:

    ```
    effectiveness = 0.70
    ```

    现在，我们将计算每个阈值的成本和节省。我们将逐步完成每个计算并解释它，但是现在，我们需要创建空数组来保存每个阈值的结果。

5.  Create empty arrays to store analysis results. We'll explain what each one will hold in the following steps:

    ```
    n_pos_pred = np.empty_like(thresholds)
    total_cost = np.empty_like(thresholds)
    n_true_pos = np.empty_like(thresholds)
    total_savings = np.empty_like(thresholds)
    ```

    这些创建的空数组的元素数量与我们分析中的阈值数量相同。我们将遍历每个阈值来填充这些数组。

6.  Make a `counter` variable and open a `for` loop to go through thresholds:

    ```
    counter = 0
    for threshold in thresholds:
    ```

    对于每个阈值，根据有多少预测概率高于该阈值，将有不同数量的肯定预测。这些对应于预测违约的账户。每一个被预测违约的账户都会接到一个咨询电话，这是有成本的。所以，这是成本计算的第一部分。

7.  Determine which accounts get positive predictions at this threshold:

    ```
        pos_pred = test_set_pred_proba > threshold
    ```

    `pos_pred`是一个布尔数组。`pos_pred`之和表示该阈值下的预测违约数量。

8.  计算给定阈值的肯定预测数:

    ```
        n_pos_pred[counter] = sum(pos_pred)
    ```

9.  Calculate the total cost of counseling for the given threshold:

    ```
        total_cost[counter] \
            = n_pos_pred[counter] * cost_per_counseling
    ```

    既然我们已经描述了咨询项目的可能成本，在每一个门槛，我们需要看看预计的节省是多少。当咨询被提供给正确的账户持有人时，储蓄就被获得了:那些否则会违约的人。就分类问题而言，这些是积极的预测，其中响应变量的真实值也是积极的——换句话说，真正的积极。

10.  根据正面预测的数组和响应变量:

    ```
        true_pos = pos_pred & y_test_all.astype(bool)
    ```

    确定哪些账户是真正的正面账户
11.  Calculate the number of true positives as the sum of the true positive array:

    ```
        n_true_pos[counter] = sum(true_pos)
    ```

    我们可以从成功咨询账户持有人(否则他们会违约)中获得的储蓄取决于每次预防违约的储蓄，以及咨询的有效率。我们无法防止每一次违约。

12.  使用真阳性的数量、由于防止违约而节省的费用(使用上个月的账单估计)以及咨询的有效率来计算每个阈值的预期节省:

    ```
        total_savings[counter] = np.sum(
            true_pos.astype(int)
            * X_test_all[:,5]
            * effectiveness
            ) 
    ```

13.  Increment the counter:

    ```
    counter += 1
    ```

    *步骤 5* 到 *13* 应该在 Jupyter 笔记本的一个单元格中作为`for`循环运行。之后，每个阈值的净节省可以计算为节省减去成本。

14.  Calculate the net savings for all the thresholds by subtracting the savings and cost arrays:

    ```
    net_savings = total_savings - total_cost
    ```

    现在，我们可以想象通过向合适的账户持有人提供咨询，我们可以帮助我们的客户节省多少钱。让我们想象一下。

15.  Plot the net savings against the thresholds as follows:

    ```
    mpl.rcParams['figure.dpi'] = 400
    plt.plot(thresholds, net_savings)
    plt.xlabel('Threshold')
    plt.ylabel('Net savings (NT$)')
    plt.xticks(np.linspace(0,1,11))
    plt.grid(True)
    ```

    结果图应该如下所示:

    ![Figure 7.12: Plot of net savings versus thresholds
    ](image/B16392_07_12.jpg)

    图 7.12:净节约与阈值的关系图

    该图表明阈值的选择是重要的。虽然有可能在阈值的许多不同值下产生净节省，但是看起来最高的净节省将通过将阈值设置在大约 0.25 到 0.5 的范围内的某处而产生。

    让我们确定创造最大节约的最佳阈值，并看看节约了多少。

16.  使用 NumPy 的`argmax` :

    ```
    max_savings_ix = np.argmax(net_savings)
    ```

    找到净储蓄数组的最大元素的索引
17.  Display the threshold that results in the greatest net savings:

    ```
    thresholds[max_savings_ix]
    ```

    输出应该如下所示:

    ```
    0.36
    ```

18.  Display the greatest possible net savings:

    ```
    net_savings[max_savings_ix]
    ```

    输出应该如下所示:

    ```
    13415710.0
    ```

我们看到最大的净节省出现在阈值 0.36 处。对于这个账户测试数据集，在这个阈值实现的净节省金额超过新台币 1300 万元。假设我们正在处理的数据代表所有这些账户，那么这些节省将需要根据客户服务的账户数量进行调整，以估计总的可能节省。

然而，请注意，节省量在阈值 0.5 左右时大致相同，如图*图 7.12* 所示。

随着门槛的提高，我们正在“提高”客户的风险，以便我们联系他们并提供咨询。将阈值从 0.36 提高到 0.5 意味着我们将只联系概率大于 0.5 的高风险客户。这意味着联系更少的客户，降低项目的前期成本。*图 7.12* 表明，通过联系更少的人，我们仍然可以创造大致相同的净节省额。虽然净效果是一样的，但最初的咨询费用会更少。这可能是客户所希望的。我们将在下面的活动中进一步探讨这一概念。

## 活动 7.01:获得财务洞察力

财务分析的原始资料完成了。但是，在本次活动中，您的目标是从这些结果中获得一些额外的见解，为客户提供更多关于我们构建的预测模型如何为他们创造价值的背景信息。特别是，我们已经查看了从模型构建中保留的测试集的结果。客户可能拥有比他们提供给我们的账户更多的账户，这些账户代表了他们的业务。你应该向他们报告结果，无论他们的业务规模有多大，就客户数量而言，这些结果都很容易调整。

我们还可以帮助他们了解这项计划的成本；虽然净储蓄是一个需要考虑的重要数字，但客户必须在实现这些储蓄之前为咨询项目提供资金。最后，我们将把财务分析与标准的机器学习模型性能指标联系起来。

完成活动后，你应该能够向客户传达咨询项目的初始成本，并获得如下精确和回忆图:

![Figure 7.13: Expected precision-recall curve
](image/B16392_07_13.jpg)

图 7.13:预期精度-召回曲线

该曲线将有助于解释模型在不同阈值下创造的价值。

执行以下步骤来完成活动:

注意

包含这项活动代码的 Jupyter 笔记本可以在这里找到:[https://packt.link/2kTVB](https://packt.link/2kTVB)。根据本章之前的结果，在笔记本中添加了为本次活动准备数据的其他步骤。在尝试此活动之前，请执行笔记本中显示的额外步骤。

1.  如果没有咨询项目，使用测试集计算所有违约的成本。
2.  计算咨询项目可以降低多少百分比的违约成本。
3.  计算最佳阈值下每个帐户的净节省额，考虑可能建议的所有帐户，换句话说，相对于整个测试集。
4.  针对每个阈值，绘制每个账户的净储蓄与每个账户的咨询成本。
5.  在每个阈值绘制预测为正的账户比例(这称为“标记率”)。
6.  绘制测试数据的精确度-召回曲线。
7.  Plot precision and recall separately on the *y*-axis against threshold on the *x*-axis.

    注意

    此活动的解决方案可通过[此链接](B16925_Solution_ePub.xhtml#_idTextAnchor161)找到。

# 关于向客户交付预测模型的最终想法

我们现在已经完成了建模活动，并且还创建了一个财务分析，以向客户表明他们可以如何使用该模型。虽然我们已经完成了作为数据科学家责任的重要的智力贡献，但有必要与客户就所有这些贡献的交付形式达成一致。

一个关键的贡献是体现在训练模型中的预测能力。假设客户机可以使用我们用 XGBoost 创建的经过训练的模型对象，这个模型可以像我们所做的那样保存到磁盘上并发送给客户机。然后，客户将能够在他们的工作流程中使用它。这种模型交付途径可能需要数据科学家与客户组织中的工程师合作，在客户的基础设施中部署模型。

或者，可能有必要将模型表示为一个数学方程(例如，使用逻辑回归系数)或一组 if-then 语句(如决策树或随机森林)，客户端可以使用它们来实现 SQL 中的预测功能。虽然在 SQL 代码中表达随机森林很麻烦，因为可能有许多具有许多级别的树，但是有一些软件包可以从训练有素的 scikit-learn 模型中为您创建这种表示(例如，[https://pypi.org/project/SKompiler/](https://pypi.org/project/SKompiler/))。

注意:用于模型开发和部署的云平台

在本书中，我们使用 scikit-learn 和 XGBoost 包在我们的计算机上本地构建预测模型。最近，**亚马逊网络服务** ( **AWS** )等云平台已经通过亚马逊 SageMaker 等产品提供了机器学习能力。SageMaker 包括一个 XGBoost 版本，您可以使用它来训练模型，语法与我们在这里所做的相似。在本书中显示的方法和 SageMaker 的 Amazon 发行版之间的模型训练的实现中可能存在细微的差异，鼓励您检查您的工作的每一步，以确保您的结果符合预期。例如，使用提前停止来拟合 XGBoost 模型可能需要在 SageMaker 中执行额外的步骤，以确保训练模型使用最佳迭代进行预测，而不是在训练停止时使用最后一次迭代。

AWS 等云平台很有吸引力，因为它们可以极大地简化将经过训练的机器学习模型集成到客户的技术堆栈中的过程，在许多情况下，这些技术堆栈可能已经建立在云平台上。

在使用模型进行预测之前，客户需要*确保数据的准备方式与我们建立模型的方式相同*。例如，移除所有特征的值为`0`的样本，以及清理`EDUCATION`和`MARRIAGE`特征，必须以本章前面演示的相同方式完成。或者，还有其他可能的方法来交付模型预测，例如客户端向数据科学家交付要素并接收返回的预测。

讨论可交付成果的另一个重要考虑因素是:*预测应该以什么格式交付？*根据二元分类模型(如我们为案例研究创建的模型)进行预测的典型交付格式是根据预测的违约概率对客户进行排名。预测的概率应该与帐户 ID 和客户想要的任何其他列一起提供。这样，当呼叫中心通过帐户持有人的名单提供咨询时，他们可以首先联系违约风险最高的人，然后在时间和资源允许的情况下联系优先级较低的帐户持有人。应告知客户使用哪个阈值来预测概率，以产生最高的净储蓄。该阈值将代表帐户持有人名单上的停止点，如果它在预测的违约概率上排名的话。

## 模型监控

根据客户聘用数据科学家的时间长短，随着模型的使用，监控模型的性能总是有益的。预测能力是保持不变还是随着时间的推移而下降？在对案例研究进行评估时，重要的是要记住，如果账户持有人正在接受咨询，由于新咨询计划的预期效果，他们的违约概率预计会低于预测概率。出于这个原因，并且为了测试咨询计划的有效性，不管信用违约风险如何，保留随机选择的一部分不会接受任何咨询的账户持有人是一种好的做法。这个小组将被称为对照组，与接受咨询的其他人相比应该很小，但是足够大，可以从中得出有统计学意义的推论。

虽然详细介绍如何设计和使用控制组超出了本书的范围，但在这里可以说，模型预测能力可以在控制组上进行评估，因为他们没有接受过咨询，类似于模型训练的客户群。控制组的另一个好处是，违约率和由于违约造成的财务损失可以与接受模型指导咨询计划的帐户进行比较。如果该计划按预期运行，接受咨询的账户应该有较低的违约率和较小的因违约造成的财务损失。控制组可以提供程序实际上正在运行的证据。

注:选择性处理的高级建模技术——隆起建模

当一个企业正在考虑有选择地向其客户提供昂贵的治疗时，如案例研究中的咨询项目，应该考虑一种称为提升建模的技术。隆起建模寻求在个体基础上确定治疗的有效性。我们做了一个笼统的假设，电话咨询治疗对客户的平均有效率为 70%。然而，有效性可能因客户而异；有些顾客更容易接受，有些则不太容易接受。有关隆起建模的更多信息，请参见[https://www.steveklosterman.com/uplift-modeling/](https://www.steveklosterman.com/uplift-modeling/)。

监视模型实现的一种相对简单的方法是，与用于模型定型的总体相比，查看模型预测的分布是否随时间而变化。我们在*图 7.2* 中绘制了测试集的预测概率直方图。如果预测概率的直方图的形状显著改变，则可能是特征已经改变，或者特征和响应之间的关系已经改变并且模型可能需要重新训练或重建的迹象。为了量化分布的变化，鼓励感兴趣的读者查阅统计资料，了解卡方拟合优度检验或 Kolmogorov-Smirnov 检验。如果根据选择的阈值，预测违约的账户比例以显著的方式变化，则模型预测的变化分布也可能变得明显。

本章和整本书中介绍的所有其他模型评估指标也可以是监控生产中模型性能的好方法:十分位数和等间隔图表、校准、ROC AUC 等。

## 预测建模中的伦理

随着机器学习的范围扩大到触及大多数现代企业，模型是否能做出公平预测的问题受到了越来越多的关注。可以基于模型在为不同受保护类别(例如，不同性别组)的成员做出预测时是否同样熟练来评估公平性。

在本书中，我们采取的方法是将性别从模型的特性中去除。然而，可能其他特征可以有效地作为性别的代理，因此，即使性别没有被用作特征，模型也可能最终对不同的性别组产生有偏见的结果。筛选这种偏差可能性的一个简单方法是检查模型中使用的任何特征是否与受保护的类有特别高的关联，例如，通过使用 t-检验。如果是这样，最好从模型中删除这些功能。

如何确定一个模型是否公平，如果不公平，该怎么办，这是积极研究的主题。鼓励你熟悉人工智能公平 360([https://aif360.mybluemix.net/](https://aif360.mybluemix.net/))等努力，这些努力正在提供工具，以提高机器学习的公平性。在开始与公平相关的工作之前，重要的是从客户那里了解公平的定义是什么，因为由于不同国家的不同法律以及客户组织的具体政策，这可能因地理区域而异。

# 总结

在本章中，您学习了几种分析技术来提供对模型性能的深入了解，例如按模型预测箱划分的违约率的十分位数和等间隔图表，以及如何调查模型校准的质量。使用模型测试集来推导这些见解以及计算 ROC AUC 等指标是很好的，因为这旨在表示模型在真实世界中对新数据的表现。

我们还看到了如何着手进行模型性能的财务分析。虽然我们将这一点留到了本书的结尾，但是从一个典型项目的开始就应该理解成本和节省以及由该模型指导的决策。这使得数据科学家能够朝着增加利润或节约成本的切实目标努力。对于二元分类模型，该过程中的一个关键步骤是选择一个预测概率的阈值，在该阈值上宣布一个肯定的预测，使得由于模型引导的决策制定而产生的利润或节省最大化。

最后，我们考虑了与交付和监控模型相关的任务，包括建立一个控制组来监控模型性能和测试由模型输出指导的任何程序的有效性。控制组的结构和模型监控策略将因项目而异，因此您需要在每个新案例中确定适当的行动过程。为了加深您在现实世界中使用模型的知识，我们鼓励您继续学习一些主题，如实验设计、可用于训练和部署模型的云平台(如 AWS)以及预测建模中的公平性问题。

现在，您已经完成了项目，并准备向客户交付您的发现。除了保存到磁盘的训练模型，或者您可能提供给客户的其他数据产品或服务，您可能还希望创建一个演示文稿，通常是幻灯片，详细介绍您的进展。此类演示的内容通常包括问题陈述、数据探索和清理的结果、您构建的不同模型的性能比较、模型解释(如 SHAP 值)以及显示您的工作价值的财务分析。当你制作工作演示文稿时，通常最好用图片讲述你的故事，而不是大量的文字。我们已经在整本书中展示了许多可视化技术，您可以使用它们来实现这一点，并且您应该继续探索描述数据和建模结果的方法。

一定要问客户他们想在演示中有哪些具体的东西，并且一定要回答他们所有的问题。当客户看到你能以一种可以理解的方式为他们创造价值，你就成功了。