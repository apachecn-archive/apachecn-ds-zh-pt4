

# 四、偏差方差权衡

概观

在这一章中，我们将涵盖逻辑回归的其余元素，包括当您调用`.fit`来训练模型时会发生什么，以及在使用这种建模技术时您应该知道的统计假设。您将学习如何使用 L1 和 L2 正则化和逻辑回归来防止过度拟合，以及如何使用交叉验证来决定正则化强度。阅读本章后，您将能够在工作中使用逻辑回归，并在模型拟合过程中使用正则化，以利用偏差方差权衡，并提高模型对未知数据的性能。

# 简介

在这一章中，我们将介绍上一章遗留下来的逻辑回归的其余细节。除了能够使用 scikit-learn 拟合逻辑回归模型之外，您还将深入了解梯度下降过程，该过程类似于在 scikit-learn 中使用“引擎盖下”(用户不可见)来完成模型拟合的过程。最后，我们将通过熟悉这种方法的正式统计假设来完成对逻辑回归模型的讨论。

我们通过检查如何扩展逻辑回归模型来解决过拟合问题，开始探索过拟合、欠拟合和偏差方差权衡的基本机器学习概念。在回顾了用于减轻过度拟合的正则化方法的数学细节之后，您将学习一种用于调整正则化的超参数的有用实践:交叉验证。通过正则化方法和一些简单的特征工程，你将了解如何改进过拟合和欠拟合模型。

尽管我们在本章中关注的是逻辑回归，但是过度拟合、欠拟合、正则化和偏差方差权衡的概念与机器学习中几乎所有的监督建模技术都是相关的。

# 估计逻辑回归的系数和截距

在前一章中，我们了解到，当在 scikit-learn 中对逻辑回归模型调用`.fit`方法时，逻辑回归模型的系数(每个系数都有一个特定的特性)以及截距是使用训练数据确定的。这些数字被称为模型的**参数**，为它们寻找最佳值的过程被称为参数**估计**。一旦找到参数，逻辑回归模型基本上就是一个成品:有了这些数字，我们就可以在任何可以执行普通数学函数的环境中使用逻辑回归模型。

很明显，参数估计的过程是重要的，因为这是我们如何从数据中建立预测模型的方法。那么，参数估计是如何工作的呢？为了理解这一点，第一步是让我们熟悉**成本函数**的概念。成本函数是一种告知模型预测距离完美描述数据有多远的方式。模型预测和实际数据之间的差异越大，成本函数返回的“成本”就越大。

对于回归问题来说，这是一个简单的概念:预测值和真实值之间的差异可以用于成本，在经过变换(如绝对值或平方)以使成本值为正，然后在所有训练样本上对其进行平均之后。

对于分类问题，尤其是在拟合逻辑回归模型时，典型的成本函数是**对数损失**函数，也称为交叉熵损失。这是 scikit-learn 使用的成本函数，以修改后的形式来拟合逻辑回归:

![Figure 4.1: The log-loss function
](img/B16925_4_1.jpg)

图 4.1:对数损失函数

这里有 *n* 个训练样本， *y* i 是第 *i* 个样本的真实标号(0 或 1)， *p* i 是第 *i* 个样本的标号等于 1 的预测概率，log 是自然对数。所有训练样本上的求和符号(即大写希腊字母 sigma)和除以 *n* 用于取所有训练样本上该成本函数的平均值。考虑到这一点，请看下图中的自然对数函数，并考虑该成本函数的解释是什么:

![Figure 4.2: Natural logarithm on the interval (0, 1)
](img/B16925_4_2.jpg)

图 4.2:区间(0，1)上的自然对数

要了解对数损失成本函数的工作原理，请考虑真实标签为 1 的样本的值，在本例中为 *y = 1* ，因此成本函数的第二部分*(1-y*I*)log(1-p*I*)*将正好等于 0，并且不会影响该值。那么代价函数值就是*-y*I*log(p*I*)=-log(p*I*)*既然 *y* i *= 1* 。所以，这个样本的成本就是预测概率的自然对数的负数。现在，由于样本的真实标签是 1，考虑成本函数应该如何表现。我们预计，对于接近 1 的预测概率，成本函数将会很小，这表示预测更接近真实值的误差很小。对于越接近 0 的预测，它将越大，因为预测越“错误”,成本函数应该取越大的值。

从*图 4.2* 中的自然对数图我们可以看到，对于更接近于 0 的 *p* 的值，自然对数呈现越来越大的负值。这意味着成本函数将呈现越来越多的正值，因此以非常低的概率对正样本进行分类的成本相对较高，这是应该的。相反，如果预测的概率更接近于 1，那么图表表明成本将更接近于 0——同样，这是对“更正确”的预测的预期因此，对于正样本，成本函数的行为与预期一致。对于真实标签为 0 的样本，可以进行类似的观察。

现在我们理解了对数损失成本函数如何用于逻辑回归。但这与系数和截距是如何确定的有什么关系呢？我们将在下一节学习。

注意

生成本节介绍的图的代码可以在这里找到:[https://packt.link/NeF8P](https://packt.link/NeF8P)。

## 梯度下降寻找最佳参数值

使用对数损失成本为逻辑回归模型寻找参数值(系数和截距)的问题归结为一个**优化**的问题:我们希望找到导致**最小**成本的参数集，因为越差的预测成本越高。换句话说，我们想要的是在所有训练样本中平均起来“错误最小”的参数集。这个过程由 scikit-learn 中逻辑回归模型的`.fit`方法自动完成。寻找成本最低的参数集有不同的解决方法，在实例化模型类时，您可以通过关键字`solver`选择您想要使用的方法。所有这些方法的工作方式都有些不同。不过都是基于**梯度下降**的概念。

梯度下降过程从一个**初始猜测**开始。初始猜测的选择对逻辑回归并不重要，你不需要手动选择；这是由关键字`solver`处理的。然而，对于深度神经网络等更高级的机器学习算法，参数初始猜测的选择需要更多的关注。

为了便于说明，我们将考虑一个只有一个参数需要估计的问题。我们将查看一个假设成本函数的值(*y = f(x)= x*2*–2x*)，并设计一个梯度下降过程来找到参数 *x* 的值，对于该值， *y* 的成本最低。这里，我们选择一些 *x* 值，创建一个返回成本函数值的函数，并在这个参数范围内查看成本函数值。

执行此操作的代码如下:

```py
X_poly = np.linspace(-3,5,81)
print(X_poly[:5], '...', X_poly[-5:])
```

以下是打印语句的输出:

```py
[-3\. -2.9 -2.8 -2.7 -2.6] ... [4.6 4.7 4.8 4.9 5\. ]
```

剩余的代码片段如下:

```py
def cost_function(X):
    return X * (X-2)
y_poly = cost_function(X_poly)
plt.plot(X_poly, y_poly)
plt.xlabel('Parameter value')
plt.ylabel('Cost function')
plt.title('Error surface')
```

结果图应该如下所示:

![Figure 4.3: A cost function plot
](img/B16925_4_3.jpg)

图 4.3:成本函数图

注意

在前面的代码片段中，我们假设您已经导入了必要的库。你可以参考下面的笔记本来获得本章的完整代码，包括前面片段的导入语句:[https://packt.link/A4VyF](https://packt.link/A4VyF)。

查看*图 4.3* 中的**误差面**，它是一个参数值范围内的成本函数图，很明显什么参数值会导致成本函数的最小值: *x = 1* 。事实上，通过一些微积分，你可以很容易地确认这一点，通过设置导数为零，然后求解 *x* ，确认 *x = 1* 是最小值。但是，一般来说，如此简单地解决问题并不总是可行的。在有必要使用梯度下降的情况下，我们并不总是知道整个误差面是什么样子的。相反，在我们选择了参数的初始猜测后，我们所能知道的就是该点附近误差面的方向。

**梯度下降**是一种迭代算法；从最初的猜测开始，我们试图找到一个降低成本函数的新猜测，并继续下去，直到我们找到一个好的解决方案。我们正试图在误差表面上“下坡”移动，但是我们只知道向哪个方向移动以及在那个方向上移动多远，这是基于我们当前猜测的紧邻误差表面的形状。在数学上，我们只知道当前猜测的参数值处的**导数**(在一个以上的维度上称为**梯度**)的值。如果你没有学过微积分，你可以认为梯度告诉你哪个方向是下坡，从你站的地方看山有多陡。我们利用这些信息朝着减少误差的方向“迈出一步”。我们决定迈出多大的一步取决于**学习速度**。由于梯度朝着误差减小的方向下降，我们想在梯度的负方向上迈出一步。

这些概念可以用下面的等式来形式化。为了得到新的猜测， *x* new，从当前猜测， *x* old，其中*f’(x*old*)*是当前猜测的成本函数的导数(即梯度):

![Figure 4.4: Equation to obtain the new guess from the current guess
](img/B16925_4_4.jpg)

图 4.4:从当前猜测获得新猜测的等式

在下图中，我们可以看到从 *x = 4.5* 开始梯度下降过程的结果，学习率为 0.75，然后优化 *x* 以获得成本函数的最低值:

![Figure 4.5: The gradient descent path
](img/B16925_4_5.jpg)

图 4.5:梯度下降路径

梯度下降在更高维的空间也有效；换句话说，不止一个参数。但是，您最多只能在一个图形上显示一个二维误差面(即在三维图上一次显示两个参数)。

描述了梯度下降的工作原理后，让我们执行一个练习来实现梯度下降算法，扩展本节的示例。

注意

生成本节介绍的图的代码可以在这里找到:[https://packt.link/NeF8P](https://packt.link/NeF8P)。如果你正在阅读这本书的印刷版本，你可以通过访问以下链接下载并浏览本章中一些图片的彩色版本:【https://packt.link/FAXBM

## 练习 4.01:使用梯度下降最小化成本函数

在本练习中，我们的任务是找到一组最佳参数，以最小化以下假设成本函数:*y = f(x)= x*2*–2x*。为了做到这一点，我们将使用梯度下降，这在前面的部分中描述。执行以下步骤来完成练习:

注意

在开始本练习之前，请确保您已经执行了导入必要的库和加载已清理的数据帧的先决步骤。这些步骤以及这个练习的代码可以在[https://packt.link/NeF8P](https://packt.link/NeF8P)找到。

1.  Create a function that returns the value of the cost function and look at the value of the cost function over a range of parameters. You can use the following code to do this (note that this repeats code from the preceding section):

    ```py
    X_poly = np.linspace(-3,5,81)
    print(X_poly[:5], '...', X_poly[-5:])
    def cost_function(X):
        return X * (X-2)
    y_poly = cost_function(X_poly)
    plt.plot(X_poly, y_poly)
    plt.xlabel('Parameter value')
    plt.ylabel('Cost function')
    plt.title('Error surface')
    ```

    您将获得以下成本函数图:

    ![Figure 4.6: A cost function plot
    ](img/B16925_4_6.jpg)

    图 4.6:成本函数图

2.  Create a function for the value of the gradient. This is the analytical derivative of the cost function. Use this function to evaluate the gradient at the point *x = 4.5*, and then use this in combination with the learning rate to find the next step of the gradient descent process:

    ```py
    def gradient(X):
        return (2*X) - 2
    x_start = 4.5
    learning_rate = 0.75
    x_next = x_start - gradient(x_start)*learning_rate
    x_next
    ```

    注意

    没学过微积分，不懂这部分没关系；你可以假设这是梯度的函数。在某些应用中，实际上不可能计算解析导数，因此可能需要进行数值近似。

    使用`x_next`运行单元后，您将获得以下输出:

    ```py
    -0.75
    ```

    这是在 *x = 4.5* 之后的下一个梯度下降步骤。

3.  Plot the gradient descent path, from the starting point to the next point, using the following code:

    ```py
    plt.plot(X_poly, y_poly)
    plt.plot([x_start, x_next],
             [cost_function(x_start), cost_function(x_next)],
             '-o')
    plt.xlabel('Parameter value')
    plt.ylabel('Cost function')
    plt.legend(['Error surface', 'Gradient descent path'])
    ```

    您将获得以下输出:

    ![Figure 4.7: The first gradient descent path step
    ](img/B16925_4_7.jpg)

    图 4.7:第一个梯度下降路径步骤

    在这里，似乎我们已经朝着正确的方向迈出了一步。然而，很明显我们已经超越了我们想要达到的目标。这可能是因为我们的学习速度太快了，因此，我们的步子迈得太大了。虽然调整学习率是更快收敛到最优解的好方法，但在本例中，我们可以继续说明该过程的剩余部分。在这里，看起来我们可能需要多走几步。实际上，梯度下降一直持续到步长变得非常小，或者成本函数的变化变得非常小(您可以通过使用 scikit-learn 逻辑回归中的`tol`参数来指定有多小)，这表明我们已经足够接近一个好的解决方案——也就是说，成本函数的一个**局部最小值**。对于这个例子，除了最初的猜测之外，我们将总共采取 14 个步骤，或者说**迭代**(注意，您也可以用`max_iter`在 scikit-learn 中设置最大迭代次数)。

4.  Perform 14 iterations to converge toward the local minimum of the cost function by using the following code snippet (note that `iterations = 15`, but the endpoint is not included in the call to `range()`):

    ```py
    iterations = 15
    x_path = np.empty(iterations,)
    x_path[0] = x_start
    for iteration_count in range(1,iterations):
        derivative = gradient(x_path[iteration_count-1])
        x_path[iteration_count] = x_path[iteration_count-1] \
                                  - (derivative*learning_rate)
    x_path
    ```

    您将获得以下输出:

    ```py
    array([ 4.5       , -0.75      ,  1.875     ,  0.5625    ,  1.21875   ,
            0.890625  ,  1.0546875 ,  0.97265625,  1.01367188,  0.99316406,
            1.00341797,  0.99829102,  1.00085449,  0.99957275,  1.00021362])
    ```

    这个`for`循环将连续的估计值存储在`x_path`数组中，使用当前的估计值计算导数并找到下一个估计值。从梯度下降过程的结果值来看，看起来我们已经非常接近(`1.00021362`)1 的最优解。

5.  Plot the gradient descent path using the following code:

    ```py
    plt.plot(X_poly, y_poly)
    plt.plot(x_path, cost_function(x_path), '-o')
    plt.xlabel('Parameter value')
    plt.ylabel('Cost function')
    plt.legend(['Error surface', 'Gradient descent path'])
    ```

    您将获得以下输出:

    ![Figure 4.8: The gradient descent path
    ](img/B16925_4_8.jpg)

图 4.8:梯度下降路径

我们鼓励你用不同的学习速率重复前面的过程，以便观察它们如何影响梯度下降路径。有了正确的学习率，就有可能很快收敛到一个高度精确的解。虽然学习率的选择在不同的机器学习应用中可能很重要，但对于逻辑回归，问题通常很容易解决，您不需要在 scikit-learn 中选择学习率。

当你试验不同的学习速率时，你注意到当学习速率大于 1 时会发生什么吗？在这种情况下，我们在减小误差的方向上采取的步骤太大，实际上我们会得到更大的误差。这个问题可以自我复合，并且实际上引导梯度下降过程远离最小误差区域。另一方面，如果步长太小，可能需要很长时间才能找到所需的解决方案。

## 逻辑回归的假设

由于它是一个经典的统计模型，类似于我们已经检验过的 f 检验和皮尔逊相关性，逻辑回归对数据做了某些假设。虽然没有必要严格遵循这些假设中的每一个，但是知道它们是有好处的。这样，如果一个逻辑回归模型表现得不是很好，您可以尝试调查并找出原因，使用您对逻辑回归的理想情况的了解。您可能会从不同的资源中找到稍微不同的特定假设列表。然而，这里列出的那些被广泛接受。

**特征在对数赔率中是线性的**

我们在前一章中了解了这个假设，*第三章*，*逻辑回归的细节和特征探索*。逻辑回归是一个线性模型，因此只有当特征有效地描述对数概率的线性趋势时，它才会工作得很好。特别是，逻辑回归本身不会捕捉交互、多项式特征或特征的离散化。但是，您可以将所有这些都指定为“新功能”，即使它们可能是从现有功能设计而来的。

记住上一章，单变量特征探索中最重要的特征`PAY_1`，在对数概率中没有发现是线性的。

**没有特征的多重共线性**

多重共线性意味着要素彼此相关。违反这一假设的最严重情况是要素之间完全相关，例如一个要素与另一个要素相同，或者一个要素等于另一个要素乘以一个常数。我们可以使用单变量特征选择中我们已经熟悉的相关图来研究特征的相关性。这是上一章的相关图:

![Figure 4.9: A correlation plot of features and the response
](img/B16925_4_9.jpg)

图 4.9:特性和响应的相关图

我们可以从相关图中看到完美相关的样子:由于每个特征和响应变量与其自身的相关性为 1，我们可以看到相关性为 1 是一种浅米色。从不包含-1 的颜色条中，我们知道与该值没有相关性。

注意

包含代码的 Jupyter 笔记本和本节呈现的相应情节可以在这里找到:[https://packt.link/UOEMp](https://packt.link/UOEMp)。

在我们的案例研究数据中，相关预测值的最明显的例子是`BILL_AMT`特征。直觉告诉我们，对于一个给定的账户，每个月的账单可能都是相似的。例如，可能有一个帐户的余额通常为零，或者有一个帐户的余额很大，需要一段时间才能还清。有哪些`BILL_AMT`特征是完全相关的？从*图 4.9* 看，不像。因此，虽然这些要素可能不会提供太多独立信息，但出于对多重共线性的考虑，我们不会在此时移除它们。

**观察的独立性**

这是包括线性回归在内的经典统计模型中的常见假设。这里，假设观察值(或样本)是独立的。这对于案例研究数据有意义吗？我们希望与我们的客户确认同一个人是否可以在整个数据集中持有多个信用账户，并根据其常见程度来考虑该怎么办。假设我们已经被告知，在我们的数据中，每个信用账户都属于一个独特的人，因此我们可以假设在这方面的观察是独立的。

在不同的数据领域中，一些常见的违反观察独立性的情况如下:

*   **观测值的空间自相关**；例如，在诸如土壤类型的自然现象中，地理上彼此接近的观测值可能彼此相似。
*   **观测值的时间自相关**，可能出现在时间序列数据中。通常假设当前时间点的观测值与最近的时间点相关。

然而，这些问题与我们的案例研究数据无关。

**没有异常值**

异常值是指特征或响应的值与大部分数据相差甚远或在其他方面有所不同的观察值。对于特征值的异常值观察，更合适的术语是高杠杆点，因为术语“异常值”通常适用于响应变量。然而，在我们的二元分类问题中，响应变量不可能有异常值，因为它只能取值 0 和 1。实际上，您可能会看到这两个术语都用来指代功能。

要了解为什么这些类型的点通常会对线性模型产生不利影响，请查看包含 100 个点的合成线性数据以及线性回归得出的最佳拟合线:

![Figure 4.10: “Well-behaved” linear data and a regression fit
](img/B16925_4_10.jpg)

图 4.10:“表现良好”的线性数据和回归拟合

在这里，该模型直观上似乎与数据非常吻合。但是，如果加入了离群特征值呢？为了说明这一点，我们添加了一个点，该点的 x 值与大多数观测值非常不同，而 y 值与其他观测值的范围相似。然后，我们显示结果回归线:

![Figure 4.11: A plot showing what happens when an outlier is included
](img/B16925_4_11.jpg)

图 4.11:显示包含异常值时会发生什么的图

由于单个高杠杆点的存在，适合所有数据的回归模型不再是大部分数据的非常好的表示。这显示了单个数据点对线性模型的潜在影响，尤其是当该点似乎不遵循与其余数据相同的趋势时。

有一些处理异常值的方法。但是一个更基本的问题是“这样的数据真实吗？”。如果数据看起来不正确，询问客户异常值是否可信是个好主意。如果不是，他们应该被排除在外。但是，如果它们确实代表有效数据，那么应该使用非线性模型或其他方法。

根据我们的案例研究数据，我们在特征探索期间绘制的直方图中没有观察到异常值。所以，我们没有这个顾虑。

你应该包括多少功能？

这与其说是一个假设，不如说是对模型构建的指导。没有明确的法律规定在逻辑回归模型中包括多少特征。然而，一个常见的经验法则是“10 法则”，即最罕见的结果类每出现 10 次，就可以向模型中添加 1 个特征。因此，例如，在具有 100 个样本的二元逻辑回归问题中，如果类别余额具有 20%的正面结果和 80%的负面结果，则总共只有 20 个正面结果，因此在模型中应该只使用 2 个特征。还提出了“20 规则”，这是对要包含的特性数量的更严格的限制(在我们的例子中是 1 个特性)。

在二进制特征的情况下要考虑的另一点是，对于该特征，有多少样本将具有正值，例如由一个热编码产生的特征。如果特征非常不平衡，换句话说，只有很少的样本包含 1 或 0，那么将它包含在模型中可能没有意义。

对于案例研究数据，我们很幸运地拥有相对大量的样本和相对平衡的特征，所以这些都不是问题。

注意

生成本节介绍的图的代码可以在这里找到:[https://packt.link/SnX3y](https://packt.link/SnX3y)。

## 规则化的动机:偏差方差权衡

我们可以通过使用一个被称为**收缩**或**正则化**的强大概念来扩展我们已经了解的基本逻辑回归模型。事实上，到目前为止，您在 scikit-learn 中拟合每个逻辑回归都使用了一些正则化。这是因为它是逻辑回归模型对象中的默认选项。然而，直到现在，我们都忽略了它。

随着你更深入地了解这些概念，你也会熟悉机器学习中的一些基本概念:**过拟合**、**欠拟合**和**偏差方差权衡**。如果模型在训练数据上的性能(例如 ROC AUC)比在保留测试集上的性能好得多，则该模型被称为过度拟合训练数据。换句话说，在训练集上的良好表现并不能推广到看不见的测试集。我们在*第 2 章*、*sci kit 简介-学习和模型评估*中开始讨论这些概念，当时我们区分了模型训练和测试分数。

当模型过度拟合训练数据时，它被认为具有高**方差**。换句话说，无论训练数据中存在什么样的可变性，模型都已经很好地了解了这一点——事实上，太好了。这将反映在高模型训练分数中。然而，当这样的模型用于对新的和看不见的数据进行预测时，性能较低。在下列情况下，过度拟合的可能性更大:

*   就样本数量而言，有大量可用的特征。特别是，可能有如此多的可能特征，以至于直接检查所有这些特征是很麻烦的，就像我们能够对案例研究数据所做的那样。
*   使用复杂模型，即比逻辑回归更复杂的模型。这些包括诸如梯度提升集成或神经网络的模型。

在这种情况下，模型有机会在模型拟合期间开发关于特征和训练数据中的响应变量之间的关系的更复杂的**假设**，使得过度拟合更有可能。

相反，如果模型没有很好地拟合训练数据，这被称为欠拟合，并且该模型被称为具有高**偏差**。

我们可以通过对一些假设数据拟合多项式模型，来检验欠拟合、过拟合以及介于两者之间的理想状态之间的差异:

![Figure 4.12: Quadratic data with underfit, overfit, and ideal models
](img/B16925_4_12.jpg)

图 4.12:带有欠拟合、过拟合和理想模型的二次数据

在*图 4.12* 中，我们可以看到包含的特征太少，在这种情况下，只有两个特征(斜率和截距)的 *y* 的线性模型显然不能很好地表示数据。这就是所谓的欠拟合模型。但是如果我们包含太多的特征，也就是很多高次多项式项，比如 *x* 2、 *x* 3、 *x* 4、… *x* 10，就可以近乎完美的拟合训练数据。然而，这未必是一件好事。当我们查看训练数据点之间的过度拟合模型的结果时，其中可能需要进行新的预测，我们可以看到该模型是不稳定的，并且可能不会为不在训练集中的数据提供可靠的预测。我们可以根据对特征和响应变量之间关系的直观理解来判断这一点，这可以通过可视化数据来获得。

注意

生成本节介绍的图的代码可以在这里找到:[https://packt.link/SnX3y](https://packt.link/SnX3y)。

本例的合成数据由二次(即二次)多项式生成。了解这一点后，我们可以通过对训练数据拟合二次多项式来轻松找到理想模型，如图*图 4.12* 所示。

然而，一般来说，我们不会提前知道理想的模型公式是什么。出于这个原因，我们需要比较训练和测试分数，以评估模型是否可能过拟合或欠拟合。

在某些情况下，可能需要在模型训练过程中引入一些偏差，特别是如果这可以减少过度拟合并提高新的、看不见的数据的模型性能。这样，就有可能利用偏差方差权衡来改进模型。我们可以使用**正则化**方法来实现这一点。此外，我们也可以将这些方法用于**变量选择**，作为建模过程的一部分。使用预测模型来选择变量是我们已经探索过的单变量特征选择方法的替代方法。在下面的练习中，我们开始尝试这些概念。

## 练习 4.02:合成分类数据的生成和建模

在本练习中，我们将通过使用合成数据集来观察实践中的过度拟合。假设您有一个包含许多候选要素(200 个)的二进制分类数据集，但您没有时间逐个查看所有这些要素。有可能这些特征中的一些是高度相关的，或者以其他方式相关。然而，由于存在如此多的变量，很难有效地探索所有这些变量。此外，数据集的样本相对较少:只有 1000 个。我们将通过使用 scikit-learn 的一个功能来生成这个具有挑战性的数据集，该功能允许您创建合成数据集来进行这样的概念探索。执行以下步骤来完成练习:

注意

在开始本练习之前，请确保您已经执行了导入必要库的先决步骤。这些步骤以及这个练习的代码可以在[https://packt.link/mIMsT](https://packt.link/mIMsT)找到。

1.  Import the `make_classification`, `train_test_split`, `LogisticRegression`, and `roc_auc_score` classes using the following code:

    ```py
    from sklearn.datasets import make_classification
    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import LogisticRegression
    from sklearn.metrics import roc_auc_score
    ```

    注意，我们已经从 scikit-learn 导入了几个熟悉的类，此外还有一个我们以前没有见过的新类:`make_classification`。这个类正如它的名字所表明的那样——它为一个分类问题生成数据。使用各种关键字参数，您可以指定要包括多少个样本和特性，以及响应变量将有多少个类。还有一系列其他选项可以有效地控制问题解决的“容易”程度。

    注意

    更多信息请参考[https://sci kit-learn . org/stable/modules/generated/sk learn . datasets . make _ classification . html](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html)。可以说，我们在这里选择了一些选项，这些选项使问题变得相当容易解决，并加入了一些曲线球。换句话说，我们期望高模型性能，但是我们将不得不努力一点来得到它。

2.  生成包含两个变量`x_synthetic`和`y_synthetic`的数据集。`x_synthetic`有 200 个候选特征，`y_synthetic`是响应变量，每个特征对应 1000 个样本。使用下面的代码:

    ```py
    X_synthetic, y_synthetic = make_classification(
        n_samples=1000, n_features=200,
        n_informative=3, n_redundant=10,
        n_repeated=0, n_classes=2,
        n_clusters_per_class=2,
        weights=None, flip_y=0.01,
        class_sep=0.8, hypercube=True,
        shift=0.0, scale=1.0,
        shuffle=True, random_state=24)
    ```

3.  Examine the shape of the dataset and the class fraction of the response variable using the following code:

    ```py
    print(X_synthetic.shape, y_synthetic.shape)
    print(np.mean(y_synthetic))
    ```

    您将获得以下输出:

    ```py
    (1000, 200) (1000,)
    0.501
    ```

    在检查了输出的形状之后，注意我们已经生成了一个几乎完美平衡的数据集:接近 50/50 类平衡。同样重要的是要注意，我们已经生成了所有的特征，因此它们具有相同的`shift`和`scale`——也就是说，平均值为 0，标准偏差为 1。确保要素处于相同的比例，或具有大致相同的值范围，这是使用正则化方法的一个关键点-稍后我们将了解原因。如果原始数据集中的要素在很大程度上处于不同的比例，建议对其进行归一化，使其处于相同的比例。Scikit-learn 具有使这变得简单的功能，我们将在本章末尾的活动中了解这一点。

4.  Plot the first few features as histograms to show that the range of values is the same using the following code:

    ```py
    for plot_index in range(4):
        plt.subplot(2, 2, plot_index+1)
        plt.hist(X_synthetic[:, plot_index])
        plt.title('Histogram for feature {}'.format(plot_index+1))
    plt.tight_layout()
    ```

    您将获得以下输出:

    ![Figure 4.13: Histograms for the first 4 of 200 synthetic features
    ](img/B16925_4_13.jpg)

    图 4.13:200 个合成特征中前 4 个的直方图

    因为我们生成了这个数据集，所以我们不需要直接检查所有 200 个要素来确保它们处于相同的比例。那么，这个数据集可能有什么问题呢？根据响应变量的类别分数，数据是平衡的，因此我们不需要欠采样、过采样或使用其他有助于不平衡数据的方法。特征本身、特征和响应变量之间的关系如何？这些关系有很多，直接调查它们是一个挑战。根据我们的经验法则(即最稀有类的每 10 个样本允许 1 个特征)，200 个特征太多了。在最稀有的类中，我们有 500 个观察值，因此根据该规则，我们不应该有超过 50 个特征。有可能有这么多的特征，模型训练过程将会超负荷。我们现在将开始学习如何使用 scikit-learn 逻辑回归中的选项来防止这种情况。

5.  Split the data into training and test sets using an 80/20 split, and then instantiate a logistic regression model object using the following code:

    ```py
    X_syn_train, X_syn_test, y_syn_train, y_syn_test = \
    train_test_split(X_synthetic, y_synthetic,\
                     test_size=0.2, random_state=24)
    lr_syn = LogisticRegression(solver='liblinear', penalty='l1',
                                C=1000, random_state=1)
    lr_syn.fit(X_syn_train, y_syn_train)
    ```

    请注意，我们在逻辑回归模型中指定了一些新的选项，到目前为止，我们还没有注意到这些选项。首先，我们将`penalty`参数指定为`l1`。这意味着我们将使用 **L1 正则化**，也称为**套索正则化**。我们稍后会讨论它的数学定义。其次，请注意，我们已经将`C`参数设置为等于 1000。`C`是“正则化强度的倒数”，根据 scikit-learn 文档([https://sci kit-learn . org/stable/modules/generated/sk learn . linear _ model)。LogisticRegression.html](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)。这意味着`C`值越高，对应的正则化程度越低。通过选择一个相对较大的数字，比如 1，000，我们使用了相对较少的正则化。`C`的默认值为 1。因此，我们在这里并没有真正使用太多的正则化，相反，我们只是熟悉了这样做的选项。最后，我们正在使用`liblinear`解算器，这是我们过去用过的。

    尽管我们碰巧在这里使用了缩放数据(所有要素的平均值为 0，标准差为 1)，但在这一点上值得注意的是，在我们为求解器提供的各种选项中，`liblinear`是“对未缩放数据稳健的”另请注意，`liblinear`是仅有的两个支持 L1 惩罚的解算器选项之一，另一个选项是`saga`。

    注意

    您可以在[https://sci kit-learn . org/stable/modules/linear _ model . html # logistic-regression](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression)找到有关可用解算器的更多信息。

6.  Fit the logistic regression model on the training data using the following code:

    ```py
    lr_syn.fit(X_syn_train, y_syn_train)
    ```

    以下是输出:

    ```py
    LogisticRegression(C=1000, penalty='l1', random_state=1, \
                       solver='liblinear')
    ```

7.  Calculate the training score using this code by first getting predicted probabilities and then obtaining the ROC AUC:

    ```py
    y_syn_train_predict_proba = lr_syn.predict_proba(X_syn_train)
    roc_auc_score(y_syn_train, y_syn_train_predict_proba[:,1])
    ```

    输出应该如下所示:

    ```py
    0.9420000000000001
    ```

8.  Calculate the test score similar to how the training score was obtained:

    ```py
    y_syn_test_predict_proba = lr_syn.predict_proba(X_syn_test)
    roc_auc_score(y_syn_test, y_syn_test_predict_proba[:,1])
    ```

    输出应该如下所示:

    ```py
    0.8075807580758075
    ```

    从这些结果来看，很明显，逻辑回归模型过度拟合了数据。也就是说，训练数据的 ROC AUC 分数显著高于测试数据的 ROC AUC 分数。

## 拉索(L1)和里奇(L2)的正规化

在将正则化应用于逻辑回归模型之前，让我们花点时间来理解正则化是什么以及它是如何工作的。scikit-learn 中正则化 logistic 回归模型的两种方式称为**套索**(也称为 **L1** 正则化)和**岭**(也称为 **L2** 正则化)。当从 scikit-learn 类实例化模型对象时，可以选择`penalty = 'l1'`或`'l2'`。这些被称为“惩罚”，因为正则化的效果是为拟合的逻辑回归模型中较大的系数值添加惩罚或成本。

正如我们已经了解到的，逻辑回归模型中的系数描述了响应的对数概率和每个特征之间的关系。因此，如果系数值特别大，那么该特征的小变化将对预测产生大的影响。当模型被拟合并且正在学习特征和响应变量之间的关系时，模型可以开始学习数据中的噪声。我们之前在*图 4.12* 中看到了这一点:如果在拟合模型时有许多可用的特征，并且在它们的系数可以采用的值上没有护栏，那么模型拟合过程可能会试图发现特征和响应变量之间的关系，这些关系不会推广到新数据。这样，模型就适应了伴随现实世界中不完美数据的不可预测的随机噪声。不幸的是，这只能增加模型预测训练数据的技能，而不是我们的最终目标。因此，我们应该设法从模型中根除这种虚假的关系。

套索和岭正则化使用不同的数学公式来实现这一目标。这些方法通过改变用于模型拟合的成本函数来工作，我们之前将其作为对数损失函数进行了介绍。套索正则化使用所谓的**1-范数**(因此有术语 L1):

![Figure 4.14: Log-loss equation with lasso penalty
](img/B16925_4_14.jpg)

图 4.14:带有套索惩罚的对数损失方程

图 4.14 中*方程的第一项 1 范数，就是 *m* 个不同特征的系数的绝对值之和。使用绝对值是因为系数在正方向或负方向过大都会导致过度拟合。那么，与我们之前看到的对数损失函数相比，这个成本函数还有什么不同呢？好了，现在有一个 *C* 因子乘以对数损失函数之和前面的分数。*

这是“正则化强度的倒数”，如 scikit-learn 文档([https://sci kit-learn . org/stable/modules/generated/sk learn . linear _ model)中所述。LogisticRegression.html](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)。由于该因子在计算预测误差的成本函数的项之前，与进行正则化的项相反，因此使其更大使得预测误差在成本函数中更重要，而正则化变得不那么重要。简而言之，在 scikit-learn 实现中，*较大的 C 值导致较少的正则化*。

L2 或岭正则化类似于 L1，只是岭使用系数的平方和而不是系数的绝对值之和，称为 **2 范数**:

![Figure 4.15: Log-loss equation with ridge penalty
](img/B16925_4_15.jpg)

图 4.15:带山脊惩罚的对数损失方程

请注意，如果您在 scikit-learn 文档中查看逻辑回归的成本函数，具体形式与这里使用的形式不同，但总体思想是相似的。此外，在您熟悉了套索和脊惩罚的概念后，您应该知道还有一种称为**弹性网**的额外正则化方法，它是套索和脊的组合。

为什么正则化有两种不同的表述？

其中一个可能会提供更好的样本外性能，因此您可能希望同时测试两者。这些方法还有另一个关键区别:除了正则化之外，L1 罚函数还执行特征选择。它通过在正则化过程中将一些系数值设置为零来实现这一点，从而有效地从模型中移除要素。L2 正则化使系数值变小，但不会完全消除它们。并非 scikit-learn 中的所有求解器选项都支持 L1 正则化和 L2 正则化，因此您需要为要使用的正则化技术选择合适的求解器。

注意

为什么 L1 正则化会移除特征而 L2 不会移除特征的数学细节超出了本书的范围。然而，为了更彻底地解释这个主题和进一步阅读，我们推荐非常可读(和免费)的资源，Gareth James 等人的《统计学习简介》，特别是，参见第 7 次印刷的*第 222 页*，关于 L1 和 L2 正则化之间的差异的有用图形。

**截距和规则化**

我们没有过多地讨论截距，只是注意到我们一直在用线性模型估计截距，以及每个特征的系数。那么，你应该使用拦截吗？答案可能是肯定的，直到你对线性模型有了深入的了解，并且确定在特定的情况下你不应该这样做。然而，这种情况确实存在，例如，在线性回归中，特征和响应变量都被标准化为平均值为零。

截取不属于任何特定的功能。因此，调整它们没有多大意义，因为它们不应该导致过度拟合。注意，在 L1 的正则化罚项中，求和从 *j = 1* 开始，类似地，对于 L2，我们跳过了 *σ* 0，这是截距项。

这是理想的情况:不调整截距。然而，scikit-learn 中的一些解算器，比如`liblinear`，实际上确实正则化了截距。您可以向模型类提供一个`intercept_scaling`选项来抵消这种影响。我们在这里没有说明这一点，因为尽管这在理论上是不正确的，但在实践中，调整截距通常不会对模型的预测质量产生太大影响。

**缩放和正则化**

如前一练习所述，最佳实践是在使用正则化之前对数据进行**缩放**，以使所有要素具有大致相同的值范围。这是因为在成本函数中，所有系数都将受到相同的惩罚。如果特定特征的值的范围，例如我们数据集中的`LIMIT_BAL`，比其他特征(例如`PAY_1`)大得多，那么实际上可能希望`PAY_1`的系数具有较大的值，而`LIMIT_BAL`的系数具有较小的值，以便在用于模型预测的特征和系数的线性组合中，将它们的影响放在相同的尺度上。在使用正则化之前对所有要素进行归一化可以避免仅由比例差异引起的此类复杂情况。

事实上，根据您使用的规划求解，缩放数据可能也是必要的。scikit-learn 中可用的梯度下降过程的不同变体可能或可能无法有效地处理未缩放的数据。

**选择正确解算器的重要性**

据我们了解，scikit-learn 中可用于逻辑回归的不同解算器在以下方面有不同的行为:

*   他们是否支持 L1 和 L2 正规化
*   他们如何处理正则化期间的截距
*   How they deal with unscaled data

    注意

    还有其他不同之处。在[https://sci kit-learn . org/stable/modules/linear _ model . html # logistic-regression](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression)上有一个比较这些和其他特征的有用表格。您可以使用此表来决定哪个规划求解适合您的问题。

总结这一节，我们已经学习了套索和脊正则化的数学基础。*这些方法的工作原理是将系数值向 0 收缩，在套索的情况下，将一些系数精确地设置为 0，从而执行特征选择*。你可以想象，在我们在*图 4.12* 中的过度拟合的例子中，如果复杂的过度拟合的模型有一些系数向 0 收缩，它看起来会更像有更少系数的理想模型。

这是一个正则化回归模型的图，使用与过度拟合模型相同的高次多项式要素，但具有岭惩罚:

![Figure 4.16: An overfit model and regularized model using the same features
](img/B16925_4_16.jpg)

图 4.16:使用相同特征的过拟合模型和正则化模型

正则化模型看起来与理想模型相似，证明了正则化校正过拟合的能力。但是，请注意，不应建议使用正则化模型进行外推。这里，我们可以看到正则化模型开始向*图 4.16* 的右侧增加。应该怀疑这种增加，因为在训练数据中没有任何东西表明这是可以预期的。这是一个普遍观点的例子，即不建议在训练数据范围之外对模型预测进行*外推*。然而，从*图 4.16* 中可以清楚地看出，即使我们不知道用于生成该合成数据的模型(因为我们通常不知道现实世界预测建模工作中的数据生成过程)，当大量候选特征可用时，我们仍然可以使用正则化来减少过度拟合的影响。

**型号和功能选择**

L1 正则化是使用模型(如逻辑回归)来执行特征选择的一种方式。其他方法包括从候选特征池向前或向后**逐步选择**。下面是这些方法背后的高级思想:在**正向选择**的情况下，一次向模型添加一个特性，并沿途观察样本外的性能。在每次迭代中，考虑来自候选池的所有可能特征的添加，并选择导致样本外性能最大增加的特征。当添加额外的特征不再改善模型的性能时，不再需要从候选中添加更多的特征。在**反向选择**的情况下，你首先从模型中的所有特征开始，确定你应该删除哪一个:导致样本外性能下降最小的那个。您可以继续以这种方式删除功能，直到性能开始明显下降。

注意

生成本节介绍的图的代码可以在这里找到:[https://packt.link/aUBMb](https://packt.link/aUBMb)。

# 交叉验证:选择正则化参数

到目前为止，您可能怀疑我们可以使用正则化来减少我们在*练习 4.02* 、*生成和模拟综合分类数据*中尝试模拟综合数据时观察到的过度拟合。问题是，我们如何选择正则化参数， *C* ？ *C* 是模型**超参数**的一个例子。超参数不同于模型定型时估计的参数，例如逻辑回归的系数和截距。超参数不是像参数一样由自动化过程估计，而是由用户作为关键字参数直接输入，通常是在实例化模型类时。那么，我们如何知道选择什么样的价值观呢？

超参数比参数更难估计。这是因为由数据科学家来确定什么是最佳值，而不是让优化算法来找到它。然而，可以通过编程选择超参数值，这本身就可以被视为一个优化过程。实际上，在正则化参数 *C* 的情况下，这通常通过用特定值 *C* 拟合一组数据的模型，确定模型训练性能，然后评估另一组数据的样本外性能来完成。

我们已经熟悉了使用模型训练和测试集的概念。然而，这里有一个关键的区别；例如，如果我们多次使用测试集来查看不同的 *C* 值的影响，会发生什么？

您可能会想到，在第一次使用看不见的测试集来评估特定值 *C* 的样本外性能之后，它就不再是一个“看不见的”测试集了。虽然只有训练数据用于估计模型参数(即系数和截距)，但现在测试数据正用于估计超参数 *C* 。实际上，测试数据现在已经成为额外的训练数据，因为它被用来为超参数寻找一个好的值。

因此，通常将数据分为三部分:训练集、测试集和验证集。验证集有多种用途:

**估计超参数**

验证集可重复用于评估不同超参数值的样本外性能，以选择超参数。

**不同型号的对比**

除了找到模型的超参数值，验证集还可以用于估计不同模型的样本外性能；例如，如果我们想比较逻辑回归和随机森林。

注意

**数据管理最佳实践**

作为一名数据科学家，如何为不同的预测建模任务划分数据取决于您。在理想情况下，在您已经选择了模型超参数和最佳模型之后，您应该为过程的最后保留一部分数据。这个**看不见的测试集**被保留到最后一步，当它可以被用来评估你的模型构建工作的终点时，看看最终的模型如何推广到新的看不见的数据。保留测试集时，最好确保特征和响应与其余数据具有相似的特征。换句话说，类分数应该相同，特征分布应该相似。这样，测试数据应该能够代表您用来构建模型的数据。

虽然模型验证是一个好的实践，但它提出了一个问题，即我们为训练、验证和测试数据选择的特定划分是否对我们正在跟踪的结果有任何影响。例如，在我们保留的不可见测试集中，或者在验证集中，与训练集相比，特征和响应变量之间的关系可能略有不同。很可能不可能消除所有这样的可变性，但是我们可以使用**交叉验证**的方法来避免过于相信数据的某个特定分割。

Scikit-learn 提供了方便的功能来促进交叉验证分析。这些函数扮演着与我们已经在使用的`train_test_split`相似的角色，尽管默认行为有些不同。现在让我们来熟悉一下它们。首先，导入这两个类:

```py
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import KFold
```

与`train_test_split`类似，我们需要指定数据集的多大比例用于训练和测试。然而，对于交叉验证(特别是在我们刚刚导入的类中实现的 **k 倍交叉验证**)，我们不是直接指定一个比例，而是简单地指出我们想要多少倍——即“ **k 倍**这里的想法是将数据分成 **k** 等份。例如，如果我们指定 4 个文件夹，那么每个文件夹将包含 25%的数据。这些折叠将是模型训练的四个单独实例中的测试数据，而来自每个折叠的剩余 75%将用于训练模型。在这个过程中，每个数据点总共被用作训练数据 *k - 1* 次，并且仅被用作测试数据一次。

当实例化该类时，如果我们希望在不同的运行中得到可重复的结果，我们会指出折叠的次数、是否在分割之前打乱数据以及随机种子:

```py
n_folds = 4
k_folds = KFold(n_splits=n_folds, shuffle=False)
```

在这里，我们已经实例化了一个对象，它有四个折叠，没有洗牌。我们使用返回的对象(我们称之为`k_folds`)的方式是将我们希望用于交叉验证的特性和响应数据传递给这个对象的`.split`方法。这输出了一个**迭代器**，这意味着我们可以循环输出来获得训练和测试数据的不同分割。如果我们从综合分类问题`X_syn_train`和`y_syn_train`中获取训练数据，我们可以像这样循环遍历拆分:

```py
for train_index, test_index in k_folds_iterator.split(X_syn_train,
                                                      y_syn_train):
```

迭代器将返回`X_syn_train`和`y_syn_train`的行索引，我们可以用它们来索引数据。在这个`for`循环中，我们可以编写代码来使用这些索引来选择数据，以便用不同的数据子集来重复训练和测试模型对象。这样，当使用一个特定的超参数值时，我们可以获得样本外性能的可靠指示，然后使用另一个超参数值重复整个过程。因此，交叉验证循环可能在不同的超参数值上嵌套在外循环中。我们将在下面的练习中说明这一点。

首先，这些裂缝看起来像什么？如果我们简单地将来自`train_index`和`test_index`的指数绘制成不同的颜色，我们会得到如下结果:

![Figure 4.17: Training/test splits for k-folds with four folds and no shuffling
](img/B16925_4_17.jpg)

图 4.17:具有四个折叠且没有洗牌的 k 折叠的训练/测试分割

在这里，我们看到，使用我们为`KFold`类指定的选项，该过程根据行的顺序，简单地将前 25%的数据作为第一个测试折叠，然后将下 25%的数据作为第二个折叠，依此类推。但是如果我们想要分层褶皱呢？换句话说，如果我们想确保响应变量的类分数在每一个折叠中都是相等的呢？虽然`train_test_split`允许这个选项作为关键字参数，但是有一个单独的`StratifiedKFold`类实现这个选项来进行交叉验证。我们可以说明分层拆分将如何出现，如下所示:

```py
k_folds = StratifiedKFold(n_splits=n_folds, shuffle=False)
```

![Figure 4.18: Training/test splits for stratified k-folds
](img/B16925_4_18.jpg)

图 4.18:分层 k 折叠的训练/测试分割

在*图 4.18* 中，我们可以看到不同褶皱之间有一些“洗牌”。该程序根据需要在折叠之间移动样本，以确保每个折叠中的类别分数相等。

现在，如果我们想打乱数据，从每个测试折叠的指数范围中选择样本，会怎么样呢？首先，我们为什么要这么做？嗯，有了我们为我们的问题创建的合成数据，我们可以确定这些数据没有特定的顺序。然而，在许多现实情况下，我们收到的数据可能会以某种方式进行排序。

例如，可能数据行已经按照帐户创建的日期或其他逻辑进行了排序。因此，在拆分之前对数据进行洗牌可能是个好主意。这样，任何可能用于分类的特征在整个折叠中都是一致的。否则，不同折叠中的数据可能具有不同的特征，可能导致特征和响应之间的不同关系。

这可能会导致折叠之间模型性能不均匀的情况。为了“混合”数据集所有行索引中的折叠，我们需要做的就是将`shuffle`参数设置为`True`:

```py
k_folds = StratifiedKFold(n_splits=n_folds, shuffle=True,
                          random_state=1)
```

![Figure 4.19: Training/test splits for stratified k-folds with shuffling
](img/B16925_4_19.jpg)

图 4.19:带洗牌的分层 k 折叠的训练/测试分割

通过混排，测试折叠在输入数据的索引间随机且相当均匀地展开。

K-fold 交叉验证是数据科学中广泛使用的方法。然而，选择使用多少折叠取决于手头的特定数据集。使用较少数量的折叠意味着每个折叠中的训练数据量相对较小。因此，这增加了模型欠拟合的机会，因为模型通常在更多数据上训练时工作得更好。尝试一些不同的折叠次数，看看 k-fold 测试分数的平均值和可变性是如何变化的，这是一个好主意。常见的折叠次数从 4 次或 5 次到 10 次不等。

在数据集非常小的情况下，可能有必要在交叉验证折叠中使用尽可能多的数据进行训练。在这个场景中，您可以使用一种叫做**留一交叉验证** ( **LOOCV** )的方法。在 LOOCV，每个折叠的测试集由一个样本组成。换句话说，训练数据中有多少个样本，就会有多少个折叠。对于每次迭代，除了一个样本之外，模型在所有样本上进行训练，并对该样本进行预测。然后，可以使用这些预测来构建准确度或其他性能度量。

与测试集的创建相关的其他关注点，例如为必须使用过去的观察来预测未来事件的问题选择过时的测试集，也适用于交叉验证。

在*练习 4.02* 、*生成和建模综合分类数据*中，我们看到对我们的训练数据进行逻辑回归拟合会导致过度拟合。事实上，测试分数( *ROC AUC = 0.81* )大大低于训练分数( *ROC AUC = 0.94* )。通过将正则化参数 *C* 设置为一个相对较大的值(1000)，我们基本上很少或没有使用正则化。现在我们来看看当我们在一个很宽的范围内改变 C 值时会发生什么。

注意

生成本节介绍的图的代码可以在这里找到:[https://packt.link/37Zks](https://packt.link/37Zks)。

## 练习 4.03:减少合成数据分类问题上的过拟合

本练习是*练习 4.02* 、*生成和建模综合分类数据*的延续。这里，我们将使用交叉验证程序，以便为超参数 *C* 找到一个好的值。我们将通过仅使用训练数据来做到这一点，将测试数据保留到模型构建完成之后。做好准备——这是一个漫长的练习——但它将说明一个通用程序，你将能够在许多不同类型的机器学习模型中使用它，因此值得在这里花费时间。执行以下步骤来完成练习:

注意

在开始这个练习之前，您需要执行一些先决步骤，这些步骤和这个练习的代码可以在下面的笔记本中找到:[https://packt.link/JqbsW](https://packt.link/JqbsW)。

1.  Vary the value of the regularization parameter, *C*, to range from *C = 1000* to *C = 0.001*. You can use the following snippets to do this.

    首先，定义指数，它是 10 的幂，如下所示:

    ```py
    C_val_exponents = np.linspace(3,-3,13)
    C_val_exponents
    ```

    以下是上述代码的输出:

    ```py
    array([ 3\. ,  2.5,  2\. ,  1.5,  1\. ,  0.5,  0\. , -0.5, -1\. , -1.5, -2\. , -2.5, -3\. ])
    ```

    现在，将 *C* 改变 10 的幂，如下所示:

    ```py
    C_vals = np.float(10)**C_val_exponents
    C_vals
    ```

    以下是上述代码的输出:

    ```py
    array([1.00000000e+03, 3.16227766e+02, 1.00000000e+02, 3.16227766e+01,
           1.00000000e+01, 3.16227766e+00, 1.00000000e+00, 3.16227766e-01,
           1.00000000e-01, 3.16227766e-02, 1.00000000e-02, 3.16227766e-03,
           1.00000000e-03])
    ```

    通常，以 10 的幂改变正则化参数或使用类似的策略是一个好主意，因为训练模型可能会花费大量时间，尤其是在使用 k 倍交叉验证时。这让您很好地了解了大范围的 *C* 值如何影响偏差方差权衡，而无需训练大量的模型。除了 10 的整数次方之外，我们还包括 log10 标度上大约介于两者之间的点。如果看起来在这些相对较宽的值之间有一些有趣的行为，您可以在可能值范围的较小部分中为 *C* 添加更细粒度的值。

2.  Import the `roc_curve` class:

    ```py
    from sklearn.metrics import roc_curve
    ```

    我们将继续使用 ROC AUC 分数来评估、培训和测试绩效。既然我们有几个值 *C* 要尝试，有几个折叠(在本例中是四个)要交叉验证，我们将希望存储每个折叠和每个值 *C* 的训练和测试分数。

3.  Define a function that takes the `k_folds` cross-validation splitter, the array of *C* values (`C_vals`), the model object (`model`), and the features and response variable (`X` and `Y`, respectively) as inputs, to explore different amounts of regularization with k-fold cross-validation. Use the following code:

    ```py
    def cross_val_C_search(k_folds, C_vals, model, X, Y):
    ```

    注意

    我们在此步骤中启动的函数将返回 ROC AUCs 和 ROC 曲线数据。返回块将在本练习的后续步骤中写入。现在，您可以简单地编写前面的代码，因为随着练习的进行，我们将定义`k_folds`、`C_vals`、`model`、`X`和`Y`。

4.  Within this function block, create a NumPy array to hold model performance data, with dimensions `n_folds` by `len(C_vals)`:

    ```py
    n_folds = k_folds.n_splits
    cv_train_roc_auc = np.empty((n_folds, len(C_vals)))
    cv_test_roc_auc = np.empty((n_folds, len(C_vals)))
    ```

    接下来，我们将在列表的**列表中存储伴随每个测试 ROC AUC 分数的真和假阳性率和阈值的数组。**

    注意

    这是存储所有模型性能信息的一种便捷方式，因为 Python 中的列表可以包含任何类型的数据，包括另一个列表。这里，列表的列表**中的内部列表的每一项将是保存 TPR、FPR 和每个折叠的阈值的数组的元组，用于每个 C 值。元组是 Python 中的有序集合数据类型，类似于列表，但不同于列表，它们是不可变的:元组中的项目在元组创建后不能更改。当一个函数返回多个值时，比如 scikit-learn 的 roc_curve 函数，这些值可以输出到一个变量，这个变量将是这些值的元组。当我们稍后访问这些数组以便检查它们时，这种存储结果的方式应该更明显。**

5.  Create a list of empty lists using `[[]]` and `*len(C_vals)` as follows:

    ```py
    cv_test_roc = [[]]*len(C_vals)
    ```

    使用`*len(C_vals)`表示对于 *C* 的每个值，应该有一个度量(TPR、FPR、阈值)的元组列表。

    在前一节中，我们已经学习了如何遍历不同的折叠进行交叉验证。我们现在需要做的是编写一个外部循环，我们将在其中嵌套交叉验证循环。

6.  Create an outer loop for training and testing each of the k-folds for each value of *C*:

    ```py
    for c_val_counter in range(len(C_vals)):
        #Set the C value for the model object
        model.C = C_vals[c_val_counter]
        #Count folds for each value of C
        fold_counter = 0
    ```

    我们可以重用已经拥有的同一个模型对象，并在循环的每次运行中简单地设置一个新的值 *C* 。在 *C* 值的循环中，我们运行交叉验证循环。我们首先为每个分割产生训练和测试数据行索引。

7.  获取每个折叠的训练和测试指标:

    ```py
    for train_index, test_index in k_folds.split(X, Y):
    ```

8.  Index the features and response variable to obtain the training and test data for this fold using the following code:

    ```py
    X_cv_train, X_cv_test = X[train_index], X[test_index]
    y_cv_train, y_cv_test = Y[train_index], Y[test_index]
    ```

    然后使用当前折叠的训练数据来训练模型。

9.  Fit the model on the training data, as follows:

    ```py
    model.fit(X_cv_train, y_cv_train)
    ```

    这将有效地从先前的系数和截距“重置”模型，以反映对该新数据的训练。

    然后获得训练和测试 ROC AUC 分数，以及 TPR、FPR 和阈值的数组，以及测试数据。

10.  获取训练 ROC AUC 分数:

    ```py
    y_cv_train_predict_proba = model.predict_proba(X_cv_train)
    cv_train_roc_auc[fold_counter, c_val_counter] = \
    roc_auc_score(y_cv_train, y_cv_train_predict_proba[:,1])
    ```

11.  获得测试 ROC AUC 分数:

    ```py
    y_cv_test_predict_proba = model.predict_proba(X_cv_test)
    cv_test_roc_auc[fold_counter, c_val_counter] = \
    roc_auc_score(y_cv_test, y_cv_test_predict_proba[:,1])
    ```

12.  Obtain the test ROC curves for each fold using the following code:

    ```py
    this_fold_roc = roc_curve(y_cv_test, y_cv_test_predict_proba[:,1])
    cv_test_roc[c_val_counter].append(this_fold_roc)
    ```

    我们将使用一个折叠计数器来跟踪增加的折叠，一旦超出交叉验证循环，我们就将状态更新打印到标准输出中。每当执行长时间的计算过程时，定期打印作业的状态是一个好主意，这样您可以监视其进度并确认事情仍然正常工作。这种交叉验证过程在你的笔记本电脑上可能只需要几秒钟，但对于更长时间的工作来说，这尤其令人放心。

13.  使用以下代码增加折叠计数器:

    ```py
    fold_counter += 1
    ```

14.  编写以下代码来指示 *C* :

    ```py
    print('Done with C = {}'.format(lr_syn.C))
    ```

    的每个值的执行进度
15.  Write the code to return the ROC AUCs and ROC curve data and finish the function:

    ```py
    return cv_train_roc_auc, cv_test_roc_auc, cv_test_roc
    ```

    请注意，我们将继续使用我们之前说明的分成四个折叠的方法，但是我们鼓励您尝试使用不同数量的折叠来比较效果。

    在前面的步骤中，我们已经介绍了很多材料。你可能需要花一些时间和你的同学一起复习，以确保你理解了每一部分。运行该函数相对简单。这就是一个设计良好的功能的美妙之处——所有复杂的部分都被抽象掉，让你专注于使用。

16.  Run the function we've designed to examine cross-validation performance, with the *C* values that we previously defined, and by using the model and data we were working with in the previous exercise. Use the following code:

    ```py
    cv_train_roc_auc, cv_test_roc_auc, cv_test_roc = \
    cross_val_C_search(k_folds, C_vals, lr_syn, X_syn_train, y_syn_train)
    ```

    当您运行这段代码时，您应该会看到代码单元格下面填充了以下输出，因为对每个值 *C* 的交叉验证已经完成:

    ```py
    Done with C = 1000.0
    Done with C = 316.22776601683796
    Done with C = 100.0
    Done with C = 31.622776601683793
    Done with C = 10.0
    Done with C = 3.1622776601683795
    Done with C = 1.0
    Done with C = 0.31622776601683794
    Done with C = 0.1
    Done with C = 0.03162277660168379
    Done with C = 0.01
    Done with C = 0.0031622776601683794
    Done with C = 0.001
    ```

    那么，交叉验证的结果是什么样的呢？有几种方法可以检验这一点。单独查看每个折叠的性能是很有用的，这样您就可以看到结果的可变性。

    这将告诉您数据的不同子集作为测试集的表现，从而大致了解您可以从看不见的测试集中获得的性能范围。我们在这里感兴趣的是，我们是否能够使用正则化来减轻我们看到的过度拟合。我们知道使用*C = 1000*会导致过度拟合——我们通过比较训练和测试分数了解到这一点。但是我们尝试过的其他 *C* 值呢？形象化这一点的一个好方法是将训练和测试分数绘制在 *y 轴*上，将 *C* 的值绘制在 *x 轴*上。

17.  Loop over each of the folds to view their results individually by using the following code:

    ```py
    for this_fold in range(k_folds.n_splits):
        plt.plot(C_val_exponents, cv_train_roc_auc[this_fold], '-o',\
                 color=cmap(this_fold),\
                 label='Training fold {}'.format(this_fold+1))
        plt.plot(C_val_exponents, cv_test_roc_auc[this_fold], '-x',\
                 color=cmap(this_fold),\
                 label='Testing fold {}'.format(this_fold+1))
    plt.ylabel('ROC AUC')
    plt.xlabel('log$_{10}$(C)')
    plt.legend(loc = [1.1, 0.2])
    plt.title('Cross validation scores for each fold')
    ```

    您将获得以下输出:

    ![Figure 4.20: The training and test scores for each fold and C-value
    ](img/B16925_4_20.jpg)

    图 4.20:每个折叠和 C 值的训练和测试分数

    我们可以看到，对于交叉验证的每一个折叠，随着 *C* 的减少，训练性能也下降。然而，与此同时，测试性能也提高了。对于 *C* 的一些折叠和值，测试 ROC AUC 分数实际上超过了训练数据的分数，而对于其他数据，这两个指标只是更接近而已。在所有情况下，我们可以说 10-1.5 和 10-2 的 *C* 值看起来具有相似的测试性能，这大大高于 *C = 10* 3 的测试性能。因此，看来正则化已经成功地解决了我们的过度拟合问题。

    但是 *C* 的下限值呢？对于低于 10-2 的值，ROC AUC 指标突然下降到 0.5。如您所知，这个值意味着分类模型本质上是无用的，其性能不比抛硬币好。鼓励您稍后在探索正则化如何影响系数值时检查这一点；然而，当应用太多 L1 正则化以至于所有模型系数收缩到 0 时，就会发生这种情况。显然，这样的模型对我们没有用，因为它们没有对特征和响应变量之间的关系进行编码。

    查看每个 k 倍分割的训练和测试性能有助于深入了解模型性能的可变性，当模型在新的、看不见的数据上评分时，可能会出现这种可变性。但是为了总结 k-folds 过程的结果，一种常见的方法是对于所考虑的超参数的每个值，对 folds 上的性能度量进行平均。我们将在下一步中执行此操作。

18.  Plot the mean of training and test ROC AUC scores for each *C* value using the following code:

    ```py
    plt.plot(C_val_exponents, np.mean(cv_train_roc_auc, axis=0), \
             '-o', label='Average training score')
    plt.plot(C_val_exponents, np.mean(cv_test_roc_auc, axis=0), \
             '-x', label='Average testing score')
    plt.ylabel('ROC AUC')
    plt.xlabel('log$_{10}$(C)')
    plt.legend()
    plt.title('Cross validation scores averaged over all folds')
    ```

    ![Figure 4.21: The average training and test scores across cross-validation folds
    ](img/B16925_4_21.jpg)

    图 4.21:交叉验证的平均训练和测试分数

    从这个图中可以看出 *C = 10* -1.5 和 *10* -2 是 *C* 的最佳值。这里很少或没有过度拟合，因为平均训练和测试分数几乎相同。您可以搜索一个更细的 *C* 值网格(即 *C = 10* -1.1 *、* *10* -1.2 等等)，以便更精确地定位一个 *C* 值。然而，从我们的图表中，我们可以看到 *C = 10* -1.5 或 *C = 10* -2 可能是好的解决方案。我们将以 *C = 10* -1.5 前进。

    检查 ROC AUC 的汇总指标是快速了解模型表现的好方法。然而，对于任何现实世界的业务应用程序，您通常需要选择一个特定的阈值，该阈值与特定的真阳性率和假阳性率相关联。这些将需要使用分类器来做出所需的“是”或“否”决定，在我们的案例研究中，这是对一个帐户是否会违约的预测。出于这个原因，查看交叉验证的不同折叠的 ROC 曲线是有用的。为了便于实现这一点，前面的函数被设计为在列表的列表`cv_test_roc`中为每个测试折叠和 *C* 的值返回真阳性率和假阳性率以及阈值。首先，我们需要找到与我们选择的 *C* 值 *10* -1.5 相对应的外部列表的索引。

    为了实现这一点，我们可以简单地查看我们的 *C* 值列表并手动计数，但是通过查找布尔数组的非零元素的索引来以编程方式进行计数更安全，如下一步所示。

19.  Use a Boolean array to find the index where *C = 10*-1.5 and convert it to an integer data type with the following code:

    ```py
    best_C_val_bool = C_val_exponents == -1.5
    best_C_val_bool.astype(int)
    ```

    以下是上述代码的输出:

    ```py
    array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])
    ```

20.  Convert the integer version of the Boolean array into a single integer index using the `nonzero` function with this code:

    ```py
    best_C_val_ix = np.nonzero(best_C_val_bool.astype(int)) best_C_val_ix[0][0]
    ```

    以下是上述代码的输出:

    ```py
    9
    ```

    我们现在已经成功地找到了我们想要使用的 *C* 值。

21.  Access the true and false positive rates in order to plot the ROC curves for each fold:

    ```py
    for this_fold in range(k_folds_n_splits):
        fpr = cv_test_roc[best_C_val_ix[0][0]][this_fold][0]
        tpr = cv_test_roc[best_C_val_ix[0][0]][this_fold][1]
        plt.plot(fpr, tpr, label='Fold {}'.format(this_fold+1))
    plt.xlabel('False positive rate')
    plt.ylabel('True positive rate')
    plt.title('ROC curves for each fold at C = $10^{-1.5}$')
    plt.legend()
    ```

    您将获得以下输出:

    ![Figure 4.22: ROC curves for each fold
    ](img/B16925_4_22.jpg)

    图 4.22:每次折叠的 ROC 曲线

    在 ROC 曲线中似乎有相当多的可变性。例如，如果出于某种原因，我们希望将假阳性率限制在 40%，那么从图中可以看出，我们可能能够实现大约 60%到 80%的真阳性率。您可以通过检查我们绘制的数组来找到确切的值。这可以让您了解在新数据上部署模型时，预期的性能变化有多大。一般来说，可用的训练数据越多，交叉验证倍数之间的可变性就越小，因此这也可能是收集额外数据的好主意，特别是如果训练倍数之间的可变性似乎高得不可接受。您也可以尝试不同的折叠次数，以便观察不同折叠次数对结果可变性的影响。

    虽然通常我们会在我们的合成数据问题上尝试其他模型，如随机森林或支持向量机，但如果我们认为在交叉验证中，逻辑回归被证明是最好的模型，我们会决定将它作为我们的最终选择。当选择了最终模型时，可以使用通过交叉验证选择的超参数，使用所有训练数据来拟合模型。最好在模型拟合中使用尽可能多的数据，因为模型通常在更多数据上训练时工作得更好。

22.  Train the logistic regression on all the training data from our synthetic problem and compare the training and test scores, using the held-out test set as shown in the following steps.

    注意

    这是模型选择过程的最后一步。只有在您选择的模型和超参数被认为已经完成之后，您才应该使用不可见的测试集，否则它就不是“不可见的”

23.  Set the *C* value and train the model on all the training data with this code:

    ```py
    lr_syn.C = 10**(-1.5)
    lr_syn.fit(X_syn_train, y_syn_train)
    ```

    以下是上述代码的输出:

    ```py
    LogisticRegression(C=0.03162277660168379, penalty='l1', \
                       random_state=1, solver='liblinear'))
    ```

24.  Obtain predicted probabilities and the ROC AUC score for the training data with this code:

    ```py
    y_syn_train_predict_proba = lr_syn.predict_proba(X_syn_train)
    roc_auc_score(y_syn_train, y_syn_train_predict_proba[:,1])
    ```

    以下是上述代码的输出:

    ```py
    0.8802812499999999
    ```

25.  Obtain predicted probabilities and the ROC AUC score for the test data with this code:

    ```py
    y_syn_test_predict_proba = lr_syn.predict_proba(X_syn_test)
    roc_auc_score(y_syn_test, y_syn_test_predict_proba[:,1])
    ```

    以下是上述代码的输出:

    ```py
    0.8847884788478848
    ```

    在这里，我们可以看到，通过使用正则化，模型训练和测试分数是相似的，表明过拟合问题已经大大减少。训练分数较低，因为我们以方差为代价在模型中引入了偏差。然而，这是可以的，因为测试分数，这是最重要的部分，更高。样本外测试分数对预测能力至关重要。鼓励您通过打印我们之前绘制的数组中的值来检查这些训练和测试分数是否与交叉验证过程中的分数相似；你应该会发现他们是。

    注意

    在现实世界的项目中，在将这个模型交付给客户进行生产使用之前，您可能希望根据您得到的所有数据(包括看不见的测试集)来训练这个模型。这遵循了一个观点，即一个模型看到的数据越多，它在实践中的表现就可能越好。然而，一些从业者更喜欢只使用已经测试过的模型，这意味着您将交付只在训练数据上训练过的模型，不包括测试集。

    我们知道 L1 正则化通过降低逻辑回归系数的大小(即绝对值)来工作。它还可以将一些系数设置为零，从而执行特征选择。在下一步中，我们将确定有多少系数被设置为零。

26.  Access the coefficients of the trained model and determine how many do not equal zero (`!= 0`) with this code:

    ```py
    sum((lr_syn.coef_ != 0)[0])
    ```

    输出应该如下所示:

    ```py
    2
    ```

    此代码接受指示非零系数位置的布尔数组的总和，因此它显示了模型中有多少系数没有被 L1 正则化设置为零。200 个特征中只选择了 2 个！

27.  Examine the value of the intercept using this code:

    ```py
    lr_syn.intercept_
    ```

    输出应该如下所示:

    ```py
    array([0.])
    ```

    这表明截距被调整为 0。

在这个练习中，我们完成了几个目标。我们使用 k-fold 交叉验证过程来调整正则化超参数。我们看到了正则化对于减少过度拟合的能力，以及在逻辑回归中 L1 正则化的情况下，选择特征。

许多机器学习算法提供某种类型的特征选择能力。许多还需要调整超参数。这里循环超参数并执行交叉验证的函数是一个强大的概念，可以推广到其他模型。Scikit-learn 提供了使这一过程更容易的功能；特别是`sklearn.model_selection.GridSearchCV`过程，它将交叉验证应用到超参数的网格搜索中。当有多个超参数需要优化时，通过查看您指定的不同超参数范围的所有组合，**网格搜索**会很有帮助。当彻底的网格搜索需要太长时间时，**随机网格搜索**可以通过随机选择少量的组合来加速这个过程。一旦你熟悉了这里展示的概念，你就可以用这些方便的功能来简化你的工作流程。

## sci kit-Learn 中的逻辑回归选项

我们已经使用并讨论了在实例化或调优一个`LogisticRegression`模型类的超参数时，您可能提供给 scikit-learn 的大多数选项。在这里，我们将它们全部列出，并提供一些关于它们用法的一般性建议:

![Figure 4.23: A complete list of options for the logistic regression model in scikit-learn
](img/B16925_4_23.jpg)

图 4.23:sci kit-learn 中逻辑回归模型选项的完整列表

如果您对使用哪个选项进行逻辑回归有疑问，我们建议您查阅 scikit-learn 文档以获得进一步的指导([https://sci kit-learn . org/stable/modules/linear _ model . html # logistic-regression](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression))。一些选项，如正则化参数 *C* ，或正则化惩罚的选择，将需要通过交叉验证过程进行探索。在这里，正如数据科学中的许多选择一样，没有适用于所有数据集的通用方法。了解给定数据集使用哪些选项的最佳方法是尝试其中的几个选项，看看哪个选项提供了最佳的样本外性能。交叉验证为您提供了一种强大的方法来做到这一点。

## 扩展 Scikit-Learn 中的数据、管道和交互功能

**缩放数据**

与我们刚刚处理的合成数据相比，案例研究数据相对较大。如果我们想要使用 L1 正则化，那么根据官方文档([https://sci kit-learn . org/stable/modules/linear _ model . html # logistic-regression](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression))，我们应该使用`saga`求解器。但是，该求解器对于未缩放的数据集并不稳定。因此，我们需要确保缩放数据。无论何时进行正则化，这也是一个好主意，因为所有的要素都在相同的比例上，并且在正则化过程中受到相同的惩罚。确保所有要素具有相同比例的一个简单方法是，将所有要素进行减去最小值并除以从最小值到最大值的范围的变换。这将转换每个要素，使其最小值为 0，最大值为 1。要实例化执行此操作的`MinMaxScaler`缩放器，我们可以使用以下代码:

```py
from sklearn.preprocessing import MinMaxScaler
min_max_sc = MinMaxScaler()
```

**管道**

以前，我们在交叉验证循环中使用逻辑回归模型。然而，现在我们正在扩展数据，有什么新的考虑吗？从训练数据的最小值和最大值中有效地“学习”了缩放。在此之后，逻辑回归模型将在由模型训练数据的极值缩放的数据上训练。然而，我们不知道新的、看不见的数据的最小值和最大值。因此，遵循使交叉验证成为对看不见的数据的模型性能的有效指标的原则，我们需要使用每个交叉验证折叠中的训练数据的最小和最大值，以便在对测试数据进行预测之前缩放该折叠中的测试数据。Scikit-learn 的功能有助于将几个培训和测试步骤结合起来，以应对以下情况:`Pipeline`。我们的管道将由两个步骤组成:定标器和逻辑回归模型。这两者都可以符合训练数据，然后用于对测试数据进行预测。安装管道的过程是作为代码中的一个步骤执行的，因此从这个意义上来说，管道的所有部分都是一次安装好的。下面是如何实例化一个`Pipeline`的:

```py
from sklearn.pipeline import Pipeline
scale_lr_pipeline = Pipeline(steps=[('scaler', min_max_sc), \
                                    ('model', lr)])
```

**交互特性**

考虑案例研究数据，您认为具有所有可能特征的逻辑回归模型是过拟合还是欠拟合？您可以从经验法则的角度来考虑这个问题，例如“10 法则”，以及我们拥有的特征数量(17)与样本数量(26，664)。或者，你可以考虑到目前为止我们对这些数据所做的所有工作。例如，我们有机会将所有特征可视化，并确保它们有意义。由于特征相对较少，并且我们有相对较高的信心认为它们是高质量的，因为我们进行了数据探索工作，所以我们的情况与本章中的综合数据练习不同，在综合数据练习中，我们有大量的特征，但我们对这些特征了解相对较少。因此，在这一点上，过度拟合对我们的案例研究来说可能不是一个问题，正则化的好处可能并不显著。

事实上，我们可能会仅使用数据附带的 17 个特征来对模型进行欠拟合。解决这个问题的一个策略是设计新的功能。我们讨论的一些简单的特征工程技术包括交互和多项式特征。考虑到一些数据的编码方式，多项式可能没有意义；比如 *-1* 2 *= 1* ，对于`PAY_1`来说可能不太明智。然而，我们可能希望尝试创建交互特征来捕捉特征之间的关系。`PolynomialFeatures`仅可用于创建交互特征，无多项式特征。示例代码如下:

```py
make_interactions = PolynomialFeatures(degree=2, \
                                       interaction_only=True, \
                                       include_bias=False)
```

这里，`degree`表示多项式特征的次数，`interaction_only`取一个布尔值(设置为`True`表示只创建交互特征)，`include_bias`也是如此，为模型添加一个截距(默认值为`False`，这里是正确的，因为逻辑回归模型会添加截距)。

## 活动 4.01: 利用案例研究数据进行交叉验证和特征工程

在本活动中，我们将把在本章中学到的交叉验证和规范化知识应用到案例研究数据中。我们将执行基本的特征工程。为了估计案例研究数据的正则化逻辑回归模型的参数，我们将使用`saga`求解器，案例研究数据的大小大于我们使用的合成数据。为了使用这个解算器，并且为了正则化，我们将需要**缩放**我们的数据作为建模过程的一部分，这将引导我们使用 scikit-learn 中的`Pipeline`类。完成活动后，通过使用交互功能，您应该可以获得更好的交叉验证测试性能，如下图所示:

![Figure 4.24: Improved model test performance
](img/B16925_4_24.jpg)

图 4.24:改进的模型测试性能

执行以下步骤来完成活动:

1.  Select the features from the DataFrame of the case study data.

    您可以使用我们在本章中已经创建的特性名称列表，但是一定不要包含响应变量，这是一个非常好的(但是完全不合适的)特性！

2.  Make a training/test split using a random seed of 24.

    我们将继续使用它，并将这个测试数据保留为不可见的测试集。通过指定随机种子，我们可以使用相同的训练数据，通过其他建模方法轻松创建单独的笔记本。

3.  实例化`MinMaxScaler`来缩放数据。
4.  用`saga`解算器实例化一个逻辑回归模型，L1 惩罚，并设置`max_iter`为`1000`，因为我们希望解算器有足够的迭代来找到一个好的解决方案。
5.  导入`Pipeline`类，并使用 scaler 和逻辑回归模型创建一个管道，分别为步骤使用名称`'scaler'`和`'model'`。
6.  使用`get_params`和`set_params`方法查看如何查看管道每个阶段的参数并更改它们。
7.  创建一个更小范围的 *C* 值来进行交叉验证测试，因为这些模型将需要更长的时间来训练，并使用比我们之前的练习更多的数据进行测试；我们推荐*C =【10*2*，10，1，10* -1 *，10* -2 *，10*-3*。*
**   做一个新版本的`cross_val_C_search`函数叫做`cross_val_C_search_pipe`。这个函数没有使用`model`参数，而是使用了`pipeline`参数。函数内部的变化将是使用管道上的`set_params(model__C = <value you want to test>)`设置 *C* 值，用管道替换模型用于`fit`和`predict_proba`方法，并使用`pipeline.get_params()['model__C']`访问 *C* 值用于打印状态更新。*   Run this function as in the previous exercise, but using the new range of *C* values, the pipeline you created, and the features and response variable from the training split of the case study data.

    您可能会在这里或后面的步骤中看到关于求解器不收敛的警告。您可以尝试使用`tol`或`max_iter`选项来尝试实现收敛，尽管您使用`max_iter = 1000`获得的结果可能已经足够了。

    *   针对每个 *C* 值，跨折叠绘制平均训练和测试 ROC AUC。*   为案例研究数据创建交互特征，并确认新特征的数量是合理的。*   Repeat the cross-validation procedure and observe the model performance when using interaction features.

    请注意，由于要素数量较多，这将花费更多的时间，但可能不到 10 分钟。那么，平均交叉验证测试性能是否随着交互特性而提高？正规化有用吗？

    注意

    包含此活动的 Python 代码的 Jupyter 笔记本可以在[https://packt.link/ohGgX](https://packt.link/ohGgX)找到。通过[链接](B16925_Solution_ePub.xhtml#_idTextAnchor155)可以找到该活动的详细分步解决方案。* 

 *# 总结

在本章中，我们介绍了逻辑回归的最终细节，并继续了解如何使用 scikit-learn 来拟合逻辑回归模型。通过学习成本函数的概念，我们对模型拟合过程如何工作有了更多的了解，成本函数通过梯度下降过程最小化，以在模型拟合期间估计参数。

通过引入欠拟合和过拟合的概念，我们还了解到了正则化的必要性。为了减少过度拟合，我们看到了如何调整成本函数，使用 L1 或 L2 罚函数来调整逻辑回归模型的系数。我们使用交叉验证通过调整正则化超参数来选择正则化的量。为了减少欠拟合，我们看到了如何对案例研究数据的交互特性进行一些简单的特性工程。

我们现在已经熟悉了机器学习中一些最重要的概念。到目前为止，我们只使用了一个非常基本的分类模型:逻辑回归。然而，随着您知道如何使用的模型工具箱的增加，您会发现过拟合和欠拟合、偏差方差权衡和超参数调整的概念会一次又一次地出现。这些想法，以及我们在本章中编写的交叉验证函数的方便的 scikit-learn 实现，将帮助我们探索更高级的预测方法。

在下一章，我们将学习决策树，一种与逻辑回归完全不同的预测模型，以及基于它们的随机森林。然而，我们将使用我们在这里学到的相同概念，交叉验证和超参数搜索，来调整这些模型。*