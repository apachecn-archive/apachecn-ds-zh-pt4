<title>B16925_06_ePub</title> <link href="css/epub.css" rel="stylesheet" type="text/css">

# 6。梯度增强、XGBoost 和 SHAP 值

概观

读完这一章，你将能够描述梯度增强的概念，这是 XGBoost 包的基本思想。然后，您将在合成数据上训练 XGBoost 模型，同时学习提前停止以及几个 XGBoost 超参数。除了使用与我们之前相似的方法来种树(通过设置`max_depth`)，您还将发现 XGBoost 提供的一种新的种树方法:损失导向的树生长。在学习了 XGBoost 之后，你将会被介绍一种新的强大的解释模型预测的方法，叫做 **SHAP** ( **沙普利附加解释**)。您将了解如何使用 SHAP 值为任何数据集(不仅仅是训练数据)的模型预测提供个性化解释，并了解 SHAP 值的可加性。

# 简介

正如我们在前一章看到的，决策树和基于它们的集成模型为创建机器学习模型提供了强大的方法。虽然随机森林已经存在了几十年，但最近关于不同类型的树集合(梯度增强树)的工作已经产生了最先进的模型，这些模型已经主导了使用表格数据或组织成结构化表格的数据(类似于案例研究数据)进行预测建模的领域。今天，机器学习数据科学家使用两个主要的软件包来创建具有表格数据的最准确的预测模型，这两个软件包是 XGBoost 和 LightGBM。在本章中，我们将使用一个合成数据集来熟悉 XGBoost，然后将它应用于活动中的案例研究数据。

注意

也许使用 XGBoost 的一些最好的动机来自描述这个机器学习系统的论文，在 Kaggle 的背景下，一个流行的机器学习竞赛在线论坛:

“在 2015 年 Kaggle 博客上发布的 29 个挑战获奖解决方案中，有 17 个解决方案使用了 XGBoost。在这些解决方案中，有八个单独使用 XGBoost 来训练模型，而大多数其他解决方案将 XGBoost 与神经网络结合在一起。作为比较，在 11 个解决方案中使用了第二种最流行的方法，深度神经网络”(Chen and Guestrin，2016，)。

正如我们将看到的，XGBoost 将我们到目前为止讨论的一些不同的想法联系在一起，包括决策树和集成建模以及梯度下降。

除了更具性能的模型，最近的机器学习研究已经产生了更详细的方法来解释模型的预测。我们不再依赖于只代表总体模型训练集的解释，如逻辑回归系数或随机森林的特征重要性，而是使用一个名为 SHAP 的新包来单独解释模型预测，并针对我们需要的任何数据集，如验证或测试数据。这非常有助于我们作为数据科学家以及我们的业务合作伙伴在粒度级别上理解模型的工作方式，即使是对于新数据。

# 梯度增强和 XGBoost

## 什么是助推？

**Boosting** 是一个创建许多机器学习模型的集成的过程，或**估计器**，类似于作为随机森林模型基础的 bagging 概念。像 bagging 一样，虽然 boosting 可以用于任何类型的机器学习模型，但它通常用于构建决策树的集合。与 bagging 的一个关键区别是，在 boosting 中，添加到集合中的每个新估计量都依赖于在它之前添加的所有估计量。因为 boosting 过程在连续的阶段中进行，并且集合成员的预测被相加以计算整体集合预测，所以它也被称为**阶段相加建模**。装袋和增压之间的差异可以在图 6.1 中看到:

![Figure 6.1: Bagging versus boosting
](image/B16925_06_01.jpg)

图 6.1:装袋与增压

bagging 使用训练数据的不同随机样本训练许多估计器，boosting 使用关于集合中哪些样本被先前的估计器错误分类的信息训练新的估计器。通过将新的估计器集中在这些样本上，目标是整个集合在整个训练数据集上将具有更好的性能。作为 **XGBoost** 的前身，AdaBoost 通过在训练集合中的新估计器时给错误分类的样本更多权重来实现这个目标。

## 梯度增强和 XGBoost

XGBoost 是一个建模过程和 Python 包，是当今使用的最流行的机器学习方法之一，因为它在从商业到自然科学的许多领域都有卓越的性能。XGBoost 也被证明是机器学习竞赛中最成功的工具之一。我们不会讨论 XGBoost 是如何实现的所有细节，而是从高层次了解它是如何工作的，并查看一些最重要的超参数。有关更多细节，感兴趣的读者应该参考陈天琦和卡洛斯·盖斯特林(【https://dl.acm.org/doi/abs/10.1145/2939672.2939785】)的出版物 *XGBoost:一个可扩展的树提升系统*。

梯度增强过程的 XGBoost 实现是一个类似于 AdaBoost 的分阶段加法模型。然而，XGBoost 没有在模型训练期间直接给错误分类的样本更多的权重，而是使用本质上类似于梯度下降的过程。回想一下第四章*、*、*中的偏差方差权衡*，梯度下降优化在训练逻辑回归模型时使用关于**损失函数**(成本函数的另一个名称)导数的信息来更新估计系数。损失函数的导数包含关于在过程的每次迭代中调整系数估计的方向和程度的信息，以便降低预测中的误差水平。

XGBoost 将梯度下降思想应用于阶段式加法建模，使用关于损失函数的梯度(导数的另一种说法)的信息来训练新的决策树以添加到集成中。事实上，XGBoost 比梯度下降更进了一步，如在*第 4 章*、*偏差-方差权衡*中所述，并且使用了关于一阶和二阶导数的信息。使用误差梯度训练决策树的方法是*第 5 章*、*决策树和随机森林*中介绍的节点杂质概念的替代方法。从概念上讲，XGBoost 训练新的树，目标是使集合预测朝着减少误差的方向移动。在该方向采取多大的步长由`learning_rate`超参数控制，类似于*练习 4.01 中的`learning_rate`使用梯度下降最小化成本函数*，来自*第 4 章*、*偏差方差权衡*。

至此，我们应该对 XGBoost 的工作原理有了足够的了解，可以开始动手使用它了。为了说明 XGBoost，我们将使用 scikit-learn 的`make_classification`函数为二元分类创建一个合成数据集。该数据集将包含 5000 个样本和 40 个要素。这里的其余选项控制分类任务的难度，您应该参考 scikit-learn 文档来更好地理解它们。特别有趣的是，我们将有多个聚类(`n_clusters_per_class`)，这意味着多维特征空间中将有几个属于某个类别的点区域，类似于*图 5.3* 中最后一章所示的聚类。基于树的模型应该能够识别这些集群。此外，我们指定总共 40 个特征中只有 3 个信息特征(`n_informative`)，以及 2 个冗余特征(`n_redundant`)，它们将包含与信息特征相同的信息。所以，总的来说，40 个特征中只有 5 个对预测有用，而且所有的信息都包含在其中的 3 个中。

如果你想在你的电脑上学习本章中的例子，请参考位于[https://packt.link/L5oS7](https://packt.link/L5oS7)的 Jupyter 笔记本:

```
from sklearn.datasets import make_classification
X, y = make_classification(n_samples=5000, n_features=40,\
                           n_informative=3, n_redundant=2,\
                           n_repeated=0, n_classes=2,\
                           n_clusters_per_class=3,\
                           weights=None, flip_y=0.05,\
                           class_sep=0.1, hypercube=True,\
                           shift=0.0,scale=1.0, shuffle=True,\
                           random_state=2)
```

请注意，响应变量`y`的类别分数约为 50%:

```
y.mean()
```

这将输出以下内容:

```
0.4986
```

在本章中，我们不使用交叉验证，而是将这个合成数据集一次拆分成一个训练集和验证集。然而，我们在这里介绍的概念可以扩展到交叉验证场景。我们将把这些合成数据分成 80%用于训练，20%用于验证。在现实世界的数据问题中，我们还希望保留一个测试集，供以后评估最终模型时使用，但我们在这里将放弃这一点:

```
from sklearn.model_selection import train_test_split
X_train, X_val, y_train, y_val = \
train_test_split(X, y, test_size=0.2, random_state=24)
```

既然我们已经为建模准备了数据，我们需要实例化一个`XGBClassifier`类的对象。请注意，我们现在将使用 XGBoost 包，而不是 scikit-learn 来开发预测模型。然而，XGBoost 有一个 API(应用程序编程接口),它被设计成与 scikit-learn 的 API 相似，所以使用这个类应该是直观的。使用`XGBClassifier`类可以用`fit`和`predict`方法以及其他熟悉的功能创建模型对象，我们可以在实例化该类时指定模型超参数。我们将在这里指定几个我们已经讨论过的超参数:`n_estimators`是用于模型的推进轮次的数量(换句话说，是用于逐级加法建模过程的级数)，`objective`是将用于计算梯度的损失函数，`learning_rate`控制每个新的估计器添加到集合中的量，或者，本质上，控制采取多远的步骤来减少预测误差。其余的超参数与我们希望在模型训练(`verbosity`)期间看到多少输出以及即将被否决的`label_encoder`选项有关，XGBoost 开发人员建议将其设置为`False`:

```
xgb_model_1 = xgb.XGBClassifier(n_estimators=1000,\
                                verbosity=1,\
                                use_label_encoder=False,\
                                objective='binary:logistic',\
                                learning_rate=0.3)
```

我们指出的超参数值规定:

*   我们将有 1000 个评估者，或推进轮。我们将很快更详细地讨论需要多少轮；默认值为 100。
*   我们从*第四章*、*偏差-方差权衡*中熟悉二元逻辑回归的目标函数(也称为成本函数)。XGBoost 还为一系列任务提供了各种各样的目标函数，包括分类和回归。
*   The learning rate is set to `0.3`, which is the default. Different values can be explored via hyperparameter search procedures, which we'll demonstrate.

    注意

    建议使用 Anaconda 环境安装 XGBoost 和 SHAP，如*前言*所示。如果您安装的版本与所示版本不同，您的结果可能会与此处显示的不同。

现在我们已经有了一个模型对象和一些训练数据，我们已经准备好去拟合这个模型了。这看起来类似于它在 scikit-learn 中的做法:

```
%%time
xgb_model_1.fit(X_train, y_train,\
                eval_metric="auc",\
                verbose=True)
```

在这里，我们使用 Jupyter 笔记本中的`%%time`“单元格魔术”来跟踪拟合过程需要多长时间。我们需要提供训练数据的特征`X_train`和响应变量`y_train`。我们还提供了`eval_metric`并设置了详细程度，稍后我们将对此进行解释。执行此单元格应该会产生类似如下的输出:

```
CPU times: user 52.5 s, sys: 986 ms, total: 53.4 s
Wall time: 17.5 s
Out[7]:
XGBClassifier(base_score=0.5, booster='gbtree',\
              colsample_bylevel=1, colsample_bynode=1,\
              colsample_bytree=1, gamma=0, gpu_id=-1,\
              importance_type='gain',interaction_constraints='',\
              learning_rate=0.3, max_delta_step=0, max_depth=6,\
              min_child_weight=1, missing=nan,\
              monotone_constraints='()', n_estimators=1000,\
              n_jobs=4, num_parallel_tree=1, random_state=0,\
              reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\
              subsample=1, tree_method='exact',\
              use_label_encoder=False, validate_parameters=1,\
              verbosity=1)
```

输出告诉我们，这个单元花了 17.5 秒来执行，称为“墙上时间”，或者可能挂在墙上的时钟所用的时间。CPU 时间比这个长，因为 XGBoost 有效地同时使用多个处理器。XGBoost 还打印出所有的超参数，包括我们设置的参数和其他保留默认值的参数。

现在，为了检查这个拟合模型的性能，我们将评估验证集的 ROC 曲线下的面积。首先，我们需要获得预测的概率:

```
val_set_pred_proba = xgb_model_1.predict_proba(X_val)[:,1]
from sklearn.metrics import roc_auc_score
roc_auc_score(y_val, val_set_pred_proba)
```

该单元的输出应该如下所示:

```
0.7773798710782294
```

这表明 ROC AUC 约为 0.78。这将是我们的模型性能基线，使用 XGBoost 的几乎默认的选项。

# XGBoost 超参数

## 提前停止

当使用 XGBoost 训练决策树的集成时，有许多选项可用于减少过度拟合和利用偏差-方差权衡。**提前停止**是其中一个简单的方法，可以自动回答“需要多少轮助推？”。值得注意的是，早期停止依赖于除了训练集之外的单独的数据验证集。然而，该验证集实际上将在模型训练过程中使用，因此它不符合从模型训练中获得的“看不见的”数据的条件，类似于我们在*第 4 章*、*偏差-方差权衡*中如何在交叉验证中使用验证集来选择模型超参数。

当 XGBoost 正在训练连续的决策树以减少训练集上的错误时，有可能向集成添加越来越多的树将为训练数据提供越来越好的拟合，但开始导致保留数据的性能降低。为了避免这种情况，我们可以使用一个验证集，XGBoost 也称之为评估集或`eval_set`。评估集将作为特征元组及其相应响应变量的列表提供。无论哪个元组出现在这个列表的最后，都将被用于提前停止。我们希望将此作为验证集，因为训练数据将用于拟合模型，并且不能提供样本外泛化的估计值:

```
eval_set = [(X_train, y_train), (X_val, y_val)]
```

现在我们可以再次拟合模型，但是这次我们用刚刚创建的评估集来提供关键字参数`eval_set`。此时，`auc`的`eval_metric`就变得重要了。这意味着在每一轮提升后，在训练另一棵决策树之前，ROC 曲线下的区域将在所有提供有`eval_set`的数据集上进行评估。由于我们将指明`verbosity=True`，我们将在单元格下方打印训练集和验证集的 ROC AUC 输出。这提供了一个很好的实时视图，显示了随着更多的助推轮次被训练，模型性能如何根据训练和验证数据而变化。

由于在预测建模中，我们主要对模型在新的和未知的数据上的表现感兴趣，所以当发现额外的提升轮次不能提高模型在样本外数据上的表现时，我们会停止训练额外的提升轮次。`early_stopping_rounds=30`参数表明，一旦完成 30 轮增强，而验证集的 ROC AUC 没有任何额外改善，XGBoost 应停止模型训练。一旦模型训练完成，最终拟合的模型将仅具有在验证集上获得最高模型性能所需的集合成员。这意味着集合的最后 30 个成员将被丢弃，因为它们没有提供验证集性能的任何提高。现在让我们来拟合这个模型，并观察进度:

```
%%time
xgb_model_1.fit(X_train, y_train, eval_set=eval_set,\
                eval_metric='auc',\
                verbose=True, early_stopping_rounds=30)
```

输出应该如下所示:

```
[0]	validation_0-auc:0.80412	validation_1-auc:0.75223
[1]	validation_0-auc:0.84422	validation_1-auc:0.79207
[2]	validation_0-auc:0.85920	validation_1-auc:0.79278
[3]	validation_0-auc:0.86616	validation_1-auc:0.79517
[4]	validation_0-auc:0.88261	validation_1-auc:0.79659
[5]	validation_0-auc:0.88605	validation_1-auc:0.80061
[6]	validation_0-auc:0.89226	validation_1-auc:0.80224
[7]	validation_0-auc:0.89826	validation_1-auc:0.80305
[8]	validation_0-auc:0.90559	validation_1-auc:0.80095
[9]	validation_0-auc:0.91954	validation_1-auc:0.79685
[10]	validation_0-auc:0.92113	validation_1-auc:0.79608
…
[33]	validation_0-auc:0.99169	validation_1-auc:0.78323
[34]	validation_0-auc:0.99278	validation_1-auc:0.78261
[35]	validation_0-auc:0.99329	validation_1-auc:0.78139
[36]	validation_0-auc:0.99344	validation_1-auc:0.77994
CPU times: user 2.65 s, sys: 136 ms, total: 2.78 s
Wall time: 2.36 s
…
```

请注意，这比上一次拟合花费的时间要少得多。这是因为，由于提前停止，我们只训练了 37 轮助推(注意助推轮是零索引的)。这意味着增强程序只需要 8 轮就可以达到最好的验证分数，而不是我们之前尝试的 1000 轮！您可以使用模型对象的`booster`属性访问达到最佳验证集分数所需的提升回合数以及该分数。与我们一直使用的 scikit-learn API 相比，该属性为模型提供了一个更低级别的接口:

```
xgb_model_1.get_booster().attributes()
```

输出应该如下所示，确认迭代次数和最佳验证分数:

```
{'best_iteration': '7', 'best_score': '0.80305'}
```

从训练程序中，我们还可以看到每一轮后训练数据`validation_0-auc`和验证数据`validation_1-auc`的 ROC AUC，这提供了随着增强程序的进行对过度拟合的洞察。这里我们可以看到，验证分数增加到第 8 轮，之后开始下降，表明进一步提高可能会产生不希望的过度拟合模型。然而，训练分数继续增加，直到程序终止，这表明 XGBoost 能够多么有力地拟合训练数据。

我们可以进一步确认拟合的模型对象仅代表七轮增强，并通过如我们之前所做的那样手动计算 ROC AUC 来检查验证集性能:

```
val_set_pred_proba_2 = xgb_model_1.predict_proba(X_val)[:,1]
roc_auc_score(y_val, val_set_pred_proba_2)
```

这将输出以下内容:

```
0.8030501882609966
```

这与七轮助推后达到的最高验证分数相匹配。因此，通过对模型训练过程的一个简单调整，通过使用验证集和早期停止，我们能够将验证集上的模型性能从大约 0.78 提高到 0.80，这是一个实质性的提高。由此可见提前停止在助推中的重要性。

这里一个自然的问题是“我们怎么知道 30 个回合的提前停止就足够了？”。与任何超参数一样，您可以试验这个数字，不同的值可能适用于不同的数据集。您可以查看验证分数如何随着每一轮提升而变化，从而对此有所了解。有时，验证分数可能会在不同轮次之间以一种跳跃的方式增加和减少，所以有足够的轮次来确保你已经找到了最大值，并通过任何暂时的减少来提高分数是一个好主意。

## 调整学习率

学习率在 XGBoost 文档中也被称为 **eta** ，以及**步长收缩**。这个超参数控制每个新估计量对集合预测的贡献大小。如果提高学习率，您可能会更快地达到最佳模型，该模型被定义为在验证集上具有最高性能。但是，将它设置得太高会导致升压步长过大。在这种情况下，由于类似于*练习 4.01 中讨论的问题，梯度推进程序可能不会收敛于最优模型，使用梯度下降来最小化成本函数*来自*第 4 章，偏差方差权衡*，关于梯度下降中的大学习率。让我们探索学习率如何影响我们的合成数据的模型性能。

学习率是一个介于 0 和 1 之间的数字(包括端点，尽管学习率为零是没有用的)。我们用 0.01 到 1 之间的 25 个均匀分布的数字组成一个数组，作为我们要测试的学习率:

```
learning_rates = np.linspace(start=0.01, stop=1, num=25)
```

现在我们设置一个`for`循环来为每个学习率训练一个模型，并将验证分数保存在一个数组中。我们还将跟踪达到最佳迭代所需的推进轮数。接下来的几个代码块应该作为 Jupyter 笔记本中的一个单元一起运行。我们首先测量这需要多长时间，创建空列表来存储结果，并打开`for`循环:

```
%%time
val_aucs = []
best_iters = []
for learning_rate in learning_rates:
```

在每次循环迭代中，`learning_rate`变量将保存`learning_rates`数组的连续元素。一旦进入循环，第一步是用新的学习率更新模型对象的超参数。这是使用`set_params`方法完成的，我们提供了一个双星号`**`和一个将超参数名称映射到值的字典。Python 中的`**`函数调用语法允许我们提供任意数量的关键字参数，也称为 **kwargs** ，作为一个字典。在本例中，我们只更改了一个关键字参数，所以字典只有一个条目:

```
    xgb_model_1.set_params(**{'learning_rate':learning_rate})
```

现在我们已经在模型对象上设置了新的学习率，我们像以前一样使用早期停止来训练模型:

```
    xgb_model_1.fit(X_train, y_train, eval_set=eval_set,\
                    eval_metric='auc',\
                    verbose=False, early_stopping_rounds=30)
```

拟合后，我们获得验证集的预测概率，然后用它们计算验证 ROC AUC。使用`append`方法将其添加到我们的结果列表中:

```
    val_set_pred_proba_2 = xgb_model_1.predict_proba(X_val)[:,1]
    val_aucs.append(roc_auc_score(y_val, val_set_pred_proba_2))
```

最后，我们还获取了每个学习率所需的回合数:

```
     best_iters.append(
        int(xgb_model_1.get_booster().\
                        attributes()['best_iteration']))
```

前面的五个代码片段应该在一个单元中一起运行。输出应该如下所示:

```
CPU times: user 1min 23s, sys: 526 ms, total: 1min 24s
Wall time: 22.2 s
```

现在我们有了这个超参数搜索的结果，我们可以可视化验证集的性能和迭代次数。由于这两个指标在不同的尺度上，我们想要创建一个双 *y* 轴图。pandas 使这变得简单，所以首先我们将所有数据放入一个数据框中:

```
learning_rate_df = \
pd.DataFrame({'Learning rate':learning_rates,\
              'Validation AUC':val_aucs,\
              'Best iteration':best_iters})
```

现在，我们可以像这样可视化不同学习率的性能和迭代次数，注意:

*   我们设置索引(`set_index`)，这样学习率被绘制在 *x* 轴上，其他列在 *y* 轴上。
*   `secondary_y`关键字参数指示在右边的 *y* 轴上绘制哪一列。
*   `style`参数允许我们为绘制的每个列指定不同的线条样式。`-o`是带点的实线，而`--o`是带点的虚线:

    ```
    mpl.rcParams['figure.dpi'] = 400
    learning_rate_df.set_index('Learning rate')\
    .plot(secondary_y='Best iteration', style=['-o', '--o'])
    ```

结果图应该如下所示:

![Figure 6.2: XGBoost model performance on a validation set, with the number of boosting rounds until best iteration, for different learning rates
](image/B16925_06_02.jpg)

图 6.2: XGBoost 模型在验证集上的性能，以及在不同的学习速率下，直到最佳迭代的推进轮数

总的来说，似乎较小的学习率导致该合成数据的更好的模型性能。通过使用小于默认值 0.3 的学习率，我们可以获得的最佳性能如下所示:

```
max(val_aucs)
```

输出如下所示:

```
0.8115309360232714
```

通过调整学习率，我们能够将验证 AUC 从约 0.80 增加到 0.81，表明使用适当学习率的益处。

一般来说，较小的学习率通常会导致更好的模型性能，尽管它们需要更多轮次的提升，因为每轮次的贡献较小。这将转化为模型训练所需的更多时间。我们可以在*图 6.2* 中达到最佳迭代所需的轮数图中看到这一点。在这种情况下，看起来用不到 50 轮就可以获得良好的性能，并且在任何情况下，模型训练时间对于该数据都不是很长。对于较大的数据集，训练时间可能会更长。根据您有多少计算时间，降低学习率和训练更多轮次可能是提高模型性能的有效方法。

当探索更小的学习速率时，确保将`n_estimators`超参数设置得足够大，以允许训练过程找到最佳模型，最好是结合早期停止。

## XGBoost 中的其他重要超参数

我们已经看到，XGBoost 中的过度适应可以通过使用不同的学习速率以及早期停止来补偿。其他可能相关的超参数有哪些？XGBoost 有很多超参数，这里就不一一列举了。我们鼓励你查阅文档([https://xgboost.readthedocs.io/en/latest/parameter.html](https://xgboost.readthedocs.io/en/latest/parameter.html))以获得完整的列表。

在下面的练习中，我们将在包括学习率在内的六个超参数范围内进行网格搜索。我们还将包括`max_depth`，这应该是从*第五章*、*决策树和随机森林*中熟悉的，并控制集合中的树木生长的深度。除此之外，我们还将考虑以下因素:

*   `gamma`通过仅允许在损失函数值的减少大于特定量的情况下分裂节点来限制集合中树的复杂性。
*   `min_child_weight`也控制树的复杂性，如果节点至少有一定数量的“样本权重”，则只拆分节点如果所有样本都具有相同的权重(就像我们的练习中一样)，这相当于一个节点中训练样本的最小数量。这类似于 scikit-learn 中决策树的`min_weight_fraction_leaf`和`min_samples_leaf`。
*   `colsample_bytree`是随机选择的一部分特征，将用于生长集合中的每棵树。这类似于 scikit-learn 中的`max_features`参数(它在节点级别进行选择，而不是在树级别)。XGBoost 还使`colsample_bylevel`和`colsample_bynode`可以分别在每棵树的每一层和每个节点进行特征采样。
*   `subsample`控制在为集合生成新树之前，从训练数据中随机选择样本的比例。这类似于 scikit-learn 中随机森林的`bootstrap`选项。这两个参数和`colsample`参数限制了模型训练期间可用的信息，增加了个体集合成员的偏差，但也有望减少整体集合的方差并改善样本外模型性能。

如您所见，XGBoost 中的梯度提升树实现了决策树和随机森林中常见的几个概念。现在，让我们探索这些超参数如何影响模型性能。

## 练习 6.01:调整 XGBoost 超参数的随机网格搜索

在本练习中，我们将使用随机网格搜索来探索六个超参数的空间。当您想要搜索许多超参数的许多值时，随机网格搜索是一个很好的选择。我们将在这里查看六个超参数。例如，如果我们想要测试的每一个都有五个值，我们将需要 *5* 6 = 15，625 次搜索。即使每个模型只需要一秒钟，我们仍然需要几个小时来彻底搜索所有可能的组合。随机网格搜索仅通过搜索所有这些组合的随机样本就可以获得令人满意的结果。在这里，我们将展示如何使用 scikit-learn 和 XGBoost 来实现这一点。

随机网格搜索的第一步是为每个超参数指定要从中采样的值的范围。这可以通过提供一个值列表或从中采样的分布对象来实现。在离散超参数(如`max_depth`)的情况下，只有几个可能的值，将其指定为列表是有意义的。另一方面，对于连续的超参数，比如`subsample`，它可以在区间(0，1)上的任何地方变化，我们不需要指定一个值列表。相反，我们可以要求网格搜索在这个时间间隔内以统一的方式随机采样值。我们将使用均匀分布对我们考虑的几个超参数进行采样:

注意

这个练习的 Jupyter 笔记本可以在[https://packt.link/TOXso](https://packt.link/TOXso)找到。

1.  Import the `uniform` distribution class from `scipy` and specify ranges for all hyperparameters to be searched, using a dictionary. `uniform` can take two arguments, `loc` and `scale`, specifying the lower bound of the interval to sample from and the width of the interval, respectively:

    ```
    from scipy.stats import uniform
    param_grid = {'max_depth':[2,3,4,5,6,7],
                  'gamma':uniform(loc=0.0, scale=3),
                  'min_child_weight':list(range(1,151)),
                  'colsample_bytree':uniform(loc=0.1, scale=0.9),
                  'subsample':uniform(loc=0.5, scale=0.5),
                  'learning_rate':uniform(loc=0.01, scale=0.5)}
    ```

    这里，我们根据实验和经验选择了参数范围。例如，对于子采样，XGBoost 文档建议选择至少为 0.5 的值，因此我们指定了`uniform(loc=0.5, scale=0.5)`，这意味着从区间[0.5，1]采样。

2.  Now that we've indicated which distributions to sample from, we need to do the sampling. scikit-learn offers the `ParameterSampler` class, which will randomly sample the `param_grid` parameters supplied and return as many samples as requested (`n_iter`). We also set `RandomState` for repeatable results across different runs of the notebook:

    ```
    from sklearn.model_selection import ParameterSampler
    rng = np.random.RandomState(0)
    n_iter=1000
    param_list = list(ParameterSampler(param_grid, n_iter=n_iter,
                                       random_state=rng))
    ```

    我们已经在特定参数值的字典列表中返回了结果，对应于 6 维超参数空间中的位置。

    请注意，在本练习中，我们将遍历 1，000 个超参数组合，这可能需要 5 分钟以上。您可能希望减少该数字以更快获得结果。

3.  Examine the first item of `param_list`:

    ```
    param_list[0]
    ```

    这将从所示的分布中返回六个参数值的组合:

    ```
    {'colsample_bytree': 0.5939321535345923,
     'gamma': 2.1455680991172583,
     'learning_rate': 0.31138168803582195,
     'max_depth': 5,
     'min_child_weight': 104,
     'subsample': 0.7118273996694524}
    ```

4.  Observe how you can set multiple XGBoost hyperparameters simultaneously with a dictionary, using the `**` syntax. First create a new XGBoost classifier object for this exercise.

    ```
    xgb_model_2 = xgb.XGBClassifier(
        n_estimators=1000,
        verbosity=1,
        use_label_encoder=False,
        objective='binary:logistic')
    xgb_model_2.set_params(**param_list[0])
    ```

    输出应显示正在设置的指示超参数:

    ```
    XGBClassifier(base_score=0.5, booster='gbtree',\
                  colsample_bylevel=1, colsample_bynode=1,\
                  colsample_bytree=0.5939321535345923,\
                  gamma=2.1455680991172583, gpu_id=-1,\
                  importance_type='gain',interaction_constraints='',\
                  learning_rate=0.31138168803582195,\
                  max_delta_step=0, max_depth=5,\
                  min_child_weight=104, missing=nan,\
                  monotone_constraints='()', n_estimators=1000,\
                  n_jobs=4, num_parallel_tree=1,\
                  random_state=0, reg_alpha=0, reg_lambda=1,\
                  scale_pos_weight=1, subsample=0.7118273996694524,\
                  tree_method='exact', use_label_encoder=False,\
                  validate_parameters=1, verbosity=1)
    ```

    我们将在一个循环中使用这个过程来查看所有的超参数值。

5.  接下来的几个步骤将包含在一个`for`循环的一个单元格中。首先，测量这样做所需的时间，创建一个空列表来保存验证 AUC，然后启动一个计数器:

    ```
    %%time
    val_aucs = []
    counter = 1
    ```

6.  打开`for`循环，设置超参数，并拟合 XGBoost 模型，类似于前面调整学习率的示例:

    ```
    for params in param_list:
        #Set hyperparameters and fit model
        xgb_model_2.set_params(**params)
        xgb_model_2.fit(X_train, y_train, eval_set=eval_set,\
                        eval_metric='auc',\
                        verbose=False, early_stopping_rounds=30)
    ```

7.  在`for`循环中，获得预测概率和验证集 AUC:

    ```
        #Get predicted probabilities and save validation ROC AUC
        val_set_pred_proba = xgb_model_2.predict_proba(X_val)[:,1]
        val_aucs.append(roc_auc_score(y_val, val_set_pred_proba))
    ```

8.  由于这个过程需要几分钟时间，所以最好将进度打印到 Jupyter 笔记本输出中。我们使用 Python 余数语法`%`，每 50 次迭代打印一条消息，换句话说，当`counter`除以 50 的余数等于 0 时。最后，我们递增计数器:

    ```
        #Print progress
        if counter % 50 == 0:
            print('Done with {counter} of {n_iter}'.format(
                counter=counter, n_iter=n_iter))
        counter += 1
    ```

9.  在一个单元格中组装步骤 5-8 并运行 for 循环应该会给出如下输出:

    ```
    Done with 50 of 1000
    Done with 100 of 1000
    …
    Done with 950 of 1000
    Done with 1000 of 1000
    CPU times: user 24min 20s, sys: 18.9 s, total: 24min 39s
    Wall time: 6min 27s
    ```

10.  Now that we have all the results from our hyperparameter exploration, we need to examine them. We can easily put all the hyperparameter combinations in a data frame, since they are organized as a list of dictionaries. Do this and look at the first few rows:

    ```
    xgb_param_search_df = pd.DataFrame(param_list)
    xgb_param_search_df.head()
    ```

    输出应该如下所示:

    ![Figure 6.3: Hyperparameter combinations from a randomized grid search
    ](image/B16925_06_03.jpg)

    图 6.3:随机网格搜索的超参数组合

11.  We can also add the validation set ROC AUCs to the data frame and see what the maximum is:

    ```
    xgb_param_search_df['Validation ROC AUC'] = val_aucs
    max_auc = xgb_param_search_df['Validation ROC AUC'].max()
    max_auc
    ```

    输出应该如下所示:

    ```
    0.8151220995602575
    ```

    在超参数空间上搜索的结果是验证集 AUC 约为 0.815。这比我们通过提前停止和搜索学习率(*图 6.3* )获得的 0.812 要大，尽管不多。这意味着，对于这些数据，默认的超参数(除了学习率)足以实现相当好的性能。虽然使用超参数搜索并没有提高多少性能，但是了解超参数值的变化如何影响模型性能是很有意义的。在接下来的步骤中，我们将分别检查每个参数的 AUC 的边际分布。这意味着我们将查看 AUC 如何随着一个超参数的变化而变化，记住其他超参数也在我们的网格搜索结果中变化的事实。

12.  使用下面的代码建立一个由六个子图组成的网格，绘制每个超参数的性能，同时调整图形分辨率并启动一个计数器，我们将使用它来循环遍历子图:

    ```
    mpl.rcParams['figure.dpi'] = 400
    fig, axs = plt.subplots(3,2,figsize=(8,6))
    counter = 0
    ```

13.  打开一个`for`循环来遍历超参数名称，这些名称是数据帧的列，不包括最后一列。通过展平由`subplot`返回的 3 x 2 数组并用`counter`索引来访问轴对象。对于每个超参数，使用数据框的`plot.scatter`方法在适当的轴上绘制散点图。 *x* 轴将显示超参数， *y* 轴显示验证 AUC，其他选项帮助我们获得白色表面颜色的黑色圆形标记(内部):

    ```
    for col in xgb_param_search_df.columns[:-1]:
        this_ax = axs.flatten()[counter]
        xgb_param_search_df.plot.scatter(x=col,\
                                         y='Validation ROC AUC',\
                                         ax=this_ax, marker='o',\
                                         color='w',\
                                         edgecolor='k',\
                                         linewidth=0.5)
    ```

14.  The data frame's `plot` method will automatically create *x* and *y* axis labels. However, since the *y* axis label will be the same for all of these plots, we only need to include it in the first one. So we set all the others to an empty string, `''`, and increment the counter:

    ```
        if counter > 0:
            this_ax.set_ylabel('')
        counter += 1
    ```

    由于我们将绘制边际分布，当我们查看验证 AUC 如何随给定超参数变化时，所有其他超参数也在变化。这意味着关系可能会吵。为了了解总体趋势，我们还将使用超参数的每个十分位数中验证 AUC 的平均值创建线图。十分位数根据值是否属于最低的 10%，接下来的 10%，等等，直到最高的 10%，将数据组织到容器中。pandas 提供了一个名为`qcut`的函数，它将一个序列切割成分位数(一个分位数是一组相等大小的仓中的一个，例如 10 个仓中的一个十分位数)，返回另一个分位数序列，以及分位数仓的端点，您可以将其视为直方图边缘。

15.  使用 pandas `qcut`为每个超参数(除`max_depth`外)生成一系列十分位数(10 个分位数)，返回面元边缘(10 个分位数将有 11 个分位数)，如果没有足够的唯一值划分为 10 个分位数(`duplicates='drop'`)，则根据需要丢弃面元边缘。创建每对面元边缘中间的点列表，用于绘图:

    ```
        if col != 'max_depth':
            out, bins = pd.qcut(xgb_param_search_df[col], q=10,\
                                retbins=True, duplicates='drop')
            half_points = [(bins[ix] + bins[ix+1])/2
                           for ix in range(len(bins)-1)]
    ```

16.  对于`max_depth`，由于只有六个唯一值，我们可以以类似于十分位数的方式直接使用这些值:

    ```
        else:
            out = xgb_param_search_df[col]
            half_points = np.sort(xgb_param_search_df[col].unique())
    ```

17.  通过复制超参数搜索数据框创建一个临时数据框，创建一个包含十分位数系列的新列，并使用它来查找每个超参数十分位数内的验证 AUC 的平均值:

    ```
        tmp_df = xgb_param_search_df.copy()
        tmp_df['param_decile'] = out
        mean_df = tmp_df.groupby('param_decile').agg(
            {'Validation ROC AUC':'mean'})
    ```

18.  We can visualize results with a dashed line plot of the decile averages of validation AUC within each grouping, on the same axis as each scatter plot. Close the `for` loop and clean up the subplot formatting with `plt.tight_layout()`:

    ```
        this_ax.plot(half_points,\
                     mean_df.values,\
                     color='k',\
                     linestyle='--')
    plt.tight_layout()
    ```

    运行`for`循环后，结果图像应该如下所示:

    ![Figure 6.4: Validation AUCs plotted against each hyperparameter, along with the average values within hyperparameter deciles
    ](image/B16925_06_04.jpg)

    图 6.4:根据每个超参数绘制的验证 AUC，以及超参数十分位数内的平均值

    虽然我们注意到本练习中的超参数搜索并没有导致验证 AUC 比本章之前的工作有实质性的增加，但是图 6.4*中的图*仍然可以向我们显示 XGBoost 超参数如何影响该特定数据集的模型性能。XGBoost 对抗过度拟合的一种方法是通过限制生长树时可用的数据，或者通过随机选择每棵树可用的一小部分特征(`colsample_bytree`)，或者一小部分训练样本(`subsample`)。然而，对于这种合成数据，当对每棵树使用 100%的特征和样本时，模型表现得最好；低于这个值，模型性能会逐渐下降。控制过度拟合的另一种方法是通过控制它们的`max_depth`、叶子中训练样本的最小数量(`min_child_weight`)或者分裂节点所需的损失函数减少值的最小减少量(`gamma`，来限制集合中树的复杂性。在我们的例子中，`max_depth`和`gamma`似乎对模型性能都没有太大影响，而限制叶子中的样本数量似乎是有害的。

    在这种情况下，梯度增强过程本身似乎足够健壮，足以实现良好的模型性能，而不需要任何额外的技巧来减少过拟合。然而，与我们上面观察到的类似，较小的`learning_rate`是有益的。

19.  We can show the optimal hyperparameter combination and the corresponding validation set AUC as follows:

    ```
    max_ix = xgb_param_search_df['Validation ROC AUC'] == max_auc
    xgb_param_search_df[max_ix]
    ```

    这将返回一行数据框，如下所示:

![Figure 6.5: Optimal hyperparameter combination and validation set AUC
](image/B16925_06_05.jpg)

图 6.5:最佳超参数组合和验证集 AUC

验证集 AUC 类似于我们通过仅调整学习率在上面(*步骤 10* )所实现的。

# 另一种种树方式:XGBoost 的 grow_policy

除了使用`max_depth`超参数来限制树的最大深度之外，还有另一种控制树增长的范例:找到分裂将导致损失函数最大减少的节点，并分裂该节点，而不管它将使树有多深。这可能会导致一棵树有一个或两个非常深的分支，而其他分支可能不会长得很远。XGBoost 提供了一个名为`grow_policy`的超参数，将其设置为`lossguide`会导致这种树的生长，而`depthwise`选项是默认选项，会将树生长到指定的`max_depth`，就像我们在*第 5 章*、*决策树和随机森林*中所做的一样，到目前为止，我们已经在本章中做了这些。`lossguide`增长策略是 XGBoost 中的一个新选项，它模仿了另一个流行的渐变增强包 LightGBM 的行为。

要使用`lossguide`策略，需要设置另一个我们还没有讨论的超参数`tree_method`，它必须设置为`hist`或`gpu-hist`。在不涉及太多细节的情况下，`hist`方法将使用一种更快的方式来搜索拆分。`hist`方法构建了一个直方图，并且只考虑直方图边缘的分裂，而不是在一个节点中的训练样本的每个有序特征值对之间寻找。因此，例如，如果在一个节点中有 100 个样本，它们的特征值可以被分成 10 组，这意味着只需要考虑 9 个可能的分裂，而不是 99 个。

我们可以为`lossguide` grow 策略实例化一个 XGBoost 模型，如下所示，使用基于上一练习中超参数探索的直觉的学习速率`0.1`:

```
xgb_model_3 = xgb.XGBClassifier(
    n_estimators=1000,
    max_depth=0,
    learning_rate=0.1,
    verbosity=1,
    objective='binary:logistic',
    use_label_encoder=False,
    n_jobs=-1,
    tree_method='hist',
    grow_policy='lossguide')
```

注意这里我们已经设置了`max_depth=0`，因为这个超参数与`lossguide`策略无关。相反，我们将设置一个名为`max_leaves`的超参数，它简单地控制树木中将要生长的最大叶子数量。我们将对范围从 5 到 100 个叶的值进行超参数搜索:

```
max_leaves_values = list(range(5,105,5))
print(max_leaves_values[:5])
print(max_leaves_values[-5:])
```

这将输出以下内容:

```
[5, 10, 15, 20, 25]
[80, 85, 90, 95, 100]
```

现在，我们准备在这个超参数值范围内重复拟合和验证模型，类似于我们之前所做的:

```
%%time
val_aucs = []
for max_leaves in max_leaves_values:
    #Set parameter and fit model
    xgb_model_3.set_params(**{'max_leaves':max_leaves})
    xgb_model_3.fit(X_train, y_train, eval_set=eval_set,\
                    eval_metric='auc', verbose=False,\
                    early_stopping_rounds=30)
    #Get validation score
    val_set_pred_proba = xgb_model_3.predict_proba(X_val)[:,1]
    val_aucs.append(roc_auc_score(y_val, val_set_pred_proba))
```

输出将包括所有这些拟合的墙壁时间，在测试中大约是 24 秒。现在让我们将结果放入数据框中:

```
max_leaves_df = \
pd.DataFrame({'Max leaves':max_leaves_values,
              'Validation AUC':val_aucs})
```

我们可以可视化验证 AUC 如何随着最大叶子数而变化，类似于我们对学习率的可视化:

```
mpl.rcParams['figure.dpi'] = 400
max_leaves_df.set_index('Max leaves').plot()
```

这将导致这样的情节:

![Figure 6.6: Validation AUC against the max_leaves hyperparameter
](image/B16925_06_06.jpg)

图 6.6:根据 max_leaves 超参数验证 AUC

较小的`max_leaves`值将限制为集合生成的树的复杂性，这将理想地增加偏差，但也减少方差以改善样本外性能。当树限于 15 或 20 片叶子时，我们可以在更高的验证集 AUC 中看到这一点。什么是最大验证集 AUC？

```
max_auc = max_leaves_df['Validation AUC'].max()
max_auc
```

这将输出以下内容:

```
0.8151200989120475
```

让我们确认该最大验证 AUC 发生在`max_leaves=20`，如图 6.6 中的*所示:*

```
max_ix = max_leaves_df['Validation AUC'] == max_auc
max_leaves_df[max_ix]
```

这将返回数据框的一行:

![Figure 6.7: Optimal max_leaves
](image/B16925_06_07.jpg)

图 6.7:最佳 max_leaves

通过使用`lossguide` grow 策略，我们可以实现至少与我们迄今为止尝试的任何其他方法一样好的性能。`lossguide`策略的一个关键优势是，对于较大的数据集，它可以产生比`depthwise`策略更快的训练时间，尤其是对于较小的`max_leaves`值。虽然这里的数据集足够小，没有实际意义，但在其他应用程序中，这种速度可能是理想的。

# 用 SHAP 值解释模型预测

随着 XGBoost 等前沿建模技术的出现，解释模型预测的实践在最近几年有了长足的发展。到目前为止，我们已经了解到逻辑回归系数，或者来自随机森林的特征重要性，可以提供对模型预测原因的洞察。Scott Lundberg 和 Su-In Lee(【https://arxiv.org/abs/1705.07874】)在 2017 年的一篇论文*中描述了一种解释模型预测的更强大的技术。这项技术被称为 **SHAP** ( **沙普利加法解释**)，因为它是基于数学家劳埃德·沙普利的早期工作。Shapely 开发了博弈论的一个领域，以理解玩家联盟如何对游戏的整体结果做出贡献。最近对模型解释的机器学习研究利用了这一概念来考虑预测模型中的特征组或组合如何有助于输出模型预测。通过考虑不同特征组的贡献，SHAP 方法可以隔离单个特征的影响。*

注意

在撰写本文时，*第 6 章*、*梯度增强、XGBoost 和 SHAP 值*中使用的 SHAP 库与 Python 3.9 不兼容。因此，如果您使用 Python 3.9 作为您的基础环境，我们建议您按照*前言*中的描述建立一个 Python 3.8 环境。

使用 SHAP 值解释模型预测的一些值得注意的方面包括:

*   SHAP 值可以用来对模型预测进行**个性化**解释；换句话说，单个样本的预测，就每个特征的贡献而言，可以用 SHAP 来理解。这与我们已经看到的解释随机森林的特征重要性方法形成对比，该方法仅考虑特征在模型训练集中的平均重要性。
*   SHAP 值是相对于背景数据集计算的。默认情况下，这是训练数据，尽管也可以提供其他数据集。
*   SHAP 值是可加的，这意味着对于单个样本的预测，可以将 SHAP 值相加以恢复预测值，例如预测概率。

对于各种类型的模型，SHAP 方法有不同的实现方式，这里我们将重点关注树木的 SHAP(Lundberg 等人，2019，[https://arxiv.org/abs/1802.03888](https://arxiv.org/abs/1802.03888))，以深入了解 XGBoost 模型对我们的合成数据验证集的预测。首先，让我们用最佳数量的`max_leaves`、`20`来改装上一节的`xgb_model_3`:

```
%%time
xgb_model_3.set_params(**{'max_leaves':20})
xgb_model_3.fit(X_train, y_train,\
                eval_set=eval_set,\
                eval_metric='auc',
                verbose=False,\
                early_stopping_rounds=30)
```

现在，我们准备开始计算验证数据集的 SHAP 值。这里有 40 个特性和 1，000 个样本:

```
X_val.shape
```

这将输出以下内容:

```
(1000, 40)
```

为了自动标记我们可以用`shap`包制作的图，我们将把验证集特性放在一个带有列名的数据框中。我们将使用列表理解来创建通用要素名称，例如，“要素 0，要素 1，…”，并按如下方式创建数据框:

```
feature_names = ['Feature {number}'.format(number=number)
                 for number in range(X_val.shape[1])]
X_val_df = pd.DataFrame(data=X_val, columns=feature_names)
X_val_df.head()
```

头部应该是这样的:

![Figure 6.8: Data frame of the validation features
](image/B16925_06_08.jpg)

图 6.8:验证特征的数据框

有了经过训练的模型、`xgb_model_3`和验证特性的数据框架，我们就可以创建一个`explainer`接口了。SHAP 包有各种各样的解释器，我们将使用一个专门针对树模型的解释器:

```
explainer = shap.explainers.Tree(xgb_model_3, data=X_val_df)
```

这就创建了一个使用模型验证数据作为背景数据集的解释器。现在我们准备使用解释器来获得 SHAP 值。SHAP 一揽子计划使这变得非常简单。我们需要做的就是传入我们想要解释的数据集:

```
shap_values = explainer(X_val_df)
```

这就是全部了！已经创建的变量`shap_values`是什么？如果您直接检查`shap_values`变量的内容，您会看到它包含三个属性。第一个是`values`，包含了 SHAP 价值观。让我们检查一下形状:

```
shap_values.values.shape
```

这将返回以下内容:

```
(1000, 40)
```

因为 SHAPs 提供了个性化的解释，所以验证集中的 1，000 个样本中的每一个都有一行。有 40 列，因为我们有 40 个特征，SHAP 值告诉我们每个特征对每个样本的预测的贡献。`shap_values`还包含一个`base_values`属性，它是在考虑任何特征贡献之前的原始预测，也被定义为整个数据集的平均预测。每个样本(1000)都有一个这样的问题。最后，还有一个`data`属性，它包含特征值。所有这些信息都可以以各种方式组合起来解释模型预测。

令人欣慰的是，`shap`包不仅提供了计算 SHAP 值的快速便捷的方法，还提供了一套丰富的可视化技术。其中最流行的是 SHAP 汇总图，它可视化了每个特征对每个样本的贡献。让我们创建这个情节，然后了解正在显示什么。请注意，大多数有趣的 SHAP 可视化都使用彩色，所以如果您阅读的是黑白的，请参考 GitHub 库中的彩色图片:

```
mpl.rcParams['figure.dpi'] = 75
shap.summary_plot(shap_values.values, X_val_df)
```

这会产生以下结果:

![Figure 6.9: SHAP summary plot for the synthetic data validation set
](image/B16925_06_09.jpg)

图 6.9:合成数据验证集的 SHAP 汇总图

注意

如果你正在阅读这本书的印刷版本，你可以通过访问以下链接下载并浏览本章中一些图片的彩色版本:[https://packt.link/ZFiYH](https://packt.link/ZFiYH)

*图 6.9* 包含了很多帮助我们解释模型的信息。汇总图最多可包含 40，000 个绘制点，40 个特征和 1，000 个验证样本中的每一个都有一个绘制点(尽管默认情况下仅显示前 20 个特征)。让我们从了解 *x* 轴开始。SHAP 值表示每个特征值对样本预测的附加贡献。此处显示的是相对于预期值的 SHAP 值，即之前描述的`base_values`。因此，如果给定特征对给定样本的预测有很小的影响，它不会使预测远离期望值，并且 SHAP 值将接近于零。然而，如果一个特征具有很大的影响，在我们的二元分类问题的情况下，这意味着预测的概率将被推向更接近 0 或 1，SHAP 值将远离 0。负 SHAP 值表示将预测值向 0 靠拢的特征，而正 SHAP 值表示向 1 靠拢的特征。

注意，图 6.9 中*所示的 SHAP 值不能直接解释为预测概率。默认情况下，具有`binary:logistic`目标函数的 XGBoost 二元分类模型的 SHAP 值是使用概率的对数优势表示法计算和绘制的，这在*第 3 章*、*逻辑回归的详细信息和特征探索*中有介绍*为什么逻辑回归被视为线性模型？*节。这意味着它们可以相加和相减，或者换句话说，我们可以对它们进行线性变换。*

*图 6.9* 中的点的颜色呢？这些代表每个样本的特征值，红色代表较高的值，蓝色代表较低的值。例如，我们可以在图的第四行看到，最低的 SHAP 值来自特征 29 的高特征值(红点)。

点的垂直排列，换句话说，每个特征的点带宽度，表示在 *x* 轴上的那个位置有多少个点。如果样本很多，点带会更宽。

图表中要素的垂直排列基于要素的重要性。换句话说，最重要的要素(即对模型预测具有最大平均影响(平均绝对 SHAP 值)的要素)位于列表顶部。

虽然*图 6.9* 中的汇总图是一次性查看所有最重要特征及其 SHAP 值的好方法，但它可能不会揭示一些有趣的关系。例如，最重要的要素(要素 3)似乎有一大块紫色点(位于要素值范围的中间),这些点具有正 SHAP 值，而该要素的负 SHAP 值可能是由高或低的要素值造成的。

这是怎么回事？通常，当功能的影响从 SHAP 汇总图看起来不清楚时，我们使用的基于树的模型捕捉功能之间的交互影响。为了进一步了解单个特征及其与其他特征的相互作用，我们可以使用 SHAP 散点图。首先，让我们制作一个简单的特性 3 的 SHAP 值散点图。注意，我们可以用与数据框相似的方式索引`shap_values`对象:

```
shap.plots.scatter(shap_values[:,'Feature 3'])
```

这将产生以下情节:

![Figure 6.10: Scatter plot of SHAP values for Feature 3
](image/B16925_06_10.jpg)

图 6.10:特征 3 的 SHAP 值散点图

从*图 6.10* 中，我们可以告诉我们从*图 6.9* 的汇总图中可以得到的几乎相同的信息:在范围中间的特征值具有高的 SHAP 值，而在极端的特征值较低。然而，`scatter`方法也允许我们用另一个特征值来给散点图的点着色，这样我们就可以看到特征之间是否有相互作用。我们将根据第二个最重要的特征(特征 5)来给点着色:

```
shap.plots.scatter(shap_values[:,'Feature 3'],
                   color=shap_values[:,'Feature 5'])
```

结果图应该如下所示:

![Figure 6.11: Scatter plot of SHAP values for Feature 3, colored by feature values of Feature 5\. Arrows A and B indicated interesting interaction effects between these features
](image/B16925_06_11.jpg)

图 6.11:特征 3 的 SHAP 值散点图，由特征 5 的特征值着色。箭头 A 和 B 表示这些特征之间有趣的相互作用

*图 6.11* 显示了特征 3 和特征 5 之间有趣的相互作用。当样本处于特征 3 的特征值范围的中间时，换句话说，在*图 6.11* 中驼峰形状的顶部，从这里的点簇的底部到顶部，点的颜色看起来变得更红(箭头 A)。这意味着对于特征 3 范围中间的特征值，随着特征 5 的值增加，特征 3 的 SHAP 值也增加。我们还可以看到，随着特征 3 的特征值沿着 *x* 轴从范围的中间向顶部增加，这种关系反转到特征 5 的较高特征值开始对应于特征 3 的较低 SHAP 值的地方(箭头 B)。因此，与特征 5 的相互作用似乎对特征 3 的 SHAP 值有很大影响。

图 6.11 中描述的复杂关系显示了当存在交互影响时，增加特征值可能会导致 SHAP 值的增加或减少。*图 6.11* 中模式的具体原因与我们正在建模的合成数据集的创建有关，其中我们在特征空间中指定了多个聚类。正如在*第 5 章*、*决策树和随机森林*中所讨论的，在*使用决策树:优势和预测概率*一节中，基于树的模型(如 XGBoost)能够有效地对多维特征空间中属于某个类别的点的聚类进行建模。SHAP 的解释可以帮助我们理解模型是如何做出这些表示的。

在这里，我们使用了合成数据，这些特征没有真实世界的解释，所以我们不能给我们观察到的交互赋予任何意义。但是，对于真实世界的数据，对 SHAP 值和交互的详细探索可以提供对模型如何表示客户或用户属性之间的复杂关系的洞察。SHAP 值也很有用，因为它们可以提供与任何背景数据集相关的解释。虽然随机森林的逻辑回归系数和特征重要性完全由模型训练数据确定，但是可以为任何背景数据集计算 SHAP 值；到目前为止，在这一章中，我们一直在使用验证数据。当预测的模型被部署到生产环境中时，这提供了一个机会来理解新的预测是如何做出的。如果新预测的 SHAP 值与模型训练和测试数据的值非常不同，这可能表明传入数据的性质已经改变，可能是时候考虑开发新模型了。我们将在最后一章考虑在现实世界中使用模型的这些实际方面。

## 练习 6.02:绘制 SHAP 相互作用，特征重要性，以及从 SHAP 值重建预测概率

在本练习中，您将更加熟悉使用 SHAP 值来提供模型工作的可见性。首先，我们将交替查看功能 3 和 5 之间的交互，然后使用 SHAP 值来计算功能重要性，类似于我们在*第 5 章、* *决策树和随机森林*中对随机森林模型所做的。最后，我们将了解如何利用 SHAP 值的可加性从其获得模型输出:

注意

这个练习的 Jupyter 笔记本可以在[https://packt.link/JcMoA](https://packt.link/JcMoA)找到。

1.  Given the preliminary steps accomplished in this section already, we can take another look at the interaction between Features 3 and 5, the two most important features of the synthetic dataset. Use the following code to make an alternate version of *Figure 6.11*, except this time, look at the SHAP values of Feature 5, colored by those of Feature 3:

    ```
    shap.plots.scatter(shap_values[:,'Feature 5'],
                       color=shap_values[:,'Feature 3'])
    ```

    结果图应该如下所示:

    ![Figure 6.12: Scatter plot of SHAP values for Feature 5, colored by feature values of Feature 3
    ](image/B16925_06_12.jpg)

    图 6.12:特征 5 的 SHAP 值散点图，由特征 3 的特征值着色

    与*图 6.11* 相反，这里我们看到的是特性 5 的 SHAP 值。总的来说，从散点图中，我们可以看到，对于特征 5，SHAP 值往往随着特征值的增加而增加。然而，这种总体趋势肯定有反例，以及与特征 3 的有趣互动:对于特征 5 的给定值，它可以被认为是图像的垂直切片，对于负特征值，点的颜色可以从底部到顶部变得更红，或者对于正特征值，点的颜色变得不那么红。这意味着对于特征 5 的给定值，其 SHAP 值取决于特征 3 的值。这进一步说明了特性 3 和 5 之间有趣的相互作用。在实际项目中，您将选择显示哪个图取决于您想要用数据讲述什么样的故事，与特征 3 和 5 可能代表的真实世界量有关。

2.  Create a feature importance bar plot using the following code:

    ```
    mpl.rcParams['figure.dpi'] = 75
    shap.summary_plot(shap_values.values, X_val, plot_type='bar')
    ```

    ![Figure 6.13: Feature importance bar plot using SHAP values
    ](image/B16925_06_13.jpg)

    图 6.13:使用 SHAP 值的特征重要性条形图

    特征重要性条形图给出了类似于在*练习 5.03 中获得的信息的视觉呈现，拟合随机森林，*第 5 章决策树和随机森林*中的*和随机森林:这是每个特征的单个数字，代表它对数据集的整体重要性。

    这些结果有意义吗？回想一下，我们用三个信息特征和两个冗余特征创建了这个合成数据。在*图 6.13* 中，似乎有四个特性比所有其他特性重要得多，因此可能其中一个冗余特性是以这样的方式创建的，XGBoost 经常选择它来分割节点，但另一个冗余特性并没有被经常使用。

    与我们在*第五章*、*决策树和随机森林*中发现的特征重要性相比，这里的特征重要性略有不同。我们可以从 scikit-learn 为随机森林模型获得的特征重要性是使用由于该特征而导致的节点杂质减少以及由该特征分割的训练样本部分来计算的。相比之下，使用 SHAP 值的特征重要性计算如下:首先，取所有 SHAP 值(`shap_values.values`)的绝对值，然后对每个特征取所有样本的平均值，如轴标签 *x* 所示。感兴趣的读者可以通过直接从`shap_values`计算这些指标来证实这一点。

    现在我们已经熟悉了 SHAP 值的一系列用途，让我们看看它们的可加性如何允许预测概率的重建。

3.  SHAP values are calculated relative to the expected value, or base value, of a model. This can be interpreted as the average prediction over all samples in the background dataset. However, the prediction will be in units of log-odds as opposed to probability, as mentioned earlier, to support additivity. The expected value of a model can be accessed from the explainer object as follows:

    ```
    explainer.expected_value
    ```

    输出应该如下所示:

    ```
    -0.30949621941894295
    ```

    这些信息本身并不是特别有用。然而，它给了我们一个基线，我们可以从这个基线重建预测的概率。

4.  Recall that the shape of the SHAP values matrix is the number of samples by the number of features. In our exercise with the validation data, here that would be 1,000 by 40\. To add up all the SHAP values for each sample, we therefore want to take a sum over the column axis (`axis=1`). This adds all the feature contributions, effectively providing the offset from the expected value. If we add the expected value to this, we then have the following predictions:

    ```
    shap_sum = shap_values.values.sum(axis=1) + explainer.expected_value
    shap_sum.shape
    ```

    这将返回以下内容:

    ```
    (1000,)
    ```

    表明我们现在对每个样本都有一个单一的数字。然而，这些预测是在对数优势空间。为了将它们转换到概率空间，我们需要应用第 3 章*中介绍的逻辑函数，逻辑回归和特征探索的细节*。

5.  Apply the logistic transformation to log-odds predictions like this:

    ```
    shap_sum_prob = 1 / (1 + np.exp(-1 * shap_sum))
    ```

    现在，我们想要将从 SHAP 值获得的预测概率与直接模型输出进行比较，以进行确认。

6.  Obtain predicted probabilities for the model validation set and check the shape with this code:

    ```
    y_pred_proba = xgb_model_3.predict_proba(X_val)[:,1]
    y_pred_proba.shape
    ```

    输出应该如下所示:

    ```
    (1000,)
    ```

    正如所料，这与我们从 SHAP 得出的预测形状相同。

7.  Put the model output and sums of SHAP values together in a data frame for side-by-side comparison, and spot check a random selection of five rows:

    ```
    df_check = pd.DataFrame(
        {'SHAP sum':shap_sum_prob,
         'Predicted probability':y_pred_proba})
    df_check.sample(5, random_state=1)
    ```

    输出应该确认这两种方法具有相同的结果:

    ![Figure 6.14: Comparison of SHAP-derived predicted probabilities 
    and those obtained directly from XGBoost
    ](image/B16925_06_14.jpg)

    图 6.14:SHAP 得出的预测概率和直接从 XGBoost 得到的预测概率的比较

    抽样检查表明这五个样本具有相同的值。虽然由于机器算术的舍入误差，这些值可能不完全相等，但是您可以使用 NumPy 的`allclose`函数来确保它们在用户可配置的舍入误差范围内是相同的。

8.  Ensure that the SHAP-derived probabilities and model output probabilities are all very close to each other like this:

    ```
    np.allclose(df_check['SHAP sum'],\
                df_check['Predicted probability'])
    ```

    输出应该如下所示:

    ```
    True
    ```

    这表明两列的所有元素在舍入误差范围内相等。`allclose`适用于存在舍入误差且精确等式(可用`np.array_equal`测试)不成立的情况。

到现在为止，你应该对 SHAP 价值观帮助理解机器学习模型的力量有了印象。SHAP 价值观的样本特异性和个体化特性为非常详细的分析提供了可能性，这有助于回答商业利益相关者提出的各种潜在问题，如“该模型如何为这样的人做出预测？”或者“为什么模型会对这个特定的人做出这个预测”？现在，我们已经熟悉了 XGBoost 和 SHAP 值这两种最先进的机器学习技术，我们回到案例研究数据来应用它们。

# 缺失数据

关于 XGBoost 和 SHAP 使用的最后一点，这两个包的一个有价值的特点是它们处理缺失值的能力。回想一下，在*第 1 章*、*数据探索和清理*中，我们发现案例研究数据中的一些样本缺少`PAY_1`特性的值。到目前为止，我们的方法是在建立模型时简单地从数据集中删除这些样本。这是因为，如果不以某种方式专门解决缺失值，scikit-learn 实现的机器学习模型就无法处理这些数据。忽略它们是一种方法，尽管这可能不令人满意，因为它涉及到丢弃数据。如果只是数据的一小部分，这可能没问题；然而，一般来说，能够知道如何处理丢失的值是很好的。

有几种方法可用于输入要素的缺失值，例如使用该要素的非缺失值的平均值或众数来填充缺失值，或者从非缺失值中随机选择一个值。您还可以构建一个模型，将相关要素作为响应变量输出，所有其他要素作为新模型的要素，然后预测缺失的特征值。这些方法在本书的第一版([https://packt.link/oLb6C](https://packt.link/oLb6C))中进行了探索。然而，由于 XGBoost 通常至少与其他机器学习模型一样，对我们在这里使用的表格数据执行二元分类任务，并处理缺失值，我们将放弃对输入缺失值的更深入的探索，让 XGBoost 为我们做这项工作。

XGBoost 如何处理缺失数据？在每次分割节点时，XGBoost 只考虑没有丢失的特征值。如果选择具有缺失值的特征来进行分割，则根据最小化损失函数，该特征的具有缺失值的样本将沿着最优路径被发送到其中一个子节点。

## 将 Python 变量保存到文件中

在本章的练习中，为了读写文件，我们将使用一个新的 python 语句(`with`)和`pickle`包。`with`语句使处理文件变得更容易，因为它们都打开和关闭文件，而不是用户需要单独做这些。您可以使用如下代码片段将变量保存到文件中:

```
with open('filename.pkl', 'wb') as f:
    pickle.dump([var_1, var_2], f)
```

其中`filename.pkl`是您选择的文件路径，`'wb'`表示文件以二进制格式打开写入，`pickle.dump`将变量列表`var_1`和`var_2`保存到文件中。要打开这个文件并加载这些变量，可能要加载到一个单独的 Jupyter 笔记本中，代码是类似的，但是现在文件需要以二进制格式打开进行读取(`'rb'`):

```
with open('filename.pkl', 'rb') as f:
    var_1, var_2 = pickle.load(f)
```

## 活动 6.01:用 XGBoost 对案例研究数据建模，用 SHAP 解释模型

在本活动中，我们将利用本章中学到的合成数据集，并将其应用于案例研究数据。我们将了解 XGBoost 模型在验证集上的表现，并使用 SHAP 值解释模型预测。我们已经为该活动准备了数据集，替换了先前忽略的`PAY_1`特征中有缺失值的样本，同时为没有缺失值的样本保持相同的训练/测试分割。您可以在本次活动笔记本的附录中看到这些数据是如何准备的。

注意

包含解答和附录的 Jupyter 笔记本可以在这里找到:[https://packt.link/YFb4r](https://packt.link/YFb4r)。

1.  加载为此练习准备的案例研究数据。文件路径为`../../Data/Activity_6_01_data.pkl`，变量为:`features_response, X_train_all, y_train_all, X_test_all, y_test_all`。
2.  定义一个验证集来训练 XGBoost 提前停止。
3.  实例化 XGBoost 模型。使用`lossguide` grow 策略来检查几个`max_leaves`值的验证集性能。
4.  创建一个从 5 到 200 的`max_leaves`值列表，以 5 为单位计数。
5.  为提前停止创建评估集。
6.  使用与*练习 6.01:调整 XGBoost 超参数的随机网格搜索*中相同的技术，遍历超参数值并创建一个 ROC AUCs 验证列表。
7.  创建超参数搜索结果的数据框，并根据`max_leaves`绘制验证 AUC。
8.  观察验证集上最高 ROC AUC 对应的`max_leaves`号。
9.  用最佳超参数改装 XGBoost 模型。这样我们就可以检查验证集的 SHAP 值，制作该数据的数据框。
10.  使用验证数据作为背景数据集，为我们的新模型创建一个 SHAP 解释器，获取 SHAP 值，并绘制一个摘要图。
11.  制作一个`LIMIT_BAL` SHAP 值的散点图，用交互作用最强的特征进行着色。
12.  Save the trained model along with the training and test data to a file.

    注意

    此活动的解决方案可通过[此链接](B16925_Solution_ePub.xhtml#_idTextAnchor159)找到。

# 总结

在这一章中，我们学习了一些用表格数据构建机器学习模型的最前沿的技术。虽然其他类型的数据(如图像或文本数据)需要使用不同类型的模型(如神经网络)进行探索，但许多标准业务应用程序都利用表格数据。XGBoost 和 SHAP 是一些最先进和最流行的工具，您可以使用它们来构建和理解这类数据的模型。熟悉了这些工具并获得了使用合成数据的实践经验后，在接下来的活动中，我们将回到案例研究的数据集，看看如何使用 XGBoost 对其建模，包括缺少特征值的样本，并使用 SHAP 值来理解模型。