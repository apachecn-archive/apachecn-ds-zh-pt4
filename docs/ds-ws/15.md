

# 十五、集成学习

概观

本章结束时，你将能够描述集成学习，并应用不同的集成学习技术到你的数据集。您还将能够在模型上拟合数据集，并在集成学习后分析结果。

在本章中，我们将使用信用卡申请数据集，在这里我们将尝试预测一个信用卡申请是否会被批准。

# 简介

在前一章中，我们学习了各种技术，如反向消除技术、因子分析等，这些技术有助于我们处理高维数据集。

在这一章中，我们将使用另一套称为集成学习的技术来进一步增强我们的技能，其中我们将处理不同的集成学习技术，如下所示:

*   求平均值
*   加权平均
*   最大投票
*   制袋材料
*   助推
*   混合

# 集成学习

顾名思义，集成学习(Ensemble learning)是一种将几种机器学习模型结合起来生成一个更好的模型的方法，从而减少可变性/方差和偏差，并提高性能。

在我们探索什么是集成学习之前，让我们借助经典的偏差-方差象限来看看偏差和方差的概念，如下所示:

![Figure 15.1: Bias-variance quadrant
](image/B15019_15_01.jpg)

图 15.1:偏差-方差象限

## 方差

方差是对数据分布程度的度量。在机器学习的上下文中，具有高方差的模型意味着，当使用不同的训练集来拟合模型时，在相同测试集上生成的预测会有很大不同。高可变性的潜在原因可能是由于模型适应训练数据的具体细微差别，而不是概括输入和输出之间的关系。理想情况下，我们希望每个机器学习模型都具有低方差。

## 偏见

偏差是实际情况和我们预测的平均值之间的差异。低偏差表示预测值非常接近实际值。高偏差意味着模型过度简化了输入和输出之间的关系，导致测试集的高错误率，这也是不希望的结果。

*图 15.1* 有助于我们形象化偏差和方差之间的权衡。左上角是一个场景的描述，其中偏差较高，方差较低。右上象限显示了一个偏差和方差都很高的场景。从图中我们可以看到，当偏差较高时，它离真相更远，在这种情况下，这就是*的靶心*。方差的存在表现为箭头是散开还是聚集在一点。

集成模型结合了许多方差和偏差不同的较弱模型，从而创建了一个更好的模型，优于单个较弱模型。整体模特体现了格言*群体的智慧*。在这一章中，我们将学习不同的合奏技术，这些技术可以分为两种类型，即简单技术和高级技术:

![Figure 15.2: Different ensemble learning methods
](image/B15019_15_02.jpg)

图 15.2:不同的集成学习方法

## 业务背景

你在银行的信用卡部门工作。贵公司的运营主管请求您帮助确定某个客户是否有信誉。我们已经向您提供了信用卡操作数据。

该数据集包含大约 15 个变量的信用卡申请。这些变量是与信用卡操作相关的连续数据和分类数据的混合。数据集的标签是一个标志，它指示应用是否已被批准。

您希望拟合一些基准模型，并在数据集上尝试一些集成学习方法来解决问题，并提出一种工具来预测给定客户的信贷申请是否应获得批准。

## 练习 15.01:加载、浏览和清理数据

在本练习中，我们将下载信用卡数据集，将其加载到我们的 Colab 笔记本中，并执行一些基本的探索。此外，我们还将清理数据集以移除不需要的字符。

注意

我们将在这个练习中使用的数据集来自 https://packt.live/39NCgZ2 的 UCI 机器学习库。你可以从我们位于 https://packt.live/3018OdD[的 GitHub 下载数据集。](https://packt.live/3018OdD)

以下步骤将帮助您完成本练习:

1.  打开一个新的 Colab 笔记本文件。
2.  现在，将`pandas`导入到您的 Colab 笔记本:

    ```py
    import pandas as pd
    ```

3.  接下来，设置上传`crx.data`的 GitHub 存储库的路径，如下面的代码片段所示:

    ```py
    #Loading data from the GitHub repository to colab notebook
    filename = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter15/Dataset/crx.data'
    ```

4.  Read the file using the `pd.read_csv()` function from the `pandas` data frame:

    ```py
    credData = pd.read_csv(filename,sep= ", ",header = None,na_values =  "? ")
    credData.head()
    ```

    `pd.read_csv()`函数的参数是字符串形式的文件名和 CSV 文件的限制分隔符，即`,`。

    注意

    该数据集没有标题；我们使用`header = None`命令特别提到了这一点。

    我们使用`na_values = "? "`参数将数据集中表示为`?`的缺失值替换为`na`值。这种替换是为了便于进一步处理。

    读取文件后，使用`.head()`功能打印数据帧。

    您应该得到以下输出:

    ![Figure 15.3: Loading data into the Colab notebook
    ](image/B15019_15_03.jpg)

    图 15.3:将数据加载到 Colab 笔记本中

5.  Change the classes to `1` and `0`.

    如果您在数据集中注意到，列`15`中表示的类是特殊字符:`+`表示批准，`-`表示未批准。您需要将其改为数值`1`表示批准，数值`0`表示未批准，如下面的代码片段所示:

    ```py
    # Changing the Classes to 1 & 0
    credData.loc[credData[15] == '+' , 15] = 1
    credData.loc[credData[15] == '-' , 15] = 0
    credData.head()
    ```

    您应该得到以下输出:

    ![Figure 15.4: Data frame after replacing special characters
    ](image/B15019_15_04.jpg)

    图 15.4:替换特殊字符后的数据框

    在前面的代码片段中，`.loc()`用于定位第 15 列，并用`1`和`0`分别替换`+`和`-`值。

6.  Find the number of `null` values in the dataset.

    我们现在将使用`.isnull()`函数找到每个特征中的`null`值的数量。`.sum()`函数对数据集中每一列的所有空值求和。

    这在下面的代码片段中有所体现:

    ```py
    # Finding number of null values in the data set
    credData.isnull().sum()
    ```

    您应该得到以下输出:

    ![Figure 15.5: Summarizing null values in the dataset
    ](image/B15019_15_05.jpg)

    图 15.5:汇总数据集中的空值

    从前面的输出可以看出，有许多列带有`null`值。

7.  Now, print the shape and data types of each column:

    ```py
    # Printing Shape and data types
    print('Shape of raw data set',credData.shape)
    print('Data types of data set',credData.dtypes)
    ```

    您应该得到以下输出:

    ![Figure 15.6: Shape and data types of each column
    ](image/B15019_15_06.jpg)

    图 15.6:每个列的形状和数据类型

8.  Remove the rows with `na` values.

    为了清理数据集，让我们使用带有以下代码片段的`.dropna()`函数删除所有带有`na`值的行:

    ```py
    # Dropping all the rows with na values
    newcred = credData.dropna(axis = 0)
    newcred.shape
    ```

    您应该得到以下输出:

    ```py
    (653, 16)
    ```

    如您所见，大约 37 行具有`na`值的数据被删除。在代码片段中，我们定义了`axis = 0`来表示`na`值的删除应该沿着行进行。

9.  Verify that no `null` values exist:

    ```py
    # Verifying no null values exist
    newcred.isnull().sum()
    ```

    您应该得到以下输出:

    ![Figure 15.7: Verifying that no null values are present
    ](image/B15019_15_07.jpg)

    图 15.7:验证不存在空值

10.  Next, make dummy values from the categorical variables.

    正如您从数据类型中看到的，有许多变量具有分类值。必须使用`pd.get_dummies()`功能将其转换为虚拟值。这是使用以下代码片段完成的:

    ```py
    # Separating the categorical variables to make dummy variables
    credCat = pd.get_dummies(newcred[[0,3,4,5,6,8,9,11,12]])
    ```

11.  Separate the numerical variables.

    我们还将从原始数据集中分离出数字变量，并将它们与虚拟变量连接起来。该步骤按如下方式完成:

    ```py
    # Separating the numerical variables
    credNum = newcred[[1,2,7,10,13,14]]
    ```

12.  Create the `X` and `y` variables.

    虚拟变量和数值变量现在将被连接起来形成`X`变量。`y`变量将通过获取数据集的标签单独创建。让我们在下面的代码片段中看到这些操作步骤:

    ```py
    # Making the X variable which is a concatenation of categorical and numerical data
    X = pd.concat([credCat,credNum],axis = 1)
    print(X.shape)
    # Separating the label as y variable
    y = newcred[15]
    print(y.shape)
    ```

    您应该得到以下输出:

    ```py
    (653, 46)
    (653,)
    ```

13.  使用`MinMaxScaler()`函数对数据集进行归一化:

    ```py
    # Normalizing the data sets
    # Import library function
    from sklearn import preprocessing
    # Creating the scaling function
    minmaxScaler = preprocessing.MinMaxScaler()
    # Transforming with the scaler function
    X_tran = pd.DataFrame(minmaxScaler.fit_transform(X))
    ```

14.  Split the dataset into training and test sets.

    作为数据准备的最后一步，我们现在将使用`train_test_split()`函数将数据集分成训练集和测试集:

    ```py
    from sklearn.model_selection import train_test_split
    # Splitting the data into train and test sets
    X_train, X_test, y_train, y_test = train_test_split(X_tran, y, test_size=0.3, random_state=123)
    ```

现在，我们已经为进一步的操作准备好了所需的数据集。和往常一样，让我们首先在清理后的数据集上使用逻辑回归拟合一个基准模型。这将在下一个活动中实现。

## 活动 15.01:根据信用卡数据拟合逻辑回归模型

您刚刚清理了接收到的用于预测客户信用度的数据集。在应用集成学习方法之前，您需要在数据集上拟合一个基准模型。

执行以下步骤来完成本练习:

1.  打开新的 Colab 笔记本。
2.  实施从*练习 15.01* 开始的所有步骤，直到将数据集分成训练集和测试集。
3.  对定型集拟合逻辑回归模型。
4.  获得测试集上的预测。
5.  Print the confusion matrix and classification report for the benchmark model.

    在数据集上拟合逻辑回归模型后，您应该会得到类似于以下内容的输出:

    ![Figure 15.8: Expected output after fitting the logistic regression model
    ](image/B15019_15_08.jpg)

图 15.8:拟合逻辑回归模型后的预期输出

注意

请注意，由于预测过程中的可变性，您不会得到准确的输出值。

这个活动的解决方案可以在这里找到:[https://packt.live/2GbJloz](https://packt.live/2GbJloz)。

在此活动中，我们创建了一个基准模型，用于与后续模型进行比较。

正如您从输出中看到的，我们使用基准模型达到了`0.89`的精度水平。

既然我们已经拟合了一个基准模型，我们将在下一节探索集成学习的不同方法，从简单的方法开始。

# 集成学习的简单方法

正如本章前面所定义的，集成学习就是结合单个模型的优势来得到一个更好的模型。在本节中，我们将探索一些简单的技术，如下所示:

*   求平均值
*   加权平均
*   最大投票

让我们依次看一下它们。

## 平均

平均是进行集成学习的一种简单方法；然而，它也非常有用。这种技术背后的基本思想是获取多个单独模型的预测，然后对这些预测进行平均以生成最终预测。假设是，通过平均不同个体学习者的预测，我们消除了个体学习者所犯的错误，从而生成优于基础模型的模型。进行平均的一个先决条件是基础模型的预测是不相关的。这意味着不同的模型不应该犯同样的错误。模型的多样性是确保不相关误差的一个重要方面。

在实现平均技术时，需要注意预测中的一些细微差别。预测的时候，到目前为止，我们一直用的是`predict()`函数。现在您可能已经知道了，`predict()`函数输出概率最高的类。例如，在我们的基准模型中，当我们对测试集进行预测时，对于每个测试示例，我们得到的输出不是‘1’就是‘0’。还有另一种方法来进行预测，那就是生成每一类的概率。如果我们要为基准模型输出每个类的概率，我们将为每个示例得到两个对应于每个类的概率的输出。下表中的预测示例说明了这一点:

![Figure 15.9: An example prediction
](image/B15019_15_09.jpg)

图 15.9:预测示例

从前面的例子中，我们可以看到每个测试例子都有两个对应于每个类的概率的输出。因此，对于第一个例子，预测将是类别‘1’，因为类别`1` ( `0.902`)的概率高于类别`0` ( `0.098`)。例如`2`和`3` 的相应预测将分别是类别`0`和类别`1`。

当我们通过平均方法生成集成时，我们生成每个类别的概率，而不是类别预测。使用一个名为`predict_proba()`的独立函数来预测每一类的概率。我们将在*练习 15.02* 中看到平均法的实施。

## 练习 15.02:使用平均技术的集成模型

在这个练习中，我们将使用平均技术实现一个集成模型。我们将在本练习中使用的基础模型是我们用作基准模型的逻辑回归模型，以及在*第 4 章*、*随机森林多类分类*和*第 8 章*、*超参数调整*中介绍的 KNN 和随机森林模型:

1.  打开新的 Colab 笔记本。
2.  执行从*练习 15.01* 开始的所有步骤，直到将数据集分成训练集和测试集。
3.  让我们定义三个基本模型。导入我们将用作基础模型的所选分类器:

    ```py
    from sklearn.linear_model import LogisticRegression
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.ensemble import RandomForestClassifier
    model1 = LogisticRegression(random_state=123)
    model2 = KNeighborsClassifier(n_neighbors=5)
    model3 = RandomForestClassifier(n_estimators=500)
    ```

4.  在训练集上拟合所有三个模型:

    ```py
    # Fitting all three models on the training data
    model1.fit(X_train,y_train)
    model2.fit(X_train,y_train)
    model3.fit(X_train,y_train)
    ```

5.  我们现在将使用`predict_proba()`函数预测每个模型的概率:

    ```py
    # Predicting probabilities of each model on the test set
    pred1=model1.predict_proba(X_test)
    pred2=model2.predict_proba(X_test)
    pred3=model3.predict_proba(X_test)
    ```

6.  对所有三个模型生成的预测进行平均:

    ```py
    # Calculating the ensemble prediction by averaging three base model predictions
    ensemblepred=(pred1+pred2+pred3)/3
    ```

7.  Display the first four rows of the ensemble prediction array:

    ```py
    # Displaying first 4 rows of the ensemble predictions
    ensemblepred[0:4,:]
    ```

    您应该会得到类似如下的输出:

    ![Figure 15.10: First four rows of ensemble predictions
    ](image/B15019_15_10.jpg)

    图 15.10:集合预测的前四行

    正如您在前面的输出中所看到的，我们对每个类的每个例子都有两个概率。

8.  Print the order of each class from the prediction output. As you can see from *Step 6*, the prediction output has two columns corresponding to each class. In order to find the order of the class prediction, we use a method called `.classes_`. This is implemented in the following code snippet:

    ```py
    # Printing the order of classes for each model
    print(model1.classes_)
    print(model2.classes_)
    print(model3.classes_)
    ```

    您应该得到以下输出:

    ![Figure 15.11: Order of classes
    ](image/B15019_15_11.jpg)

    图 15.11:类的顺序

9.  We now have to get the final predictions for each example from the output probabilities. The final prediction will be the class with the highest probability. To get the class with the highest probability, we use the `numpy` function, `.argmax()`. This is executed as follows:

    ```py
    import numpy as np
    pred = np.argmax(ensemblepred,axis = 1)
    pred
    ```

    根据前面的代码，`axis = 1`意味着我们需要找到跨列的最大值的索引。

    您应该得到以下输出:

    ![Figure 15.12: Array output
    ](image/B15019_15_12.jpg)

    图 15.12:数组输出

10.  Generate the confusion matrix for the predictions:

    ```py
    # Generating confusion matrix
    from sklearn.metrics import confusion_matrix
    confusionMatrix = confusion_matrix(y_test, pred)
    print(confusionMatrix)
    ```

    您应该会得到类似如下的输出:

    ![Figure 15.13: Confusion matrix
    ](image/B15019_15_13.jpg)

    图 15.13:混淆矩阵

11.  Generate a classification report:

    ```py
    # Generating classification report
    from sklearn.metrics import classification_report
    print(classification_report(y_test, pred))
    ```

    您应该会得到类似如下的输出:

    ![Figure 15.14: Classification report
    ](image/B15019_15_14.jpg)

图 15.14:分类报告

在这个练习中，我们实现了用于集成学习的平均技术。正如您在分类报告中看到的，我们设法通过平均将准确率从基准模型实现的`0.89`提高到了`0.91`。然而，应该注意的是，集合方法并不保证在所有情况下都能改善结果。可能会有观察不到性能提高的情况。

让我们从信用卡应用的业务环境来看结果。`91%`的准确性意味着在测试集中的`196`个案例中，我们能够正确地预测客户在这些案例的`91%`中是否有信誉。查看类别`0`(即`91%`)的召回值也会很有趣。在这种情况下，我们在案例的`91%`中正确识别了不值得购买的客户。另一个令人担忧的地方是，不值得的客户的余额`9%`被错误地认定为有信誉的，这实际上是信用卡部门的一个风险。理想情况下，如果我们想降低信用卡部门的风险，我们会希望提高不值得的客户的召回价值。

另一方面,还有一个问题是如何通过对信誉良好的客户的正确预测来最大化商业机会。我们已经看到，总共`107`中的`91%`个信誉良好的客户被正确预测，这是一个积极的结果。信誉良好的客户的余额将是一个失去的商业机会。

微调模型是一种平衡行为，数据科学家必须认识到这一点。数据科学家必须根据业务的偏好行事。如果企业厌恶风险，宁愿放弃商业机会，那么模型将不得不调整，以增加无价值客户的召回价值。另一方面，如果企业是积极进取的，并希望寻求增长，那么首选的途径将是提高信誉良好的客户的召回价值。归根结底，微调模型是基于业务现实的平衡行为。

## 加权平均

加权平均是我们之前看到的平均方法的扩展。这两种方法的主要区别在于生成组合预测的方式。在加权平均法中，我们为每个模型的预测分配权重，然后生成组合预测。权重是基于我们对哪个模型在集合中最有影响力的判断来分配的。这些权重最初是任意分配的，必须经过大量实验才能进化。首先，我们假设一些权重，然后对每个模型使用不同的权重进行迭代，以验证我们是否在性能上有所改进。让我们在接下来的练习中实施加权平均法。

## 练习 15.03:使用加权平均技术的集成模型

在这个练习中，我们将使用加权平均技术实现一个集成模型。我们将使用在*练习 15.02* 中使用的相同基础模型、逻辑回归、KNN 和随机森林，以及使用平均技术的*集成模型:*

1.  打开新的 Colab 笔记本。
2.  使用平均技术执行从*练习 15.02* 、*集成模型的所有步骤，直到预测三个模型的概率。*
3.  Take the weighted average of the predictions. In the weighted averaging method, weights are assigned arbitrarily based on our judgment of each of the predictions. This is done as follows:

    ```py
    # Calculating the ensemble prediction by applying weights for each prediction
    ensemblepred=(pred1 *0.60 + pred2 * 0.20 + pred3 * 0.20)
    ```

    请注意，权重的分配方式是所有权重之和变为`1` ( `0.6 + 0.2 + 0.2 = 1`)。

4.  Display the first four rows of the ensemble prediction array:

    ```py
    # Displaying first 4 rows of the ensemble predictions
    ensemblepred[0:4,:]
    ```

    您应该会得到类似如下的输出:

    ![Figure 15.15: Array output for ensemble prediction
    ](image/B15019_15_15.jpg)

    图 15.15:集合预测的数组输出

    正如你从输出中看到的，我们有两个概率对应于每个类的每个例子。

5.  Print the order of each class from the prediction output:

    ```py
    # Printing the order of classes for each model
    print(model1.classes_)
    print(model2.classes_)
    print(model3.classes_)
    ```

    您应该得到以下输出:

    ![Figure 15.16: Order of class from prediction output
    ](image/B15019_15_16.jpg)

    图 15.16:来自预测输出的类别顺序

6.  Calculate the final predictions from the probabilities.

    我们现在必须使用`np.argmax()`函数从输出概率中获得每个例子的最终预测:

    ```py
    import numpy as np
    pred = np.argmax(ensemblepred,axis = 1)
    pred
    ```

    您应该会得到类似如下的输出:

    ![Figure 15.17: Array for final predictions
    ](image/B15019_15_17.jpg)

    图 15.17:最终预测的数组

7.  Generate the confusion matrix for the predictions:

    ```py
    # Generating confusion matrix
    from sklearn.metrics import confusion_matrix
    confusionMatrix = confusion_matrix(y_test, pred)
    print(confusionMatrix)
    ```

    您应该会得到类似如下的输出:

    ![Figure 15.18: Confusion matrix
    ](image/B15019_15_18.jpg)

    图 15.18:混淆矩阵

8.  Generating a classification report:

    ```py
    # Generating classification report
    from sklearn.metrics import classification_report
    print(classification_report(y_test, pred))
    ```

    您应该会得到类似如下的输出:

    ![Figure 15.19: Classification report
    ](image/B15019_15_19.jpg)

图 15.19:分类报告

### 不同权重的迭代 2

从第一次迭代开始，我们看到我们获得了`89%`的精确度。这个指标反映了我们在第一次迭代中应用的权重。让我们尝试改变权重，看看它对指标有什么影响。尝试各种权重的过程是基于我们对数据集和数据分布的判断。假设我们认为数据分布更加线性，因此我们决定增加线性回归模型的权重，减少其他两个模型的权重。现在让我们在*迭代 2* 中尝试新的权重组合:

1.  Take the weighted average of the predictions.

    在这次迭代中，我们将逻辑回归预测的权重从`0.6`增加到`0.7`，并将另外两个从`0.2`减少到`0.15`:

    ```py
    # Calculating the ensemble prediction by applying weights for each prediction
    ensemblepred=(pred1 *0.70+pred2 * 0.15+pred3 * 0.15)
    ```

2.  Calculate the final predictions from the probabilities.

    我们现在必须使用`np.argmax()`函数从输出概率中获得每个例子的最终预测:

    ```py
    # Generating predictions from probabilities
    import numpy as np
    pred = np.argmax(ensemblepred,axis = 1)
    ```

3.  Generate the confusion matrix for the predictions:

    ```py
    # Generating confusion matrix
    from sklearn.metrics import confusion_matrix
    confusionMatrix = confusion_matrix(y_test, pred)
    print(confusionMatrix)
    ```

    您应该会得到类似如下的输出:

    ![Figure 15.20: Confusion matrix
    ](image/B15019_15_20.jpg)

    图 15.20:混淆矩阵

4.  Generate a classification report:

    ```py
    # Generating classification report
    from sklearn.metrics import classification_report
    print(classification_report(y_test, pred))
    ```

    您应该会得到类似如下的输出:

    ![Figure 15.21: Classification report
    ](image/B15019_15_21.jpg)

图 15.21:分类报告

在这个练习中，我们实现了用于集成学习的加权平均技术。我们对权重进行了两次迭代。我们看到，在第二次迭代中，我们将逻辑回归预测的权重从`0.6`增加到`0.7`，准确性实际上从`0.89`提高到了`0.90`。这证实了我们关于逻辑回归模型在集合中的突出性的假设。为了检查是否有更多的改进空间，我们应该再次改变权重，就像我们在迭代`2`中所做的那样，然后根据度量进行验证。我们应该继续这些迭代，直到度量中没有进一步的改进。

将它与平均方法的指标进行比较，我们可以看到精度水平已经从`0.91`下降到`0.90`。然而，等级`1`的召回值从`0.91`上升到`0.92`，等级`0`的相应值从`0.91`下降到`0.88`。可能是我们应用的权重导致了我们从平均方法中得到的结果的边际退化。

从业务角度看结果，我们可以看到，随着类别`1`召回值的增加，信用卡部门获得了更多信誉良好的客户。然而，这是以增加更多不值得的客户的风险为代价的，随着`12%` ( `100% - 88%`)被标记为信誉良好的客户。

### 最大投票

最大投票法是基于多数决原则的。在这种方法中，多数人的意见起决定作用。在这种技术中，单个模型，或者用集成学习行话来说，单个学习者，适合训练集，然后在测试集上生成它们的预测。每个学习者的预测都被认为是一次投票。在测试集上，获得最多投票的类是最终的赢家。让我们用一个玩具例子来证明这一点。

假设我们有三个在训练集中学习的个体学习者。它们中的每一个都在测试集上生成它们的预测，下表列出了这些预测。预测是针对类“1”或类“0”:

![Figure 15.22: Predictions for learners
](image/B15019_15_22.jpg)

图 15.22:对学习者的预测

在前面的例子中，我们可以看到对于`Example 1`和`Example 3`，大多数投票是支持类“1”，而对于另外两个例子，大多数投票是支持类“0”。最终的预测是基于哪个阶层获得了多数票。我们输出一个类的这种投票方法被称为“硬”投票。

当使用`scikit-learn`库实现 max voting 方法时，我们使用一个叫做`VotingClassifier()`的特殊函数。我们提供个人学习者作为`VotingClassifier`的输入来创建集成模型。该集成模型然后用于拟合训练集，然后最终用于对测试集进行预测。我们将在*练习 15.04* 中探索 max voting 的动态。

## 练习 15.04:使用最大投票的集成模型

在本练习中，我们将使用最大投票技术实现一个集成模型。我们将选择的个别学员与我们在之前的练习中选择的学员相似，即逻辑回归、KNN 和随机森林:

1.  打开新的 Colab 笔记本。
2.  执行从*练习 15.03* 开始的所有步骤，直到将数据集分成训练集和测试集。
3.  我们现在将导入选定的分类器，我们将把它们用作单独的学习者:

    ```py
    Defining the voting classifier and three individual learners
    from sklearn.ensemble import VotingClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.ensemble import RandomForestClassifier
    # Defining the models
    model1 = LogisticRegression(random_state=123)
    model2 = KNeighborsClassifier(n_neighbors=5)
    model3 = RandomForestClassifier(n_estimators=500)
    ```

4.  Having defined the individual learners, we can now construct the ensemble model using the `VotingClassifier()` function. This is implemented by the following code snippet:

    ```py
    # Defining the ensemble model using VotingClassifier
    model = VotingClassifier(estimators=[('lr', model1),('knn', model2),('rf', model3)], voting= 'hard')
    ```

    正如您在代码片段中看到的，使用`estimators`参数将单个学习者作为输入给出。估计器将每个已定义的单个学习器与字符串值一起表示它是哪个模型。例如，`lr`表示逻辑回归。另外，请注意投票是“硬的”，这意味着输出将是类别标签而不是概率。

5.  在集成模型上拟合训练集:

    ```py
    # Fitting the model on the training set
    model.fit(X_train,y_train)
    ```

6.  Print the accuracy scores after training:

    ```py
    # Predicting accuracy on the test set using .score() function
    model.score(X_test,y_test)
    ```

    您应该会得到类似如下的输出:

    ```py
    0.9081632653061225
    ```

7.  在测试集上从集成模型生成预测:

    ```py
    # Generating the predictions on the test set
    preds = model.predict(X_test)
    ```

8.  Generate the confusion matrix for the predictions:

    ```py
    # Printing the confusion matrix
    from sklearn.metrics import confusion_matrix
    # Confusion matrix for the test set
    print(confusion_matrix(y_test, preds))
    ```

    您应该会得到类似如下的输出:

    ![Figure 15.23: Confusion matrix
    ](image/B15019_15_23.jpg)

    图 15.23:混淆矩阵

9.  Generate the classification report:

    ```py
    # Printing the classification report
    from sklearn.metrics import classification_report
    print(classification_report(y_test, preds))
    ```

    您应该会得到类似如下的输出:

    ![Figure 15.24: Classification report
    ](image/B15019_15_24.jpg)

图 15.24:分类报告

在这个练习中，我们实现了用于集成学习的最大投票技术。从分类报告中可以看到，结果和我们用平均法(`0.91`)得到的结果差不多。从商业背景来看，我们可以看到这个结果更加平衡。有价值客户的召回值高，为`92%`；然而，这是以拥有更多不值得拥有的客户为代价的。这种情况下的`100%` - `90%`，不值得的客户比例大概在`10%`左右。

## 集成学习的高级技术

已经学习了集成学习的简单技术，现在让我们探索一些高级技术。在高级技术中，我们将处理三种不同的集成学习:

*   制袋材料
*   助推
*   堆叠/混合

在我们处理它们中的每一个之前，需要破译这些高级集成学习技术的一些基本动力学。正如本章开始时所描述的，集成学习的本质是将单个模型组合起来形成一个更好的模型。在高级技术中生成高级模型的方式有一些微妙的差别。在这些技术中，单个模型或学习器生成预测，这些预测用于形成最终预测。生成第一组预测的单个模型或学习器被称为**基础** **学习器**或**基础** **估计器**，而组合了基础学习器预测的模型被称为**元** **学习器**或**元估计器**。对于每一种高级技术，元学习者从基础学习者那里学习的方式是不同的。让我们详细了解一下每一项高级技术。

### 装袋

Bagging 是**B**ootstrap**Agg**regat**ing**的笔名。在我们解释 bagging 如何工作之前，让我们先描述一下什么是 bootstrapping。Bootstrapping 的词源来自短语*通过自己的引导使自己振作起来*。这句话的精髓是充分利用现有资源。在统计学背景下，自举需要通过替换从可用数据集中获取样本。让我们用一个玩具例子来看看这个概念。

假设我们有一个数据集，由从 1 到 10 的 10 个数字组成。我们现在需要从可用的数据集中创建 4 个不同的数据集，每个数据集 10 个。我们如何做到这一点？这就是自举概念派上用场的地方。在这种方法中，我们从可用数据集中逐个抽取样本，然后在抽取下一个样本之前替换我们抽取的样本数。我们继续这样做，直到我们得到所需数据点数量的样本。由于我们在选择数字后会替换每个数字，因此样本中的给定数据点有可能不止一个。下图对此进行了解释:

![Figure 15.25: Bootstrapping
](image/B15019_15_25.jpg)

图 15.25:引导

现在我们已经理解了引导，让我们将这个概念应用到机器学习环境中。在本章的前面，我们讨论了集成学习有助于减少预测的方差。减少这种差异的一种方法是对多个学习者的预测进行平均。在打包中，使用引导创建数据的多个子集。在这些数据子集中的每一个上，基础学习者被拟合并且预测被生成。来自所有基础学习者的这些预测然后被平均以获得元学习者或最终预测。

在实现 bagging 时，我们使用一个名为`BaggingClassifier()`的函数，这个函数在`Scikit learn`库中。创建集成模型时提供的一些重要参数包括:

*   `base_estimator`:此参数用于定义要使用的基本估计量。
*   `n_estimator`:该参数定义了将在集合中使用的基本估计量的数量。
*   `max_samples`:使用此参数定义用于拟合基本估计量的自举样本的最大大小。这表示为一个比例(0.8、0.7 等等)。
*   `max_features`:当拟合多个个体学习者时，已经发现随机选择要在每个数据集中使用的特征会产生更好的性能。`max_features`参数表示要使用的特征数量。例如，如果数据集中有 10 个特征，并且`max_features`参数被定义为 0.8，那么只有 8 个(0.8 x 10)特征将被用于使用基础学习器来拟合模型。

让我们在*练习 15.05* 中用 bagging 探索集成学习。

## 练习 15.05:使用 Bagging 的集成学习

在本练习中，我们将使用 bagging 实现一个集成模型。我们将选择的个别学员将是随机森林:

1.  打开新的 Colab 笔记本。
2.  执行从*练习 15.04* 开始的所有步骤，直到将数据集分成训练集和测试集。
3.  定义基本学习器，它将是一个随机森林分类器:

    ```py
    # Defining the base learner
    from sklearn.ensemble import RandomForestClassifier
    bl1 = RandomForestClassifier(random_state=123)
    ```

4.  Having defined the individual learner, we can now construct the ensemble model using the `BaggingClassifier()` function. This is implemented by the following code snippet:

    ```py
    # Creating the bagging meta learner
    from sklearn.ensemble import BaggingClassifier
    baggingLearner = BaggingClassifier(base_estimator=bl1, n_estimators=10, max_samples=0.8, max_features=0.7)
    ```

    我们给出的论点是任意值。最佳值必须通过实验来确定。

5.  在集成模型上拟合训练集:

    ```py
    # Fitting the model using the meta learner
    model = baggingLearner.fit(X_train, y_train)
    ```

6.  在测试集上从集成模型生成预测:

    ```py
    # Predicting on the test set using the model
    pred = model.predict(X_test)
    ```

7.  Generate a confusion matrix for the predictions:

    ```py
    # Printing the confusion matrix
    from sklearn.metrics import confusion_matrix
    print(confusion_matrix(y_test, pred))
    ```

    您应该会得到类似如下的输出:

    ![Figure 15.26: Confusion matrix
    ](image/B15019_15_26.jpg)

    图 15.26:混淆矩阵

8.  Generate the classification report:

    ```py
    # Printing the classification report
    from sklearn.metrics import classification_report
    print(classification_report(y_test, pred))
    ```

    您应该会得到类似如下的输出:

    ![Figure 15.27: Classification report
    ](image/B15019_15_27.jpg)

图 15.27:分类报告

在这个练习中，我们使用 bagging 实现了集成学习。正如你从分类报告中看到的，我们得到的结果(`0.90`)比我们从平均和最大投票法(`0.91`)得到的结果稍低。然而，从商业的角度来看，我们可以看到两个类的召回值有很大的波动。我们看到信誉良好的客户的召回价值在 87%左右。这意味着 T2 到处都有失去的机会。我们还可以看到，识别不值得购买的客户的风险也在降低。识别不值得的客户的召回值大约是 93%，这意味着只有大约 7%的不值得的客户被错误地分类为有信誉的。所以，对于一个比较厌恶风险的企业，建议你使用这种模式。

## 助推

我们在上一节讨论的 bagging 技术可以被称为并行学习技术。这意味着每一个基础学习者都是独立的，他们的预测是聚合的。与装袋方法不同，增压是按顺序进行的。它的工作原理是校正每个基础学习者的预测误差。基础学习者按顺序一个接一个地适应。一个基础学习者试图纠正前一个学习者产生的错误，这个过程一直持续到产生一个更好的元学习者。升压技术中涉及的步骤如下:

1.  基础学习者适合数据集的子集。
2.  模型拟合后，将对整个数据集进行预测。
3.  预测中的误差通过与实际标签进行比较来识别。
4.  那些产生错误预测的例子被给予更大的权重。
5.  另一个基础学习器适合数据集，其中在先前步骤中错误预测的例子的权重被改变。
6.  这个基础学习者试图纠正早期模型的错误并给出他们的预测。
7.  重复步骤 4 、 *5* 和 *6* ，直到产生一个强元学习者。

当实现 boosting 技术时，我们可以使用的一个方法是 scikit-learn 中的`AdaBoostClassifier()`。像 bagging 估计量一样，`AdaBoostClassifier()`方法的一些重要参数是`base_estimator`和`n_estimators`。我们现在将在*练习 15.06* 中实现 boosting 算法。

## 练习 15.06:使用 Boosting 的集成学习

在本练习中，我们将使用 boosting 实现一个集成模型。我们将选择的个别学习者将是逻辑回归模型。实现该算法的步骤与 bagging 算法非常相似:

1.  打开一个新的 Colab 笔记本文件。
2.  执行从*练习 15.05* 开始的所有步骤，直到将数据集分成训练集和测试集。
3.  定义基础学习者，这将是一个逻辑回归分类器:

    ```py
    # Defining the base learner
    from sklearn.linear_model import LogisticRegression
    bl1 = LogisticRegression(random_state=123)
    ```

4.  Having defined the individual learner, we can now construct the ensemble model using the `AdaBoostClassifier()` function. This is implemented by the following code snippet:

    ```py
    # Define the boosting meta learner
    from sklearn.ensemble import AdaBoostClassifier
    boosting = AdaBoostClassifier(base_estimator=bl1, n_estimators=200)
    ```

    我们给出的论点是任意值。最佳值必须通过实验来确定。

5.  在集成模型上拟合训练集:

    ```py
    # Fitting the model on the training set
    model = boosting.fit(X_train, y_train)
    ```

6.  在测试集上从集成模型生成预测:

    ```py
    # Getting the predictions from the boosting model
    pred = model.predict(X_test)
    ```

7.  Generate a confusion matrix for the predictions:

    ```py
    # Printing the confusion matrix
    from sklearn.metrics import confusion_matrix
    print(confusion_matrix(y_test, pred))
    ```

    您应该会得到与下面类似的输出:

    ![Figure 15.28: Confusion matrix
    ](image/B15019_15_28.jpg)

    图 15.28:混淆矩阵

8.  Generate the classification report:

    ```py
    # Printing the classification report
    from sklearn.metrics import classification_report
    print(classification_report(y_test, pred))
    ```

    您应该会得到类似如下的输出:

    ![Figure 15.29: Classification report
    ](image/B15019_15_29.jpg)

图 15.29:分类报告

在本练习中，我们使用 boosting 实现了集成学习模型。正如您在分类报告中看到的，我们得到的结果(0.90)与我们在之前的练习中实施的 bagging 方法非常相似。从商业角度来看，与我们用 bagging 方法得到的结果(召回值为 0.93 和 0.87)相比，结果更加平衡。在这里，我们可以看到不值得的客户(90%)和有信誉的客户(91%)的召回值彼此非常接近，这表明了一个非常平衡的结果。

## 堆叠

原则上，堆叠的工作方式类似于打包和提升，因为它将基础学习者组合成元学习者。然而，从基础学习者中获取元学习者的方法在堆栈方面有很大不同。在堆叠中，元学习者适合基础学习者做出的预测。堆叠算法可以解释如下:

1.  训练集被分成多个部分，比如说五个部分。
2.  一个基础学习者(比如说 KNN)适合训练集的四个部分，然后在第五个部分进行预测。这个过程一直持续到基础学习者对训练集的五个部分中的每一个进行预测。如此生成的所有预测将被整理以获得完整训练集的预测。
3.  然后，相同的基本学习器也用于在测试集上生成预测。
4.  然后用不同的基础学习者(比如随机森林)重复步骤 2 和 *3* 。
5.  接下来进入一个新的模型，它充当元学习者(比如逻辑回归)。
6.  元学习者适合基础学习者在训练集上生成的预测。
7.  Once the meta learner is fit on the training set, the same model is used to predict on the predictions generated on the test set by the base learners.

    所有这些过程都被形象地解释如下:

    ![Figure 15.30: Process of stacking
    ](image/B15019_15_30.jpg)

图 15.30:堆叠过程

堆栈的实现是通过一个名为`StackingClassifier()`的函数来完成的。这可以从一个名为`mlxtend`的包中获得。这个函数的各种参数是我们指定为基础学习者的模型和指定为元学习者的模型。堆叠技术的实现在*练习 15.07* 中执行。

## 练习 15.07:使用堆叠的集成学习

在本练习中，我们将使用堆叠实现一个系综模型。我们将使用的个人学习者是 KNN 和随机森林。我们的元学习者将是逻辑回归:

1.  打开新的 Colab 笔记本。
2.  执行从*练习 15.06* 开始的所有步骤，直到将数据集分成训练集和测试集。
3.  导入基础学习者和元学习者。在这个实现中，我们将使用两个基础学习者(KNN 和随机森林)。元学习者将进行逻辑回归:

    ```py
    # Importing the meta learner and base learners
    from sklearn.linear_model import LogisticRegression
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.ensemble import RandomForestClassifier
    bl1 = KNeighborsClassifier(n_neighbors=5)
    bl2 = RandomForestClassifier(random_state=123)
    ml = LogisticRegression(random_state=123)
    ```

4.  Once the base learners and meta learner are defined, we will proceed to create the stacking classifier:

    ```py
    # Creating the stacking classifier
    from mlxtend.classifier import StackingClassifier
    stackclf = StackingClassifier(classifiers=[bl1, bl2], 
                              meta_classifier=ml)
    ```

    我们得到的论据是两个基础学习者和一个元学习者。

5.  在集成模型上拟合训练集:

    ```py
    # Fitting the model on the training set
    model = stackclf.fit(X_train, y_train)
    ```

6.  在测试集上从集成模型生成预测:

    ```py
    # Generating predictions on test set
    pred = model.predict(X_test)
    ```

7.  Generate the classification report:

    ```py
    # Printing the classification report
    from sklearn.metrics import classification_report
    print(classification_report(y_test, pred))
    ```

    您应该会得到与下面类似的输出:

    ![Figure 15.31: Classification report
    ](image/B15019_15_31.jpg)

    图 15.31:分类报告

8.  Generate a confusion matrix for the predictions:

    ```py
    # Printing the confusion matrix
    from sklearn.metrics import confusion_matrix
    print(confusion_matrix(y_test, pred))
    ```

    您应该会得到与下面类似的输出:

    ![Figure 15.32: Confusion matrix
    ](image/B15019_15_32.jpg)

图 15.32:混淆矩阵

在本练习中，我们使用堆栈实现了集成学习模型。正如您在分类报告中所看到的，使用堆叠分类器，我们并没有在基准模型上获得任何改进。可能的原因包括我们使用的基础学习者和元学习者的选择以及数据集的大小。应该注意的是，并不是所有的合奏学习者都是理想的银弹。在许多情况下，许多高级方法都无法提高性能。这次演习就是这样一个例子。然而，获得提高性能的最佳方法的秘诀是大量的实验。这将会产生结果。毕竟，在机器学习中，没有免费的午餐。

从商业角度来看，这一结果对收入有着巨大的影响，因为大量信誉良好的客户`16%` ( `100%` - `84%`)被贴上了不值得的标签。召回的风险方面非常好，识别出的不值得购买的客户的百分比(`92%`)更高。

到目前为止，我们已经看到了集成学习的三种高级技术。现在让我们将所有这些技术应用于信用卡数据集，然后选择最佳方法。我们将在*活动 15.02* 中这样做。

## 活动 15.02:先进集成技术的比较

场景:您已经在信用卡数据集上尝试了基准模型，并获得了一些基准指标。学习了一些高级集成技术后，您想决定对信用卡审批数据集使用哪种技术。

在本练习中，您将使用所有三种高级技术并比较结果，然后选择最终技术。

步骤如下:

1.  打开新的 Colab 笔记本。
2.  实施从*练习 15.07* 开始的所有步骤，直到将数据集分成训练集和测试集。
3.  将基础学习者作为逻辑回归模型来实施 bagging 技术。在装袋分类器中，定义`n_estimators = 15`、`max_samples = 0.7`和`max_features = 0.8`。在训练集上拟合模型，生成预测，并打印混淆矩阵和分类报告。
4.  以随机森林为基础学习器实现 boosting。在`AdaBoostClassifier`中，定义`n_estimators = 300`。在训练集上拟合模型，生成预测，并打印混淆矩阵和分类报告。
5.  实施堆叠技术。使 KNN 和逻辑回归模型成为基础学习者，随机森林成为元学习者。在训练集上拟合模型，生成预测，并打印混淆矩阵和分类报告。
6.  比较所有三种技术的结果，并选择最佳技术。
7.  Output: You should get an output similar to the following for all three methods. Please note you will not get exact values as output due to variability in the prediction process.

    装袋的输出如下:

    ![Figure 15.33: Output for bagging
    ](image/B15019_15_33.jpg)

图 15.33:装袋的输出

升压的输出如下:

![Figure 15.34: Output for boosting
](image/B15019_15_34.jpg)

图 15.34:升压输出

堆叠的输出如下:

![Figure 15.35: Output for stacking
](image/B15019_15_35.jpg)

图 15.35:堆叠的输出

注意

这个活动的解决方案可以在这里找到:[https://packt.live/2GbJloz](https://packt.live/2GbJloz)。

在这项活动中，我们在信用卡数据集上实现了所有三种高级集成技术。基于这些指标，我们发现 boosting (0.91)比 bagging (0.90)和 stacking (0.87)有更好的结果。因此，我们选择 boosting 算法来提升模型的性能。从商业角度来看，boosting 算法产生了更加平衡的结果，信誉良好和信誉不佳的客户的召回值(91%)是相似的。

# 总结

在这一章中，我们学习了集成学习的各种技术。让我们总结一下本章的学习内容。

在本章的开始，我们介绍了方差和偏差的概念，我们了解到集成学习是一种旨在将单个模型组合起来以创建更好的模型的技术，从而减少方差和偏差并提高性能。为了进一步探索集成学习的不同技术，我们下载了信用卡审批数据集。我们还使用逻辑回归拟合了一个基准模型。

在随后的章节中，我们介绍了六种不同的集成学习技术；其中三个在简单技术下，其余三个在高级技术下。平均方法通过组合基本学习者的预测并平均预测概率来创建集成。使用这种技术，我们能够获得比基准模型更好的结果。加权平均法类似于平均法。不同之处在于预测的组合方式。在这种方法中，任意权重被应用到单个学习者的预测中，以获得最终的预测。最大投票是一种基于大多数基础学习者的投票得出最终预测的技术。

使用 bagging 杠杆自举技术的集成学习。基础学习器被安装在自举数据集上，结果被聚集以得到元学习器。Boosting 是一个顺序学习器，其工作原理是对基础学习器进行纠错。我们发现提升技术为我们的环境产生了一些更好的结果。堆叠技术旨在通过从基础学习器的预测输出中学习来生成最终预测。

本章的目的是让你掌握一整套旨在提高机器学习模型性能的技能。然而，需要注意的是，在机器学习技术中没有灵丹妙药。并非所有的技术都适用于所有的场景。有助于你成为优秀数据科学家的秘方是对不同技术、用例以及数据集的严格实验。

在学习了一套旨在提高性能的工具之后，我们将进入下一章，这一章将使用不同的技术进行多次实验。在下一章中，我们将介绍使用 scikit-learn pipeline 实用程序自动化机器学习工作流的技术。