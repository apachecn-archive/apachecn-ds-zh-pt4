

# 十三、不平衡数据集

概观

在本章结束时，你将能够识别数据集可能不平衡的用例；制定处理不平衡数据集的策略；平衡数据集后，建立分类模型，如逻辑回归模型；并分析分类标准，以验证所采用的策略是否产生了预期的结果。

在这一章中，你将处理不平衡的数据集，这在现实生活中非常普遍。您将使用诸如`SMOTE`、`MSSMOTE`和随机欠采样等技术来处理不平衡的数据集。

# 简介

在前一章*第 12 章*、*特征工程*中，我们处理了与日期相关的数据点，我们正在处理与特征相关的场景。在这一章中，我们将讨论样本在整个数据集中所占比例带来挑战的情况。

让我们重温一下我们在*第 3 章*、*二元分类*中处理的数据集，其中关于定期存款“否”的例子远远多于“是”的例子，比例为 88%比 12%。我们还确定了在该数据集上使用逻辑回归模型得出次优结果的一个原因是样本比例的偏差。像我们在*第 3 章*、*、*中分析的数据集，被称为不平衡数据集，在现实世界的用例中非常常见。

我们遇到不平衡数据集的一些用例包括:

*   信用卡或保险索赔欺诈检测
*   我们必须检测罕见疾病存在的医疗诊断
*   网络中的入侵检测

在所有这些用例中，我们可以看到我们真正想要检测的是少数情况。例如，在罕见疾病的医学诊断等领域，存在罕见疾病的例子甚至可能少于总例子的 1%。不平衡数据集用例的一个固有特征是，如果没有使用正确的度量，分类器的质量就不明显。这使得不平衡数据集的问题非常具有挑战性。

在本章中，我们将讨论识别不平衡数据集的策略以及减轻不平衡数据集影响的方法。

# 了解业务环境

你作为数据科学家工作的银行的业务主管最近对你在第三章、*二进制分类*中构建的定期存款倾向模型的结果提出了警告。据观察，被确定为定期存款目标营销潜在案例的大部分客户都拒绝了这一提议。这大大削弱了销售团队在追加销售和交叉销售方面的指标。业务团队迫切需要您帮助解决这个问题，以达到本季度的销售目标。不过不要担心——这是我们将在本章后面解决的问题。

首先，我们开始分析这个问题。

## 练习 13.01:对数据集上的逻辑回归模型进行基准测试

在本练习中，我们将分析预测客户是否会购买定期存款的问题。为此，您将拟合一个逻辑回归模型，正如您在第三章、*中所做的那样，您将仔细查看指标:*

注意

您将在本练习中使用的数据集可以在我们的 GitHub 资源库中找到:[https://packt.live/2twFgIM](https://packt.live/2twFgIM)。

1.  在 Google Colab 中打开一个新笔记本。
2.  接下来，导入`pandas`并从 GitHub 存储库加载数据:

    ```py
    import pandas as pd
    filename = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter13/Dataset/bank-full.csv'
    ```

3.  Now, load the data using `pandas`

    ```py
    #Loading the data using pandas
    bankData = pd.read_csv(filename,sep=";")
    bankData.head()
    ```

    现在，为了进一步分解数据集，让我们执行一些特征工程步骤。

4.  Normalize the numerical features (age, balance, and duration) through scaling, which was covered in *Chapter 3*, *Binary Classification*. Enter the following code:

    ```py
    from sklearn.preprocessing import RobustScaler
    rob_scaler = RobustScaler()
    ```

    在前面的代码片段中，我们使用了一个名为`RobustScaler()`的缩放函数来缩放数字数据。`RobustScaler()`是一个类似于*第三章*、*二元分类*中`MinMaxScaler`的尺度函数。

    缩放数字数据后，我们将每一列转换为缩放后的版本，如以下代码片段所示:

    ```py
    # Converting each of the columns to scaled version
    bankData['ageScaled'] = rob_scaler.fit_transform(bankData['age'].values.reshape(-1,1))
    bankData['balScaled'] = rob_scaler.fit_transform(bankData['balance'].values.reshape(-1,1))
    bankData['durScaled'] = rob_scaler.fit_transform(bankData['duration'].values.reshape(-1,1))
    ```

5.  现在，在我们使用`.drop()`函数:

    ```py
    # Dropping the original columns
    bankData.drop(['age','balance','duration'], axis=1, inplace=True)
    ```

    引入缩放后的特征后，删除原始特征
6.  Display the first five columns using the `.head()` function:

    ```py
    bankData.head()
    ```

    数据集中的分类特征必须通过转换成虚拟值来转换成数值，这在*第 3 章*、*二元分类*中有所介绍。

7.  使用`.get_dummies()`函数将所有分类变量转换为虚拟变量:

    ```py
    bankCat = pd.get_dummies(bankData[['job','marital','education','default','housing','loan','contact','month','poutcome']])
    ```

8.  Separate the numerical data as in the following code snippet:

    ```py
    bankNum = bankData[['ageScaled','balScaled','day','durScaled','campaign','pdays','previous']]
    ```

    变换分类值后，必须将其与数据框的缩放数值相结合，以获得要素工程数据集。

9.  Create the independent variables, `X`, and dependent variables, `Y`, from the combined dataset for modeling, as in the following code snippet:

    ```py
    # Merging with the original data frame
    # Preparing the X variables
    X = pd.concat([bankCat, bankNum], axis=1)
    print(X.shape)
    # Preparing the Y variable
    Y = bankData['y']
    print(Y.shape)
    X.head()
    ```

    我们现在已经为建模任务做好了准备。让我们首先导入必要的包。

10.  现在，`sklearn` :

    ```py
    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import LogisticRegression
    ```

    中`train_test_split()`和`LogisticRegression`的必要功能
11.  使用分割函数中的`test_size = 0.3`变量，按照 **70:30** 的比例将数据分割成训练集和测试集。我们还为代码的可复制性设置了`random_state`:

    ```py
    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=123)
    # Defining the LogisticRegression function
    bankModel = LogisticRegression()
    ```

12.  Now, fit the model using `.fit` on the training data:

    ```py
    bankModel.fit(X_train, y_train)
    ```

    既然模型是合适的，现在让我们预测测试集并生成度量标准。

13.  接下来，找到测试集上的预测，并打印准确性分数:

    ```py
    pred = bankModel.predict(X_test)
    print('Accuracy of Logistic regression model prediction on test set: {:.2f}'.format(bankModel.score(X_test, y_test)))
    ```

14.  Now, use both the `confusion_matrix()` and `classification_report()` functions to generate the metrics for further analysis, which we will cover in the *Analysis of the Result* section:

    ```py
    # Confusion Matrix for the model
    from sklearn.metrics import confusion_matrix
    confusionMatrix = confusion_matrix(y_test, pred)
    print(confusionMatrix)
    from sklearn.metrics import classification_report
    print(classification_report(y_test, pred))
    ```

    您应该得到以下输出:

    注意

    您将获得与以下类似的指标。但是，由于建模过程中的可变性，这些值会有所不同。

![Figure 13.1: Metrics showing the accuracy result along with the confusion matrix
](img/B15019_13_01.jpg)

图 13.1:显示准确性结果和混淆矩阵的度量

在本练习中，我们发现一份报告可能导致了预期购买定期存款计划的客户数量的问题。从这些指标中，我们可以看到`No`的值的数量相对高于`Yes`的值的数量。

为了更好地理解扭曲结果背后的原因，我们将在下一节详细分析这些指标。

## 结果分析

为了分析上一节中获得的结果，让我们以如下形式展开混淆矩阵:

![Figure 13.2: Confusion matrix of the resulting metrics obtained
](img/B15019_13_02.jpg)

图 13.2:获得的结果度量的混淆矩阵

我们输入值`11707`、`291`、`1060`和`506`，这些值来自我们在前一个练习中得到的输出。然后，我们将这些值如图所示放置。我们将把定期存款(`No`)的倾向表示为正类，另一个表示为负类。因此，从混淆矩阵中，我们可以计算准确性度量，这在*第 3 章*、*二进制分类*中有所涉及。模型的精度由下式给出:

![Figure 13.1: Metrics showing the accuracy result along with the confusion matrix
](img/B15019_13_03.jpg)

图 13.3:模型的准确性

在我们的例子中，它将是(11707 + 506) / (11707 + 1060 + 291 + 506)，即 90%。

从准确性的角度来看，该模型似乎做了合理的工作。然而，现实可能完全不同。为了找出真实的情况，让我们看看精度和召回值，它们可以从我们获得的分类报告中获得。任何类别的精度公式都包含在第 3 章、*二进制分类*中

任何类别的精度值由下式给出:

![Figure 13.4: Precision of a model
](img/B15019_13_04.jpg)

图 13.4:模型的精度

在我们的例子中，对于正类，精度为 *TP/(TP + FP)* ，即 11707/ (11707 + 1060)，大约为 92%。

在负类的情况下，精度可以写成 *TN / (TN + FN)* ，即 506 / (506 + 291)，大约为 63%。

类似地，任何类别的召回值可以表示如下:

![Figure 13.5: Recalling a model
](img/B15019_13_05.jpg)

图 13.5:召回一个模型

阳性类的召回值*TP/(TP+FN)*= 11707/(11707+291)，达到大约 98%。

否定类的召回值*TN/(TN+FP)*= 506/(506+1060)，达到大约 32%。

召回表示分类器正确识别各个类别的能力。从度量标准中，我们看到我们构建的模型在识别积极类方面做得很好，但是在正确识别消极类方面做得很差。

为什么认为分类器偏向一类？这个问题的答案可以通过查看训练集中的类平衡来找到。

下面的代码将生成训练数据中类的百分比:

```py
print('Percentage of negative class :',(y_train[y_train=='yes'].value_counts()/len(y_train) ) * 100)
print('Percentage of positive class :',(y_train[y_train=='no'].value_counts()/len(y_train) ) * 100)
```

您应该得到以下输出:

```py
Percentage of negative class: yes    11.764148
Name: y, dtype: float64
Percentage of positive class: no    88.235852
Name: y, dtype: float64
```

由此，我们可以看到大多数训练集(88%)是由正面类组成的。这种不平衡是我们选择的逻辑回归分类器的衡量指标不佳的主要原因之一。

现在，让我们看看不平衡数据集的挑战。

# 不平衡数据集的挑战

从分类器示例中可以看出，不平衡数据集的最大挑战之一是偏向多数类，在前面的示例中，这一比例最终达到了 88%。这将导致次优的结果。然而，如果没有使用正确的度量标准，结果的欺骗性会使这种情况变得更加困难。

让我们以一个数据集为例，其中阴性类别约为 99%，阳性类别为 1%(例如，在一个必须检测罕见疾病的用例中)。

看看下面的代码片段:

```py
Data set Size: 10,000 examples
Negative class : 9910
Positive Class : 90
```

假设我们有一个很差的分类器，它只能预测负类；我们会得到下面的混淆矩阵:

![Figure 13.6: Confusion matrix of the poor classifier
](img/B15019_13_06.jpg)

图 13.6:不良分类器的混淆矩阵

从混淆矩阵，让我们来计算准确性措施。看看下面的代码片段:

```py
# Classifier biased to only negative class
Accuracy = (TP + TN ) / ( TP + FP + FN + TN)
 = (0 + 9900) / ( 0 + 0 + 90 + 9900) = 9900/10000
 = 99%
```

使用这样的分类器，如果我们使用一个度量标准，比如准确性，我们仍然会得到大约 99%的结果，在正常情况下，这看起来很突出。然而，在这种情况下，分类器做得不好。想想使用这样一个分类器和一个度量标准(如准确性)对现实生活的影响。这对患有罕见疾病的患者和被错误归类为非疾病患者的影响可能是致命的。

因此，识别具有不平衡数据集的案例是很重要的，同样重要的是选择正确的指标来分析这样的数据集。本例中的正确指标应该是查看两个类的召回值:

```py
Recall Positive class  = TP / ( TP + FN ) = 0 / ( 0 + 90)
 = 0
Recall Negative Class = TN / ( TN + FP) = 9900 / ( 9900 + 0)
= 100%
```

根据回忆值，我们可以确定分类器对多数类的偏差，这促使我们寻找减轻这种偏差的策略，这是我们将关注的下一个主题。

# 处理不平衡数据集的策略

既然我们已经确定了不平衡数据集的挑战，让我们来看看应对不平衡数据集的策略:

![Figure 13.7: Strategies for dealing with imbalanced datasets
](img/B15019_13_07.jpg)

图 13.7:处理不平衡数据集的策略

## 收集更多数据

遇到不平衡的数据集时，你需要问的第一个问题是是否有可能获得更多的数据。这可能看起来很天真，但是收集更多的数据，特别是来自少数民族的数据，然后平衡数据集应该是解决阶级不平衡的首要策略。

## 重采样数据

在许多情况下，收集更多的数据，尤其是从少数民族群体中收集数据，可能会很困难，因为少数民族群体的数据点非常少。在这种情况下，我们需要采用不同的策略来处理我们的约束，并努力平衡我们的数据集。一个有效的策略是对数据集进行重采样，使数据集更加平衡。重采样意味着从可用数据集中提取样本来创建新的数据集，从而使新的数据集达到平衡。

让我们详细看看这个想法:

![Figure 13.8: Random undersampling of the majority class
](img/B15019_13_08.jpg)

图 13.8:多数类的随机欠采样

如*图 13.8* 所示，重采样背后的想法是从多数类中随机选取样本，以使最终数据集更加平衡。在该图中，我们可以看到少数类与原始数据集具有相同数量的示例，并且多数类采样不足，以使最终数据集更加平衡。对这种类型的样本进行重采样被称为随机欠采样，因为我们对多数类进行欠采样。我们将在下面的练习中执行随机欠采样。

## 练习 13.02:对我们的银行数据集实施随机欠采样和分类，以找到最佳结果

在本练习中，您将对多数类(倾向`'No'`)进行欠采样，然后平衡数据集。在新的平衡数据集上，您将拟合逻辑回归模型，然后分析结果:

注意

您将在本练习中使用的数据集可以在我们的 GitHub 资源库中找到:[https://packt.live/2twFgIM](https://packt.live/2twFgIM)。

1.  为此练习打开一个新的 Colab 笔记本。
2.  执行*练习 13.01* 、*的初始任务，对数据集*上的逻辑回归模型进行基准测试，从而将数据集分为训练集和测试集。
3.  Now, join the `X` and `y` variables for the training set before resampling:

    ```py
    # Let us first join the train_x and train_y for ease of operation
    trainData = pd.concat([X_train,y_train],axis=1)
    ```

    在这一步中，我们将`X_train`和`y_train`数据集连接成一个数据集。这样做是为了使后续步骤中的重采样过程更容易。为了连接两个数据集，我们使用来自`pandas`的`.concat()`函数。在代码中，我们使用`axis = 1`来表示连接是水平进行的，沿着列进行。

4.  Now, display the new data with the `.head()` function:

    ```py
    trainData.head()
    ```

    您应该得到以下输出

    ![Figure 13.9: Displaying the first five rows of the dataset using .head()
    ](img/B15019_13_09.jpg)

    图 13.9:使用。头部()

    前面的输出显示了数据集的一些列。

    现在，让我们将少数民族类和多数民族类分成单独的数据集。

    我们接下来要做的是把少数阶级和多数阶级分开。这是必需的，因为我们必须从多数类中单独取样，以制作一个平衡的数据集。为了分离少数类，我们必须识别数据集的索引，其中数据集具有“是”使用`.index()`功能识别指标。

    一旦识别出这些索引，就使用`.loc()`函数将它们从主数据集中分离出来，并存储在 minority 类的一个新变量中。少数数据集的形状也会打印出来。对于多数类遵循类似的过程，在这两个步骤之后，我们有两个数据集:一个用于少数类，一个用于多数类。

5.  Next, find the indexes of the sample dataset where the propensity is `yes`:

    ```py
    ind = trainData[trainData['y']=='yes'].index
    print(len(ind))
    ```

    您应该得到以下输出:

    ```py
    3723
    ```

6.  Separate by the minority class as in the following code snippet:

    ```py
    minData = trainData.loc[ind]
    print(minData.shape)
    ```

    您应该得到以下输出:

    ```py
    (3723, 52)
    ```

7.  Now, find the indexes of the majority class:

    ```py
    ind1 = trainData[trainData['y']=='no'].index
    print(len(ind1))
    ```

    您应该得到以下输出:

    ```py
    27924
    ```

8.  Separate by the majority class as in the following code snippet:

    ```py
    majData = trainData.loc[ind1]
    print(majData.shape)
    majData.head()
    ```

    您应该得到以下输出:

    ![Figure 13.10: Output after separating the majority classes
    ](img/B15019_13_10.jpg)

    图 13.10:分离多数类后的输出

    一旦多数类被分开，我们就可以从多数类中取样。采样完成后，将打印多数类数据集的形状及其头部。

    取一个等于少数类长度的随机样本，使数据集平衡。

9.  Extract the samples using the `.sample()` function:

    ```py
    majSample = majData.sample(n=len(ind),random_state = 123)
    ```

    被抽样的样本数等于少数类中的样本数。这是通过参数`(n=len(ind))`实现的。

10.  Now that sampling is done, the shape of the majority class dataset and its head is printed:

    ```py
    print(majSample.shape)
    majSample.head()
    ```

    您应该得到以下输出:

    ![Figure 13.11: Output showing the shape of the majority class dataset
    ](img/B15019_13_11.jpg)

    图 13.11:显示多数类数据集形状的输出

    现在，我们开始准备新的训练数据

11.  After preparing the individual dataset, we can now concatenate them together using the `pd.concat()` function:

    ```py
    # Concatenating both data sets and then shuffling the data set
    balData = pd.concat([minData,majSample],axis = 0)
    ```

    注意

    在这种情况下，我们在垂直方向上进行连接，因此使用了`axis = 0`。

12.  Now, shuffle the dataset so that both the minority and majority classes are evenly distributed using the `shuffle()` function:

    ```py
    # Shuffling the data set
    from sklearn.utils import shuffle
    balData = shuffle(balData)
    balData.head()
    ```

    您应该得到以下输出:

    ![Figure 13.12: Output after shuffling the dataset
    ](img/B15019_13_12.jpg)

    图 13.12:混洗数据集后的输出

13.  Now, separate the shuffled dataset into the independent variables, `X_trainNew`, and dependent variables, `y_trainNew`. The separation is to be done using the index features `0` to `51` for the dependent variables using the `.iloc()` function in `pandas`. The dependent variables are separated by sub-setting with the column name `'y'`:

    ```py
    # Making the new X_train and y_train
    X_trainNew = balData.iloc[:,0:51]
    print(X_trainNew.head())
    y_trainNew = balData['y']
    print(y_trainNew.head())
    ```

    您应该得到以下输出:

    ![Figure 13.13: Shuffling the dataset into independent variables
    ](img/B15019_13_13.jpg)

    图 13.13:将数据集放入独立变量中

    现在，根据新数据拟合模型，并为我们的分析生成混淆矩阵和分类报告。

14.  首先，用下面的代码片段定义`LogisticRegression`函数:

    ```py
    from sklearn.linear_model import LogisticRegression
    bankModel1 = LogisticRegression()
    bankModel1.fit(X_trainNew, y_trainNew)
    ```

15.  Next, perform the prediction on the test with the following code snippet:

    ```py
    pred = bankModel1.predict(X_test)
    print('Accuracy of Logistic regression model prediction on test set for balanced data set: {:.2f}'.format(bankModel1.score(X_test, y_test)))
    ```

    `{:.2f}'.format`用于打印字符串值以及从`bankModel1.score(X_test, y_test)`输出的准确度分数。在这里，`2f`是指有两位小数的数字分数。

16.  Now, generate the confusion matrix for the model and print the results:

    ```py
    from sklearn.metrics import confusion_matrix
    confusionMatrix = confusion_matrix(y_test, pred)
    print(confusionMatrix)
    from sklearn.metrics import classification_report
    print(classification_report(y_test, pred))
    ```

    您应该得到以下输出:

    ![Figure 13.14: Confusion matrix for the model obtained
    ](img/B15019_13_14.jpg)

图 13.14:获得的模型的混淆矩阵

注意

由于建模过程会发生变化，因此输出中的值可能会有所不同。

## 分析

让我们分析结果，并将其与我们在本章开始时构建的基准逻辑回归模型进行比较。在基准模型中，我们的问题是模型偏向于大多数类，对于`yes`案例，召回值非常低。

现在，通过平衡数据集，我们已经看到少数民族的召回率有了巨大的提高，从低的`0.32`到大约`0.82`。这意味着通过平衡数据集，分类器提高了其识别阴性病例的能力。

然而，我们可以看到我们的整体准确性受到了影响。从 90%左右的高位，已经下降到 85%左右。准确性受到打击的一个主要方面是假阳性的数量，即那些被错误预测为`Yes`的`No`病例。

从业务角度分析结果，这是一个比我们在基准模型中得到的场景好得多的场景。在基准模型中，在总共 1，566 个`Yes`案例中，只有 506 个被正确识别。然而，在平衡之后，我们能够从数据集中的 1，566 名客户中识别出 1，277 名可能购买定期存款的客户，这可能会带来更好的转换率。然而，另一方面，销售团队也将不得不在不太可能购买定期存款的客户身上花费大量时间。从混淆矩阵中，我们可以看到，在基准模型中，假阴性从早期的 291 个增加到了 1，795 个。理想情况下，我们希望象限 2 和象限 3 下降，以有利于其他两个象限。

# 生成合成样本

在上一节中，我们研究了欠采样方法，在这种方法中，我们缩小了多数类以使数据集平衡。然而，在欠采样时，我们减小了数据集的大小。在许多情况下，缩小数据集会对分类器的预测能力产生不利影响。应对数据集缩减的有效方法是对少数类进行过采样。过采样是通过生成与少数类相似的新合成数据点来实现的，从而平衡数据集。

生成这种合成点的两种非常流行的方法是:

*   合成少数过采样技术(SMOTE)
*   改进的 SMOTE

`SMOTE`算法生成合成数据的方式是查看少数类的邻域并在邻域内生成新的数据点:

![Figure 13.15: Dataset with two classes
](img/B15019_13_15.jpg)

图 13.15:包含两个类的数据集

让我们解释一下用图形表示生成合成数据集的概念。让我们假设*图 13.15* 表示一个有两个类的数据集:灰色圆圈表示少数类，黑色圆圈表示多数类。

在创建合成点时，会创建一条连接邻域中所有少数样本的假想线，并在这条线上生成新的数据点，如图*图 13.16* 所示，从而平衡数据集:

![  Figure 13.16: Connecting samples in a neighborhood
](img/B15019_13_16.jpg)

图 13.16:连接邻域中的样本

然而，`MSMOTE`是对`SMOTE`算法的一个改进，它采用了不同的方法来生成合成点。`MSMOTE`将少数类分为三个不同的组:**安全样本**、**边界样本**和**潜在噪声样本**。基于每个少数类所属的组，采用不同的策略来生成邻域点。

我们将在下一节看到`SMOTE`和`MSMOTE`的实现。

## SMOTE 和 MSMOTE 的实现

`SMOTE`和`MSMOTE`可以从 Python 中一个名为`smote-variants`的包中实现。该库可以通过 Colab 笔记本中的`pip install`进行安装，如下所示:

```py
!pip install smote-variants
```

注意

更多关于该套件及其不同变体的细节可以在[https://packt.live/2QsNhat](https://packt.live/2QsNhat)获得。

现在让我们实现这两种方法并分析结果。

## 练习 13.03:在我们的银行数据集上实施 SMOTE 以找到最佳结果

在本练习中，我们将使用`SMOTE`生成少数类的合成样本，然后使数据集平衡。然后，在新的平衡数据集上，我们将拟合逻辑回归模型并分析结果:

1.  实施*练习 13.01* 、*的所有步骤，对数据集*上的逻辑回归模型进行基准测试，直到分离训练集和测试集。
2.  Now, print the count of both the classes before we oversample:

    ```py
    # Shape before oversampling
    print("Before OverSampling count of yes: {}".format(sum(y_train=='yes')))
    print("Before OverSampling count of no: {} \n".format(sum(y_train=='no')))
    ```

    您应该得到以下输出:

    ```py
    Before OverSampling count of yes: 3694
    Before OverSampling count of no: 27953
    ```

    注意

    由于采样过程的可变性，此输出中提到的计数可能会有所不同。

    接下来，我们将使用`SMOTE`对训练集进行过采样。

3.  Begin by importing `sv` and `numpy`:

    ```py
    import smote_variants as sv
    import numpy as np
    ```

    对训练集进行过采样所需的库文件包括我们之前安装的`smote_variants`库。这个导入为`sv`。所需的另一个库是`numpy`，因为训练集必须为`smote_variants`库提供一个`numpy`数组。

4.  Now, instantiate the `SMOTE` library to a variable called `oversampler` using the `sv.SMOTE()` function:

    ```py
    # Instantiating the SMOTE class
    oversampler= sv.SMOTE()
    ```

    这是实例化来自`smote_variants`库的`SMOTE`的任何变体的常见方式。

5.  Now, sample the process using the `.sample()` function of `oversampler`:

    ```py
    # Creating new training set
    X_train_os, y_train_os = oversampler.sample(np.array(X_train), np.array(y_train))
    ```

    注意

    在应用`.sample()`函数之前，`X`和`y`变量都被转换成`numpy`数组。

6.  Now, print the shapes of the new `X` and `y` variables and the `counts` of the classes. You will note that the size of the overall dataset has increased from the earlier count of around 31,647 (3694 + 27953) to 55,906\. The increase in size can be attributed to the fact that the minority class has been oversampled from 3,694 to 27,953:

    ```py
    # Shape after oversampling
    print('After OverSampling, the shape of train_X: {}'.format(X_train_os.shape))
    print('After OverSampling, the shape of train_y: {} \n'.format(y_train_os.shape))
    print("After OverSampling, counts of label 'Yes': {}".format(sum(y_train_os=='yes')))
    print("After OverSampling, counts of label 'no': {}".format(sum(y_train_os=='no')))
    ```

    您应该得到以下输出:

    ```py
    After OverSampling, the shape of train_X: (55906, 51)
    After OverSampling, the shape of train_y: (55906,) 
    After OverSampling, counts of label 'Yes': 27953
    After OverSampling, counts of label 'no': 27953
    ```

    注意

    由于采样过程的可变性，此输出中提到的计数可能会有所不同。

    现在我们已经使用`SMOTE`生成了合成点并平衡了数据集，让我们在新样本上拟合一个逻辑回归模型，并使用混淆矩阵和分类报告分析结果。

7.  定义`LogisticRegression`功能:

    ```py
    # Training the model with Logistic regression model
    from sklearn.linear_model import LogisticRegression
    bankModel2 = LogisticRegression()
    bankModel2.fit(X_train_os, y_train_os)
    ```

8.  现在，在测试集上使用`.predict`进行预测，如下面的代码片段所示:

    ```py
    pred = bankModel2.predict(X_test)
    ```

9.  接下来，`print`精度值:

    ```py
    print('Accuracy of Logistic regression model prediction on test set for Smote balanced data set: {:.2f}'.format(bankModel2.score(X_test, y_test)))
    ```

10.  然后，为模型

    ```py
    from sklearn.metrics import confusion_matrix
    confusionMatrix = confusion_matrix(y_test, pred)
    print(confusionMatrix)
    ```

    生成`ConfusionMatrix`
11.  Generate `Classification_report` for the model:

    ```py
    from sklearn.metrics import classification_report
    print(classification_report(y_test, pred))
    ```

    您应该得到以下输出:

![Figure 13.17: Classification report for the model
](img/B15019_13_17.jpg)

图 13.17:模型的分类报告

从生成的指标中，我们可以看到结果与欠采样结果非常相似，只是`'Yes'`案例的召回值从`0.82`减少到了大约`0.81`。生成的结果因用例而异。`SMOTE`及其变体已被证明在平衡数据方面具有稳健的结果，因此是当遇到具有高度不平衡数据的用例时最常用的方法。

在下一个练习中，我们将实现`MSMOTE`。

## 练习 13.04:在我们的银行数据集上实施 MSMOTE 以找到最佳结果

在本练习中，我们将使用`MSMOTE`生成少数类的合成样本，然后使数据集平衡。然后，在新的平衡数据集上，我们将拟合逻辑回归模型并分析结果。这个练习与上一个非常相似。

1.  实施*练习 13.01* 、*的所有步骤，对数据集*上的逻辑回归模型进行基准测试，直到分离训练集和测试集。
2.  Now, print the count of both the classes before we oversample:

    ```py
    # Shape before oversampling
    print("Before OverSampling count of yes: {}".format(sum(y_train=='yes')))
    print("Before OverSampling count of no: {} \n".format(sum(y_train=='no')))
    ```

    您应该得到以下输出:

    ```py
    Before OverSampling count of yes: 3723
    Before OverSampling count of no: 27924
    ```

    注意

    由于采样过程的可变性，此输出中提到的计数可能会有所不同。

    接下来，我们将使用`MSMOTE`对训练集进行过采样。

3.  Begin by importing the `sv` and `numpy`:

    ```py
    import smote_variants as sv
    import numpy as np
    ```

    对训练集进行过采样所需的库文件包括我们之前安装的`smote_variants`库。这个导入为`sv`。所需的另一个库是`numpy`，因为训练集必须为`smote_variants`库提供一个`numpy`数组。

4.  现在，使用`sv.MSMOTE()`函数:

    ```py
    # Instantiating the MSMOTE class
    oversampler= sv.MSMOTE()
    ```

    将`MSMOTE`库实例化为一个名为`oversampler`的变量
5.  Now, sample the process using the `.sample()` function of `oversampler`:

    ```py
    # Creating new training set
    X_train_os, y_train_os = oversampler.sample(np.array(X_train), np.array(y_train))
    ```

    注意

    在应用`.sample()`函数之前，`X`和`y`变量都被转换成`numpy`数组。

    现在，打印新的`X`和`y`变量的形状以及类的`counts`:

    ```py
    # Shape after oversampling
    print('After OverSampling, the shape of train_X: {}'.format(X_train_os.shape))
    print('After OverSampling, the shape of train_y: {} \n'.format(y_train_os.shape))
    print("After OverSampling, counts of label 'Yes': {}".format(sum(y_train_os=='yes')))
    print("After OverSampling, counts of label 'no': {}".format(sum(y_train_os=='no')))
    ```

    您应该得到以下输出:

    ```py
    After OverSampling, the shape of train_X: (55848, 51)
    After OverSampling, the shape of train_y: (55848,) 
    After OverSampling, counts of label 'Yes': 27924
    After OverSampling, counts of label 'no': 27924
    ```

    现在我们已经使用`MSMOTE`生成了合成点并平衡了数据集，让我们在新样本上拟合一个逻辑回归模型，并使用混淆矩阵和分类报告分析结果。

6.  定义`LogisticRegression`功能:

    ```py
    # Training the model with Logistic regression model
    from sklearn.linear_model import LogisticRegression
    # Defining the LogisticRegression function
    bankModel3 = LogisticRegression()
    bankModel3.fit(X_train_os, y_train_os)
    ```

7.  现在，在测试集上使用`.predict`进行预测，如下面的代码片段所示:

    ```py
    pred = bankModel3.predict(X_test)
    ```

8.  接下来，`print`精度值:

    ```py
    print ('Accuracy of Logistic regression model prediction on test set for MSMOTE balanced data set: {:.2f}'.format(bankModel3.score(X_test, y_test)))
    ```

9.  为模型

    ```py
    from sklearn.metrics import confusion_matrix
    confusionMatrix = confusion_matrix(y_test, pred)
    print(confusionMatrix)
    ```

    生成`ConfusionMatrix`
10.  Generate the `Classification_report` for the model:

    ```py
    from sklearn.metrics import classification_report
    print(classification_report(y_test, pred))
    ```

    您应该得到以下输出:

    ![Figure 13.18: Classification report for the model
    ](img/B15019_13_18.jpg)

图 13.18:模型的分类报告

从`MSMOTE`的实现可以看出，与*练习 13.03* 、*中的`SMOTE`实现相比，指标有所下降，在我们的银行数据集上实现 SMOTE 以找到最优结果*。然后我们可以得出结论，`MSMOTE`可能不是这个用例的最佳方法。

## 在电信数据集上应用平衡技术

现在我们已经看到了不同的平衡技术，让我们将这些技术应用到一个与电信客户流失相关的新数据集。该数据集可通过以下链接获得:[https://packt.live/37IvqSX](https://packt.live/37IvqSX)。

该数据集包含与移动连接使用水平相关的各种变量，例如总通话时间、通话费用、一天中特定时段的通话次数、国际通话的详细信息以及客户服务通话的详细信息。

问题陈述是预测客户是否会流失。这个数据集是一个高度不平衡的数据集，客户流失的情况是少数。您将在以下活动中使用该数据集。

## 活动 13.01:通过在电信客户流失数据集中安装分类器，找到最佳平衡技术

您是一家电信公司的数据科学家。您遇到了一个高度不平衡的数据集，您希望在调整分类器以分析客户流失之前纠正类不平衡。您知道用于校正数据集中不平衡的不同方法，并且您希望在拟合模型之前比较它们以找到最佳方法。

在本活动中，您需要实施目前为止遇到的所有三种方法，并比较结果。

注意

您将使用您在*第 10 章*、*中使用的电信客户流失数据集来分析数据集*。

使用`MinMaxscaler`函数来缩放数据集，而不是您目前使用的强大的缩放函数。根据在数据集上拟合逻辑回归模型所获得的结果来比较这些方法。

步骤如下:

1.  实现所有的初始步骤，包括安装 smote 变体和使用 pandas 加载数据。
2.  使用我们在*第 3 章，二进制分类*中所学的`MinMaxScaler()`函数对数值原始数据进行归一化。
3.  使用`pd.get_dummies()`函数为分类变量创建虚拟数据。
4.  将数字数据从原始数据框中分离出来。
5.  使用`pd.concat()`函数连接数字数据和虚拟分类数据。
6.  Split the earlier dataset into train and test sets using the `train_test_split()` function.

    由于数据集是不平衡的，您需要执行以下步骤中提到的各种技术。

7.  对于欠采样方法，使用`.index()`函数找到少数类的索引，并分离少数类。之后，对多数类进行采样，并使用`.sample()`函数使多数数据集等于少数类。连接少数类和欠采样多数类以形成新数据集。打乱数据集，分离`X`和`Y`变量。
8.  对欠采样数据集拟合逻辑回归模型，并将其命名为`churnModel1`。
9.  对于`SMOTE`方法，使用`sv.SMOTE()`功能创建过采样器，并创建新的`X`和`Y`训练集。
10.  使用`SMOTE`拟合逻辑回归模型，并将其命名为`churnModel2`。
11.  导入`smote-variant`库，并使用`sv.MSMOTE()`函数实例化`MSMOTE`算法。
12.  使用过采样器创建过采样数据。请注意，`X`和`y`变量必须在过采样之前转换成一个`numpy`数组
13.  使用`MSMOTE`数据集拟合逻辑回归模型，并将模型命名为`churnModel3`。
14.  为每个模型生成三个独立的预测。
15.  为每个预测生成单独的准确性度量、分类报告和混淆矩阵。
16.  分析结果并选择最佳方法。

**预期产量**:

您可以预期的最终指标将与您在这里看到的类似。

**欠采样输出**

![Figure 13.19: Undersampling output report
](img/B15019_13_19.jpg)

图 13.19:欠采样输出报告

**SMOTE 输出**

![Figure 13.20: SMOTE output report
](img/B15019_13_20.jpg)

图 13.20: SMOTE 输出报告

**m 远程输出**

![Figure 13.21: MSMOTE output report
](img/B15019_13_21.jpg)

图 13.21: MSMOTE 输出报告

注意

由于建模在本质上是随机的，您将得到不同的输出。

活动的解决方案可以在这里找到:[https://packt.live/2GbJloz](https://packt.live/2GbJloz)。

# 总结

在本章中，我们学习了不平衡数据集和处理不平衡数据集的策略。我们介绍了会遇到不平衡数据集的用例。我们看了不平衡数据集带来的挑战，并了解了在不平衡数据集的情况下应该使用的指标。我们制定了处理不平衡数据集的策略，并实施了不同的策略，如随机欠采样和过采样，以平衡数据集。然后，在平衡数据集并分析结果后，我们拟合不同的模型。

平衡数据集是提高分类器性能的一种非常有效的方法。然而，应该注意的是，由于平衡，多数类的整体精度测量可能会降低。在什么情况下采用什么策略应该基于问题陈述，并且在对那些问题陈述进行严格的实验之后得出。

已经了解了处理不平衡数据集的方法，我们现在将介绍另一种在许多现代数据集中流行的重要技术，称为降维。不同的降维技术将在*第 14 章*、*降维*中阐述。