        

# 十九、使用 Chalice 的无服务器 API

在前一章中，我们创建了一个 REST API，通过管理我们自己的服务器和应用程序来为我们的预测模型提供服务。虽然这种方法是目前最流行的，但还有一种方法对于特定的任务也非常有用——使用无服务器应用程序。

在这一章中，我们将使用 Chalice Python 包构建一个 API，它类似于我们在[第 18 章](e1d8b121-e8db-45da-9dbf-a034664926fa.xhtml)、*中构建的 API，使用 RESTful API* 为模型提供服务，但是它将作为一个无服务器应用程序运行在云中。在此过程中，我们将讨论这种方法的所有利弊。

在本章中，我们将了解以下内容:

*   什么是无服务器应用程序
*   如何使用 Chalice 包构建一个简单的应用程序
*   如何减轻圣杯的局限性
*   调度无服务器进程
*   使用 Zappa 部署超极限应用程序

        

# 技术要求

本章的代码需要版本为 1.9.1 的`chalice`包。我们建议安装来自`conda-forge`的圣杯，并使用这个特定版本进行复制:`conda install -c conda-forge chalice=1.9.1`。

像往常一样，本章的代码位于 GitHub 存储库中的`Chapter19`文件夹下([https://GitHub . com/packt publishing/Learn-Python-by-Building-Data-Science-Applications](https://github.com/PacktPublishing/Learn-Python-by-Building-Data-Science-Applications))[。](https://github.com/PacktPublishing/Python-Programming-Projects-Learn-Python-3.7-by-building-applications/tree/master/Chapter18)

        

# 了解无服务器

“无服务器”这个词可能有些误导—无服务器应用程序仍然在服务器上运行。不过，主要的区别在于责任区。有了 serverless，我们不用租电脑，不用部署自己的 APIs 相反，我们将 Python(或 JavaScript，或 Go，或其他任何东西)功能，连同我们的需求，发送给一个提供者(可能是**亚马逊网络服务** ( **AWS** )，谷歌云平台，或其他什么)，当被触发时，他们在他们的服务器上执行这些功能。我们不需要考虑配置服务器、打开和关闭服务器或扩展服务器，我们触发的功能将在需要时以所需的规模工作(如果需要，提供商将在幕后添加计算机)。最精彩的部分？我们将只为执行的事实付费——如果一个函数没有被触发，我们将不付费。

因此，在以下情况下，无服务器应用程序是运行您自己的服务器的绝佳替代方案:

*   如果请求不频繁，否则您将不得不为一个几乎没有负载的服务器付费。AWS 等提供商提供了在特定事件下自动触发无服务器应用程序的解决方案，比如将新文件上传到 S3 存储桶。无服务器应用程序也可以作为 API 端点，在您请求时运行。
*   如果请求率很难预测或者很不稳定，那么就很难自己调整工作人员的数量。
*   如果问题中的函数本身比较简单快速。
*   如果你只需要几个简单的无状态端点(无服务器功能可以调用其他服务并服务它们的结果，比如为大型复杂的**机器学习** ( **ML** )模型服务前端)。

当然，无服务器也有自己的限制和注意事项:

*   代码需要以特定的方式进行预打包。
*   上传您的代码和资产(包括所有的依赖项，除了一些默认的依赖项)所需的内存上限是 50 MB。
*   冷启动的问题:如果一个端点在一定时间内没有被使用，虚拟服务器将被停止，并在下一次请求时恢复。这意味着停止后的最初几个请求可能需要更长时间来执行。如果这很重要，我们可以偶尔 ping 一下端点，这样服务器就不会停止，但这意味着一些额外的成本。

手动构建无服务器应用程序需要一些时间，并且可能是一个乏味的过程。所有的东西都应该被隔离和压缩，并且归档应该满足一定的标准。幸运的是，有一些 Python 包可以帮助将代码准备和部署为无服务器应用程序。

总而言之，无服务器应用程序是允许你专注于你的特定任务的代码的服务；运行代码、服务器配置、调度、伸缩等都由服务提供商负责。你只为执行的事实买单。应用程序的代码需要预先打包，并且需要满足一些要求。幸运的是，有一些框架可以帮助我们简化工作流程。

现在我们知道了什么是无服务器，在下一节中，我们将使用 Chalice 构建我们自己的无服务器应用程序。

        

# 圣杯入门

让我们试着把我们在前一章中为 311 做的 API 端点复制成一个无服务器的应用程序。为此，我们将使用一个名为 **Chalice** 的框架。

Chalice 是用于 AWS 上无服务器应用的 Python 包，它本身是由 Amazon 开发的。从模板到部署，It 可以照顾应用程序。它也非常适合测试，因为它模拟了免费部署、身份验证，甚至不需要互联网连接。

在我们开始开发无服务器应用程序之前，让我们让 Chalice 生成一个模板。在您的终端中，键入以下内容:

```
chalice new-project
```

在这之后，键入项目的名称:`311estimate`。这将生成一个包含几个文件的新文件夹:

```
311estimate/ ...
```

        

# 建立一个简单模型

类似于我们在[第 18 章](e1d8b121-e8db-45da-9dbf-a034664926fa.xhtml)、*中如何构建 REST API，用 RESTful API* 服务模型，让我们从服务 JSON 文件的中值开始。这将有助于我们树立使用圣杯的典范:

1.  首先，我们需要加载 JSON 对象:

```
import json

with open('./model.json', 'r') as f:
    model = json.load(f)
```

2.  现在，我们将重命名 route，并定义最后一个映射到 complaint 类型的资源(与我们为 FastAPI 所做的一样！).我们还必须导入一个`Response`对象:

```
from chalice import Response

@app.route('/predict/{complaint_type}', methods=['GET'])
def predict(complaint_type:str) -> Response:
```

3.  最后，通过添加简单的查找逻辑来最终确定函数；在这里，我们决定友好地让我们的用户知道他们是否传递了错误的投诉类型:

```
@app.route('/predict/{complaint_type}', methods=['GET'])
def predict(complaint_type:str) -> Response:

    if complaint_type in model:
        return Response(status_code=200,
                        headers={'Content-Type': 
                                 'application/json'},
                        body={'status': 'success',
                              'complaint_type': complaint_type,
                              'estimated_time': 
                                      model[complaint_type]})
    else:
        return Response(status_code=400,
                        headers={'Content-Type': 
                                 'application/json'},
                        body={'status': 'failure',
                              'problem': 'Complaint type is 
                                          not in database',
                              'complaint_type': complaint_type})
```

4.  然后，我们像以前一样在本地部署它:

```
$ chalice local
Serving on 127.0.0.1:8000
```

5.  现在，让我们从另一个终端尝试一下:

```
$ curl -X GET http://localhost:8000/predict/appliance
{"status":"success","complaint_type":"appliance","estimated_time":63.53}
```

6.  让我们看看如果我们要求错误的投诉类型会发生什么:

```
$ curl -X GET http://localhost:8000/predict/wrongtype
{"status":"failure","problem":"Complaint type is not in database","complaint_type":"wrongtype"}
```

如您所见，它将返回一个错误，带有我们传递的消息。现在让我们重构代码，这样数据将存储在 Python 脚本之外。

        

# 外化媒体

到目前为止，这是一个非常简单的脚本，但是您可能希望不断地更新 JSON 而不需要每次都重新部署这个函数。我们就这么做吧。我们将把 JSON 移动到某个公共桶(或者不是一个*公共*桶——只要确保使用有权限访问它的凭证)，并让一个函数在请求或部署时下载它。我们将使用内置的`urllib`包，而不是`requests`，因为我们不想在一个依赖包上花费我们 50 MB 的内存。删除本地 JSON 以保持代码简洁，并添加以下代码:

```
import json, urllib.requesturl = 'https://raw.githubusercontent.com/PacktPublishing/Python-Programming-Projects-Learn-Python-3.7-by-building-applications/master/Chapter18/data/model.json' ...
```

        

# 为 ML 模型构建无服务器 API

用 10 行代码获得对数据的公共访问是有用的。但是现在让我们做一些更复杂的事情——比方说，为一个实际的 ML 模型服务。

我们再创建一个 app— `311predictions`。和以前一样，我们需要调用`chalice new-project`并键入新项目的名称。

现在，对于前面的应用程序，我们不需要任何依赖关系；为了服务于我们在前一章中使用的 ML 模型，我们需要有`pandas`和`sklearn`。问题是这两者都不符合 50 MB 的限制。事实上，直到最近，还没有简单的方法来适应它们——正常的`pip install`需要下载所有的源代码并在机器上编译。幸运的是，现在可以安装一个预编译的版本，并且`chalice`将明确地寻找一个预编译的二进制文件，它是为我们将要运行的 Linux 机器生成的。

然而，我们必须决定如何减少我们的内存使用。在这种特殊情况下，没有多少选择。没有`sklearn`我们肯定不能为模型服务，所以我们必须去掉`pandas`。让我们将`sklearn`添加到需求中(注意它在`pip`中有不同的名称):

```
scikit-learn==0.21.2
```

现在让我们重新创建 API，只使用`sklearn`和 NumPy(反正它是`sklearn`的依赖项)。首先，让我们从 S3 加载我们的模型:

```
import boto3

BUCKET, KEY = 'philipp-packt', 'model.pkl'

def _load_pickle(bucket, key):
    S3 = boto3.client('s3', region_name='us-east-1')
    response = S3.get_object(Bucket=bucket, Key=key)

    body = response['Body'].read()
    return pickle.loads(body)

model = _load_pickle(BUCKET, KEY)
```

请注意，该模型将在每次部署时预加载，而不是针对每次请求。为了给请求本身节省更多的时间，让我们预定义一个 NumPy singleton 对象(一个单行矩阵，将由来自请求的数据填充:

```
singleton = np.empty(shape=(1, 4), dtype='object')
```

与 FastAPI 不同，它没有内置的解析机制，所以我们必须自己解析值。让我们为每个参数预定义一个解析机制，除了不需要解析的`complaint_type`:

```
dtypes = {
    'lon': float,
    'lat': float,
    'date': np.datetime64
}
```

现在我们可以开始编写端点本身了。在下面的代码中，我们使用了`app.current_request.query_params`字典，它存储了 URL 中的所有参数。对于请求的主体，有一个类似的字典。

另一个有用的命令是`app.log.debug`。如果 lambda 在调试模式下运行，这将把值溢出到日志中:

```
@app.route('/predict/{complaint_type}', methods=['GET'])
def index(complaint_type:str):
    try:
        app.log.debug(app.current_request.query_params)
        singleton[0, 0] = complaint_type

        for i, col in enumerate(dtypes.keys(), 1):
            singleton[0, i] = dtypes[col](app.current_request.query_params.get(col, np.nan))

        app.log.debug(singleton.astype(str).tolist())
```

最后，我们可以添加预测本身并定义响应——包括失败和成功案例。这部分看起来非常类似于 FastAPI 版本。下面是整个函数:

```
@app.route('/predict/{complaint_type}', methods=['GET'])
def index(complaint_type:str):
    try:
        app.log.debug(app.current_request.query_params)
        singleton[0, 0] = complaint_type

        for i, col in enumerate(dtypes.keys(), 1):
            singleton[0, i] = dtypes[col](app.current_request.query_params.get(col, np.nan))

        app.log.debug(singleton.astype(str).tolist())

        prediction = model.predict(singleton)[0]
        app.log.debug(prediction)

        return Response(status_code=200,
                        headers={'Content-Type': 'application/json'},
                        body={'status': 'success',
                              'estimated_time': prediction})
    except Exception as e:
        return Response(status_code=400,
                        headers={'Content-Type': 'application/json'},
                        body={'status': 'failure',
                              'error message': str(e)})
```

这是我们需要的所有代码。然而，如果您尝试运行它，它将抛出一个错误——仍然有两个问题需要我们解决。

首先，pickled 模型存储对象，但不存储它的依赖项(比如外部库)。更糟糕的是，相对于加载的 pickle，它期望找到它们在序列化时被导入的确切位置。例如，它期望`TimeTransformer`不仅可用，而且作为`ml`名称空间的一部分可用。理论上，我们可以破解名称空间，但是复制`ml.py`文件并导入对象似乎更容易。事实上，这是一个更好的选择——除了`chalice`不会从文件夹中推送任何 Python 文件，除了`app.py`。为了推送我们的`ml`文件，我们需要创建一个名为`vendor`的文件夹，然后创建另一个名为`ml`的文件夹，并将其作为一个包，将代码移动到那里。由于我们需要匹配精确的`ml.TimeTransformer`，我们将创建一个`__init__.py`文件——事实上，为了简单起见，我们可以将`ml.py`移动到那里并重命名。

第二个问题是在`TimeTransformer`内部:它使用了`pandas`，我们不能发货——它太大了。我们怎样才能让`pandas`脱离依赖关系？

您可能还记得，这个对象将任何给定的日期数组转换为由三个数字特征组成的数组:一天中的时间、一年中的日期和一周中的日期。问题的第一部分是如何用 NumPy 执行那个逻辑。幸运的是，每一个`DateTime`物体都是自 UTC 时间 1970 年 1 月 1 日午夜以来的大整数秒。因此，所有这些操作都可以看作是减法、除法和得到提醒的组合。我们可以使用将`DateTime`值转换成不同单位的方法。考虑以下代码:

```
def day_of_week_num(dts):
    return (dts.astype('datetime64[D]').view('int64') - 4) % 7

def day_of_year_num(dts):
    return (dts.astype('datetime64[D]').view('int64') - dts.astype('datetime64[Y]').astype('datetime64[D]').view('int64'))

def time_of_day_num(dts):
    return dts.astype('datetime64[s]').view('int64') - dts.astype('datetime64[D]').astype('datetime64[s]').view('int64')
```

类似于`pandas`的实现，这三个函数都将以数字的形式返回相应的值。

太好了！但是`TimeTransformer`对象仍然依赖于`pandas`。一个解决方案是完全去掉它——在应用程序和模型训练中只使用前面的函数；毕竟，那些操作是独立于训练集的。这个解决方案完全没问题。

或者，您可能会注意到`TimeTransformer`需要`pandas`来找到`DateTime`列并对它们进行操作。这意味着我们可以像存储列名一样存储列的索引，然后在得到 NumPy 数组而不是 DataFrame 时使用它们。事实上，这是完全可行的(完整代码请参见资源库)。最精彩的部分？我们甚至不需要再次重新训练我们的模型——虽然我们的管道使用了幕后的`TimeTransform`对象，但它不要求它与用于训练的对象相同，只要它具有相同的名称和相似的行为。

终于，我们的 ML 模型可以上菜了！让我们使用如下 URL 部署模型并进行现场测试:

```
<deployment_url>/predict/commercial?lat=40.636626&lon=-73.951694&date=2019-06-08 00:00:09
```

我们得到了暂停。看来推理需要更多的运算记忆。我们可以通过 AWS web 控制台改变这一点(也有很多其他选项，比如使用环境变量)，或者我们可以为`lambda_memory_size`添加一个对应的`config`到`.chalice/config.json`:

```
# .chalice/config.json

{
  "version": "2.0",
  "app_name": "311predictions-v2",
  "stages": {
    "dev": {
      "api_gateway_stage": "api", 
      "lambda_memory_size": 520
    },
  ""
  }
}
```

再重新部署一次。现在成功了！看这里:

```
$ <deployment_url>/predict/commercial?lat=40.636626&lon=-73.951694&date=2019-06-08 00:00:09
{
 "status": "success",
 "estimated_time": 1.36
}
```

        

# 当我们仍然没有记忆的时候

我们能够将大小缩小到刚好低于内存限制。然而，这样做并不总是可能或可取的。如果我们的依赖关系很复杂，我们的文件很大，我们还有两个选择:

*   首先，lambda 可以只是一个入口点——它可以调用 Docker 映像(一个运行在云中其他地方的隔离虚拟环境),在那里传递参数，并将结果传递回来。
*   或者——这有点麻烦——我们可以像下载模型一样下载所有的依赖项:在运行时。一旦服务器关闭，这些数据将会丢失，如果没有任何东西触发无服务器功能，就会发生这种情况。重新部署可能需要大量时间...

        

# 将无服务器功能构建为数据管道

到目前为止，我们只使用了无服务器函数作为 API 端点，但是它们也可以以许多其他方式提供服务。例如，它们可以被触发来为上传到 S3 上特定文件夹的每个新文件运行，或者被安排在特定时间运行。

让我们再创建一个数据收集应用程序。我们可以在`requirements.txt`中指定我们需要`requests`库。我们也可以从 [第 15 章](eb2254cc-485d-4603-9d17-7a442aa5e3b8.xhtml)、*用 Poetry 和 PyTest* 打包测试中复制粘贴`_get_data`函数，以及资源和时间列。我们仍然缺少的一部分代码是上传数据到 S3。代码如下:

```
def _upload_json(obj, filename, bucket, key):
    S3 = boto3.client('s3', region_name='us-east-1')
    key += ('/' + filename)

    S3.Object(Bucket=bucket, Key=key).put(Body=json.dumps(obj))
```

有了所有必要的部分，让我们把它们作为一个功能放在一起。代码如下:

```
from datetime import date, timedelta

def get_data(event):
    yesterday = date.today() - timedelta(days=1)

    data = _get_data(resource, time_col, yesterday, offset=0)
    _upload_json(data, f'{yesterday:%Y-%m-%d}.json', bucket=BUCKET, key=KEY)
```

最后，我们现在需要做的就是添加一个`chalice`装饰器`@app.schedule('rate(1 day)')`。这里，我们不使用`app.route`装饰器，而是使用`app.schedule`并定义相应的频率。下面是它的整体外观:

```
import json
from datetime import date, timedelta
BUCKET, FOLDER = 'philipp-packt', '311/raw_data'
resource = 'fhrw-4uyv'
time_col = 'Created Date'
app = Chalice(app_name='collect-311')

def _upload_json(obj, filename, bucket, key):
    S3 = boto3.client('s3', region_name='us-east-1')
    key += ('/' + filename)

    S3.Object(Bucket=bucket, Key=key).put(Body=json.dumps(obj))

def _get_data(resource, time_col, date, offset=0):
    '''collect data from NYC open data
    '''

    Q = f"where=created_date between '{date:%Y-%m-%d}' AND '{date:%Y-%m-%d}T23:59:59.000'"
    url = f'https://data.cityofnewyork.us/resource/{resource}.json?$limit=50000&$offset={offset}&${Q}'
    r = rq.get(url)
    r.raise_for_status()

    data = r.json()
    if len(data) == 50_000:
        offset2 = offset + 50000
        data2 = _get_data(resource, time_col, date, offset=offset2)
        data.extend(data2)

    return data

@app.schedule('rate(1 day)')
def get_data(event):
    yesterday = date.today() - timedelta(days=1)
    data = _get_data(resource, time_col, yesterday, offset=0)
    _upload_json(data, f'{yesterday:%Y-%m-%d}.json', bucket=BUCKET, key=FOLDER)
```

一旦部署，这个函数将每天运行，收集前一天的数据，并将其作为 JSON 存储在我们的 S3 桶中。但是我们能更进一步，为我们的预测模型自动准备中位数吗？让我们在下一节中找出答案。

        

# S3 引发的事件

到目前为止，我们已经编写了一个 lambda 函数，它是由 API 请求驱动的，或者是计划触发的。现在，让我们通过添加一个 S3 触发的任务来完成我们的应用程序的数据周期，该任务将在每次收集新数据集时计算每个类别的中位数，换句话说，就是在计划的任务完成后。

为了做到这一点，我们将向我们一直在处理的同一个数据收集应用程序中再添加一个操作:

1.  首先，让我们重新定义中位数计算。原始代码也使用了`pandas`，所以我们有两个选择:使用 NumPy，就像我们刚才对 ML 部分所做的那样，或者使用 vanilla Python。因为我们的原始数据收集不需要 NumPy，所以让我们坚持第二个选项。下面是的不依赖代码...

        

# 摘要

在这一章中，我们向您介绍了无服务器函数——一种不同的 API 和计算方法。无服务器功能不需要维护，自动伸缩，安全，易于编写。对于不需要大量请求的操作，或者当需求出现不可预测的高峰时，它们可能是一个很好的选择。除了充当 API 之外，lambdas 还可以通过一行代码进行调度，或者由外部事件触发，比如新文件到达 S3 桶。无服务器应用程序的缺点是它们有严格的内存限制，这对于某些任务可能是一个严重的障碍。在长时间中断后，响应时间也可能首次变长——但在某种程度上有办法解决这个问题。

作为练习，我们能够将我们的 311 API 端点重新创建为无服务器应用程序。此外，我们还编写了另外两个函数，用于计划的数据收集和中位数的计算。换句话说，我们使用 lambdas 重新创建了我们在[第 17 章](a0274de8-bfb3-43a0-82f2-b3a67c088ffc.xhtml)、*让我们建立一个仪表板*和[第 18 章](e1d8b121-e8db-45da-9dbf-a034664926fa.xhtml)、*中用 RESTful API* 服务模型的功能，所有这些都是通过无服务器应用程序实现的。

在下一章，我们将学习使用 Python 的一些最佳实践，使用 Python 的一些问题，以及 Python 的性能。

        

# 问题

1.  无服务器应用程序意味着什么？
2.  无服务器方法的局限性是什么？
3.  无服务器 API 有什么好处？
4.  Chalice 在无服务器应用程序的开发中扮演什么角色？

        

# 进一步阅读

*Mohit Gupta 著《带 AWS 的无服务器架构*，Packt Publishing 出版([https://www . packtpub . com/networking-and-servers/server less-Architectures-AWS](https://www.packtpub.com/networking-and-servers/serverless-architectures-aws))。