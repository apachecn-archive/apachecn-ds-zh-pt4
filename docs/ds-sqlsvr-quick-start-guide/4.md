<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 数据概述

在前三章介绍了所有三种语言之后，是时候做一些严肃的工作了。在做一些高级分析之前，你需要了解你的数据。在这个阶段，你通常要做一些初步的统计分析和一些数据可视化。

在本章中，您将学习以下主题:

*   数据科学项目的生命周期
*   测量数据值的方法
*   用描述性统计和可视化分析连续变量
*   用频率表和图表分析离散变量
*   获得变量对之间关联的基本概念

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 熟悉数据科学项目的生命周期

一个长期的数据科学项目不知何故永远不会完成。它有自己完整的生命周期。这种良性循环包括以下步骤:

1.  识别业务问题
2.  使用数据挖掘和机器学习技术将数据转化为可操作的信息
3.  根据信息采取行动
4.  衡量结果

数据科学不是产品。数据科学为您提供了一个不断学习如何改进业务的平台。为了学习如何最大限度地利用数据挖掘，您需要根据通过数据挖掘提取的信息来衡量您的行动结果。测量为持续改进结果提供反馈。您可以在下图中看到生命周期:

![](Images/a8869cdd-bf14-4afc-b2d8-2628308d46c0.png)

图 4.1:数据科学项目生命周期

我给你举个例子。对于信用卡发行商和网上银行来说，欺诈检测是一项相当常见的任务。您希望尽快识别欺诈交易，以最大限度地减少损失。你意识到你的系统中有一些欺诈。您发现了一个问题，因此这是**识别**部分。然后，您使用现有数据并在其上实现数据科学算法来获得模型。这是**改造**的部分。然后，您使用该模型执行在线预测，并在可能的欺诈交易出现在您的系统中时立即将其转移进行检查。这是《T4》第五幕的一部分。现在，你需要结束这个循环。您意识到欺诈者会学习，欺诈模式会随着时间的推移而改变。因此，您在生产中部署的模型可能会过时。您需要度量预测随时间的质量:执行生命周期的**度量**部分。当质量下降的时候，就是你完善模型的时候了。这意味着你刚刚发现了一个问题。

当然，并不是每个项目都像欺诈检测这样复杂。对于一个简单的一次性营销活动，你不用测量部分来结束这个循环；一旦在生产中使用了模型，项目就可以关闭了。

生命周期的第二步是将数据转化为可操作的知识，这一步是您做最复杂工作的部分。这是本书关注的部分。这一部分进一步划分为可以循环执行的步骤。数据挖掘 ( **CRISP** )模型的**跨行业标准流程是**转换**部分的非正式标准化流程。它将流程分为六个阶段。阶段的顺序并不严格。总是需要在不同阶段之间来回移动。每个阶段的结果决定了必须执行的下一个阶段(或某个阶段的特定任务)。箭头表示阶段之间最重要和最常见的依赖关系。下图描述了 CRISP 模型:**

![](Images/a9e98f63-e88d-498c-b874-651858412e7c.png)

图 4.2:清晰模型

六个清晰的阶段应该以一些可交付成果结束。典型可交付成果的阶段包括:

*   **业务理解**:数据挖掘问题定义
*   **数据理解**:数据质量报告、描述性统计、数据的图形化展示等等
*   **数据准备**:清理训练和评估数据集，包括派生变量
*   **建模**:不同的模型使用不同的算法和不同的参数
*   **评估**:决定是否使用一个模型以及使用哪个模型
*   **部署**:最终用户报告、OLAP 立方体结构、OLTP 软约束等等

你可以在[https://en . Wikipedia . org/wiki/Cross-industry _ standard _ process _ for _ data _ mining](https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining)了解更多关于这种模式的信息。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 测量数据值的方法

我已经介绍了统计学术语，它也用于数据科学:您使用**变量**分析**案例**。在 RDBMS 数据库中，事例表示为表中的一行，变量表示为同一表中的一列。在 Python 和 R 中，您分析数据框，它类似于表，只是具有位置访问。

你需要决定的第一件事是你想要分析的案例是什么。有时候，准确定义你的情况并不容易。例如，如果您正在执行信用风险分析，您可能会将一个家庭定义为一个案例，而不是一个客户。

下一件你必须理解的事情是数据值是如何在你的数据集中被测量的。典型的数据科学团队应该包括一名能够解释变量值含义的主题专家。有几种不同类型的变量:

*   **连续**变量有一个无限的取值范围。还有几种不同类型的连续变量:
    *   **真数值**对下限和上限都没有限制。它们支持所有的算术运算。
    *   在商业中，你经常会得到一些有限制的连续变量，至少在天平的一边。比如年龄不能到零下。有限连续变量为**区间**。它们只能有一个或两个边界；他们有订单；他们允许一些算术。例如，想想温度。减法有意义，而求和，很多时候没有意义。
    *   单调增加的连续变量，有界或无界，都是**单调**变量。即使这样一个变量只是作为一个键来使用，在您的分析中使用它可能还是很有趣的。例如，不断增长的标识号可以告诉您案件进入系统的时间:较低的标识号通常比较高的标识号更老。请注意，这取决于源系统。因此，在做出任何结论之前，确实有必要联系一位主题专家。
*   **离散**变量的可能值有限:
    *   离散变量的值只能是标签，没有自然顺序。那些是**绝对的**或**名义的**。例如，你可以用几个不同的值来表示你的情绪:高兴、悲伤、生气等等。
    *   如果一个离散变量的值有自然顺序，那么这就是一个**序数**变量，或者一个**等级**。尽管顺序很清楚，但您不能对这些值使用任何算术运算。序数的典型例子包括各种产品评估、教育和**装箱的**(分组的、**离散的**)真数值。
    *   一些分类变量非常具体。如果它们只能取一个可能的值，那么它们就是**常数**。常量对于分析来说并不有趣，因为您总是可以在没有分析的情况下预测变量值。如果它们可以取两个不同的值，那么我们称它们为**二分变量**。如果这两个值分别是 0 和 1，那么也叫**二进制**变量；如果值是逻辑值 true 和 false，那么它们有时被称为**布尔**变量。很多时候，我们希望预测一个布尔变量，例如一个案例的判决——是或否。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 介绍连续变量的描述性统计

连续变量可以取一个区间或所有实数中的任何值；这里对不同值的数量没有限制。当然，你可以尝试将一个连续变量离散化，然后将其视为一个离散变量。我将在下一章讨论不同的离散化选项。在本节中，我将介绍一些描述连续变量分布的统计度量，这些度量被称为**描述性统计**。

你想了解一个连续变量的分布。您可以为所有连续变量创建图表。但是，目测对比几十张甚至几百张图并不能告诉你太多。你也可以用描述性统计数字来描述这种分布。比较数字比比较图形要快得多，也容易得多。你用的是 a 的**时刻**。

众所周知的是分布的**中心**、**价差**、**偏斜度**和**尾部**(我将在本节稍后定义这些表达式)。您将了解以下内容:

*   分配中心的各种度量
*   分布的扩散
*   人口增长时刻

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 计算分布的中心

我们都习惯在日常用语中使用*平均*这个术语。例如，在体育运动中，你可以听到某个特定球队的球员年龄一般。平均值以某种方式描述了你所说的情况。例如，某个群体的平均收入高于其他群体可能意味着他们更富有。然而，你很快就会知道，平均值本身不足以给你一个群体的正确估计。在提到的群体中，仅仅一个非常非常富有的人就可以将平均收入向右移动很远，达到更高的值，尽管该群体中的所有其他人可能都非常贫穷。

因此，我们需要衡量的不仅仅是平均值。要测量您正在分析的案例的中心，以下是两种最常用的测量方法:

*   **中值**是当您按要计算中值的变量对案例进行排序时，在样本分布中间得到的值。中间线把箱子分成两半:上面的和下面的。对于奇数行，中值是中间行的值。如果你的数据集中有偶数行，那么中位数通常计算为中间两行的平均值(财务中位数)；您也可以使用中间的两个值中较小的一个(较低的统计中值)，或较大的一个(较高的统计中值)。对于偶数行，我会计算财务中值，就叫中值。例如，在集合 1，1，3，4，4 中，中位数是 3，在集合 1，2，3，4，5，6 中，中位数是 3.5。
*   **算术平均值**就是著名的平均值。这是值的总和除以案例数。数列 1，1，3，4，4 的算术平均值是 2.6。从现在开始，我将只使用术语“平均值”来表示算术平均值。

为了更好地理解数据，您需要计算分布的多个中心。通过比较中位数和平均数，你已经可以对分布有一个基本的概念。如果分布是对称的，那么中位数和均值就很接近，甚至重合。如果不是，这种分布在某种程度上是偏斜的。

如果一个分布向右或向左有一个长尾巴，那么它就是偏斜的。例如，收入分布可能在右侧有一条长尾，也可能向右倾斜，只有少数非常富有的人。但是，收入更低的人要多得多。在这种情况下，中值将低于平均值，因为分布大小左侧的情况比右侧多，而几个非常高的值将显著提高平均值。如果平均值低于中位数，那么你可以得出结论，你的分布是偏左的。

众所周知，平均值的定义是所有值的总和除以病例数。我来介绍一下正式公式:

![](Images/9af2c833-20ba-4315-abdf-abc6806227f4.png)

在 R 和 Python 中，获得基本的描述性统计数据甚至更简单。在 R 中，我使用了`summary()`函数来快速概述`Age`变量:

```
summary(Age)
```

在下面的结果中，您可以看到该函数返回了最小值和最大值，第一个和第三个四分位数的值，以及中值和平均值。我稍后将解释除平均值和中值之外的其他值:

```
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
  17.00   24.00   31.00   33.66   41.00   87.00
```

请注意，`AdventureWorksDW2017`中的数据有些陈旧，您可能会得到不同的结果。我使用下面的代码使我的数据库中的客户年轻了`15`岁:

`USE AdventureWorksDW2017;

UPDATE dbo.DimCustomer
 SET BirthDate = DATEADD(year, 15, BirthDate);`

在 Python 中，熊猫包中也有类似的`describe()`函数。代码如下:

```
TM.Age.describe()
```

此函数返回事例的计数、平均值、标准偏差、最小值和最大值、第一个和第三个四分位数的值，以及作为 50%人口的值的中值:

```
count    18484.000000
mean        33.662357
std         11.517815
min         17.000000
25%         24.000000
50%         31.000000
75%         41.000000
max         87.000000
```

您可以使用更具体的函数来计算单个值。这是 Python 中计算平均值和中值的代码:

```
TM.Age.mean()
TM.Age.median()
```

Python 代码的 R 对应物如下所示:

```
mean(Age)
median(Age)
```

在 T-SQL 中，`PERCENTILE_CONT()`函数根据 SQL Server 中列值的连续分布计算百分位数。百分位数是输入参数。如果您使用值 0.5 作为百分位数，这意味着您正在搜索中间值或中间值。此函数计算财务中位数。该函数返回具有相同值的所有行。为了获得单个值，我使用关键字`DISTINCT`，就像您在下面的代码中看到的那样:

```
SELECT DISTINCT
 PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY Age) OVER () AS Median
FROM dbo.vTargetMail;
```

结果是`31`。

我不会过多地解释 T-SQL 查询的细节，这将在本章的后面变得更加复杂。我在这里关注统计度量，并用三种不同的语言显示代码。如果你想了解我在这里写的关于查询的编程逻辑的细节，请参考 Itzik Ben-Gan，Dejan Sarka，Adam kinic 和 Kevin Farlee 的书*T-SQL query*，微软出版社，2015 年([https://www . Pearson . com/us/higher-education/program/Ben-Gan-T-SQL-query/PGM 254820 . html](https://www.pearson.com/us/higher-education/program/Ben-Gan-T-SQL-Querying/PGM254820.html))。我写了这本书的第 8 章， *T-SQL for BI 从业者，在那里我解释了如何用 T-SQL 编写计算不同统计度量的查询的细节。*

您可以使用`AVG()`内置的 T-SQL 聚合函数来计算平均值，如以下查询所示:

```
SELECT AVG(1.0*Age) AS Mean
FROM dbo.vtargetMail;
```

我的结果是`33.662356`。

我将停止对中心的计算。让我提一下，在本书附带的代码中，您可以找到更多计算的代码，包括模式、几何和调和平均值。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 测量价差

有了分布的中心后，下一个有趣的问题是这些值是如何分布的。您是否有一个非常均匀的样本，其中绝大多数值接近平均值，或者您是否有大量数据远离中心的两侧？

**范围**是价差的最简单度量；它只是一个变量的最大值和最小值之差。将此定义写成公式如下所示:

![](Images/d7c24f44-8689-4843-8994-d33931cd7874.png)

在 R 中，您可以简单地使用基础安装中的`min()`和`max()`函数来计算范围。

```
min(Age)
max(Age)
range(Age)
```

结果是`70`。下面是 Python 中的等效代码:

```
TM.Age.min()
TM.Age.max()
TM.Age.max() - TM.Age.min()
```

当然，您可以使用`MAX()`和`MIN()` T-SQL 聚合函数来计算变量的范围:

```
SELECT MAX(Age) - MIN(Age) AS Range
FROM dbo.vTargetMail;
```

您可以将分布分成更多部分，称为**分位数**，而不是将分布分成两半来获得中位数。如果你把它分成四部分，你得到**四分位数**；这是将数据集分成四份的三个值(所有行的 25%、50%和 75%)。第二个四分位数位于数据集的一半——这是中位数。第一个四分位数也称为下四分位数，第三个四分位数称为上四分位数。**四分位距** ( **IQR** )定义为上四分位值减去下四分位值:

![](Images/41c1ac9b-1d5d-48c6-b894-fd442ee32ce7.png)

在 R 中，您可以使用内置函数`IQR()`来计算四分位数之间的范围，使用`quantile()`函数来获得特定分位数的值。

```
quantile(Age, 1 / 4)
quantile(Age, 3 / 4)
IQR(Age)
```

在 Python 中，您可以借助于`quantile()`方法手动计算 IQR:

```
TM.Age.quantile(0.25)
TM.Age.quantile(0.75)
TM.Age.quantile(0.75) - TM.Age.quantile(0.25)
```

与中位数类似，您也可以使用 T-SQL 中的`PERCENTILE_CONT()`函数来计算 IQR:

```
SELECT DISTINCT
 PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY 1.0*Age) OVER () -
 PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY 1.0*Age) OVER () AS IQR
FROM dbo.vTargetMail;
```

IQR 就像抵抗数值大幅波动的中值，因为在计算中不使用最低和最高值。你只用了两个关键的观察。当范围远远高于四分位间距时，这意味着一些值远离平均值。

假设您只有一个观察值(n=1)。这个数据集的平均值等于这个单个案例的值，并且分布为零。如果您有不止一个观察值，计算分布是有意义的。因此，只有(n–1)条信息对传播有帮助。这个数字(n-1)被称为自由度。自由度告诉你有多少条信息是可变的。最后一块是固定的。想象一个只有四种不同状态的变量。所有四个值的累积百分比为 100。当你知道任意三个状态的频率时，你可以计算第四个频率；所以这个是由其他三个决定的。

**方差**衡量与平均值偏差的平方和，同时考虑自由度。使用平方偏差是因为有些偏差是负的，有些是正的，基本和为零。方差( **Var** )的公式如下:

![](Images/5e795a62-11ba-4289-8f54-4a3882b3cf97.png)

这是一个样本的**方差的公式，当你处理样本而不是整个人口或人口普查时。这对于统计学来说是非常典型的。您可以使用这个方差作为总体**的**方差的估计量。但是，如果您有人口普查数据，那么人口方差的公式不考虑自由度:**

![](Images/86234881-5d6f-4a66-814f-f0d71c926426.png)

对于大样本，Var 和 VarP 之间的差异可以忽略不计。

将**标准差** ( **σ** )定义为方差的平方根。这是衡量价差最流行的方法。用平方根，它补偿方差中的平方。公式如下:

![](Images/bb8e9eab-e18d-4203-ab7b-d8d9676f3175.png)

因为方差有两个变量，所以样本和总体的标准差也有两个变量。

我引入了价差的绝对度量，对单个变量的解释非常明显——方差或标准差越大，价差越大。但是，如何比较两个或更多不同变量的价差呢？在这种情况下，一个相对的衡量标准会很方便。现在，我引入变异系数 ( **CV** )的**，它是标准差与平均值的简单除法:**

![](Images/940c13fa-1e59-4f5a-972d-5ade29638620.png)

在 T-SQL 中，您可以获得用于计算一切的函数:`VARP()`函数用于计算总体的方差，`VAR()`函数用于计算样本的方差，`STDEVP()`函数用于计算总体的标准差，`STDEV()`函数用于计算样本的标准差，您可以将它用作总体标准差的估计量。因此，下面的查询非常简单明了。它计算`Age`和`YearlyIncome`变量的标准偏差和变异系数:

```
SELECT STDEV(1.0*Age) AS StDevAge,
 STDEV(1.0*YearlyIncome) AS StDevIncome,
 STDEV(1.0*Age) / AVG(1.0*Age) AS CVAge,
 STDEV(1.0*YearlyIncome) / AVG(1.0*YearlyIncome) AS CVIncome
FROM dbo.vTargetMail;
```

结果如下:

```
StDevAge          StDevIncome       CVAge              CVIncome
----------------  ----------------  -----------------  -----------------
11.5178146121881  32285.8417029682  0.342157114974011  0.563395923529214
```

你可以看到，虽然`YearlyIncome`的标准偏差比`Age`高得多，但是`YearlyIncome`的平均值也比`Age`的平均值高得多，因此变异系数没有太大的不同。

让我计算 R 中变量`Age`的方差、标准差和变异系数:

```
var(Age)
sd(Age)
sd(Age) / mean(Age)
```

和往常一样，Python 中也有同样的计算:

```
TM.Age.var()
TM.Age.std()
TM.Age.std() / TM.Age.mean()
```

正如我所说的，一个群体可以是偏斜的，也可以是中间偏瘦，有长尾。你如何衡量偏度和峰度？是时候切换到下一个话题了，更高的人口时刻。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 人口增长时刻

在处理两个更高的总体矩，即**偏度**和**峰度**之前，让我们简单讨论一下**正态**和**标准正态分布**。

正态分布是统计学中最重要的分布。这个分布的形状就是著名的**钟形曲线**。正态分布是对称的，靠近中部的观察值比靠近尾部的多。为了纪念卡尔·弗里德里希·高斯，该分布也被称为**高斯分布**，该曲线被称为**高斯曲线**。

正态分布的公式包括平均值和标准差:

![](Images/c588063f-961f-4a10-82fb-78eaaa99186e.png)

如果你事先不知道一个变量的分布，你就假设它服从正态分布。

**标准正态分布**，也称为 **Z 分布**，是围绕平均值 0 标准化的正态分布，标准差为 1。以下公式对正态分布的 x 值进行归一化:

![](Images/645963c3-01ff-4700-a084-401200853210.png)

您可以在下面的屏幕截图中看到一个正态分布的示例:

![](Images/7347b3db-712d-4e69-854f-10d757e6b870.png)

图 4.3:钟形曲线

曲线两侧远离平均值的两个标准差之间的区域覆盖了大约 95%的人口。这意味着只有 2.5%的病例在每条尾巴下面，或者只有 5%的病例在两条尾巴下面。因此，如果一个观察值远离平均值，例如四个标准差，假设分布是正态的，这个观察值多少是可疑的。这可能是一个异常值:一个罕见且远远超出界限的值。这可能只是数据中的一个错误，或者是一个真正的异常值。

**偏斜度**是一种描述概率分布不对称性的度量。它显示了平均值周围分布的不对称程度。如果偏度为正，则分布在平均值的右侧有一个较长的尾部。负偏度表示相反的情况，即不对称的尾部向低于平均值的值延伸。

如果你有一个偏态分布，那么远离平均值的情况仍然有效。对于正偏度，您可以接受较高的值作为有效值，即分布曲线右尾部下方的值，而对于负偏度，您可以接受左侧远离平均值的值。

是时候介绍一下偏斜度的公式了:

![](Images/5cbc7fcf-e97a-4cc0-aa39-a15ee064134f.png)

您可以在下面的屏幕截图中看到一个正偏态分布的示例:

![](Images/adb52cf0-1c93-422b-8911-c71b4ee1b794.png)

图 4.4:正偏态分布

什么如果一个分布两边都有长尾？然后就可以用**峰度**了。峰度告诉你关于一个分布与正态分布相比的相对尾部。正峰度意味着在均值的一侧或两侧存在一些极值，即在一侧或两侧存在长尾。分布在平均值附近可能非常窄，有一个峰值。然而，尾部值给计算带来更多的东西；因此，具有正峰度的分布不一定也具有高峰。负峰度表示短尾，在平均值附近可能有相对平坦的分布。对于尾部分布，考虑在任何方向远离平均值的值都可能是正确的。峰度的公式如下:

![](Images/21e35818-fa8c-4ddd-8b7e-9b35e31cbc0b.png)

下面的屏幕截图显示了一个尾部分布，在本例中也有一个峰值:

![](Images/6d0b40ee-643b-4655-8677-77a679877685.png)

图 4.5:尾部分布

basic R 中没有计算偏度和峰度的函数，自然可以在一些附加包中得到。但是，您也可以编写自定义函数。我将利用这个机会向你展示如何用 r 写一个函数，我的函数计算偏度和峰度。下面是代码，包括以`Age`变量作为参数的函数调用:

```
skewkurt <- function(p) {
 avg <- mean(p)
 cnt <- length(p)
 stdev <- sd(p)
 skew <- sum((p - avg) ^ 3 / stdev ^ 3) / cnt
 kurt <- sum((p - avg) ^ 4 / stdev ^ 4) / cnt - 3
 return(c(skewness = skew, kurtosis = kurt))
}
skewkurt(Age)
```

结果如下:

```
   skewness    kurtosis
 0.70826579 -0.02989311
```

由于偏斜度为正，这意味着`Age`变量在平均值的右侧比左侧有更长的尾部。不过偏度挺小的，所以右尾不是很长。峰度的结果非常接近于零。你可以说`Age`变量的分布与正态分布差别不大。

在 Python 中，pandas 库包括计算偏斜度和峰度的函数，因此代码比 R:

```
TM.Age.skew()
TM.Age.kurt()
```

T-SQL 中没有计算偏度和峰度的统计函数。然而，用非常有效的查询来计算它们是可能的。下面是一个如何有效计算偏斜度的示例:

```
WITH SkewCTE AS
(
SELECT SUM(1.0*Age) AS rx,
 SUM(POWER(1.0*Age,2)) AS rx2,
 SUM(POWER(1.0*Age,3)) AS rx3,
 COUNT(1.0*Age) AS rn,
 STDEV(1.0*Age) AS stdv,
 AVG(1.0*Age) AS av
FROM dbo.vTargetMail
)
SELECT
 (rx3 - 3*rx2*av + 3*rx*av*av - rn*av*av*av)
 / (stdv*stdv*stdv) * rn / (rn-1) / (rn-2) AS Skewness
FROM SkewCTE;
```

类似地，您可以使用同样有效的查询来计算峰度:

```
WITH KurtCTE AS
(
SELECT SUM(1.0*Age) AS rx,
 SUM(POWER(1.0*Age,2)) AS rx2,
 SUM(POWER(1.0*Age,3)) AS rx3,
 SUM(POWER(1.0*Age,4)) AS rx4,
 COUNT(1.0*Age) AS rn,
 STDEV(1.0*Age) AS stdv,
 AVG(1.*Age) AS av
FROM dbo.vTargetMail
)
SELECT
 (rx4 - 4*rx3*av + 6*rx2*av*av - 4*rx*av*av*av + rn*av*av*av*av)
 / (stdv*stdv*stdv*stdv) * rn * (rn+1) / (rn-1) / (rn-2) / (rn-3)
 - 3.0 * (rn-1) * (rn-1) / (rn-2) / (rn-3) AS Kurtosis
FROM KurtCTE;
```

在读完这一章之前，我想让你体验一下中级分析。此外，在这个只有代码和数字的长部分之后，我将向您展示一些图表。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 使用频率表理解离散变量

对于离散变量的概述，您可以使用`frequency`表格和图表。频率表可以显示以下内容:

*   价值观
*   值的计数或绝对频率
*   值的比例，或绝对百分比
*   累积频率
*   累计百分比
*   另外，您可以创建一个数值绝对百分比的**条形图**或**直方图**

至少，您需要计算变量的不同值的计数。

让我从用 T-SQL 计算频率开始。窗口集合函数在这里非常方便。下面的查询非常有效。如果查看查询的第一部分，您会注意到有一个计算绝对数字或计数的通用表表达式(CTE)查询。累积值(累计总数)是在窗口聚合函数的帮助下计算的。

该查询从来自`AdventureWorksDW2017`数据库的`dbo.vTargetMail`视图中计算`CommuteDistance`变量的频率。注意，这个变量虽然是字符串，但是有内在的顺序；它是一个序数。我需要在`CASE` T-SQL 表达式的帮助下更改值以定义正确的顺序:

```
USE AdventureWorksDW2017;
WITH freqCTE AS
(
SELECT CASE v.CommuteDistance 
         WHEN '0-1 Miles' THEN '1 - 0-1 Miles'
     WHEN '1-2 Miles' THEN '2 - 1-2 Miles'
         WHEN '2-5 Miles' THEN '3 - 2-5 Miles'
         WHEN '5-10 Miles' THEN '4 - 5-10 Miles'
     WHEN '10+ Miles' THEN '5 - 10+ Miles'
       END AS CommuteDistance,
 COUNT(v.CommuteDistance) AS AbsFreq,
 CAST(ROUND(100\. * (COUNT(v.CommuteDistance)) /
       (SELECT COUNT(*) FROM vTargetMail), 0) AS INT) AS AbsPerc
FROM dbo.vTargetMail AS v
GROUP BY v.CommuteDistance
)
SELECT CommuteDistance,
 AbsFreq,
 SUM(AbsFreq) 
  OVER(ORDER BY CommuteDistance 
       ROWS BETWEEN UNBOUNDED PRECEDING
      AND CURRENT ROW) AS CumFreq,
 AbsPerc,
 SUM(AbsPerc)
  OVER(ORDER BY CommuteDistance
       ROWS BETWEEN UNBOUNDED PRECEDING
      AND CURRENT ROW) AS CumPerc,
 CAST(REPLICATE('*',AbsPerc) AS VARCHAR(50)) AS Histogram
FROM freqCTE
ORDER BY CommuteDistance;
```

以下截图显示了结果:

![](Images/53b995c9-ae76-4b88-a518-a8d08992c7f2.png)

图 4.6:T-SQL 结果的频率

现在我将使用 R 来计算同一个视图中`NumberCarsOwned`变量的频率。首先，我们来读一下数据:

```
library(RODBC)
con <- odbcConnect("AWDW", uid = "RUser", pwd = "Pa$$w0rd")
TM <-
sqlQuery(con,
 "SELECT CustomerKey, 
 TotalChildren, NumberChildrenAtHome, 
 Gender, HouseOwnerFlag,
 NumberCarsOwned, MaritalStatus,
 Age, YearlyIncome, BikeBuyer,
 EnglishEducation AS Education,
 EnglishOccupation AS Occupation
 FROM dbo.vTargetMail;")
close(con)
```

您可以使用内核 R 的`table()`函数来获取计数:

```
table(TM$NumberCarsOwned)
```

这是结果。请注意，此变量可以被视为下限等于零的连续区间，也可以被视为离散有序变量或序数。我在这里用它作为序数。我不需要定义顺序—值本身正确地定义了顺序(通常，因为它们是整数):

```
   0    1    2    3    4
4238 4883 6457 1645 1261
```

在 R 中，你可以**附加**一个数据帧。这意味着您正在将其添加到内部搜索路径中。之后，你可以只引用变量的名字；您不需要编写带有数据框名称和美元符号前缀的变量。搜索路径中包含的数据框的变量名必须唯一。我用下面一行代码做到了这一点:

```
attach(TM)
```

`Education`变量也是离散的，但是，变量是一个字符串。默认情况下，r 按照字母顺序对字符串进行排序。因此，我需要通知 R 正确的顺序。我在这个任务中使用了`factor()`函数。然后代码使用`plot()`函数生成一个条形图。请注意，我在代码中仅使用变量名称引用了变量`Education`，而不是使用`TM$Education`格式，因为我将 TM 数据帧附加到了搜索路径:

```
Education = factor(Education, order = TRUE,
 levels = c("Partial High School",
 "High School", "Partial College",
 "Bachelors", "Graduate Degree"))
plot(Education, main = 'Education',
 xlab = 'Education', ylab = 'Number of Cases',
 col = "purple")
```

你可以在下面的截图中看到剧情:

![](Images/062c571f-a6ed-409a-ab5e-57e81680fa56.png)

图 4.7:教育条形图

正如你已经知道的，在 r 中总是有很多方法来做一些事情。对于频率和其他描述性统计，你可以使用`descr`包。下面的代码安装这个包，将其加载到内存中，并计算`Education`变量的频率:

```
install.packages("descr")
library(descr)
freq(Education)
```

`freq()`功能提供文本和图形结果。我之所以显示文本结果，只是因为该图与上一张图相同:

```
Education
                    Frequency Percent Cum Percent
Partial High School      1581   8.553       8.553
High School              3294  17.821      26.374
Partial College          5064  27.397      53.771
Bachelors                5356  28.976      82.747
Graduate Degree          3189  17.253     100.000
Total                   18484 100.000           
```

我换成 Python 吧。以下代码首先导入我将在本章中使用的库，然后从 SQL Server 中读取数据:

```
import numpy as np
import pandas as pd
import pyodbc
import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns

con = pyodbc.connect('DSN=AWDW;UID=RUser;PWD=Pa$$w0rd')
query = """SELECT CustomerKey, 
 TotalChildren, NumberChildrenAtHome, 
 Gender, HouseOwnerFlag,
 NumberCarsOwned, MaritalStatus,
 Age, YearlyIncome, BikeBuyer,
 EnglishEducation AS Education,
 EnglishOccupation AS Occupation
 FROM dbo.vTargetMail"""
TM = pd.read_sql(query, con)
```

你已经知道你可以用熊猫来制作图表。在前面的代码中，您可以看到我导入了一些我还没有描述的库。让我来介绍他们。

您将学习如何使用两个 Python 库制作图形:matplotlib 和 seaborn。这两者都包含在 SQL Server ML 服务附带的 Python 版本中(在数据库中)。Matplotlib 是一个跨平台的图形引擎，用作其他库中许多其他图形函数的主干。除了导入这个库之外，您还需要向它导入一个接口。

Matplotlib 就是整个库。`Matplotlib.pyplot`是 matplotlib 中的一个模块，是底层绘图库的接口。与 R 不同，在 R 中图形被自动发送到屏幕上，您需要从 pyplot 接口调用`show()`函数来打开带有您的图形的图形窗口。基于 matplotlib 构建的可视化库之一是 seaborn 库。该库增加了增强的制图选项，使处理 pandas 数据框变得容易，编码也变得非常简单。

要获得绝对频率，您可以使用 pandas `value_counts()`函数。例如，您可以对`Education`变量这样做:

```
TM['Education'].value_counts()
```

如果您执行了前一行，您会注意到`Education`值的顺序不正确。与 R 一样，您还需要通知 Python 值的正确顺序。让我将变量定义为一个分类变量，并对值进行重新排序和正确计算计数:

```
TM['Education'] = TM['Education'].astype('category')
TM['Education'].cat.reorder_categories(
 ["Partial High School", 
 "High School","Partial College", 
 "Bachelors", "Graduate Degree"], inplace=True)
TM['Education'].value_counts().sort_index()
```

结果如下:

```
Partial High School    1581
High School            3294
Partial College        5064
Bachelors              5356
Graduate Degree        3189
```

这是熊猫`plot()`函数的另一个例子。首先，您需要将计数存储在一个对象中，然后绘制这个对象。代码将绘图存储在`ax`对象中，然后添加标签。最后，它展示了情节:

```
edu = TM['Education'].value_counts().sort_index()
ax = edu.plot(kind = 'bar',
 color = ('b'),
 fontsize = 14, legend = False, 
 use_index = True, rot = 1)
ax.set_xlabel('Education', fontsize = 16)
ax.set_ylabel('Count', fontsize = 16)
plt.show()
```

我再次没有在这里显示该图，因为它与上图中用 R 创建的条形图相同。我会给你看一个不同的条形图。这一次，我使用的是 seaborn `countplot()`函数:

```
sns.countplot(x="Education", hue="BikeBuyer", data=TM);
plt.show()
```

我在函数中使用了两个变量；我在展示不同教育水平的群体中不同价值观的数量。这已经不仅仅是一个简单的条形图；你已经可以注意到这两个变量之间的一些小关联——受过高等教育的人倾向于购买更多的自行车。您可以在下面的截图中看到该图表:

![](Images/3b0a41a2-abdc-4d6f-80a8-5b63dbcce289.png)

图 4.8:不同教育水平的自行车购买者

我将在本章后面更深入地讨论关联。现在让我转到连续变量的数据概述。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 以图形方式显示关联

这一次，我将只向您展示 Python 中的代码。我将在本书的第 6 章《中间统计和图表》中讨论离散变量和连续变量的关联的不同度量，以及这些关联的图形表示。接下来的两张图只是为了梳理一下。

**散点图**是两个连续变量分布的常见表示。平面上的每个点都有由这两个变量定义的坐标。从这些点的位置，你可以得到这两个变量分布的印象，以及它们之间可能的联系。下面是将为`Age`和`YearlyIncome`变量创建散点图的 Python 代码:

```
TM1 = TM.head(200)
plt.scatter(TM1['Age'], TM1['YearlyIncome'])
plt.xlabel("Age", fontsize = 16)
plt.ylabel("YearlyIncome", fontsize = 16)
plt.title("YearlyIncome over Age", fontsize = 16)
plt.show()
```

注意，为了得到一个不那么杂乱的散点图，我只对前 200 种情况进行了限制。剧情是这样的:

![](Images/3978c63a-d171-47d5-be9c-8af5f6cd8589.png)

图 4.9:年龄和年收入散点图

这两个变量之间的关联是很有可能的。然而，这种关联可能不是简单的线性关系。你可以注意到，收入最初随着年龄的增长而增加；然而，后来收入随着年龄的增长而减少。实际上，这种关联是多项式的，我将在第 6 章《中级统计和图表》中向你展示。

在 seaborn 库中，可以找到`jointplot()`函数。此函数显示平面中两个变量的联合分布，以及每个变量在该平面边缘的边缘分布:

```
with sns.axes_style('white'):
 sns.jointplot('Age', 'YearlyIncome', TM, kind = 'kde')
plt.show()
```

本章的最终屏幕截图如下所示:

![](Images/c5829802-35a0-4240-9910-19a47eca3463.png)

图 4.10:年龄和年收入散点图

从前面的截图中，您可以很容易地注意到每个输入变量的分布，以及它们之间是否存在某种关联。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 摘要

所以，在这一章中，你从一些真正的工作开始。向您简要介绍了描述变量分布的统计方法，以及如何用三种不同的语言计算它们。这种统计和数据的可视化有时可能已经是最终结果，是最终报告所需的一切。然而，在数据科学项目中，这只是第一步。

在实际项目中，大约 70%的时间用于数据概述和数据准备。这意味着在下一章有一些更繁琐的工作等着你，我将更多地处理数据准备任务。