

# 八、打磨数据

在处理数据时，您通常会发现，在缺失值、异常值和类似异常的情况下，数据可能并不总是完美或清晰的。处理和清理不完美的或所谓的脏数据是每个数据科学家日常生活的一部分，甚至更多，它可能占用我们实际处理数据的 80%的时间！

数据集错误通常是由于不适当的数据获取方法造成的，但与其重复和调整数据收集过程，通常更好的(在节省金钱、时间和其他资源的意义上)或不可避免的是通过一些简单的函数和算法来润色数据。在本章中，我们将介绍:

*   各种函数的`na.rm`参数的不同用例
*   `na.action`及相关功能，用于消除缺失数据
*   提供用户友好的数据估算方法的几个软件包
*   带有几个极值统计测试的`outliers`包
*   作为一个脑筋急转弯，如何自己实现 Lund 异常值测试
*   参考一些健壮的方法

# 缺失数据的类型和来源

首先，我们必须快速查看丢失数据的可能不同来源，以确定我们通常为什么以及如何得到丢失的值。数据丢失有很多不同的原因，可以分为三种不同的类型。

例如，丢失数据的主要原因可能是设备故障或人为因素导致数据输入错误。**完全随机缺失** ( **MCAR** )意味着数据集中的每一个值都有相同的缺失概率，因此不会因为缺失数据而出现系统误差或失真，我们也无法解释缺失值的模式。如果我们的数据集中有`NA`(意思是:没有答案、不适用或不可用)值，这是最好的情况。

但是一种更加频繁和不幸的丢失数据类型是**随机丢失** ( **三月**)相比 MCAR。在 MAR 的情况下，丢失值的模式是已知的，或者至少可以识别出，尽管它与实际的丢失值无关。例如，一个人可能会认为男性比女性更孤独或懒惰，因此他们不愿意回答调查中的所有问题——不管实际问题是什么。因此，这并不是因为男性的收入比女性多或少，所以他们没有捐出自己的薪水，而是他们倾向于随意跳过问卷中的几个问题。

### 注意

这种缺失数据的分类和类型由 Donald B. Rubin 于 1976 年在他的*推理和缺失数据*中首次提出，发表在 *Biometrika 63(3): 581—592* 上，随后由*Roderick j . a . Little*(2002):*缺失数据的统计分析*， *Wiley* 合著的一本书对其进行了回顾和扩展，这本书非常值得一读，以了解更多细节。

最糟糕的情况是 **非随机缺失** ( **MNAR** )，其中数据因与实际问题高度相关的特定原因而缺失，这将缺失值归类为不可忽略的无响应。

在带有敏感问题的调查中，或者由于研究准备中的设计缺陷，这种情况经常发生。在这种情况下，由于后台正在进行一些潜在的过程，数据会丢失，这通常是我们希望在研究的帮助下更好地了解的事情——这可能会变成一个相当麻烦的情况。

那么我们如何解决这些问题呢？有时候相对容易。例如，如果我们有很多观察值，由于大数定律，MCAR 根本不是一个真正的问题，因为对于每个观察值来说，丢失值的概率是相同的。我们基本上有两种选择来处理未知或缺失的数据:

*   删除缺失值和/或观察值
*   用一些估计值替换缺失值



# 识别缺失数据

处理缺失值(尤其是 MCAR 数据)的最简单方法就是删除所有缺失值的观测值。如果我们想排除至少有一个缺失值的`matrix`或`data.frame`对象的每一行，我们可以使用`stats`包中的`complete.cases`函数来识别它们。

首先，让我们看看有多少行至少缺少一个值:

```r
> library(hflights)

> table(complete.cases(hflights))

 FALSE   TRUE 

 3622 223874

```

这大约是 25 万行的 1.5%:

```r
> prop.table(table(complete.cases(hflights))) * 100

 FALSE      TRUE 

 1.592116 98.407884

```

让我们看看`NA`在不同列中的分布情况:

```r
> sort(sapply(hflights, function(x) sum(is.na(x))))

 Year             Month        DayofMonth 

 0                 0                 0 

 DayOfWeek     UniqueCarrier         FlightNum 

 0                 0                 0 

 TailNum            Origin              Dest 

 0                 0                 0 

 Distance         Cancelled  CancellationCode 

 0                 0                 0 

 Diverted           DepTime          DepDelay 

 0              2905              2905 

 TaxiOut           ArrTime            TaxiIn 

 2947              3066              3066 

ActualElapsedTime           AirTime          ArrDelay 

 3622              3622              3622

```



# 忽略缺失值

因此，似乎缺失数据相对频繁地出现在与时间相关的变量中，但是我们在航班标识符和日期中没有缺失值。另一方面，如果一个航班缺少一个值，那么其他一些变量也很有可能会缺少，在总共 3，622 个至少缺少一个值的情况中:

```r
> mean(cor(apply(hflights, 2, function(x)

+    as.numeric(is.na(x)))), na.rm = TRUE)

[1] 0.9589153

Warning message:

In cor(apply(hflights, 2, function(x) as.numeric(is.na(x)))) :

 the standard deviation is zero

```

好吧，让我们看看我们都做了些什么！首先，我们调用了`apply`函数，将`data.frame`的值转换为`0`或`1`，其中`0`代表观察到的值，而`1`代表缺失的值。然后，我们计算这个新创建的矩阵的相关系数，这当然会返回许多缺失值，因为一些列只有一个唯一值，没有任何可变性，如警告消息所示。为此，我们必须将`na.rm`参数指定为`TRUE`，这样`mean`函数将通过删除`cor`函数返回的相关系数中缺失的值来返回一个实数值，而不是`NA`。

因此，一种选择是大量使用`na.rm`参数，这是大多数对丢失数据敏感的函数所支持的——从`base`和`stats`包中举出几个:`mean`、`median`、`sum`、`max`和`min`。

为了编译在基础包中有`na.rm`参数的函数的完整列表，我们可以遵循位于[http://stackoverflow.com/a/17423072/564164](http://stackoverflow.com/a/17423072/564164)的一个非常有趣的 SO 答案中描述的步骤。我发现这个答案很激励人，因为我真的相信分析我们用于分析的工具的力量，或者换句话说，花一些时间了解 R 在后台是如何工作的。

首先，让我们列出在`baseenv`(`base`包的环境)中找到的所有函数，以及完整的函数参数和函数体:

```r
> Funs <- Filter(is.function, sapply(ls(baseenv()), get, baseenv()))

```

然后我们可以从返回的列表中`Filter`所有那些函数，这些函数通过下面的方式在形式参数中有`na.rm`:

```r
> names(Filter(function(x)

+    any(names(formals(args(x))) %in% 'na.rm'), Funs))

 [1] "all"                     "any" 

 [3] "colMeans"                "colSums" 

 [5] "is.unsorted"             "max" 

 [7] "mean.default"            "min" 

 [9] "pmax"                    "pmax.int" 

[11] "pmin"                    "pmin.int" 

[13] "prod"                    "range" 

[15] "range.default"           "rowMeans" 

[17] "rowsum.data.frame"       "rowsum.default" 

[19] "rowSums"                 "sum" 

[21] "Summary.data.frame"      "Summary.Date" 

[23] "Summary.difftime"        "Summary.factor" 

[25] "Summary.numeric_version" "Summary.ordered" 

[27] "Summary.POSIXct"         "Summary.POSIXlt" 

```

这可以很容易地应用于任何 R 包，例如在`stats`包的情况下，将环境变量改为`'package:stats'`:

```r
> names(Filter(function(x)

+   any(names(formals(args(x))) %in% 'na.rm'),

+     Filter(is.function,

+       sapply(ls('package:stats'), get, 'package:stats'))))

 [1] "density.default" "fivenum"         "heatmap" 

 [4] "IQR"             "mad"             "median" 

 [7] "median.default"  "medpolish"       "sd" 

[10] "var" 

```

这些是在`base`和`stats`包中有`na.rm`参数的函数，我们已经看到，忽略单个函数调用中丢失的值的最快和最简单的方法(不实际从数据集中删除`NA`值)是将`na.rm`设置为`TRUE`。但是为什么`na.rm`不默认为`TRUE`？

## 覆盖函数的默认参数

如果您的 R 对象包含缺失值时，大多数函数都返回`NA`这一事实让您恼火，那么您可以通过使用一些定制的包装函数来覆盖这些函数，比如:

```r
> myMean <- function(...) mean(..., na.rm = TRUE)

> mean(c(1:5, NA))

[1] NA

> myMean(c(1:5, NA))

[1] 3

```

另一个选择可能是编写一个定制包，它将覆盖`base`和`stats`函数的工厂默认值，就像在 `rapportools`包中一样，它包括各种各样的助手函数，这些函数具有相同的报告默认值:

```r
> library(rapportools)

Loading required package: reshape

Attaching package: 'rapportools'

The following objects are masked from 'package:stats':

 IQR, median, sd, var

The following objects are masked from 'package:base':

 max, mean, min, range, sum

> mean(c(1:5, NA))

[1] 3

```

这种方法的问题是您已经永久地覆盖了那些列出的函数，所以您需要重启您的 R 会话或者分离`rapportools`包来重置为标准参数，比如:

```r
> detach('package:rapportools')

> mean(c(1:5, NA))

[1] NA

```

覆盖函数的默认参数的一个更通用的解决方案是依赖于`Defaults`包的一些漂亮的特性,这些特性虽然没有被主动维护，但是它确实起了作用:

```r
> library(Defaults)

> setDefaults(mean.default, na.rm = TRUE)

> mean(c(1:5, NA))

[1] 3

```

请注意，这里我们必须更新默认参数值`mean.default`，而不是简单地尝试调整`mean`，因为后者会导致错误:

```r
> setDefaults(mean, na.rm = TRUE)

Warning message:

In setDefaults(mean, na.rm = TRUE) :

 'na.rm' was not set, possibly not a formal arg for 'mean'

```

这是因为`mean`是一个没有任何形式参数的`S3`方法:

```r
> mean

function (x, ...) 

{

 if (exists(".importDefaults")) 

 .importDefaults(calling.fun = "mean")

 UseMethod("mean")

}

<environment: namespace:base>

> formals(mean)

$x

$...

```

无论您喜欢哪种方法，都可以通过在您的 `Rprofile`文件中添加几行代码，在 R 启动时自动调用这些函数。

### 注意

您可以通过一个全局或用户特定的`Rprofile`文件定制 R 环境。这是一个普通的 R 脚本，通常放在用户的主目录中，文件名中有一个前导点，每次启动新的 R 会话时都会运行。在那里，您可以调用包装在`.First`或`.Last`函数中的任何 R 函数，以便在 R 会话开始或结束时运行。这种有用的添加可能是加载一些 R 包，从数据库中打印定制的问候或 KPI 度量，或者例如安装所有 R 包的最新版本。

但是最好不要以这种非标准的方式调整 R 环境，因为您可能很快就会在分析中遇到一些深奥的、意想不到的错误或无声的故障。

例如，我已经习惯了通过在我的`Rprofile`中指定`setwd('/tmp')`来一直在一个临时目录中工作，如果你为了一些快速的工作而频繁地启动 R 会话，这是非常有用的。另一方面，花 15 分钟调试为什么一些随机的 R 函数似乎不能完成它的工作，为什么它返回一些文件没有找到的错误消息，这真的很令人沮丧。

因此，请注意:如果您更新了 R 函数的工厂默认参数，在尝试使用- `vanilla`命令行选项启动 R 并在普通 R 会话中使用重现这些错误之前，不要想着在 R 邮件列表上抱怨您在 base R 的一些主要函数中发现的一些新错误。



# 删除丢失的数据

在 R 函数中使用`na.rm`参数进行的另一种方法是在将数据传递给分析函数之前从数据集中移除`NA`。这意味着我们将从数据集中永久删除缺失的值，这样它们在分析的后续阶段不会造成任何问题。为此，我们可以使用`na.omit`或`na.exclude`功能:

```r
> na.omit(c(1:5, NA))

[1] 1 2 3 4 5

attr(,"na.action")

[1] 6

attr(,"class")

[1] "omit"

> na.exclude(c(1:5, NA))

[1] 1 2 3 4 5

attr(,"na.action")

[1] 6

attr(,"class")

[1] "exclude"

```

这两个函数唯一的区别是返回的 R 对象的`na.action`属性的类，分别是`omit`和`exclude`。这种微小的差异只在建模时才重要。`na.exclude`函数返回残差和预测的`NA`，而`na.omit`隐藏向量的那些元素:

```r
> x <- rnorm(10); y <- rnorm(10)

> x[1] <- NA; y[2] <- NA

> exclude <- lm(y ~ x, na.action = "na.exclude")

> omit <- lm(y ~ x, na.action = "na.omit")

> residuals(exclude)

 1     2     3     4     5     6     7     8     9    10 

 NA    NA -0.89 -0.98  1.45 -0.23  3.11 -0.23 -1.04 -1.20 

> residuals(omit)

 3     4     5     6     7     8     9    10 

-0.89 -0.98  1.45 -0.23  3.11 -0.23 -1.04 -1.20

```

重要的是要注意在表格数据的情况下，比如一个`matrix`或`data.frame`，如果它包含至少一个缺失值，这些函数将删除整行。为了快速演示，让我们创建一个 3 列 3 行的矩阵，值从 1 到 9 递增，但是用`NA`替换所有可被 4 整除的值:

```r
> m <- matrix(1:9, 3)

> m[which(m %% 4 == 0, arr.ind = TRUE)] <- NA

> m

 [,1] [,2] [,3]

[1,]    1   NA    7

[2,]    2    5   NA

[3,]    3    6    9

> na.omit(m)

 [,1] [,2] [,3]

[1,]    3    6    9

attr(,"na.action")

[1] 1 2

attr(,"class")

[1] "omit"

```

如此处所示，我们可以在`na.action`属性中找到被移除案例的行号。



# 在实际分析之前或期间过滤缺失数据

假设我们想计算航班实际长度的`mean`:

```r
> mean(hflights$ActualElapsedTime)

[1] NA

```

结果是过程的`NA`，因为如前所述，这个变量包含缺失值，几乎每一次用`NA`进行的 R 操作都会导致`NA`。因此，让我们按如下方式解决这个问题:

```r
> mean(hflights$ActualElapsedTime, na.rm = TRUE)

[1] 129.3237

> mean(na.omit(hflights$ActualElapsedTime))

[1] 129.3237

```

有性能问题吗？或者其他决定使用哪种方法的方法？

```r
> library(microbenchmark)

> NA.RM   <- function()

+              mean(hflights$ActualElapsedTime, na.rm = TRUE)

> NA.OMIT <- function()

+              mean(na.omit(hflights$ActualElapsedTime))

> microbenchmark(NA.RM(), NA.OMIT())

Unit: milliseconds

 expr       min        lq    median        uq       max neval

 NA.RM()  7.105485  7.231737  7.500382  8.002941  9.850411   100

 NA.OMIT() 12.268637 12.471294 12.905777 13.376717 16.008637   100

```

第一眼看到在`microbenchmark`包的帮助下计算的这些选项的性能(请参见[第 1 章](ch01.html "Chapter 1. Hello, Data!")、 *Hello Data* 中的*加载合理大小的文本文件*一节以了解更多细节)表明，在单个函数调用的情况下，使用`na.rm`是更好的解决方案。

另一方面，如果我们希望在分析中的某个稍后的阶段重用数据，从数据集中只省略一次缺失值和观察值，而不是总是指定`na.rm`为`TRUE`，这是更可行和有效的。



# 数据插补

有时忽略缺失值是不合理的或根本不可能的，例如由于低数量的观察值或缺失数据似乎不是随机的。在这种情况下，数据插补是一种真正的替代方法，这种方法可以用基于各种算法的一些真实值代替`NA`，例如用以下值填充空单元格:

*   已知的标量
*   列中出现的前一个值(热卡)
*   同一列中的随机元素
*   列中最常见的值
*   具有给定概率的同一列中的不同值
*   基于回归或机器学习模型的预测值

将多个数据集连接在一起时，经常使用热卡方法。在这种情况下，`data.table`的`roll`参数会非常有用和高效，否则一定要检查一下 `VIM`包中的`hotdeck`函数，它提供了一些可视化缺失数据的非常有用的方法。但是当处理数据集的一个已经给定的列时，我们还有一些其他简单的选择。

例如，输入一个已知的标量是一个非常简单的情况，我们知道所有丢失的值都是由于一些研究设计模式。让我们设想一个数据库，它存储了你每个工作日到达和离开办公室的时间，通过计算这两个时间之间的差值，我们可以分析每天在办公室花费的工作时间。如果这个变量在一段时间内返回`NA`，实际上这意味着我们一整天都不在办公室，因此计算出的值应该是零而不是`NA`。

不仅仅是理论上，这在 R 中也很容易实现(这个例子是上一个演示代码的延续，我们用两个缺失值定义了`m`):

```r
> m[which(is.na(m), arr.ind = TRUE)] <- 0

> m

 [,1] [,2] [,3]

[1,]    1    0    7

[2,]    2    5    0

[3,]    3    6    9

```

类似地，用随机数、其他值的`sample`或变量的`mean`替换丢失的值可以相对容易地完成:

```r
> ActualElapsedTime <- hflights$ActualElapsedTime

> mean(ActualElapsedTime, na.rm = TRUE)

[1] 129.3237

> ActualElapsedTime[which(is.na(ActualElapsedTime))] <-

+   mean(ActualElapsedTime, na.rm = TRUE)

> mean(ActualElapsedTime)

[1] 129.3237

```

使用 `Hmisc`包中的`impute`功能可以更加容易:

```r
> library(Hmisc)

> mean(impute(hflights$ActualElapsedTime, mean))

[1] 129.3237

```

当然，我们似乎保留了算术平均值的值，但是您应该意识到一些非常严重的副作用:

```r
> sd(hflights$ActualElapsedTime, na.rm = TRUE)

[1] 59.28584

> sd(ActualElapsedTime)

[1] 58.81199

```

当用平均值替换缺失值时，与原始分布相比，转换变量的方差自然会更低。这在某些需要更复杂方法的情况下会非常成问题。

## 建模缺失值

除了前面提到的单变量方法，您还可以在数据集中的完整案例上拟合模型，而不是在剩余的行上拟合这些模型来估计缺失值。或者简而言之，我们用多元预测代替缺失值。

有太多的相关函数和包，例如，您可能有兴趣检查`Hmisc`包中的`transcan`函数，或者`imputeR`包，其中也包括用于输入分类变量和连续变量的各种模型。

大多数插补方法和模型都是针对一种类型的变量:连续变量或分类变量。在混合型数据集的情况下，我们通常使用不同的算法来处理不同类型的缺失数据。这种方法的问题是，不同类型的数据之间的一些可能的关系可能会被忽略，从而产生一些部分模型。

为了克服这个问题，并在书中节省几页关于传统回归和其他数据插补相关方法的描述(虽然你可以在[第 5 章](ch05.html "Chapter 5. Building Models (authored by Renata Nemeth and Gergely Toth)")、*架构物模型(Renata Nemeth 和 Gergely Toth 著)*和[第 6 章](ch06.html "Chapter 6. Beyond the Linear Trend Line (authored by Renata Nemeth and Gergely Toth)")、*超越线性趋势线(Renata Nemeth 和 Gergely Toth 著)*中找到一些相关方法)， 我们将通过 `missForest`包中一个非常用户友好的界面，集中讨论一种可以同时处理分类变量和连续变量的非参数方法。

这个迭代过程将随机森林模型与可用数据相拟合，以预测缺失值。由于我们的`hflights`数据对于这样一个过程来说相对较大，并且运行示例代码需要花费很多时间，所以在接下来的例子中，我们将使用标准的`iris`数据集。

首先让我们看看数据集的原始结构，它不包括任何缺失值:

```r
> summary(iris)

 Sepal.Length    Sepal.Width     Petal.Length    Petal.Width 

 Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100 

 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300 

 Median :5.800   Median :3.000   Median :4.350   Median :1.300 

 Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199 

 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800 

 Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500 

 Species 

 setosa    :50 

 versicolor:50 

 virginica :50 

```

现在，让我们加载包并将一些缺失值(完全随机地)添加到数据集中，以便为即将推出的模型生成可重现的最小示例:

```r
> library(missForest)

> set.seed(81)

> miris <- prodNA(iris, noNA = 0.2)

> summary(miris)

 Sepal.Length    Sepal.Width     Petal.Length    Petal.Width 

 Min.   :4.300   Min.   :2.000   Min.   :1.100   Min.   :0.100 

 1st Qu.:5.200   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300 

 Median :5.800   Median :3.000   Median :4.450   Median :1.300 

 Mean   :5.878   Mean   :3.062   Mean   :3.905   Mean   :1.222 

 3rd Qu.:6.475   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.900 

 Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500 

 NA's   :28      NA's   :29      NA's   :32      NA's   :33 

 Species 

 setosa    :40 

 versicolor:38 

 virginica :44 

 NA's      :28 

```

因此，现在我们在每一列中都有大约 20%的缺失值，这也在前面的摘要的最后一行中有所陈述。每个变量完全随机缺失值的数量在 28 到 33 之间。

下一步应该是构建随机森林模型，用实数和因子等级替换缺失值。因为我们也有原始数据集，所以我们可以使用这个完整的矩阵通过`xtrue`参数来测试这个方法的性能，当我们用`verbose`调用这个函数时，它会计算并返回错误率。这在此类教学示例中非常有用，可以展示模型和预测是如何随着迭代而改进的:

```r
> iiris <- missForest(miris, xtrue = iris, verbose = TRUE)

 missForest iteration 1 in progress...done!

 error(s): 0.1512033 0.03571429 

 estimated error(s): 0.1541084 0.04098361 

 difference(s): 0.01449533 0.1533333 

 time: 0.124 seconds

 missForest iteration 2 in progress...done!

 error(s): 0.1482248 0.03571429 

 estimated error(s): 0.1402145 0.03278689 

 difference(s): 9.387853e-05 0 

 time: 0.114 seconds

 missForest iteration 3 in progress...done!

 error(s): 0.1567693 0.03571429 

 estimated error(s): 0.1384038 0.04098361 

 difference(s): 6.271654e-05 0 

 time: 0.152 seconds

 missForest iteration 4 in progress...done!

 error(s): 0.1586195 0.03571429 

 estimated error(s): 0.1419132 0.04918033 

 difference(s): 3.02275e-05 0 

 time: 0.116 seconds

 missForest iteration 5 in progress...done!

 error(s): 0.1574789 0.03571429 

 estimated error(s): 0.1397179 0.04098361 

 difference(s): 4.508345e-05 0 

 time: 0.114 seconds

```

该算法在停止之前运行了 5 次迭代，此时错误率似乎没有进一步改善。返回的`missForest`对象包括除估算数据集之外的一些其他值:

```r
> str(iiris)

List of 3

 $ ximp    :'data.frame':  150 obs. of  5 variables:

 ..$ Sepal.Length: num [1:150] 5.1 4.9 4.7 4.6 5 ...

 ..$ Sepal.Width : num [1:150] 3.5 3.3 3.2 3.29 3.6 ...

 ..$ Petal.Length: num [1:150] 1.4 1.4 1.3 1.42 1.4 ...

 ..$ Petal.Width : num [1:150] 0.2 0.218 0.2 0.2 0.2 ...

 ..$ Species     : Factor w/ 3 levels "setosa","versicolor",..: ...

 $ OOBerror: Named num [1:2] 0.1419 0.0492

 ..- attr(*, "names")= chr [1:2] "NRMSE" "PFC"

 $ error   : Named num [1:2] 0.1586 0.0357

 ..- attr(*, "names")= chr [1:2] "NRMSE" "PFC"

 - attr(*, "class")= chr "missForest"

```

框外误差是对我们的模型有多好的估计，它是基于数值的**归一化均方根误差** ( **NRMSE** )和因子的**错误分类比例** ( **PFC** )条目。由于我们也为之前运行的模型提供了完整的数据集,我们也获得了真实的插补误差率——与上述估计值非常接近。

### 注意

请在[第十章](ch10.html "Chapter 10. Classification and Clustering")、*分类和聚类*中找到关于随机森林和相关机器学习主题的更多细节。

但是这种方法与更简单的插补方法相比如何，比如用平均值代替缺失值？

## 比较不同的插补方法

在比较中，只有`iris`数据集的前四列将被使用，因此此时它不处理因子变量。让我们准备这个演示数据集:

```r
> miris <- miris[, 1:4]

```

在`iris_mean`中，我们将所有缺失值替换为实际列的平均值:

```r
> iris_mean <- impute(miris, fun = mean)

```

在`iris_forest`中，我们通过拟合随机森林模型来预测缺失值:

```r
> iris_forest <- missForest(miris)

 missForest iteration 1 in progress...done!

 missForest iteration 2 in progress...done!

 missForest iteration 3 in progress...done!

 missForest iteration 4 in progress...done!

 missForest iteration 5 in progress...done!

```

现在让我们简单地通过比较`iris_mean`和`iris_forest`与完整的`iris`数据集的相关性来检查这两个模型的准确性。对于`iris_forest`，我们将从`ximp`属性中提取实际的估算数据集，并且我们将忽略原始`iris`表的因子变量:

```r
> diag(cor(iris[, -5], iris_mean))

Sepal.Length  Sepal.Width Petal.Length  Petal.Width 

 0.6633507    0.8140169    0.8924061    0.4763395 

> diag(cor(iris[, -5], iris_forest$ximp))

Sepal.Length  Sepal.Width Petal.Length  Petal.Width 

 0.9850253    0.9320711    0.9911754    0.9868851

```

这些结果表明，与用平均值替换缺失值的简单单变量解决方案相比，非参数随机森林模型做得更好。

## 不输入缺失值

请注意，这些方法同样有它们的缺点。用预测值替换缺失值通常会缺少大多数模型的任何误差项和残差方差。

这也意味着我们降低了可变性，同时高估了数据集中的一些关联，这可能会严重影响我们的数据分析结果。为此，过去引入了一些模拟技术来克服用一些任意模型扭曲数据集和我们的假设检验的问题。

## 多重插补

多重插补背后的基本思想是在缺失值上连续几次拟合模型。这种蒙特卡罗方法通常会创建一些(如 3 到 10 个)模拟完整数据集的并行版本，每个版本都被单独分析，然后我们将结果合并以产生实际的估计值和置信区间。更多细节参见`Hmisc`包中的`aregImpute`函数。

另一方面，我们真的必须在所有情况下移除或估算缺失值吗？关于这个问题的更多细节，请参见本章的最后一节。但在此之前，我们先了解一下打磨数据的其他一些要求。



# 极端值和异常值

异常值或极值被定义为偏离其他观察值如此之远的数据点，以至于怀疑是由完全不同的机制或简单的错误产生的。识别异常值非常重要，因为这些极值可以:

*   增加误差方差
*   影响力评估
*   降低常态

或者换句话说，假设你的原始数据集是一块要在某个游戏中用作完美球的圆形石头，在实际使用它之前，它必须被清洁和打磨。石头表面有一些小孔，就像数据中缺失的值，应该用数据插补来填补。

另一方面，石头不仅在它的表面上有洞，而且一些泥也覆盖了物品的一些部分，这些部分将被移除。但是我们如何区分泥巴和真正的石头呢？在这一节中，我们将关注 `outliers`包和一些相关的方法为识别极值提供了什么。

由于这个包与`randomForest`包(由自动加载的`missForest`包)有一些冲突的函数名，所以在开始下面的例子之前，最好将后者分离出来:

```r
> detach('package:missForest')

> detach('package:randomForest')

```

`outlier`函数返回与平均值差异最大的值，与其名称相反，该值不一定是异常值。相反，该函数可用于让分析师了解哪些值可能是异常值:

```r
> library(outliers)

> outlier(hflights$DepDelay)

[1] 981

```

于是就出现了航班延误 16 个小时以上才真正起飞的情况！这令人印象深刻，不是吗？我们来看看这么晚了正常吗:

```r
> summary(hflights$DepDelay)

 Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 

-33.000  -3.000   0.000   9.445   9.000 981.000    2905

```

嗯，`mean`大约是 10 分钟，但由于它甚至比第三季度还要长，而`median`是零，因此不难猜测，相对较大的平均值是由一些极值引起的:

```r
> library(lattice)

> bwplot(hflights$DepDelay)

```

![Extreme values and outliers](img/2028OS_08_01.jpg)

前面的箱线图清楚地显示，大多数航班仅延迟了几分钟，四分位数范围约为 10 分钟:

```r
> IQR(hflights$DepDelay, na.rm = TRUE)

[1] 12

```

上图中所有的蓝色圆圈都是可能的极值，高于上四分位数的 1.5 IQR。但是我们如何(从统计学上)检验一个值呢？

## 测试极端值

`outliers`包附带了几个捆绑的极值检测算法，比如:

*   狄克逊的 Q 检验(`dixon.test`)
*   格拉布试验
*   异常和异常方差(`cochran.test`)
*   卡方检验(`chisq.out.test`)

这些功能非常容易使用。只需将一个向量传递给统计测试，显著性测试返回的 p 值将清楚地表明数据是否有异常值。例如，让我们针对一个相对较大的数字测试 10 个介于 0 和 1 之间的随机数，以验证它是这个小样本中的一个极值:

```r
> set.seed(83)

> dixon.test(c(runif(10), pi))

 Dixon test for outliers

data:  c(runif(10), pi)

Q = 0.7795, p-value < 2.2e-16

alternative hypothesis: highest value 3.14159265358979 is an outlier

```

但不幸的是，我们不能在我们的实时数据集中使用这些方便的函数，因为这些方法假设正态分布，这在我们的情况下肯定是不正确的，因为我们都从经验中知道:航班往往晚点，而不是提前很多到达目的地。

为此，我们应该使用一些更健壮的方法，比如 `mvoutlier`包，或者像 Lund 在大约 40 年前建议的一些非常简单的方法。该测试基本上是借助一个非常简单的线性回归来计算每个值与平均值的距离:

```r
> model <- lm(hflights$DepDelay ~ 1)

```

为了验证我们现在确实在测量与平均值的距离:

```r
> model$coefficients

(Intercept) 

 9.444951 

> mean(hflights$DepDelay, na.rm = TRUE)

[1] 9.444951

```

现在让我们基于 F 分布和两个辅助变量来计算临界值(其中`a`代表 alpha 值，`n`代表病例数):

```r
> a <- 0.1

> (n <- length(hflights$DepDelay))

[1] 227496

> (F <- qf(1 - (a/n), 1, n-2, lower.tail = TRUE))

[1] 25.5138

```

这可以传递到隆德公式中:

```r
> (L <- ((n - 1) * F / (n - 2 + F))^0.5)

[1] 5.050847

```

现在，让我们看看有多少值的标准化残差高于计算出的临界值:

```r
> sum(abs(rstandard(model)) > L)

[1] 1684

```

但是我们真的必须从数据中剔除这些异常值吗？极值不是很正常吗？有时候，这些对原始数据的人为编辑，比如输入缺失值或移除异常值，会带来更多的麻烦。



# 使用稳健的方法

幸运的是，有一些分析数据集的可靠方法，这些方法通常对极值不太敏感。这些稳健的统计方法自 1960 年以来一直在发展，但还有一些更早的众所周知的相关方法，如使用中位数而不是平均值作为中心趋势。当我们的数据的基本分布不被认为符合高斯曲线时，通常会使用稳健方法，因此大多数良好的旧回归模型都不起作用(更多详细信息，请参见[第 5 章](ch05.html "Chapter 5. Building Models (authored by Renata Nemeth and Gergely Toth)")、*架构模型(Renata Nemeth 和 Gergely Toth 著)*和[第 6 章](ch06.html "Chapter 6. Beyond the Linear Trend Line (authored by Renata Nemeth and Gergely Toth)")、*超越线性趋势线(Renata Nemeth 和 Gergely Toth 著)*)。

让我们以传统的线性回归为例，根据花瓣长度和一些缺失数据来预测鸢尾花的萼片长度。为此，我们将使用之前定义的`miris`数据集:

```r
> summary(lm(Sepal.Length ~ Petal.Length, data = miris))

Call:

lm(formula = Sepal.Length ~ Petal.Length, data = miris)

Residuals:

 Min       1Q   Median       3Q      Max 

-1.26216 -0.36157  0.01461  0.35293  1.01933 

Coefficients:

 Estimate Std. Error t value Pr(>|t|) 

(Intercept)   4.27831    0.11721   36.50   <2e-16 ***

Petal.Length  0.41863    0.02683   15.61   <2e-16 ***

---

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.4597 on 92 degrees of freedom

 (56 observations deleted due to missingness)

Multiple R-squared:  0.7258,  Adjusted R-squared:  0.7228 

F-statistic: 243.5 on 1 and 92 DF,  p-value: < 2.2e-16

```

所以看起来我们对萼片和花瓣长度比的估计是在`0.42`左右，顺便说一下，这与实际值并不太远:

```r
> lm(Sepal.Length ~ Petal.Length, data = iris)$coefficients

 (Intercept) Petal.Length 

 4.3066034    0.4089223

```

估计系数和实际系数之间的差异是由于前面部分中人为引入的缺失值。我们能做出更好的估计吗？我们可以用前面提到的任何方法估算缺失的数据，或者我们应该从 `MASS`包用`Petal.Length`变量预测`Sepal.Length`来拟合稳健的线性回归:

```r
> library(MASS)

> summary(rlm(Sepal.Length ~ Petal.Length, data = miris))

Call: rlm(formula = Sepal.Length ~ Petal.Length, data = miris)

Residuals:

 Min       1Q   Median       3Q      Max 

-1.26184 -0.36098  0.01574  0.35253  1.02262 

Coefficients:

 Value   Std. Error t value

(Intercept)   4.2739  0.1205    35.4801

Petal.Length  0.4195  0.0276    15.2167

Residual standard error: 0.5393 on 92 degrees of freedom

 (56 observations deleted due to missingness)

```

现在，让我们比较针对原始(完整)和模拟数据(有缺失值)运行的模型的系数:

```r
> f <- formula(Sepal.Length ~ Petal.Length)

> cbind(

+     orig =  lm(f, data = iris)$coefficients,

+     lm   =  lm(f, data = miris)$coefficients,

+     rlm  = rlm(f, data = miris)$coefficients)

 orig        lm       rlm

(Intercept)  4.3066034 4.2783066 4.2739350

Petal.Length 0.4089223 0.4186347 0.4195341

```

老实说，标准的线性回归和稳健的版本没有太大的区别。惊讶吗？数据集完全随机地包含缺失值，但是如果数据集包含其他类型的缺失值或异常值，会发生什么呢？让我们通过模拟一些更脏的数据问题(将第一次观察的萼片长度从`1.4`更新到`14`——假设由于数据输入错误)并重建模型来验证这一点:

```r
> miris$Sepal.Length[1] <- 14

> cbind(

+     orig = lm(f, data = iris)$coefficients,

+     lm   = lm(f, data = miris)$coefficients,

+     rlm  = rlm(f, data = miris)$coefficients)

 orig        lm       rlm

(Intercept)  4.3066034 4.6873973 4.2989589

Petal.Length 0.4089223 0.3399485 0.4147676

```

看起来`lm`模型的性能下降了很多，而稳健模型的系数几乎与原始模型相同，而不管数据中的异常值。我们可以得出结论，当涉及到极值时，健壮方法是非常令人印象深刻和强大的工具！有关 R 中已经实现的相关方法的更多信息，请访问位于 http://cran.r-project.org/web/views/Robust.html[的](http://cran.r-project.org/web/views/Robust.html)相关 CRAN 任务视图。



# 总结

这一章集中讨论了数据分析中一些最困难的挑战，即如何清理数据，我们还讨论了关于缺失值和极值的最重要的主题。根据您感兴趣的领域或您工作的行业，脏数据可能是一个罕见的或主要的问题(例如，我过去见过一些项目将正则表达式应用于`JSON`文件以使其有效)，但我相信不管您的背景如何，您都会发现下一章非常有趣和有用——在那里我们将学习多元统计技术。