<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 使用 K-最近邻的分类

最近邻算法根据数据实例的邻居对其进行分类。由*k*-最近邻居算法确定的数据实例的类是在*k*-最近邻居中具有最高表示的类。

在本章中，我们将讨论以下主题:

*   如何以 Mary 和她的温度偏好为例实现 k-NN 算法的基础
*   以意大利地图为例，如何选择正确的 *k* 值，使算法能够正确执行并达到最高的精确度
*   如何使用房屋偏好示例来重新调整值并为 k-NN 算法做准备
*   如何选择一个好的度量标准来测量数据点之间的距离
*   如何在高维空间中消除不相关的维度，以确保使用文本分类示例的算法准确执行

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 玛丽和她的温度偏好

例如，如果我们知道我们的朋友 Mary 在 10°C 时感觉冷，但在 25°C 时感觉暖，那么在 22°C 的房间中，最近邻算法会猜测我们的朋友会感觉暖，因为 22 更接近 25 而不是 10。

假设我们想知道 Mary 什么时候感觉温暖，什么时候感觉寒冷，就像前面的例子一样，但是另外，当 Mary 被问到她感觉温暖还是寒冷时，风速数据也是可用的:

| **摄氏度温度** | **以千米/小时为单位的风速** | **玛丽的感知** |
| Ten | Zero | 寒冷 |
| Twenty-five | Zero | 温暖的 |
| Fifteen | five | 寒冷 |
| Twenty | three | 温暖的 |
| Eighteen | seven | 寒冷 |
| Twenty | Ten | 寒冷 |
| Twenty-two | five | 温暖的 |
| Twenty-four | six | 温暖的 |

我们可以用图表来表示数据，如下所示:

![](Images/32fcee24-5625-4abb-9ff4-48c0f241fca5.png)

现在，假设我们想通过使用 *1* -NN 算法来找出当温度为 16°C 且风速为 3 km/h 时 Mary 的感觉:

![](Images/b1ef3a61-29f6-4395-9904-a8fd36dfcff9.png)

为了简单起见，我们将使用曼哈顿度量来测量网格上邻居之间的距离。邻居 *N [1] =(x [1] ，y [1] )* 距离邻居 *N [2] =(x [2] ，y [2] )* 定义为 *d [人] =|x [1]*

让我们用邻近点周围的距离来标记格网，以查看哪一个具有已知类的邻近点最接近我们想要分类的点:

![](Images/b41d305d-64c1-4f53-aa2e-2146b7586056.png)

我们可以看到，已知类别的最近邻居是温度为 15°C(蓝色)且风速为 5 km/h 的邻居。它与问题点的距离为三个单位。其类为蓝色(冷)。最近的红色(温暖)邻居距离所讨论的点有四个单位的距离。由于我们使用的是 1-最近邻算法，我们只查看最近邻，因此，所讨论的点的类别应该是蓝色(冷)。

通过将此过程应用于每个数据点，我们可以完成图表，如下所示:

![](Images/fadf736f-c76e-4d57-9868-ba3d12a30639.png)

请注意，有时，一个数据点与两个已知类别的距离可能相同:例如，20°C 和 6 km/h。在这种情况下，我们可以优先选择一个类别，或者忽略这些边界情况。实际结果取决于算法的具体实现。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# k 近邻算法的实现

现在，我们将在 Python 中实现 k-NN 算法，以找到 Mary 的温度偏好。在本节的最后，我们还将实现上一节中产生的数据的可视化，即 *Mary 和她的温度偏好*。带有输入文件的完整的可编译代码可以在本书提供的源代码中找到。这里摘录并展示了最重要的部分:

```
# source_code/1/mary_and_temperature_preferences/knn_to_data.py # Applies the knn algorithm to the input data.
# The input text file is assumed to be of the format with one line per
# every data entry consisting of the temperature in degrees Celsius,
# wind speed and then the classification cold/warm.

import sys
sys.path.append('..')
sys.path.append('../../common')
import knn # noqa
import common # noqa

# Program start
# E.g. "mary_and_temperature_preferences.data"
input_file = sys.argv[1]
# E.g. "mary_and_temperature_preferences_completed.data"
output_file = sys.argv[2]
k = int(sys.argv[3])
x_from = int(sys.argv[4])
x_to = int(sys.argv[5])
y_from = int(sys.argv[6])
y_to = int(sys.argv[7])

data = common.load_3row_data_to_dic(input_file)
new_data = knn.knn_to_2d_data(data, x_from, x_to, y_from, y_to, k)
common.save_3row_data_from_dic(output_file, new_data)
```

```
# source_code/common/common.py # ***Library with common routines and functions*** def dic_inc(dic, key):
    if key is None:
        pass
    if dic.get(key, None) is None:
        dic[key] = 1
    else:
        dic[key] = dic[key] + 1
```

```
# source_code/1/knn.py
# ***Library implementing knn algorithm***

def info_reset(info):
    info['nbhd_count'] = 0
    info['class_count'] = {}

# Find the class of a neighbor with the coordinates x,y.
# If the class is known count that neighbor.
def info_add(info, data, x, y):
    group = data.get((x, y), None)
    common.dic_inc(info['class_count'], group)
    info['nbhd_count'] += int(group is not None)

# Apply knn algorithm to the 2d data using the k-nearest neighbors with
# the Manhattan distance.
# The dictionary data comes in the form with keys being 2d coordinates
# and the values being the class.
# x,y are integer coordinates for the 2d data with the range
# [x_from,x_to] x [y_from,y_to].
def knn_to_2d_data(data, x_from, x_to, y_from, y_to, k):
    new_data = {}
    info = {}
    # Go through every point in an integer coordinate system.
    for y in range(y_from, y_to + 1):
        for x in range(x_from, x_to + 1):
            info_reset(info)
            # Count the number of neighbors for each class group for
            # every distance dist starting at 0 until at least k
            # neighbors with known classes are found.
            for dist in range(0, x_to - x_from + y_to - y_from):
                # Count all neighbors that are distanced dist from
                # the point [x,y].
                if dist == 0:
                    info_add(info, data, x, y)
                else:
                    for i in range(0, dist + 1):
                        info_add(info, data, x - i, y + dist - i)
                        info_add(info, data, x + dist - i, y - i)
                    for i in range(1, dist):
                        info_add(info, data, x + i, y + dist - i)
                        info_add(info, data, x - dist + i, y - i)
                # There could be more than k-closest neighbors if the
                # distance of more of them is the same from the point
                # [x,y]. But immediately when we have at least k of
                # them, we break from the loop.
                if info['nbhd_count'] >= k:
                    break
            class_max_count = None
            # Choose the class with the highest count of the neighbors
            # from among the k-closest neighbors.
            for group, count in info['class_count'].items():
                if group is not None and (class_max_count is None or
                   count > info['class_count'][class_max_count]):
                    class_max_count = group
            new_data[x, y] = class_max_count
    return new_data
```

**输入**:

前面的程序将使用下面的文件作为输入数据的来源。该文件包含关于 Mary 的温度偏好的已知数据的表格:

```
# source_code/1/mary_and_temperature_preferences/
marry_and_temperature_preferences.data
10 0 cold
25 0 warm
15 5 cold
20 3 warm
18 7 cold
20 10 cold
22 5 warm
24 6 warm
```

**输出**:

我们通过对`k=1`邻居使用 k-NN 算法对`mary_and_temperature_preferences.data`输入文件运行前面的实现。该算法将矩形中所有具有整数坐标的点分类为大小为`(30-5=25) by (10-0=10)`的矩形，因此大小为`(25+1) * (10+1) = 286`整数点(加 1 以计算边界上的点)。使用`wc`命令，我们发现输出文件正好包含 286 行——每个点一个数据项。使用`head`命令，我们显示输出文件的前 10 行:

```
$ python knn_to_data.py mary_and_temperature_preferences.data mary_and_temperature_preferences_completed.data 1 5 30 0 10

$ wc -l mary_and_temperature_preferences_completed.data 
286 mary_and_temperature_preferences_completed.data

$ head -10 mary_and_temperature_preferences_completed.data 
7 3 cold
6 9 cold
12 1 cold
16 6 cold
16 9 cold
14 4 cold
13 4 cold
19 4 warm
18 4 cold
15 1 cold
```

**可视化**:

对于本章前面描述的可视化，使用了`matplotlib`库。加载一个数据文件，然后显示在散点图中:

```
# source_code/common/common.py
# returns a dictionary of 3 lists: 1st with x coordinates,
# 2nd with y coordinates, 3rd with colors with numeric values
def get_x_y_colors(data):
    dic = {}
    dic['x'] = [0] * len(data)
    dic['y'] = [0] * len(data)
    dic['colors'] = [0] * len(data)
    for i in range(0, len(data)):
        dic['x'][i] = data[i][0]
        dic['y'][i] = data[i][1]
        dic['colors'][i] = data[i][2]
    return dic
```

```
# source_code/1/mary_and_temperature_preferences/
mary_and_temperature_preferences_draw_graph.py import sys
sys.path.append('../../common')  # noqa
import common
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import matplotlib
matplotlib.style.use('ggplot')

data_file_name = 'mary_and_temperature_preferences_completed.data'
temp_from = 5
temp_to = 30
wind_from = 0
wind_to = 10

data = np.loadtxt(open(data_file_name, 'r'),
                  dtype={'names': ('temperature', 'wind', 'perception'),
                         'formats': ('i4', 'i4', 'S4')})

# Convert the classes to the colors to be displayed in a diagram.
for i in range(0, len(data)):
    if data[i][2] == 'cold':
        data[i][2] = 'blue'
    elif data[i][2] == 'warm':
        data[i][2] = 'red'
    else:
        data[i][2] = 'gray'
# Convert the array into the format ready for drawing functions.
data_processed = common.get_x_y_colors(data)

# Draw the graph.
plt.title('Mary and temperature preferences')
plt.xlabel('temperature in C')
plt.ylabel('wind speed in kmph')
plt.axis([temp_from, temp_to, wind_from, wind_to])
# Add legends to the graph.
blue_patch = mpatches.Patch(color='blue', label='cold')
red_patch = mpatches.Patch(color='red', label='warm')
plt.legend(handles=[blue_patch, red_patch])
plt.scatter(data_processed['x'], data_processed['y'],
            c=data_processed['colors'], s=[1400] * len(data))
plt.show()
```

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 意大利地图示例–选择 k 值

在我们的数据中，我们从意大利及其周边地区的地图中获得了一些点(大约 1%)。蓝色的点代表水，绿色的点代表陆地；白点未知。根据我们得到的部分信息，我们想预测白色区域是否有水或土地。

在图片中仅绘制 1%的地图数据会使其几乎不可见。如果我们从意大利及其周边地区的地图中获得大约 33 倍的数据，并将其绘制在图片中，它将如下所示:

![](Images/1d1458c9-b445-498b-81df-26d1aa0aed5a.png)<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 分析

对于这个问题，我们将使用 k-NN 算法— *k* 这里的意思是我们将查看*k*—最近邻。给定一个白点，如果它的大多数 *k* 最近邻居在水域中，它将被分类为水域，如果它的大多数 *k* 最近邻居是陆地，它将被分类为陆地。我们将使用距离的欧几里德度量:给定两点， *X=[x [0] ，X[1]*和 *Y=[y [0] ，Y[1]*，它们的欧几里德距离定义为 *d [欧几里德]= sqrt((X[0]-Y[0]*

欧几里德距离是最常见的度量。给定一张纸上的两点，它们的欧几里得距离就是用尺子测量的两点之间的长度，如下图所示:

![](Images/438d455d-c50a-4050-ad3c-8cc3c04594ae.png)

为了将 k-NN 算法应用于不完整的地图，我们必须选择 *k* 的值。由于一个点的结果类是该点最接近的邻居 *k* 的大多数的类， *k* 应该是奇数。让我们将这个算法应用于 *k=1，3，5，7，9* 的值。

将该算法应用于不完整地图上的每个白点将产生以下完整地图:

![](Images/3e30176a-ac73-4bfc-bc22-ad4e9582f5c6.png)

k=1

![](Images/a3ba0c09-c93a-42c0-946d-008ef6dfa6fc.png)

k=3

![](Images/d2adcc17-bafc-4e20-aaa0-c43d020f6745.png)

k=5

![](Images/00da5203-291f-40de-906e-8f24897be3d2.png)

k=7

![](Images/89bc78d7-4053-4586-83e2-49c105cf71bd.png) 

k=9

您可能已经注意到， *k* 的最高值会产生一个具有更平滑边界的完整地图。这里展示了一幅完整的意大利地图:

![](Images/822d8fb1-cae0-4f08-8fce-a4ed19eb02a3.png)

我们可以使用这个真实的、完整的图来计算不同的 *k* 值的错误分类点的百分比，以确定不同的 *k* 值的 k-NN 算法的准确性:

| **k** | **错误分类点的百分比** |
| one | Two point nine seven |
| three | Three point two four |
| five | Three point two nine |
| seven | Three point four |
| nine | Three point five seven |

因此，对于这种特定类型的分类问题，k-NN 算法对于 *k=1* 实现了最高的准确度(最小的错误率)。

然而，在现实生活中，问题是我们通常没有完整的数据或解决方案。在这种情况下，我们需要选择一个适合部分可用数据的值 *k* 。为此，请查阅本章末尾的*问题 4* 。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 房屋所有权——数据重新调整

对于每个人，我们知道他们的年龄，年收入，以及他们是否有房子:

| **年龄** | **美元年收入** | **房屋所有权状况** |
| Twenty-three | Fifty thousand | 非所有者 |
| Thirty-seven | Thirty-four thousand | 非所有者 |
| Forty-eight | Forty thousand | 物主 |
| fifty-two | Thirty thousand | 非所有者 |
| Twenty-eight | Ninety-five thousand | 物主 |
| Twenty-five | Seventy-eight thousand | 非所有者 |
| Thirty-five | One hundred and thirty thousand | 物主 |
| Thirty-two | One hundred and five thousand | 物主 |
| Twenty | One hundred thousand | 非所有者 |
| Forty | Sixty thousand | 物主 |
| Fifty | Eighty thousand | 彼得（男子名） |

![](Images/dca3b7cb-d007-4325-8adc-6da7a4c97381.png)

房屋所有权和年收入

我们的目标是预测 50 岁、年收入 80，000 美元的 Peter 是否拥有房子，是否可能成为我们保险公司的潜在客户。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 分析

在这种情况下，我们可以尝试应用 1-NN 算法。然而，我们应该小心如何测量数据点之间的距离，因为收入范围比年龄范围宽得多。11.5 万美元和 11.6 万美元的收入水平相差 1000 美元。这些收入的两个数据点会相差很远。然而，相对于彼此，这些数据点之间的差异实际上并没有那么大。因为我们认为这两个指标(年龄和年收入)几乎同等重要，所以我们将根据以下公式从 0 到 1 来衡量这两个指标:

![](Images/d7f80a4f-06bb-4927-95df-4173f07c1cf3.png)

在我们的特殊情况下，这可以归结为以下几点:

![](Images/ce5dc1b8-a7ce-4089-b54b-3974f5cf909a.png)

![](Images/1d4d1412-e788-4d98-8880-3ebf69fc1b26.png)

缩放后，我们得到以下数据:

| **年龄** | **换算年龄** | **美元年收入** | **换算年收入** | **房屋所有权状况** |
| Twenty-three | 0.09375 | Fifty thousand | Zero point two | 非所有者 |
| Thirty-seven | 0.53125 | Thirty-four thousand | Zero point zero four | 非所有者 |
| Forty-eight | Zero point eight seven five | Forty thousand | Zero point one | 物主 |
| fifty-two | one | Thirty thousand | Zero | 非所有者 |
| Twenty-eight | Zero point two five | Ninety-five thousand | Zero point six five | 物主 |
| Twenty-five | 0.15625 | Seventy-eight thousand | Zero point four eight | 非所有者 |
| Thirty-five | 0.46875 | One hundred and thirty thousand | one | 物主 |
| Thirty-two | Zero point three seven five | One hundred and five thousand | Zero point seven five | 物主 |
| Twenty | Zero | One hundred thousand | Zero point seven | 非所有者 |
| Forty | Zero point six two five | Sixty thousand | Zero point three | 物主 |
| Fifty | 0.9375 | Eighty thousand | Zero point five | ？ |

现在，如果我们应用 1-NN 算法和欧几里德度量，我们会发现彼得很可能拥有一栋房子。请注意，如果不进行重新调整，算法会产生不同的结果。更多信息请参考*练习 1.5* 。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 文本分类–使用非欧几里德距离

对于信息学和数学主题分类中的类别文档，我们给出了与关键字**算法**和**计算机**相关的以下字数:

| **每千人算法字数** | **每 1000 人的计算机单词数** | **主题分类** |
| One hundred and fifty-three | One hundred and fifty | 信息学 |
| One hundred and five | Ninety-seven | 信息学 |
| Seventy-five | One hundred and twenty-five | 信息学 |
| Eighty-one | Eighty-four | 信息学 |
| Seventy-three | Seventy-seven | 信息学 |
| Ninety | Sixty-three | 信息学 |
| Twenty | Zero | 数学 |
| Thirty-three | Zero | 数学 |
| One hundred and five | Ten | 数学 |
| Two | Zero | 数学 |
| Eighty-four | Two | 数学 |
| Twelve | Zero | 数学 |
| Forty-one | forty-two | ？ |

那些单词**算法**和**计算机**出现频率高的文档属于`informatics`类。在某些情况下，`mathematics`类恰好包含单词**算法**出现频率较高的文档，例如，与数论领域的欧几里德算法相关的文档。但是，由于`mathematics`类在算法领域的应用比`informatics`少，单词 **computer** 在文档中出现的频率更低。

我们想对每 1000 个单词中有 41 个单词**算法**实例，每 1000 个单词中有 42 个单词**计算机**实例的文档进行分类:

![](Images/d58149ae-c5d9-458e-b369-b2c2249c17dc.png)

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 分析

例如，使用 1-NN 算法和曼哈顿或欧几里德距离将导致所讨论的文档被分配到`mathematics`类。然而，直觉上，我们应该使用不同的度量来度量距离，因为所讨论的文档中单词 **computer** 的出现频率比其他已知文档中的`mathematics`要高得多。

这个问题的另一个候选度量是测量单词的比例或文档中实例之间的角度的度量。代替角度，你可以取角度的余弦， *cos(θ)* ，然后用众所周知的点积公式计算 *cos(θ)* 。

我们用 *a=(a [x] ，a [y] ，b=(b [x] ，b [y] )* 。使用以下公式:

![](Images/ec9b933f-2f8c-4aaa-89f8-f8a64ddcbe2a.png)

这将得出以下结果:

![](Images/39906b59-4478-4f29-82d0-66365f6a52bf.png)

使用余弦距离度量，您可以将有问题的文档归类到`informatics`类:

![](Images/7c0a52f7-1e42-4cff-8f2c-d1ebc92ae0ec.png)

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 文本分类——高维 k-NN

假设我们得到了一些文档，并希望根据它们的词频计数对其他文档进行分类。例如，在钦定版圣经的古腾堡计划电子书中发现的 120 个最频繁出现的单词如下:

![](Images/e554f3ad-cab2-4a87-8abe-af4546dde5c2.png)

任务是设计一个度量，给定每个文档的词频，它将准确地确定这些文档在语义上有多接近。因此，k-NN 算法可以使用这种度量来基于现有文档对新文档中的未知实例进行分类。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 分析

假设我们考虑，例如， *N* 在我们的文档语料库中最频繁出现的单词。然后，我们统计给定文档中每个 *N* 单词的词频，并将它们放入一个代表该文档的 *N* 维向量中。然后，我们将两个文档之间的距离定义为这些文档的两个单词频率向量之间的距离(例如，欧几里德距离)。

这种解决方案的问题是，只有某些单词代表了书的实际内容，其他单词由于语法规则或其一般基本含义而需要出现在文本中。例如，在圣经中最常出现的 120 个单词中，每个单词都有不同的重要性。在下表中，我们突出显示了在圣经中出现频率高且具有重要意义的单词:

| 

121.  -Main use 1.00%
122.  -God uses 0.56%

 | 

123.  At-0.32%
124.  Wang-0.32%

 | 

 |

例如，这些词不太可能出现在数学课本中，但更可能出现在与宗教或基督教有关的课本中。

然而，如果我们只看圣经中最常见的六个词，它们对于探测文本的意义就不那么有用了:

| 

2.  -8.07%

 | 

3.  -4.37%
4.  -1.72%

 | 

5.  Represents-1.63%
6.  Represents-1.60%

 |

与数学、文学和其他主题相关的文本中这些单词的出现频率相似。差异可能主要源于写作风格。

因此，为了确定两个文档之间的相似性距离，我们只需要查看重要单词的频率计数。一些单词不太重要，这些维度最好减少，因为它们的包含最终会导致对结果的误解。因此，我们剩下要做的是选择对我们的语料库中的文档进行分类重要的词(维度)。为此，请参考*问题 6* 。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 摘要

在本章中，我们了解到*k*-最近邻算法是一种分类算法，它将*k*-最近邻中的大多数类分配给给定的数据点。两点之间的距离是用公制来测量的。我们讨论了距离的例子，包括欧几里德距离、曼哈顿距离、切向距离和余弦距离。我们还讨论了各种参数的实验和交叉验证如何帮助确定应该使用哪个参数 *k* 和哪个指标。

我们还了解到数据点的维度和位置是由其质量决定的。大量的维数会导致 k-NN 算法的低精度。减少不太重要的质量的维度可以提高准确性。类似地，为了进一步提高准确性，每个维度的距离应该根据该维度质量的重要性进行缩放。

在下一章中，我们将研究朴素贝叶斯算法，它使用贝叶斯定理基于概率方法对元素进行分类。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 问题

在本节中，我们将讨论以下问题:

*   玛丽和她的温度偏好问题
*   意大利地图–选择 *k* 的值
*   房屋所有权

为了以尽可能好的方式从本章的材料中学习，请在查看本章末尾的*分析*部分之前，先自己分析这些问题。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 玛丽和她的温度偏好问题

**问题 1** :假设你知道你的朋友玛丽在-50℃的时候感觉很冷，但是在 20℃的时候她感觉很温暖，那么 1-NN 算法会对玛丽说什么？在 22、15 和-10 的温度下，她会感到温暖还是寒冷？你认为算法正确预测了玛丽的身体对温度的感知吗？如果不是，请给出您的原因，并建议为什么算法没有给出适当的结果，以及算法需要改进哪些地方才能做出更好的分类。

**问题 2** :你认为对于 *k* > 1，1-NN 算法会比使用 *k* -NN 算法产生更好的结果吗？

**问题 3** :我们收集了更多的数据，发现玛丽在 17°C 时感觉温暖，但在 18°C 时感觉寒冷，用我们自己的常识来说，温度越高玛丽应该感觉更温暖。你能解释一下数据差异的可能原因吗？我们如何改进我们的数据分析？我们是否也应该收集一些非温度数据？假设我们有唯一可用的温度数据；你认为使用这样的数据，T2 1 T3 神经网络算法会产生更好的结果吗？对于 *k* -NN 算法应该如何选择 *k* 才能表现良好？

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 意大利地图-选择 k 值

**问题 4** :意大利地图问题给我们一张意大利的局部地图。然而，假设没有完整的数据。因此，对于不同的 *k* 值，我们不能计算所有预测点的误差率。对于 *k* -NN 算法，你应该如何选择 *k* 的值，以最大化其精度来完成意大利地图？

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 房屋所有权

**问题 5** :使用与房屋所有权问题相关的部分的数据，通过使用欧几里德度量找到与彼得最近的邻居:

a)不重新调整数据

b)通过使用缩放的数据

是最近的邻居:

a)与邻居在？

b)哪一个邻居拥有这所房子？

**问题 6** :假设你想通过使用某种度量和 1-NN 算法，在古腾堡的语料库(【www.gutenberg.org】)中找到与语料库中某一选定书籍(例如《圣经》)相似的书籍或文档。你将如何设计一个度量两本书之间相似距离的标准？

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 分析

**问题 1**:8°C 更接近于 20°C，而不是-50°C。因此，算法会将 Mary 归类为在-8°C 感觉温暖。但如果我们使用我们的常识和知识，这不太可能是真的。在更复杂的例子中，我们可能会被分析的结果所迷惑，并由于缺乏专业知识而做出错误的结论。但是请记住，数据科学利用的是实质性的专业知识，而不仅仅是数据分析。为了得出合理的结论，我们应该对问题和我们的数据有很好的理解。

该算法进一步指出，在 22 摄氏度时，玛丽应该感觉温暖，这是毫无疑问的，因为 22 摄氏度高于 20 摄氏度，温度越高，人类感觉越温暖；再一次，这是对我们知识的微不足道的利用。对于 15 摄氏度，算法会认为玛丽感到温暖，但如果我们使用我们的常识，我们可能不确定这一说法。

为了能够使用我们的算法产生更好的结果，我们应该收集更多的数据。例如，如果我们发现玛丽在 14 摄氏度时感觉寒冷，那么我们有一个非常接近 15 摄氏度的数据实例，因此，我们可以更有把握地猜测玛丽在 15 摄氏度时会感觉寒冷。

**问题 2** :我们正在处理的数据只是一维的，同样被分割成冷、暖两部分，具有如下性质:温度越高，一个人感觉越温暖。此外，即使我们知道玛丽在-40、-39、…、39 和 40 的温度下感觉如何，我们仍然只有非常有限的数据实例——大约每摄氏度只有一个实例。出于这些原因，最好只看一个最近的邻居。

问题 3 :数据中的差异可能是由测试中的不准确性造成的。这可以通过进行更多的实验来缓解。

除了不准确之外，可能还有其他因素影响玛丽的感受:例如，风速、湿度、阳光、玛丽穿得多暖和(她是穿了一件外套配牛仔裤，还是只穿了一件无袖上衣的短裤，甚至是一件游泳衣)，以及她是湿还是干。我们可以将这些额外的维度(风速和她的穿着)添加到我们的数据点向量中。这将为算法提供更多、更高质量的数据，因此可以预期更好的结果。

如果我们只有温度数据，但有更多的数据(例如，每摄氏度有 10 个分类实例)，那么我们可以增加 *k* 值，并查看更多的邻居以更准确地确定温度。但是这完全依赖于数据的可用性。我们可以修改算法，以基于某个距离内的所有邻居 *d* 进行分类，而不是基于 *k* 最近的邻居进行分类。这将使算法在两种情况下都能很好地工作，一种情况是当我们有很多数据在很近的距离内，另一种情况是当我们只有一个数据实例接近我们想要分类的实例。

**问题 4** :为此，你可以使用交叉验证(参考*附录 A-统计*中的*交叉验证*部分)来确定精度最高的 *k* 的值。您可以将来自意大利局部地图的可用数据分成学习和测试数据，例如，地图上 80%的分类像素将交给 k-NN 算法来完成地图。然后，来自部分图的剩余 20%的分类像素将用于根据 k-NN 算法计算具有正确分类的像素的百分比。

**问题 5** :

a)在不重新调整数据的情况下，Peter 最近的邻居年收入为 78，000 美元，年龄为 25 岁。这个邻居没有房子。

b)重新调整数据后，Peter 最近的邻居年收入为 60，000 美元，年龄为 40 岁。这个邻居拥有一栋房子。

**问题 6** :为了设计一个能够精确测量两个文档之间相似性距离的度量标准，我们需要选择重要的词来构成文档的频率向量的维度。不确定文档语义的单词在所有文档中具有近似相似的频率计数。因此，我们可以生成一个列表，列出文档的相对词频。例如，我们可以使用以下定义:

![](Images/53ecdce7-22e4-4db7-95d3-283325d8a832.png)

然后，文档可以由具有最高相对频率计数的 *N* 个单词的词频组成的 *N* 维向量来表示。这样的向量将倾向于由比具有最高频率计数的 *N* 个字的向量更重要的字组成。