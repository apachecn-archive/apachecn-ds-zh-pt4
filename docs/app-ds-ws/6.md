

# 五、模型验证和优化

概观

在本章中，您将学习如何使用 k-fold 交叉验证来测试模型性能，以及如何使用验证曲线来优化模型参数。您还将学习如何实现降维技术，如**主成分分析** ( **PCA** )。到本章结束时，你将完成一个端到端的机器学习项目，并产生一个可用于做出商业决策的最终模型。

# 简介

正如我们在前面的章节中看到的，用 scikit-learn 训练模型很容易，只需要几行 Python 代码。通过抽象出算法的计算复杂性，包括诸如构建成本函数和优化模型参数的细节，这是可能的。换句话说，我们处理的是一个*黑盒*，其中的内部操作对我们是隐藏的。

虽然这种方法提供的简单性从表面上看很好，但它并不能防止算法的滥用，例如，为数据集选择错误的模型，对训练集过度拟合，或者无法对看不见的数据进行正确的测试。

在本章中，我们将向您展示如何在训练分类模型时避免这些陷阱，并为您提供生成可信结果的工具。我们将介绍 k-fold 交叉验证和验证曲线，然后看看在 Jupyter 中使用它们的方法。

我们还将介绍降维的主题，并了解如何使用它以及 k-fold 交叉验证来执行模型选择。我们将把这些技术应用到我们的人力资源分析数据集模型中，以构建和呈现优化的最终解决方案。

本章的主题对于现实世界的机器学习问题非常实用。这里提供的信息和代码将使您能够构建对看不见的数据表现良好的预测模型，这是生产模型的一个重要属性。首先，我们将学习 k 重交叉验证。

# 使用 k 倍交叉验证评估模型

到目前为止，我们已经在数据子集上训练了模型，然后评估了不可见部分(称为测试集)的性能。这是一种很好的做法，因为模型在用于训练的数据上的表现并不能很好地表明它作为预测器的有效性。很容易通过过度拟合模型来提高训练数据集的准确性，这会导致对看不见的数据的性能较差。

也就是说，仅仅根据这样分割的数据训练模型是不够的。根据训练和测试的不同，数据中存在自然的差异，这种差异会导致精确度不同(即使是很小的差异)。此外，仅使用一个训练/测试分割来比较模型会引入对某些模型的偏差，并导致过度拟合。

**k-Fold 交叉验证**为这个问题提供了一个解决方案，并允许通过每次精度计算的误差估计来解释方差。

下图说明了 k 倍交叉验证的方法，从中我们可以看到如何从数据集中选择 k 倍:

![Figure 5.1: Illustration of k-fold cross validation
](img/B15916_05_01.jpg)

图 5.1:k 倍交叉验证图解

注意

图片来源:CC BY-SA 4.0:[https://commons . wikimedia . org/wiki/File:K-fold _ cross _ validation _ en . SVG](https://commons.wikimedia.org/wiki/File:K-fold_cross_validation_EN.svg)。

记住上图，k 重交叉验证算法的工作方式如下:

1.  将数据分割成 k 个大小接近相等的*折叠*。
2.  在不同的折叠组合上测试和训练 k 个模型，其中每个模型包括 k-1 个折叠的训练数据，并使用*省略的*折叠作为验证集。在这种方法中，每个折叠恰好被用作一次测试数据。
3.  通过取 k 个精度值的平均值来计算模型精度。还计算标准偏差以提供该值的误差估计。

设置 *k = 10* 是标准的，但是如果你使用一个大的数据集，应该考虑更小的 *k* 值。

这种验证方法可以用来比较不同超参数的模型性能，比使用单一训练测试数据分割更可靠，正如我们在*第 4 章*、*训练分类模型*中所做的那样。例如，我们可以使用 k-fold 交叉验证来优化 SVM 的 C 值或 KNN 分类器的 *k* (最近邻的数量)的值。

尽管 k-fold 交叉验证涉及多次将数据分成测试集和验证集，但是在该算法中应该只包括整个数据集的一个子集。这可以通过从整个数据集中留出一个随机记录样本，并保留大多数记录用于训练和 k 重交叉验证来实现。被搁置的记录将在以后的模型开发中用于测试目的。

这是我们第一次使用术语**超参数**。它引用一个在初始化模型时定义的参数，例如，我们前面提到的 SVM 和 KNN 分类器的参数，或者决策树的最大深度。相比之下，机器学习中的术语*参数*指的是在训练期间确定的模型变量，例如用于训练的 SVM 的决策边界超平面上的系数，或者通过线性回归模型学习的权重。

一旦确定了最佳模型，在生产中使用它之前(即，在使用它进行预测之前)，对整个数据集进行重新训练通常是有益的。这样，我们将模型暴露给所有可用的数据，以便它有机会从数据集中的所有模式中学习。

当用 scikit-learn 实现这一点时，通常使用普通 k-fold 算法的稍微改进的变体。这叫做**分层 k 倍**。改进之处在于分层 k-fold 交叉验证在折叠中保持了大致均匀的类别标签群体。可以想象，这减少了模型中的总体方差，并降低了高度不平衡的模型导致偏差的可能性。

## 用验证曲线调整超参数

k 重交叉验证自然有助于使用验证曲线来调整模型参数。如下图所示，验证曲线将模型准确性绘制为超参数的函数，如随机森林中使用的决策树数量或(如前所述)最大深度。通过了解如何解读这些图表，我们可以做出明智的超参数选择。

注意

像大多数 scikit-learn 文档一样，为验证曲线提供的信息非常丰富，值得一读。这包括我们将在本章中用于创建和绘制验证曲线的配方。您可以在以下网址阅读相关信息:

[https://scikit-learn.org/stable/modules/learning_curve.html](https://scikit-learn.org/stable/modules/learning_curve.html)。

考虑这条验证曲线，其中准确度分数被绘制为`gamma` SVM 超参数的函数:

![Figure 5.2: Validation curve for an SVM model
](img/B15916_05_02.jpg)

图 5.2:SVM 模型的验证曲线

注意

图片来源:[https://scikit-learn . org/stable/auto _ examples/model _ selection/plot _ validation _ curve . html](https://scikit-learn.org/stable/auto_examples/model_selection/plot_validation_curve.html)。

从图的左侧开始，我们可以看到训练数据(橙色，顶行)和测试数据(蓝色，底行)产生了相同的分数。这很好，因为这意味着模型可以很好地推广到看不见的数据。不过分数相对于其他`gamma`值也是相当低的；因此，我们说模型对数据拟合不足。

增加`gamma`的值，我们可以看到这两条线的误差线不再重叠的一个点。从这一点开始，分类器无法对看不见的数据进行很好的归纳，因为它对训练集进行了过度拟合。随着`gamma`的继续增加，我们可以看到测试数据的分数急剧下降，而训练数据的分数继续增加。

`gamma`参数的最佳值可以通过寻找每条线上误差线仍然重叠的高测试数据分数来找到。

请记住，某些超参数的验证曲线仅在其他超参数保持不变时有效。例如，如果在这个图中训练 SVM，我们可以决定选择伽玛为 10-4。然而，我们可能也想优化 C 参数。对于不同的 C 值，前面的图将会不同，我们对γ的选择可能不再是最佳的。

要处理这样的问题，你可以研究一下**网格搜索算法**。这些都可以通过 scikit 获得——学习并使用我们在这里讨论过的许多相同的想法。网格搜索就像一条更高维的验证曲线。例如，在`gamma = [10-5, 10-4, 10-3]`和`C = [0.1, 1, 10]`上的网格搜索将训练和测试九组模型，每组模型对应一个 gamma 和 c 的组合。可以想象，随着超参数的数量及其范围的增加，这很容易变得计算密集型。

既然我们已经了解了 k-fold 交叉验证和验证曲线如何工作的基本知识，是时候继续本章的动手操作部分了。我们将打开 Jupyter 笔记本，继续为员工保留问题构建模型。

## 练习 5.01:通过 scikit-learn 在 Python 中使用 k-Fold 交叉验证和验证曲线

在本练习中，您将在 Python 中实现 k-fold 交叉验证和验证曲线，并学习如何使用这些方法在 Jupyter 笔记本中评估模型和调整超参数。执行以下步骤来完成本练习:

1.  Create a new notebook using one of the following commands:

    JupyterLab (run `jupyter lab` )

    Jupyter 笔记本(运行`jupyter notebook`)

    然后，按照终端中的提示，通过复制并粘贴 URL，在 web 浏览器中打开所选平台。

2.  加载以下库并为笔记本设置绘图设置:

    ```py
    import pandas as pd
    import numpy as np
    import datetime
    import time
    import os
    import matplotlib.pyplot as plt
    %matplotlib inline
    import seaborn as sns
    %config InlineBackend.figure_format='retina'
    sns.set() # Revert to matplotlib defaults
    plt.rcParams['figure.figsize'] = (8, 8)
    plt.rcParams['axes.labelpad'] = 10
    sns.set_style("darkgrid")
    %load_ext watermark
    %watermark -d -v -m -p \
    numpy,pandas,matplotlib,seaborn,sklearn
    ```

3.  Start by loading the preprocessed training data (the same dataset we worked with in the previous chapter). Load the table by running the cell with the following code:

    ```py
    df = pd.read_csv('../data/hr-analytics/hr_data_processed.csv')
    ```

    注意

    提醒一下，你可以在 https://packt.live/2YE90iC 找到这个文件。

    在本练习中，您将使用与上一章相同的两个特性:`satisfaction_level`和`last_evaluation`。

    正如前面提到的 k-fold 交叉验证，您仍然需要将整个数据集分成训练和验证集以及测试集。您将在本练习中使用训练集和验证集，并在稍后的模型选择中使用测试集。

4.  通过运行以下命令设置训练数据:

    ```py
    from sklearn.model_selection import train_test_split
    features = ['satisfaction_level', 'last_evaluation']
    X, X_test, \
    y, y_test = train_test_split(df[features].values, \
                                 df['left'].values, \
                                 test_size=0.15, \
                                 random_state=1)
    ```

5.  Use a decision tree with `max_depth=5` to instantiate a model for k-fold cross validation

    ```py
    from sklearn.tree import DecisionTreeClassifier
    clf = DecisionTreeClassifier(max_depth=5)
    ```

    此时，您还没有执行任何有趣的计算。您已经简单地准备了一个模型对象`clf`，并定义了它的超参数(例如，`max_depth`)。

6.  To run the stratified k-fold cross validation algorithm, use the `model_selection.cross_val_score` function from scikit-learn and print the resulting score by running the following code:

    ```py
    from sklearn.model_selection import cross_val_score
    np.random.seed(1)
    scores = cross_val_score(estimator=clf, X=X, \
                             y=y, cv=10,)
    print('accuracy = {:.3f} +/- {:.3f}'.format(scores.mean(), \
                                                scores.std(),))
    ```

    在这里，您使用分层 k-fold 验证来训练我们的`clf`模型的`10`变体。注意，scikit-learn 的`cross_val_score`在默认情况下进行这种类型的验证(分层)。

    您使用`np.random.seed`来设置随机数生成器的种子，从而确保任何依赖于随机数的计算的可重复性。在这种情况下，您设置种子以确保分层 k-fold 交叉验证中每个折叠的随机选择样本的可重复性。

    请注意，您打印了每个折叠的平均准确度和标准偏差。您也可以通过查看`scores`变量来查看每个折叠的单独精度。

7.  Insert a new cell and run `print(scores)`. You should see the following output:

    ```py
    [0.92241379 0.91529412 0.92784314 0.92941176 0.9254902  0.92705882
     0.91294118 0.91607843 0.92229199 0.9277865 ]
    ```

    使用`cross_val_score`是完成 k-fold 交叉验证的一种方便的方法，但是它不能告诉你每个类中的精度。由于您的问题对每个类的准确性很敏感(正如在前面章节的练习中所确定的)，您将需要手动实现 k-fold 交叉验证，以便我们可以获得这些信息。特别是，您对 class 1 的准确性感兴趣，它代表已经离开的员工。

8.  Define a custom class for calculating k-fold cross validation class accuracies by running the following code:

    ```py
    from sklearn.model_selection import StratifiedKFold
    from sklearn.metrics import confusion_matrix
    def cross_val_class_score(clf, X, y, cv=10):
        kfold = (StratifiedKFold(n_splits=cv).split(X, y))
        class_accuracy = []
        for k, (train, test) in enumerate(kfold):
            clf.fit(X[train], y[train])
            y_test = y[test]
            y_pred = clf.predict(X[test])
            cmat = confusion_matrix(y_test, y_pred)
            class_acc = cmat.diagonal()/cmat.sum(axis=1)
            class_accuracy.append(class_acc)
            print('fold: {:d} accuracy: {:s}'.format(k+1, \
                                                     str(class_acc),))
        return np.array(class_accuracy)
    ```

    您可以使用 scikit-learn 中的`model_selection.StratifiedKFold`类手动实现 k 重交叉验证。该类将折叠数作为初始化参数，并提供 split 方法来为数据构建随机采样掩码。在这种情况下，**掩码**只是一个包含另一个数组中的项目索引的数组，其中的项目可以通过运行像`data[mask]`这样的代码返回。

9.  Having defined this function, you can now calculate the class accuracies with code that's very similar to `model_selection.cross_val_score` from before. Do this by running the following code:

    ```py
    np.random.seed(1)
    scores = cross_val_class_score(clf, X, y)
    print('accuracy = {} +/- {}'.format(scores.mean(axis=0), \
                                        scores.std(axis=0),))
    ```

    当折叠被迭代并且 10 个模型被训练时，这将打印以下输出:

    ```py
    fold: 1 accuracy: [0.98559671 0.72039474]
    fold: 2 accuracy: [0.98559671 0.68976898]
    fold: 3 accuracy: [0.98971193 0.72937294]
    fold: 4 accuracy: [0.98765432 0.74257426]
    fold: 5 accuracy: [0.99074074 0.71617162]
    fold: 6 accuracy: [0.98971193 0.72607261]
    fold: 7 accuracy: [0.98251029 0.68976898]
    fold: 8 accuracy: [0.98559671 0.69306931]
    fold: 9 accuracy: [0.98455201 0.72277228]
    fold: 10 accuracy: [0.98352214 0.74917492]
    accuracy = [0.98651935 0.71791406] +/- [0.00266409 0.0200439 ]
    ```

    这些输出显示等级精度，其中第一个值对应于等级`0`，第二个值对应于等级`1`。

    已经看到了 k-fold 交叉验证的运行，我们将继续验证曲线的主题。这些可以用 scikit-learn 轻松生成。

10.  Calculate validation curves with `model_selection.validation_curve`. This function uses stratified k-fold cross validation to train models for various values of a specified hyperparameter. Perform the calculations required to plot a validation curve by running the following code:

    ```py
    from sklearn.model_selection import validation_curve
    clf = DecisionTreeClassifier()
    max_depth_range = np.arange(3, 20, 1)
    np.random.seed(1)
    train_scores, \
    test_scores = validation_curve(estimator=clf, \
                                   X=X, y=y, \
                                   param_name='max_depth', \
                                   param_range=max_depth_range, \
                                   cv=5,);
    ```

    通过运行这个，您已经在`max_depth`值的范围内训练了一组决策树。这些值在`max_depth_range = np.arange(3, 20, 1)`行中定义，对应于`[3, 4, … 18, 19]`数组——即从`max_depth=3`到`max_depth=20`，步长为 1。

    `validation_curve`函数将返回一组模型的交叉验证(训练和测试)分数数组，其中每个模型都有一个不同的`max_depth`变量。

11.  To visualize the results, leverage a function provided in the scikit-learn documentation:

    注意

    下面代码片段中显示的三重引号(`"""`)用于表示多行代码注释的起点和终点。注释被添加到代码中以帮助解释特定的逻辑。

第 5 章 _ 工作簿. ipynb

```py
def plot_validation_curve(train_scores, \
                          test_scores, \
                          param_range, \
                          xlabel='', \
                          log=False, \
):
    """This code is from scikit-learn docs (BSD License).
    http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html
    """
    train_mean = np.mean(train_scores, axis=1)
    train_std = np.std(train_scores, axis=1)
    test_mean = np.mean(test_scores, axis=1)
    test_std = np.std(test_scores, axis=1)
```

这一步的完整代码可以在[https://packt.live/37vgad6](https://packt.live/37vgad6)找到。

这将导致下图:

![Figure 5.3: Validation curve for a decision tree
](img/B15916_05_03.jpg)

图 5.3:决策树的验证曲线

为决策树设置`max depth`参数控制欠拟合和过拟合之间的平衡。这反映在验证曲线中，我们可以看到小的最大深度值的低精度(欠拟合)，因为我们不允许决策树创建足够的分支来捕获数据中的模式。

对于图表右侧较大的`max depth`值，我们可以看到相反的情况发生，因为这里的决策树过度拟合了训练数据。我们的验证准确性(红色方块)随着最大深度的增加而降低，这一事实证明了这一点。

请注意，随着最大深度的增加，训练精度(蓝色圆圈)继续增加。这是因为决策树能够在训练数据中捕获越来越详细的模式。通过观察验证的准确性，我们可以看到这些模式对于看不见的数据不能很好地推广。

根据这个图表，`max_depth`的一个好值似乎是`6`。此时，我们可以看到验证精度已经达到最大值，并且训练和验证精度是一致的(在误差范围内)。

注意

要访问该特定部分的源代码，请参考[https://packt.live/30GTi9a](https://packt.live/30GTi9a)。

你也可以在[https://packt.live/2BcG5tP](https://packt.live/2BcG5tP)在线运行这个例子。

总之，我们已经学习并实现了两种构建可靠预测模型的重要技术。

第一个这样的技术是 k-fold 交叉验证，其中我们在数据的不同子集上训练和验证一组模型，以便为单个模型选择生成各种精度测量。从这个集合中，我们计算出平均精度和标准偏差。这个标准差是一个重要的误差指标，用来衡量我们所选模型的可变性。

我们在这一部分探索的第二个技术是验证曲线。通过在我们选择的超参数范围内比较训练和验证精度(由 k-fold 交叉验证生成),验证曲线使我们能够直观地看到模型何时欠拟合或过拟合，并帮助我们确定最佳超参数值。

在下一节中，我们将介绍降维的概念以及它为什么对训练模型有用。然后，我们将它应用于人力资源分析数据集，并重温本节的主题，以便训练预测员工流动的高度准确的模型。

# 利用主成分分析进行降维

**降维**可以简单到从训练数据中删除不重要的特征。然而，移除一组特征是否会提高模型性能通常并不明显。即使是高噪声的特征也可能提供模型可以学习的一些有价值的信息。出于这些原因，我们应该了解降低数据维数的更好方法，例如:

*   **主成分分析** ( **PCA** )
*   **线性判别分析** ( **LDA** )

这些技术允许数据压缩，其中来自一大组特征的最重要的信息可以编码在仅仅几个特征中。

在本节中，我们将重点讨论 PCA。这种技术通过将数据投影到正交主分量的新子空间来转换数据，其中具有最高特征值的分量(如本文所述)编码了用于训练模型的最多信息。然后，我们可以简单地选择一组主成分来代替原始的高维数据集。要选择的主成分的数量将取决于特定数据集的细节，但它应该是原始特征集的合理百分比。

例如，PCA 可用于对图像中每个像素的信息进行编码。在这种情况下，原始特征空间的维数等于图像中的像素数。这种高维空间然后可以用 PCA 来减少，其中用于训练预测模型的大部分有用信息可以减少到仅仅几个维度。这不仅可以节省训练和使用模型的时间，还可以通过消除数据集中的噪声来提高模型的性能。

类似于我们在本书中讨论和实现的算法，没有必要为了利用它的好处而对 PCA 有详细的理解。然而，在用 scikit-learn 实现 PCA 之前，我们将进一步挖掘技术细节，以便对底层算法有所了解。

PCA 的关键见解是基于相关性识别特征之间的模式，以便 PCA 算法计算协方差矩阵，然后将其分解为特征向量和特征值。然后，向量被用于将数据变换到新的子空间中，从该子空间中可以选择固定数量的主分量。通过这个过程，我们有效地查看高维数据集，并找到一组遵循大方差方向的向量，从而可以在更少的维度上编码大部分总信息。

在下面的练习中，我们将看一个如何使用 PCA 来降低人力资源分析数据集维度的例子。

## 练习 5.02:使用主成分分析进行降维

在使用人力资源分析数据集训练了各种预测员工流动的模型之后，我们仍然没有使用我们所拥有的大多数功能。在本练习中，我们将迈出使用这些功能的第一步。

首先，您将了解一种建模技术，该技术计算哪些要素对预测最有影响。然后，使用这些所谓的“特征重要性”，您将创建一个选择良好特征进行降维的策略。最后，您将学习如何用 scikit-learn 实现 PCA。执行以下步骤来完成本练习:

1.  Starting at the point in the notebook where the previous exercise ended, load the preprocessed dataset and print the columns by running the following code. This is the same table that you used in the previous exercise:

    ```py
    df = pd.read_csv('../data/hr-analytics/hr_data_processed.csv')
    df.columns
    ```

    以下是前面命令的输出:

    ![Figure 5.4: The columns of hr_data_processed.csv
    ](img/B15916_05_04.jpg)

    图 5.4:HR _ data _ processed . CSV 的列

    为了确定哪些要素适合使用 PCA 进行缩减，您需要计算每个要素对于进行预测的重要性。一旦您知道了这些信息，您就可以选择那些对 PCA 最不重要的特性，而让最重要的特性保持不变。

2.  Determine feature importance using a decision tree classifier. Select all available features and train a decision tree on the full dataset (not doing a train-test split), by running the following code:

    ```py
    features = ['satisfaction_level', 'last_evaluation', \
                'number_project','average_montly_hours', \
                'time_spend_company', 'work_accident', \
                'promotion_last_5years', 'department_IT', \
                'department_RandD','department_accounting', \
                'department_hr', 'department_management', \
                'department_marketing', 'department_product_mng', \
                'department_sales','department_support', \
                'department_technical', 'salary_high', \
                'salary_low', 'salary_medium']
    X = df[features].values
    y = df.left.values
    from sklearn.tree import DecisionTreeClassifier
    clf = DecisionTreeClassifier(max_depth=10)
    clf.fit(X, y)
    ```

    到目前为止，您应该清楚地认识到前面的代码在做什么。基于之前的测试，你发现在只训练两个特性时`max_depth=6`是个不错的选择:`satisfaction_level`和`last_evaluation`。当模型中包含更多的特征时，决策树往往需要更多的深度来避免欠拟合(假设所有其他超参数保持不变)。因此，选择`max_depth=10`作为有根据的猜测。很有可能，这不是最佳选择，但是对于我们这里的目的来说，这并不重要。

3.  Having trained a *quick and dirty* model, leverage it to see how important each feature is for making predictions by using the `feature_importances_` attribute of `clf`. Visualize these in a bar chart by running the following code:

    ```py
    (
        pd.Series(clf.feature_importances_, \
                  name='Feature importance', \
                  index=df[features].columns,)
        .sort_values()
        .plot.barh()
    )
    plt.xlabel('Feature importance')
    ```

    其柱状图如下:

    ![Figure 5.5: Feature importance calculated by a decision tree model
    ](img/B15916_05_05.jpg)

    图 5.5:由决策树模型计算的特征重要性

    如前面的条形图所示，在进行预测时，有几个特征非常重要，而其余的特征的重要性几乎为零。

    然而，请记住，该图表并不代表*真正的*特征重要性，而只是简单地代表*快速而肮脏的*决策树模型`clf`的特征重要性。换句话说，上图中重要性接近于零的特性可能对其他模型更重要。在任何情况下，此处的信息足以让我们选择使用 PCA 减少哪些特征。

4.  将前面图表中最重要的五个特征放在一边，以便您可以在以后的建模中使用它们，然后选择其余的用于 PCA 算法。用下面的代码做到这一点:

    ```py
    importances = list(pd.Series(clf.feature_importances_, \
                                 index=df[features].columns,)
                       .sort_values(ascending=False).index)
    low_importance_features = importances[5:]
    high_importance_features = importances[:5]
    ```

5.  Print the least of low importance features list as follows:

    ```py
    np.array(low_importance_features)
    ```

    输出如下所示:

    ```py
    array(['salary_low', 'department_technical', 'work_accident',
           'department_support', 'department_IT', 'department_RandD',
           'salary_high', 'salary_medium', 'department_management',
           'department_accounting', 'department_hr', 'department_sales',
           'department_product_mng', 'promotion_last_5years',
           'department_marketing'], dtype='<U22')
    ```

6.  Print the least of high importance features list as follows:

    ```py
    np.array(high_importance_features)
    ```

    输出如下所示:

    ```py
    array(['satisfaction_level', 'last_evaluation', 'time_spend_company',
           'number_project', 'average_montly_hours'], dtype='<U20')
    ```

7.  Having identified the features to use for dimensionality reduction, run the PCA algorithm with the following code:

    ```py
    from sklearn.decomposition import PCA
    pca_features = ['salary_low', 'department_technical', \
                    'department_support','work_accident', \
                    'salary_medium', 'department_IT', \
                    'department_RandD', 'salary_high', \
                    'department_management','department_accounting', \
                    'department_hr', 'department_sales', \
                    'department_product_mng', 'promotion_last_5years', \
                    'department_marketing']
    X_reduce = df[pca_features]
    pca = PCA(n_components=3)
    pca.fit(X_reduce)
    X_pca = pca.transform(X_reduce)
    ```

    首先，我们定义在 PCA 中使用的特性列表，这可以通过从前面的单元格中复制并粘贴`np.array(low_importance_features)`的输出来方便地完成。

    接下来，我们用`n_components=3`实例化 scikit-learn 中的 PCA 类，表明我们希望保留 PCA 算法返回的前三个组件。最后，我们拟合实例化的 PCA 类，然后转换相同的数据集。

8.  Check the shape of the component data by running `X_pca.shape`. This will print the following output:

    ```py
    (14999, 3)
    ```

    这个结果意味着我们有三个长度为 14，999 的数组，对应于数据集中每条记录的三个主成分。

9.  通过运行下面的代码将这些主成分特征插入到`df`中:

    ```py
    df['first_principle_component'] = X_pca.T[0]
    df['second_principle_component'] = X_pca.T[1]
    df['third_principle_component'] = X_pca.T[2]
    ```

10.  通过运行以下代码保存更新的数据集:

    ```py
    df.to_csv('../data/hr-analytics/hr_data_processed_pca.csv', \
              index=False,)
    ```

11.  Finally, save the "fit" PCA class. This will be needed later to process future data before feeding it into our classifier's prediction method:

    ```py
    import joblib
    joblib.dump(pca, 'hr-analytics-pca.pkl')
    ```

    注意

    要访问该特定部分的源代码，请参考[https://packt.live/30GTi9a](https://packt.live/30GTi9a)。

    你也可以在[https://packt.live/2BcG5tP](https://packt.live/2BcG5tP)在线运行这个例子。

我们的 PCA 练习到此结束。您已经学习了如何生成特性重要性，并使用该信息来识别降维的良好候选对象。使用这种技术，我们从人力资源分析数据集中找到了一组要应用 PCA 算法的特征，并对它们进行简化，以创建三个新的特征，代表它们的主要成分。

## 面向生产的模特培训

到目前为止，在本书中，我们已经训练了许多模型，并花费了相当多的精力来学习模型评估和优化技术。然而，我们主要关注用于教学目的的训练模型，而不是产生具有最佳性能的生产就绪模型。

我们在本书中多次讨论了训练数据的重要性。一般来说，我们希望有尽可能多的培训记录和信息功能。拥有大量记录的一个缺点是需要额外的工作来清理这些数据，以便为机器学习算法的使用做准备。特征的数量也是如此。

随着特征数量的增加，出现的另一个问题是很难很好地拟合模型。数字、分类和布尔等特征类型的变化会限制我们可用的模型的类型，并在模型训练期间围绕特征缩放提出技术考虑。在这一章中，我们能够通过使用决策树来完全避免特征缩放，决策树不要求特征具有可比较的规模。

相对于越来越多的特性，比上述问题更令人担忧的是所谓的**维数灾难**。这是指模型在试图拟合大量特征时遇到的困难。随着定型数据中维数的增加，模型查找模式变得越来越困难，因为高维空间中的记录之间存在固有的大距离。我们之前学到的降维技术可以有效抵消这种影响。

尽管这里列出了一些困难，但更多的训练数据通常有利于模型性能，这一点仍然成立。到目前为止，在本书中，我们主要致力于在两个特性上训练我们的大多数模型。在本节中，我们将把之前学到的知识应用到模型评估和优化中，以训练一个使用数据集中所有可用要素信息的生产就绪模型。

## 练习 5.03:为员工流动培训一个生产就绪模型

我们已经花了相当多的精力来规划机器学习策略，清理原始数据，并为员工保留问题建立预测模型。回想一下，我们的业务目标是帮助客户阻止员工离职。我们决定的策略是建立一个分类模型，通过估计员工离职的概率来预测员工流动率。这样，公司可以评估当前员工流动的可能性，并采取措施防止其发生。

根据我们的策略，我们可以将我们正在进行的预测建模类型总结如下:

*   基于标记训练数据的监督学习
*   具有两个类别标签的分类(二元)

特别是，我们正在训练模型，根据一组数字和分类特征来确定员工是否已经离开公司。

在*第 3 章*、*为预测建模准备数据*中为机器学习准备好数据后，我们继续使用两个特性实现了 SVM、KNN 和随机森林算法。这些模型能够做出总体准确率超过 90%的预测。然而，当查看特定类别的准确度时，我们发现只能以 70-80%的准确度预测已经离开的员工(类别标签 1)。

在本练习中，您将看到通过利用完整的特征空间，这些 1 级精度可以提高多少。您将看到一个使用验证曲线进行超参数调整、k 倍交叉验证和测试集验证进行模型评估的统一示例，以及准备生产就绪模型的最终步骤。执行以下步骤来完成本练习:

1.  Starting where you left off in the notebook, load the preprocessed dataset and print the columns by running the following code. This is the same table that you completed the previous exercise with:

    ```py
    df = pd.read_csv('../data/hr-analytics/hr_data_processed.csv')
    df.columns
    ```

    该命令显示以下输出:

    ![Figure 5.6: The columns of hr_data_processed.csv
    ](img/B15916_05_06.jpg)

    图 5.6:HR _ data _ processed . CSV 的列

    作为快速复习，我们将对变量描述进行简要总结。鼓励您回顾第三章、*的*分析，为预测建模*准备数据，以便查看我们生成的特征分布。*

    前两个特征`satisfaction_level`和`last_evaluation`是数值，从 0 到 1 连续变化；这些是我们在前两个练习中用来训练模型的。接下来，我们有一些数字特征，比如`number_project`和`time_spend_company`，后面是布尔字段，比如`work_accident`和`promotion_last_5years`。我们还有一次性编码的分类特征，比如`department_IT`和`salary_medium`。最后，我们有主成分分析变量代表前一个练习中选择的特征集的前三个主要成分。

    给定我们的特征集的混合数据类型，决策树或随机森林是非常有吸引力的模型，因为它们可以很好地处理由数字和分类数据组成的特征集。在本练习中，我们将训练一个决策树模型。

    注意

    如果您有兴趣在混合类型输入特征上训练 SVM 或 KNN 分类器，您可能会发现这个 StackExchange 答案中的数据缩放规定很有用:[https://stats . stack exchange . com/questions/82923/mixing-continuous-and-binary-data-with-linear-SVM/83086 # 83086](https://stats.stackexchange.com/questions/82923/mixing-continuous-and-binary-data-with-linear-svm/83)。

    一种简单的方法是对数据进行如下预处理:

    标准化连续变量，一次性编码分类特征，然后将二进制值转换为-1 和 1，而不是 0 和 1。

    这将产生混合特征类型的数据，然后可用于训练各种分类模型。

2.  Select the features to use for our model as the top five features from the PCA section, in terms of feature importance, and the first three principal components of the remaining features. Do this selection and split the data into a training and validation set (`X, y`) and a test set (`X_test, y_test`) by running the following code:

    ```py
    from sklearn.model_selection import train_test_split
    features = ['satisfaction_level', 'last_evaluation', \
                'time_spend_company','number_project', \
                'average_montly_hours', 'first_principle_component', \
                'second_principle_component', \
                'third_principle_component',]
    X, X_test, \
    y, y_test = train_test_split(df[features].values, \
                                 df['left'].values, \
                                 test_size=0.15, \
                                 random_state=1)
    ```

    请注意，您为训练测试分割设置了`test_size=0.15`,因为您想要留出 15%的完整数据集来测试您将在超参数调整后选择的模型。

    您要优化的超参数是决策树的`max_depth`。您将使用与发现验证曲线相同的方法来完成这项工作，您发现`max_depth=6`对于只有两个特征的决策树模型来说是最佳的。

3.  Calculate the validation curve for a decision tree with a maximum depth ranging from 2 up to 52 by running the following code:

    ```py
    %%time
    from sklearn.tree import DecisionTreeClassifier
    np.random.seed(1)
    clf = DecisionTreeClassifier()
    max_depth_range = np.arange(2, 52, 2)
    print('Training {} models ...'.format(len(max_depth_range)))
    train_scores, \
    test_scores = validation_curve(estimator=clf, X=X, y=y, \
                                   param_name='max_depth', \
                                   param_range=max_depth_range, \
                                   cv=10,);
    ```

    由于您使用的是`%%time`魔法函数，该单元格将打印类似如下的消息:

    ```py
    Training 25 models ...
    CPU times: user 7.93 s, sys: 29.5 ms, total: 7.96 s
    Wall time: 7.98 s
    ```

    这方面的细节将取决于您的硬件和运行时系统上发生的其他进程。

    通过执行这段代码，您运行了 25 组 k-fold 交叉验证——在我们定义的范围内，`max_depth`超参数的每个值都有一组交叉验证。通过设置`cv=10`，您可以为每个模型生成 10 个精度估计值(在 k 重交叉验证期间)，从中计算平均值和标准偏差，以便绘制验证曲线。总的来说，您在各种最大深度和数据子集上训练了 250 个模型。

4.  Having run the calculations required for the validation curve, plot it with the `plot_validation_curve` function that was defined earlier in the notebook. If needed, scroll up and rerun that cell to define the function. Then, run the following code:

    ```py
    plot_validation_curve(train_scores, test_scores, \
                          max_depth_range, xlabel='max_depth',)
    plt.ylim(0.95, 1.0)
    ```

    这将导致以下曲线:

    ![Figure 5.7: Validation curve for a decision tree with PCA features
    ](img/B15916_05_07.jpg)

    图 5.7:具有 PCA 特征的决策树的验证曲线

    查看这条验证曲线，您可以看到训练集(蓝色圆圈)的准确性很快接近 100%，在`max_depth=20`左右达到这一水平。验证集(红色方块)在`max_depth=8`附近达到最大精度，然后随着`max_depth`增加超过该点而略微下降。发生这种情况是因为此范围内的模型对训练数据过度拟合，学习的模式不能很好地概括验证集中看不见的数据。

    基于这个结果，我们可以选择`max_depth=8`作为生产模型的最佳值。

5.  Check the k-fold cross validation accuracy for each class in our model with the `cross_val_class_score` function that was defined earlier in the notebook. If needed, scroll up and rerun that cell to define the function. Then, run the following code:

    ```py
    clf = DecisionTreeClassifier(max_depth=8)
    np.random.seed(1)
    scores = cross_val_class_score(clf, X, y)
    print('accuracy = {} +/- {}'.format(scores.mean(axis=0), \
                                        scores.std(axis=0),))
    ```

    这将打印以下输出:

    ```py
    fold: 1 accuracy: [0.99382716 0.91118421]
    fold: 2 accuracy: [0.99588477 0.91089109]
    fold: 3 accuracy: [0.99897119 0.91749175]
    fold: 4 accuracy: [0.99588477 0.95379538]
    fold: 5 accuracy: [0.99279835 0.91419142]
    fold: 6 accuracy: [0.99588477 0.92079208]
    fold: 7 accuracy: [0.99485597 0.92409241]
    fold: 8 accuracy: [0.99382716 0.9339934 ]
    fold: 9 accuracy: [0.9907312  0.91419142]
    fold: 10 accuracy: [0.99176107 0.94059406]
    accuracy = [0.99444264 0.92412172] +/- [0.00226594 0.01357943]
    ```

    如可以看到的，该模型比用于类别 1 的先前模型执行得好得多，平均准确度为 92.4% +/- 1.4%。这可以归功于我们在这里使用的额外特性，相比之下，早期的模型只依赖于两个特性。

6.  Visualize the new class accuracies with a boxplot by running the following code:

    ```py
    fig = plt.figure(figsize=(5, 7))
    sns.boxplot(data=pd.DataFrame(scores, columns=[0, 1]), \
                                  palette=sns.color_palette('Set1'),)
    plt.xlabel('Left (0="no", 1="yes")')
    plt.ylabel('Accuracy')
    ```

    下面是由前面的代码创建的可视化效果:

    ![Figure 5.8: Boxplot of class accuracies for the decision tree model
    ](img/B15916_05_08.jpg)

    图 5.8:决策树模型的分类准确率的箱线图

    此时，已经完成了超参数优化，您现在应该检查模型在测试集上的表现如何。这一结果将使您更有信心在生产中进行预测时它会表现良好。

7.  Train a model on the full set of training and validation data (`X, y`). Then, determine the accuracy of each class for the test set (`X_test, y_test`) by running the following code:

    ```py
    from sklearn.metrics import confusion_matrix
    clf = DecisionTreeClassifier(max_depth=8)
    clf.fit(X, y)
    y_pred = clf.predict(X_test)
    cmat = confusion_matrix(y_test, y_pred)
    cmat.diagonal() / cmat.sum(axis=1) * 100
    ```

    这将打印以下输出:

    ```py
    array([99.23976608, 93.88888889])
    ```

    这些测试准确度应该在我们之前计算的 k 倍交叉验证准确度范围内或非常接近。对于 0 类，可以看到 99.2%，落在 99.2%–99.6%的 k 倍范围内，对于 1 类，可以看到 93.9%，刚好落在 91.0%–93.8%的 k 倍范围之上。这些都是很好的结果，让你有信心你的模型会在生产中表现良好。

8.  您几乎已经完成了生产模型的创建。选择了最佳超参数并测试了准确性后，现在使用以下代码在完整数据集上训练一个新模型:

    ```py
    features = ['satisfaction_level', 'last_evaluation', \
                'time_spend_company', 'number_project', \
                'average_montly_hours', 'first_principle_component', \
                'second_principle_component', \
                'third_principle_component',]
    X = df[features].values
    y = df['left'].values
    clf = DecisionTreeClassifier(max_depth=8)
    clf.fit(X, y)
    ```

9.  要在生产中使用此模型而不需要每次都重新训练它，请将其保存到磁盘。使用`joblib`模块，通过运行下面的代码将模型转储到一个二进制文件中:

    ```py
    import joblib
    joblib.dump(clf, 'hr-analytics-pca-tree.pkl')
    ```

10.  Check that your trained model was saved into the working directory. If your Jupyter Notebook environment has bash support, this can be done by running the following code:

    ```py
    !ls .
    ```

    这将打印工作目录的内容:

    ```py
    chapter_5_workbook.ipynb    hr-analytics-pca-tree.pkl
    hr-analytics-pca.pkl
    ```

11.  In order to use this model to make predictions, load it from this binary file by running the following code:

    ```py
    clf = joblib.load('hr-analytics-pca-tree.pkl')
    clf
    ```

    该命令的输出如下:

    ![Figure 5.9: The decision tree model's representation
    ](img/B15916_05_09.jpg)

    图 5.9:决策树模型的表示

    现在运行一个示例，展示如何使用该模型来预测员工流动率。您将从训练数据中选取一条记录，并将其输入到模型中进行预测。

12.  Select a record from the training data and filter it on the original feature columns, and pretend this is the employee profile for Bob. Do this by running the following code:

    ```py
    pca_features = ['salary_low', 'department_technical', \
                    'work_accident','department_support', \
                    'department_IT', 'department_RandD', \
                    'salary_high', 'salary_medium', \
                    'department_management','department_accounting', \
                    'department_hr', 'department_sales', \
                    'department_product_mng', 'promotion_last_5years', \
                    'department_marketing']
    non_pca_features = ['satisfaction_level', 'last_evaluation', \
                        'time_spend_company','number_project', \
                        'average_montly_hours']
    bob = df.iloc[8483][pca_features + non_pca_features]
    bob
    ```

    这将打印以下输出，显示每个员工指标的 Bobs 指标:

    ```py
    salary_low                  1.00
    department_technical        0.00
    work_accident               0.00
    department_support          0.00
    department_IT               0.00
    department_RandD            0.00
    salary_high                 0.00
    salary_medium               0.00
    department_management       0.00
    department_accounting       0.00
    department_hr               0.00
    department_sales            1.00
    department_product_mng      0.00
    promotion_last_5years       0.00
    department_marketing        0.00
    satisfaction_level          0.77
    last_evaluation             0.68
    time_spend_company          2.00
    number_project              3.00
    average_montly_hours      225.00
    Name: 8483, dtype: float64
    ```

    通常，预测样本需要以与训练数据完全相同的方式进行准备，这包括相同的数据清理方法，例如填充缺失值和一次性编码分类变量。

    在这种情况下(对于 Bob)，这个预处理已经完成了。然而，在这一点上，假设 PCA 变换还没有完成。为了生成模型所需的正确输入，这是一个必要的步骤。

13.  Load the PCA transformation class that was saved to disk earlier in this exercise and use it to transform the relevant features for Bob by running the following code:

    ```py
    pca = joblib.load('hr-analytics-pca.pkl')
    pca_feature_values = pca.transform([bob[pca_features]])[0]
    pca_feature_values
    ```

    这将打印以下输出，显示我们为 Bob 做预测所需的主要组件:

    ```py
    array([-0.67733089,  0.75837169, -0.10493685])
    ```

14.  Create a prediction vector for Bob that can be input into the prediction method of your classification model by running the following code:

    ```py
    X_bob = np.concatenate((bob[non_pca_features].values, \
                            pca_feature_values))
    X_bob
    ```

    这将打印以下输出:

    ```py
    array([ 7.70000000e-01,  6.80000000e-01,  2.00000000e+00,  
            3.00000000e+00,  2.25000000e+02, -6.77330887e-01,  
            7.58371688e-01, -1.04936853e-01])
    ```

15.  You are finally ready to see whether the model is predicting that Bob will leave the company. Calculate this outcome by running the following code:

    ```py
    clf.predict([X_bob])
    ```

    这将打印以下输出:

    ```py
    array([0])
    ```

    这表明我们的模型预测 Bob 不会离开公司，因为他被分配到 0 类。

16.  You can see what probability the model has assigned to this prediction by using its `predict_proba` method. Check this result by running the following code:

    ```py
    clf.predict_proba([X_bob])
    ```

    这将打印以下输出:

    ```py
    array([[0.98, 0.02]])
    ```

    这表明我们的模型将 Bob 留在公司的概率分配为 98%。

    注意

    要访问该特定部分的源代码，请参考[https://packt.live/30GTi9a](https://packt.live/30GTi9a)。

    你也可以在[https://packt.live/2BcG5tP](https://packt.live/2BcG5tP)在线运行这个例子。

现在，您已经完成了人力资源分析数据集的最终练习，并成功训练了一个可以预测员工流动率的模型。在本练习中，您将验证曲线用于超参数优化和 k-fold 交叉验证模型评估，以确认模型的可信度。

通过在最重要的特征上训练模型，除了通过降维产生的特征，我们能够建立一个比以前的模型表现更好的模型，这些模型来自*第 3 章*、*为预测建模准备数据*。

最后，您了解了如何将模型保存在磁盘上并重新加载它们以用于进行预测。

在接下来的活动中，您将尝试改进我们在这里培训的模型。这将给你一个机会来应用本章的主题，并运用你从本书中学到的技能。

## 活动 5.01:超参数调整和模型选择

在与机器学习相关的最后一项活动中，我们将把迄今为止学到的所有知识整合在一起，以便为员工保留问题建立另一个预测模型。我们试图通过训练一个随机森林模型来提高前面练习中模型的准确性。

为了实现这一点，你将需要使用你在本章中看到的方法，比如 k-fold 交叉验证和验证曲线。你还需要确认你的模型对测试数据的有效性，并确定它是否是对以前工作的改进。最后，您将把该模型应用到实际的业务情况中。执行以下步骤来完成本练习:

注意

本练习的详细步骤以及解决方案和附加注释在第 293 页提供。

1.  Start up one of the following platforms for running Jupyter Notebooks:

    JupyterLab (run `jupyter lab` )

    Jupyter 笔记本(运行`jupyter notebook`)

    然后，按照终端中的提示，通过复制并粘贴 URL，打开您在 web 浏览器中选择的平台。

2.  加载所需的库，并为笔记本设置打印环境。
3.  首先在笔记本(`hr_data_processed_pca.csv`)中加载您之前生成的训练数据集，将其分配给`df`变量。
4.  从表格中选择本章最后一个练习中使用的相同特征(当我们用`max_depth=8`训练决策树时)。然后，将它们分成一个训练和验证集以及一个测试集(`X, X_test, y, y_test`)。测试集应该包括 15%的记录。
5.  在从 2 到 52 的`max_depth`值范围内，以 2 为增量，用`n_estimators=50`计算随机森林分类模型的验证曲线。在验证曲线计算的 k 倍交叉验证步骤中，通过设置`cv=5`将`k`的值指定为 5。
6.  使用之前在笔记本中定义的`plot_validation_curve`可视化绘制验证曲线。解释图表，并注意与之前练习中的验证曲线不同的任何地方。你认为`max_depth`的最佳值是多少？
7.  使用您之前在笔记本中定义的`cross_val_class_score`函数执行 k 折交叉验证，将随机森林超参数设置为`n_estimators=50`和`max_depth=25`。这些结果是否优于我们在之前的练习中训练的决策树？
8.  通过在完整的测试和验证集(`X, y`)上训练该模型来评估该模型在测试集上的性能，然后计算其在测试集中每个类上的准确性(`X_test, y_test`)。分数是否在验证模型的适当范围内？
9.  在`df`的全套记录上训练这个模型。
10.  将模型保存到磁盘，然后通过重新加载来检查它是否被正确保存。
11.  通过从`df`的第 573 行中选择适当的特征，检查一个假想雇员 Alice 的模型性能。确保选择了进行预测所需的所有特征，包括第一、第二和第三主成分。
12.  预测爱丽丝是否会离开公司。然后，确定模型分配给该预测的概率。
13.  调整 Alice 的特征值，以确定改变模型预测所需的更改。尝试设置`average_montly_hours=100`和`time_spend_company=2`。然后，重新运行模型的预测概率。这种调整足以动摇模型对爱丽丝是否会离开的预测吗？

# 总结

在本章中，我们已经了解了如何使用 Jupyter 笔记本进行参数优化和模型选择。

我们在前一章所做工作的基础上，为我们的二元问题训练了预测分类模型，并了解了如何为 SVM、KNN 和随机森林模型绘制决策边界。我们通过使用验证曲线来优化参数，改进了这些简单的模型，并探索了降维如何提高模型性能。

最后，在上次练习的最后，我们探讨了如何在实践中使用最终模型来做出数据驱动的决策。这个演示将我们的结果与最初激发我们建模问题的原始业务问题联系起来。

在下一章，我们将离开机器学习，转而关注数据采集。具体来说，我们将讨论提取 web 数据的方法，并了解 HTTP 请求、使用 Python 的 web 抓取以及使用 pandas 的更多数据处理。鉴于拥有高质量数据进行研究和建模的巨大重要性，这些主题可能与数据科学家高度相关。