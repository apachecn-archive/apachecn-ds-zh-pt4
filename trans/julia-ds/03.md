

# 三、数据探索

当我们第一次收到数据集时，大多数时候我们只知道它与什么相关，这不足以开始应用算法或在其上创建模型。数据探索在数据科学中至关重要。这是创建模型之前的必要过程，因为它突出显示了数据集，并明确指出了实现我们目标的途径。数据探索使数据科学家熟悉数据，并有助于了解我们可以从数据集推断出什么样的一般假设。因此，我们可以说这是一个从数据集中提取一些信息的过程，事先不知道要寻找什么。

在本章中，我们将学习:

*   抽样、总体和权重向量
*   推断列类型
*   数据集的摘要
*   标量统计
*   变化的度量
*   使用可视化的数据探索

数据探索涉及描述性统计。描述性统计是一个数据分析领域，通过有意义地总结数据来找出模式。这可能不会导致准确的结果或我们打算建立的模型，但它肯定有助于理解数据。假设新德里有 1000 万人，如果我们计算随机抽取的 1000 名居住在那里的人的平均身高，这不会是新德里人的平均身高，但这肯定会给出一个概念。

Julia 可以有效地用于数据探索。Julia 提供了一个名为`StatsBase.jl`的包，其中包含了统计所需的函数。在本章中，我们假设您已经添加了包:

```
julia> Pkg.update() 
julia> Pkg.add("StatsBase") 

```

# 取样

在前面的例子中，我们谈到了计算居住在新德里的 1000 万人中的 1000 人的平均身高。在收集这 1000 万人的数据时，假设我们从特定的年龄或社区开始，或者以任何顺序的方式开始。现在，如果我们在数据集中选取 1000 个连续的人，他们之间很有可能有相似之处。这种相似性不会给我们提供我们试图实现的数据集的实际亮点。因此，从数据集中提取一小块连续的数据点并不能给我们想要的洞察力。为了克服这一点，我们使用抽样。

采样是一种从给定的数据集中随机选择数据的技术，这样它们就不会彼此相关，因此我们可以在整个数据集中概括我们对这些选择的数据生成的结果。抽样是对总体进行的。

## 人口

统计学中的总体是指数据集中所有数据点的集合，这些数据点至少有一个共同的属性。在前面的例子中，人们具有来自同一地理区域的共同属性。

让我们以虹膜数据集为例。尽管它只有 150 条记录，但它会让我们知道如何从数据集中抽取样本:

```
julia> using RDatasets 

julia> iris_dataframe = dataset("datasets", "iris") 

```

我们将使用包含 iris 数据集的 RDatasets 包，并将它加载到 DataFrame 中。因此，这个数据框架包含“人口”，我们想从中抽取一个样本:

```
julia> sample(iris_dataframe[:SepalLength]) 
6.6 

julia> sample(iris_dataframe[:SepalLength], 5) 
5-element Array{Float64,1}: 
 4.8 
 5.4 
 5.0 
 5.2 
 4.3 

```

`sample()`函数可用于从数据集中返回一个随机值或一组随机选择的值:

```
Julia> sample(x, num_of_elements[; replace=true, ordered=false]) 

```

`replace`和`ordered`参数用于特定情况:

*   `replace`:当返回相同的值时进行替换时使用(`default=true`)
*   `ordered`:当返回值为升序时使用(`default=false`)

理想情况下，从给定数据集中提取的样本应该代表总体。但大多数情况下，它不足或过多地代表了数据集中存在的许多组。让我们以之前的例子为例，如果我们无法从社区 X 收集 50-70 岁之间的完整数据会怎样？因此，我们的数据集并不代表准确的人口。必须采取措施来校正观察到的数据集。

加权调整是一种非常常见的校正技术。在这种技术中，调整权重被分配给每个记录。我们认为代表不足的记录或组的权重大于 1，而我们认为代表过多的记录或组的权重小于 1。

## 权重向量

Julia 有一个 WeightVec 类型来表示权重向量，以便于为样本分配权重。权重向量需要专门的数据类型:

*   为了明确区分这个特定向量与其他数据向量的角色
*   通过存储权重之和并避免再次计算权重之和来节省计算周期

权重向量可以这样构造:

```
julia> wv = WeightVec([1., 2., 3.], 6.) 
StatsBase.WeightVec{Float64,Array{Float64,1}}([1.0,2.0,3.0],6.0) 

```

我们提供了权重的总和作为第二个参数。这是可选的，这样做是为了节省计算时间。

为了简单起见，`WeightVec`支持一些通用方法。让`wv`成为`WeightVec`的类型:

```
julia> eltype(wv) 
Float64 

```

`eltype`用于获取`WeightVec`中的值的类型:

```
julia> length(wv) 
3 

julia> isempty(wv) 
false 

julia> values(wv) 
3-element Array{Float64,1}: 
 1.0 
 2.0 
 3.0 

julia> sum(wv) 
6.0 

# Applying eltypes to iris_dataframe 
# this method is of DataFrames.jl 
julia> eltypes(iris_dataframe)   
5-element Array{Type{T},1}: 
 Float64                       
 Float64                       
 Float64                       
 Float64                       
 Union{ASCIIString,UTF8String} 

```

其他方法不言自明。由于总和已经由`WeightVec`存储，所以它会立即返回，而不进行任何计算。



# 推断列类型

为了理解数据集并继续深入，我们需要首先理解我们拥有什么类型的数据。因为我们的数据存储在列中，所以在执行任何操作之前，我们应该知道它们的类型。这也称为创建数据字典:

```
julia> typeof(iris_dataframe[1,:SepalLength]) 
Float64 

julia> typeof(iris_dataframe[1,:Species]) 
ASCIIString 

```

我们在这里使用了 iris 的经典数据集。我们已经知道这些列中的数据类型。我们可以将相同的函数应用于任何相似的数据集。假设我们只得到没有标签的列；那么就很难确定这些列包含的数据类型。有时，数据集看起来好像包含数字，但它们的数据类型是`ASCIIString`。这可能会导致后续步骤出错。这些错误是可以避免的。



# 基本统计汇总

尽管我们目前正在使用 RDatasets，关于它我们有足够的细节和文档，但是这些方法和技术可以扩展到其他数据集。

让我们使用不同的数据集:

![Basic statistical summaries](graphics/B05321_03_8.jpg)

我们使用 RDatasets 包中的另一个数据集。这些是伦敦市中心的考试成绩。为了获得关于数据集的一些信息，我们将使用`describe()`函数，我们已经在前面的章节中讨论过了:

![Basic statistical summaries](graphics/B05321_03_9.jpg)

各列说明如下:

*   `Length`指记录的数量(行数)。
*   `Type`指该列的数据类型。因此，`School`属于`Pooled ASCIIString`数据类型。
*   `NA`和`NA%`是指列中出现的`NA`值的数量和百分比。这非常有用，因为您现在不需要手动检查丢失的记录。
*   `Unique`指列中存在的唯一记录的数量。
*   `Min`和`Max`是列中的最小值和最大值(这不适用于具有`ASCIIStrings`的列)。这些是 0%和 100%数据点的值。`Min`和`Max`定义数据的范围。
*   第一分位数和第三分位数分别指 25%和 75%数据点处的值。类似地，中值是指 50%数据点的值。

## 计算数组或数据帧的平均值

Julia提供了不同种类的均值函数。每种都有自己的用例:

*   `geomean(arr)`:计算`arr`的几何平均值:

![Calculating the mean of the array or dataframe](graphics/B05321_03_10.jpg)

*   `harmmean(arr)`:计算`arr`的调和平均值；

![Calculating the mean of the array or dataframe](graphics/B05321_03_11.jpg)

*   `trimmean(arr, fraction)`:用于计算修剪数据集的平均值。第二个参数用于提供将修剪数据集的分数。例如，如果`fraction`中提供的值为 0.3，将忽略前 30%和后 30%的值来计算平均值。它通常用于移除异常值:

![Calculating the mean of the array or dataframe](graphics/B05321_03_12.jpg)

均值函数也被扩展。它可以将加权向量作为参数来计算加权平均值:

![Calculating the mean of the array or dataframe](graphics/B05321_03_13.jpg)

# 标量统计

Julia 的软件包提供了各种函数来计算各种统计数据。这些函数用于根据需要以不同的方式描述数据。

## 标准偏差和方差

我们之前计算的平均值和中值(在`describe()`函数中)是集中趋势的量度。Mean 是指对所有值应用权重后计算出的中心，median 是指列表的中心。

这只是一条信息，我们希望了解更多关于数据集的信息。了解数据点在数据集中的分布情况会很有帮助。我们不能只使用最小值和最大值函数，因为数据集中可能存在异常值。因此，这些最小值和最大值函数将导致不正确的结果。

方差是对数据集中数据点之间分布的度量。它是通过计算数字与平均值的距离来计算的。方差衡量集合中的每个数字离平均值的距离。

下面是方差的公式:

![Standard deviations and variances](graphics/B05321_03_14.jpg)![Standard deviations and variances](graphics/B05321_03_15.jpg)

我们还可以有一个沿特定维度的方差，这对于数据帧很有用:

![Standard deviations and variances](graphics/B05321_03_16.jpg)

这里，第二个参数是我们要计算方差的维度。

标准差是数据集中值的分布或离差的度量。它是方差的平方根。如果接近 0，这意味着数据集与平均值的离差很小。较大的值定义了这些值与平均值的高离差。标准差不同于方差，因为它与平均值具有相同的单位:

![Standard deviations and variances](graphics/B05321_03_17.jpg)

我们也可以计算一个维度的标准偏差，比如方差。

Julia 提供了一个函数来计算平均值和方差，以及平均值和标准差:

![Standard deviations and variances](graphics/B05321_03_18.jpg)

统计分析包括基于偏度和峰度的数据特征。偏斜度是从数据集或分布的中心点缺少对称性的度量。所以，一个分布可以向左倾斜，也可以向右倾斜。

峰度是与正态分布相比，分布或数据集平坦度的度量。因此，在中心具有高峰(平均值)并且向两侧急剧下降的分布被称为具有高峰度，而在平均值处具有较平坦峰的分布被称为具有低峰度:

![Standard deviations and variances](graphics/B05321_03_19.jpg)

统计学中的一个瞬间是:

*   0 阶矩是总概率
*   一阶矩是平均值
*   第二中心矩是方差
*   第三个矩是偏斜度
*   第四个矩是峰度(带移位和归一化)

![Standard deviations and variances](graphics/B05321_03_20.jpg)

这里我们计算 k 阶中心矩。它被定义为:

```
(a - mean(a)).^k 

```



# 变化的度量

了解数据集中值的变化是有好处的。各种统计功能有助于:

*   `span(arr)` : span 用于计算数据集的总扩散，即`maximum(arr)`到`minimum(arr)`:

![Measures of variation](graphics/B05321_03_21.jpg)

*   `variation(arr)`:也叫变异系数。它是标准偏差与数据集平均值的比率。相对于总体的平均值，CV 表示变异的程度。它的优点是它是一个无量纲的数，可以用来比较不同的数据集。

![Measures of variation](graphics/B05321_03_22.jpg)

均值的标准误差:我们对从总体中抽取的不同样本进行研究。我们计算这些样本的平均值，称之为样本平均值。对于不同的样本，我们不会有相同的样本均值，而是样本均值的分布。这些样本平均值分布的标准偏差称为平均值的标准误差。

在 Julia 中，我们可以使用`sem(arr)`计算平均值的标准误差。

平均绝对偏差是集中趋势的稳健度量。稳健性是指不受离群值的影响。

![Measures of variation](graphics/B05321_03_23.jpg)

我们可以提供中心作为第二个论点。

## Z 分数

z 分数指的是与分数平均值的关系。它是通过一个元素高于或低于平均值的标准差来计算的。z 值为 0 表示与平均值相同。

它由公式 *z = (X - μ) / σ* 给出:

```
julia> a = [12,23,45,68,99,72,61,39,21,71] 

```

在这个数据集上，我们可以这样计算 z 值:

![Z-scores](graphics/B05321_03_24.jpg)

平均值和标准偏差由它们自己计算。

## 熵

熵是数据集中无序度的度量，并提供系统中随机性的近似度量。它随着随机性而增加。

让我们创建一个概率向量:

![Entropy](graphics/B05321_03_25.jpg)

我们创建了一个相当小的数组:

![Entropy](graphics/B05321_03_26.jpg)

概率向量的元素之和是 1。这里快 1 点了。我们现在计算熵:

![Entropy](graphics/B05321_03_27.jpg)

熵计算是使用自然对数完成的。如果需要，我们还可以提供对数的底数。

![Entropy](graphics/B05321_03_28.jpg)

我们提供的第二个参数是对数的底数。我们还可以计算交叉熵，这被认为是平方误差的有效替代方法:

```
Julia> crossentropy(ProbabilityVector1, ProbabilityVector2) 

```

## 分位数

为了更好地理解数据集，我们想知道数据集中的最低点和最高点。我们可以使用最小值和最大值函数。因此，我们也可以说最小和最大数据点在 0%和 100%。如果我们想找出数据集的 n%的任何数据点，我们使用`quantile`函数。

分位数在存在异常值的情况下非常有用。例如，对于`a`,我们正在分析一个网站的各种浏览器的响应时间:98%的流量来自桌面，它能够在不到一秒的时间内加载页面；剩余流量的 2%来自移动端，加载页面需要 5 秒钟。这里，我们可能想忽略这 2%(如果用例允许的话)来分析网站的实际流量。

![Quantiles](graphics/B05321_03_29.jpg)

现在，为了计算分位数:

![Quantiles](graphics/B05321_03_30.jpg)

这里，我们收到了五个值。这五个值分别代表数据集的 0%、25%、50%、75%和 100%的数据点。

四分位数间距是变异性的度量，通过上下四分位数的差值来计算，即 Q3-Q1。其计算方法如下:

![Quantiles](graphics/B05321_03_31.jpg)

百分点是统计学中的一个常用术语，用于表示数据点在数据集中的位置。它可以计算为:

![Quantiles](graphics/B05321_03_32.jpg)

我们使用了相同的数据集，并计算了 0.5 在数据集中的位置。

还有一个重要的功能，`nquantile`。它用于创建我们定义的分位数向量:

![Quantiles](graphics/B05321_03_33.jpg)

## 模式

在浏览数据集时，我们希望知道哪些数据在数据集中频繁重复。这是样本中出现概率最大的值。Julia 提供了一个计算模式的函数:

![Modes](graphics/B05321_03_34.jpg)

我们在上一个示例中使用的同一数据集上计算模式。所以，`0.2566`在数据集中出现的频率最高。

## 数据集摘要

前面我们讨论了`describe()`函数，它打印数据集的摘要。Julia 还提供了另一个功能，`summarystats()`。

在前一个例子的相同数据集上使用`summarystats(a)`,我们得到下面的结果。所以，我们现在不需要单独计算它们，这让我们知道我们有什么样的数据集。

![Summary of datasets](graphics/B05321_03_35.jpg)

# 散布矩阵和协方差

数据科学家经常使用协方差来找出两组有序的数据如何遵循相同的方向。它可以很容易地定义变量是否相关。为了最好地表示这种行为，我们创建一个协方差矩阵。协方差矩阵的非标准化版本是散布矩阵。

为了创建散布矩阵，我们使用了`scattermat(arr)`函数。

默认行为是将每一行视为一个观察值，将每一列视为一个变量。这可以通过提供关键字参数`vardim`和`mean`来改变:

*   `Vardim` : `vardim=1 (default)`表示每一列是一个变量，每一行是一个观察值。vardim=2 正好相反。
*   `mean`:平均值由`scattermat`计算。我们可以使用预定义方法来节省计算周期。

我们还可以使用`cov`函数创建一个加权协方差矩阵。出于同样的目的，它还将 vardim 和 mean 作为可选参数。



# 计算偏差

StatsBase.jl 提供了各种函数来计算两个数据集之间的偏差。这可以使用其他函数来计算，但是为了方便和易于使用，StatsBase 提供了这些有效实现的函数:

*   **平均绝对偏差**:对于`a`和`b`两个数据集，计算为`meanad(x,y)`，是`mean(abs(x-y))`的包装。
*   **最大绝对偏差**:对于`a`和`b`两个数据集，计算为`maxad(x,y)`，是对`maximum(abs(x-y))`的包装。
*   **均方差**:对于`a`和`b`两个数据集，计算为`msd(x,y)`，是对`mean(abs2(x-y))`的包装。
*   **均方根偏差**:对于`a`和`b`两个数据集，计算为`rmsd(a,b)`，是对`sqrt(msd(a, b))`的包装。



# 排名

当数据集按升序排序时，会为每个值分配一个等级。排名是一个过程，在这个过程中，数据集被转换，值被它们的排名所取代。Julia 为各种类型的排名提供了函数。

在顺序排名中，数据集中的所有项目都被赋予不同的值。具有相等值的项目被任意分配一个等级。在 Julia 中，这是使用`ordinalrank`函数完成的。

![Rankings](graphics/B05321_03_36.jpg)

假设这是我们的数据集，我们想做序数排序:

![Rankings](graphics/B05321_03_37.jpg)

使用`ordinalrank(arr)`函数，我们得到了序数排序。同样，StatsBase 也提供了查找其他类型排名的功能，比如`competerank()`、`denserank()`和`tiedrank()`。



# 计数功能

在数据探索中，经常要对一个范围进行计数。它有助于找出出现次数最多/最少的值。Julia 提供了 counts 函数来计算一个范围内的值。假设我们有一组值。为了方便起见，我们现在将使用 random 函数创建一个数组:

![Counting functions](graphics/B05321_03_38.jpg)

我们已经创建了一个包含 30 个值的数组，范围从 1 到 5。现在我们想知道它们在数据集中出现了多少次:

![Counting functions](graphics/B05321_03_39.jpg)

使用`count`函数，我们发现 1( `7`)、2( `1`)、3( `5`)、4( `11`)和 5( `6`)。计数采用不同的参数来适应用例。

`proportions()`函数用于计算数据集中值的比例，Julia 提供了该函数:

![Counting functions](graphics/B05321_03_40.jpg)

我们在前面示例中使用的同一数据集上计算比例。说明数据集中值 1 的比值为`0.23333`。这也可以看作是在数据集中找到值的概率。

其他计数功能包括:

*   `countmap(arr)`:这是一个映射函数，将值映射到数据集中出现的次数(或总权重):

![Counting functions](graphics/B05321_03_41.jpg)

*   `proportionmap(arr)`:这是一个类似于`countmap(arr)`的映射函数，但是将值映射到它们的比例:

![Counting functions](graphics/B05321_03_42.jpg)

将`countmap`和`proportionmap`应用到我们的数据集，得到了这些值。这两个函数都返回一个字典。



# 直方图

基本理解后的数据探索也可以借助可视化来完成。绘制直方图是通过可视化进行数据探索的最常见方式之一。直方图类型用于将实际平面上的数据分成规则的间隔。

使用拟合方法创建直方图:

```
julia> fit(Histogram, data[, weight][, edges]) 

```

`fit`采用以下参数:

*   `data`:数据以向量的形式传递给`fit`函数，向量可以是一维的，也可以是 n 维的(等长向量元组)。
*   `weight`:这是可选参数。如果值具有不同的权重，则可以将一个`WeightVec`类型作为参数传递。值的默认权重是 1。
*   `edges`:这是一个向量，用于给出沿每个维度的面元的边缘。

它还带有一个关键字参数`nbins`，用于定义直方图在每一边应该使用的仓的数量:

![Histograms](graphics/image_03_036.jpg)

在这个例子中，我们使用了两个随机值生成器和`nbins`来定义容器的数量。我们在随机生成的数据上创建了一个直方图。让我们在来自`RDatasets`包的数据集上尝试一下。这里解释一下这个包:[https://stat . ethz . ch/R-manual/R-devel/library/datasets/html/sleep . html](https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/sleep.html)。

![Histograms](graphics/image_03_037.jpg)

我们正在使用来自`RDatasets`包的名为`sleepstudy`的数据集。它包含三列:`Reaction (Float64)`、`Days (Integer)`和`Subject (Integer)`。我们将根据这些数据创建一个直方图。

![Histograms](graphics/image_03_038.jpg)

我们现在可以认识到，通过可视化更容易理解数据。可视化是数据探索的重要组成部分。为了真正能够可视化数据，需要必要的数据管理和对变量的一些理解。在这个特定的可视化中，我们可以观察哪些区域更密集以及反应时间。

我们之前讨论过散布矩阵。我们可以创建一个散点图，并尝试找出它是否对我们有帮助。

![Histograms](graphics/image_03_039.jpg)

我们可以很好地观察到，受试者的反应时间每天都在增加。我们能够很快得出这个结论；否则，这将花费大量的时间。

让我们更深入地了解这个数据集。假设我们想知道每个人的表现。由于所有的受试者并不相同，有些人的表现可能与其他人大相径庭。

在大型数据集上，我们可以进行分组或聚类；但在这里，由于有一个小数据集，我们可以单独分析对象。

![Histograms](graphics/image_03_040.jpg)

很明显，受试者`309`即使被剥夺了很多天的睡眠，反应时间也非常慢。这些都是我们在分析可视化数据集时有时会忽略的小细节。

我们将在[第 5 章](ch05.html "Chapter 5. Making Sense of Data Using Visualization")、*中详细讨论可视化，使用可视化理解数据*。我们将探索 Julia 提供的各种可视化包，以及如果可视化需要，我们如何调用 R 和 Python 的包。我们还将浏览一些基本的 D3.js 示例。

在 Julia 中很容易创建基本情节，例如:

![Histograms](graphics/image_03_041.jpg)

现在，让我们在 iris 数据集上尝试一些可视化:

```
julia> x=:SepalLength, y=:SepalWidth, color=:Species) 

```

虽然现在还不完全可见，但我们可以看到有可见的星团。也许，我们可以用这些聚类来区分不同的物种。因此，视觉化对发现这类洞见非常有帮助。



# 相关性分析

Julia 提供了一些函数来促进相关性分析。相关性和依赖性是统计学中的两个常用术语。相关性是指一个变量与另一个变量有统计关系，而相关性是一个变量与另一个变量有更广泛的关系，也可能包括相关性。

`autocov(x)`函数用于计算`x`的自协方差。它返回一个与`x`大小相同的向量。

![Correlation analysis](graphics/B05321_03_50.jpg)

这是我们生成的数据集。我们可以对这个数据集应用`autocov`:

![Correlation analysis](graphics/B05321_03_51.jpg)

为了计算自相关，我们使用`autocor`函数:

![Correlation analysis](graphics/B05321_03_52.jpg)

同样，我们也可以计算互协方差和互相关。为此，我们将生成另一个相同大小的随机数组:

![Correlation analysis](graphics/B05321_03_53.jpg)

长度=6 的 2 个数组的互协方差和互相关导致长度=11 的数组。



# 总结

在本章中，我们讨论了为什么数据探索很重要，以及我们如何对数据集进行探索性分析。

这些是我们讨论过的各种重要技术和概念:

*   采样是一种从给定的数据集中随机选择不相关数据的技术，这样我们就可以在整个数据集中概括我们对所选数据生成的结果。
*   当我们拥有或收集的数据集不代表实际数据时，权重向量非常重要。
*   为什么有必要了解列类型，以及汇总函数如何真正有助于获取数据集的要点。
*   均值、中值、众数、标准差、方差和标量统计，以及它们在 Julia 中是如何实现的。
*   测量数据集中的变化非常重要，z 分数和熵非常有用。
*   在一些基本的数据清理和一些理解之后，可视化可能是非常有益和有见地的。



# 参考文献

*   [http://julia.readthedocs.io/en/latest/manual/](http://julia.readthedocs.io/en/latest/manual/)
*   [https://dataframesjl.readthedocs.io/en/latest/](https://dataframesjl.readthedocs.io/en/latest/)
*   [https://github.com/JuliaStats/StatsBase.jl](https://github.com/JuliaStats/StatsBase.jl)
*   [http://dcjones.github.io/Gadfly.jl/](http://dcjones.github.io/Gadfly.jl/)