

# 第二章。数据管理

据说，数据科学家大约 50%的时间用于将原始数据转换成可用的格式。原始数据可以是任何格式或大小。它可以像 RDBMS 一样结构化，像 CSV 一样半结构化，或者像常规文本文件一样非结构化。这些包含了一些有价值的信息。为了提取这些信息，必须将其转换为数据结构或可用的格式，算法可以从中找到有价值的见解。因此，可用格式是指在数据科学过程中可以消费的模型中的数据。这种可用的格式因用例而异。

本章将指导您完成数据管理，或准备数据的过程。它涵盖以下主题:

*   什么是数据管理？
*   数据帧. jl
*   从文件上传数据
*   查找所需的数据
*   连接和索引
*   拆分-应用-组合策略
*   重塑数据
*   公式(模型框架和模型矩阵)
*   PooledDataArray
*   网页抓取

# 什么是数据管理？

Munging 一词来源于美国麻省理工学院的一些学生创造的“munge”。它被认为是数据科学过程中最重要的部分之一；它包括收集、聚合、清理和组织数据，这些数据将被用于发现或创建模型的算法所使用。这涉及许多步骤，包括从数据源提取数据，然后将数据解析或转换为预定义的数据结构。数据争吵也称为数据争吵。

## 数据管理流程

那么数据管理过程是怎样的呢？如上所述，数据可以是任何格式，数据科学过程可能需要来自多个来源的数据。这个数据聚合阶段包括从网站上搜集数据，下载数千个`.txt`或`.log`文件，或者从 RDBMS 或 NoSQL 数据存储中收集数据。

很少能找到数据科学过程可以直接使用的格式的数据。接收到的数据通常是不适合建模和分析的格式。通常，算法要求数据以表格格式或矩阵形式存储。将收集到的原始数据转换成所需格式的这一阶段会变得非常复杂和耗时。但是这个阶段为现在可以完成的复杂数据分析奠定了基础。

最好是预先定义将要提供给算法的数据的结构。这种数据结构是根据问题的性质定义的。您已经设计或将要设计的算法不仅应该能够接受这种数据格式，还应该能够轻松地识别模式、发现异常值、做出发现或满足任何期望的结果。

在定义了数据的结构之后，就可以定义实现这一目标的过程。这就像一个管道，它将接受某些形式的数据，并以预定义的格式给出有意义的数据。这个阶段由多个步骤组成。这些步骤包括将数据从一种形式转换为另一种形式，这可能需要也可能不需要字符串操作或正则表达式，以及查找缺失值和异常值。

通常，数据科学问题围绕两种数据。这两种数据要么是分类的，要么是数字的。分类数据带有标签。这些标签是由一些价值观组成的。例如，我们可以用分类特征来处理天气。天气可以是晴天、阴天、雨天、雾天或下雪天。当基础值与其中一组数据(在标签下)相关联时，就形成了这些标签。这些标签有一些独特的特征，我们可能无法对它们应用算术运算。

数字数据更常见，例如温度。温度是浮点数，我们当然可以对它进行数学运算。每个值都可以与数据集中的其他值进行比较，因此我们可以说它们彼此之间有直接的关系。



# 什么是数据帧？

数据帧是一种具有带标签的列的数据结构，每个列可能有不同的数据类型。像 SQL 表或电子表格一样，它有两个维度。也可以认为是字典列表，但从根本上来说，是不一样的。

数据框架是统计分析的推荐数据结构。Julia 提供了一个名为`DataFrames.jl`的包，其中包含了处理数据帧所需的所有函数。

Julia 的包 DataFrames 提供了三种数据类型:

*   `NA`:Julia 中缺失的值由特定的数据类型`NA.`表示
*   标准 Julia 库中定义的数组类型虽然有很多特性，但并没有为数据分析提供任何特定的功能。`DataFrames.jl`中提供的 DataArray 提供了这样的特性(例如，如果我们需要在一个数组中存储一些丢失的值)。
*   DataFrame 是二维数据结构，就像电子表格一样。它很像 R 或 pandas 的 DataFrames，并提供了许多表示和分析数据的功能。

## NA 数据类型及其重要性

在现实世界中，我们会遇到缺少值的数据。这很常见，但在 Julia 中默认不提供。这个功能是使用`DataFrames.jl`包添加的。DataFrames 包带来了 DataArray 包，它提供了 NA 数据类型。多重分派是 Julia 最强大的特性之一，NA 就是这样一个例子。Julia 有 NA 类型，它提供了我们用来表示缺失值的 singleton 对象 NA。

为什么需要 NA 数据类型？

例如，假设我们有一个包含浮点数的数据集:

```
julia> x = [1.1, 2.2, 3.3, 4.4, 5.5, 6.6]

```

这将创建一个六元素的`Array{Float64,1}`。

现在，假设这个数据集在位置[1]有一个缺失值。也就是说不是 1.1，没有值。这不能用 Julia 中的数组类型来表示。当我们试图分配安娜值时，我们得到这个错误:

```
julia> x[1] = NA 
LoadError: UndefVarError: NA not defined 
while loading In[2], in expression starting on line 1 

```

因此，现在我们不能将`NA`值添加到我们已经创建的数组中。

因此，为了将数据加载到具有`NA`值的数组中，我们使用`DataArray.`。这使我们能够在数据集中拥有 NA 值:

```
julia> using DataArrays 
julia> x = DataArray([1.1, 2.2, 3.3, 4.4, 5.5, 6.6]) 

```

这将创建一个六元素的`DataArrays.DataArray{Float64,1}`。

因此，当我们试图获得一个`NA`值时，它会给出:

```
julia> X[1] = NA 
NA 
julia> x 
6-element DataArrays.DataArray{Float64,1}: 
 1.1 
 2.2 
 3.3 
 4.4 
 5.5 
 6.6 

```

因此，通过使用 DataArrays，我们可以处理丢失的数据。提供的另一个特性是 NA 并不总是影响应用于特定数据集的函数。因此，不涉及安娜值或不受其影响的方法可以应用于数据集。如果它确实涉及 NA 值，那么它将给出 NA 作为结果。

在下面的例子中，我们应用了均值函数和`true || x`。均值函数不起作用，因为它涉及安娜值，但`true || x`按预期工作:

```
julia> true || x 
True 

julia> true && x[1] 
NA 

julia> mean(x) 
NA 

julia> mean(x[2:6]) 
4.4 

```

## data array——一种类似序列的数据结构

在上一节中，我们讨论了如何使用 DataArrays 来存储包含缺失(NA)值的数据集，因为 Julia 的标准数组类型不能这样做。

还有其他类似于 Julia 的数组类型的特性。Vector(一维数组类型)和 Matrix(二维数组类型)的类型别名是 DataArray 提供的 DataVector 和 DataMatrix。

创建一维数据数组类似于创建数组:

```
julia> using DataArrays
julia> dvector = data([10,20,30,40,50])
5-element DataArrays.DataArray{Int64,1}:
10
20
30
40
50

```

这里我们有 NA 值，不像数组。同样，我们可以创建一个二维数据数组，它将是一个数据矩阵:

```
julia> dmatrix = data([10 20 30; 40 50 60])
2x3 DataArrays.DataArray{Int64,2}:
10 20 30
40 50 60
julia> dmatrix[2,3]
60

```

在前面的例子中，为了计算平均值，我们使用了切片。这不是在应用函数时移除或不考虑 NA 值的方便方法。更好的方法是使用`dropna`:

```
julia> dropna(x)
5-element Array{Float64,1}:
2.2
3.3
4.4
5.5
6.6

```

## 数据框架——表格数据结构

可以说，这是统计计算中最重要和最常用的数据类型，无论是在 R (data.frame)还是 Python (Pandas)中。这是因为所有真实世界的数据大多是表格或类似电子表格的格式。这不能用简单的 DataArray 来表示:

```
julia> df = DataFrame(Name = ["Ajava Rhodiumhi", "Las Hushjoin"],
            Count = [14.04, 17.3],
            OS = ["Ubuntu", "Mint"])
```

![DataFrames – tabular data structures](graphics/B05321_02_01.jpg)

例如，这个数据集不能用 DataArray 表示。给定的数据集具有以下特征，因为它不能由 DataArray 表示:

*   该数据集在不同的列中有不同类型的数据。不同列中的这些不同数据类型不能用矩阵来表示。矩阵只能包含一种类型的值。
*   它是一种表格数据结构，记录与不同列的同一行中的其他记录有关系。因此，所有列的长度必须相同。不能使用向量，因为不能使用向量来强制相同长度的列。因此，DataFrame 中的一列由 DataArray 表示。
*   在前面的示例中，我们可以看到列被标记。这种标记有助于我们轻松熟悉数据并访问它，而无需记住它的确切位置。因此，可以使用数字索引和标签来访问这些列。

因此，由于这些原因，使用 DataFrames 包。因此，数据帧被用来表示将数据数组作为列的表格数据。

在给定的示例中，我们通过以下方式构建数据帧:

```
julia> df = DataFrame(Name = ["Ajava Rhodiumhi", "Las Hushjoin"], 
Count = [14.04, 17.3], 
OS = ["Ubuntu", "Mint"]) 

```

使用关键字参数，可以定义列名。

让我们通过构建一个新的数据帧来举另一个例子:

```
julia> df2 = DataFrame() 

julia> df2[:X] = 1:10 

julia> df2[:Y] = ["Head", "Tail", 
"Head", "Head", 
"Tail", "Head", 
"Tail", "Tail", 
"Head", "Tail"] 
julia> df2 

```

为了确定所创建的数据帧的大小，我们使用 size 函数:

```
julia> size(df2) 
(10, 2) 

```

这里，`10`是指行数，`2`是指列数。

为了查看数据集的前几行，我们使用`head()`，对于最后几行，我们使用`tail()`函数:

```
Julia> head(df2) 

```

![DataFrames – tabular data structures](graphics/B05321_02_02.jpg)

由于我们已经为数据帧的列指定了名称，因此可以使用这些名称来访问它们。

例如:

```
julia> df2[:X] 
10-element DataArrays.DataArray{Int64,1}: 
 1 
 2 
 3 
 4 
 5 
 6 
... 

```

这简化了对列的访问，因为我们可以为拥有大量列的真实数据集指定有意义的名称，而无需记住它们的数字索引。

如果需要，我们还可以使用重命名功能来重命名这些列:

```
Julia> rename!(df2, :X,  :newX) 

```

如果需要重命名多个列，可以使用以下命令:

```
julia> rename!(df2, {:X => :newX, :Y => :newY}) 

```

但是现在，为了便于使用，我们坚持使用旧的列名。

Julia 还提供了一个名为`describe()`的函数，它汇总了整个数据集。对于包含许多列的数据集，它可能非常有用:

```
julia> describe(df2) X
Min 1.0
1st Qu. 3.25
Median 5.5
Mean 5.5
3rd Qu. 7.75
Max 10.0
NAs 0
NA% 0.0%

Y
Length 10
Type ASCIIString
NAs 0
NA% 0.0%
Unique 2

```

## 安装和使用 DataFrames.jl

安装非常简单，因为它是一个注册的 Julia 包:

```
Julia> Pkg.update() 
julia> Pkg.add("DataFrames") 

```

这会将所有必需的包添加到当前名称空间中。要使用`DataFrames`包:

```
julia> using DataFrames 

```

拥有常用于学习目的的经典数据集也很好。这些数据集可以在`RDatasets`包中找到:

```
Julia> Pkg.add("RDatasets") 

```

可用的 R 包列表可通过以下方式找到:

```
julia> Rdatasets.packages() 

```

在这里，你可以看到这个:

```
datasets - The R Datasets Package 

```

它包含 r 可用的数据集。要使用此`dataset`，只需使用以下内容:

```
using RDatasets 
iris_dataset = dataset("datasets", "iris") 

```

这里，dataset 是接受两个参数的函数。

第一个参数是包的名称，第二个参数是我们想要加载的数据集的名称。

在下面的例子中，我们将著名的 iris 数据集加载到内存中。您可以看到`dataset()`函数已经返回了一个数据帧。数据集包含五列:`SepalLength`、`SepalWidth`、`PetalLength`、`PetalWidth`和`Species`。理解数据是相当容易的。每个物种都采集了大量样本，并测量了萼片和花瓣的长度和宽度，这可以在以后用于区分它们:

![Installation and using DataFrames.jl](graphics/B05321_02_03.jpg)

实际的数据科学问题一般不处理人工随机生成的数据或通过命令行读取的数据。但是它们处理从文件或任何其他外部来源加载的数据。这些文件可以包含任何格式的数据，我们可能需要在将数据加载到数据帧之前对其进行处理。

Julia 提供了一个`readtable()`函数，可以用来读取数据帧中的表格文件。通常，我们会遇到逗号分隔或制表符分隔格式的数据集(CSV 或 TSV)。`readtable()`与它们配合得非常好。

我们可以将文件的位置作为 UTF8String 给出，并将分隔符类型作为参数提供给 readtable()函数。CSV 的默认分隔符类型是逗号(“，”)，TSV 是制表符(“\t”)，WSV 是空格(“”)。

在下面的例子中，我们使用`readtable()`函数将样本虹膜数据集加载到数据帧中。

虽然 iris 数据集在 RDatasets 包中可用，但我们将下载 CSV 来处理外部数据集。iris CSV 可以从[https://github . com/sci kit-learn/sci kit-learn/blob/master/sk learn/datasets/data/iris . CSV](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/datasets/data/iris.csv)下载。

请记住将下载的 CSV 文件放入当前的工作目录中(REPL 就是从这个目录开始的，通常是`~/home/<username>`目录):

```
julia> using DataFramesjulia> df_iris_sample =
  readtable("iris_sample.csv",
  separator = ',')
julia> df_iris_sample

```

它与我们在上一个示例中使用的数据集相同，但是现在我们从 CSV 文件加载数据。

对于其他基于文本的数据集，如 TSV、WSV 或 TXT，`readtable()`也以类似的方式使用。假设相同的虹膜数据集是 TSV、WSV 或 TXT 格式。它将以类似的方式使用:

```
julia> df_iris_sample = readtable("iris_dataset.tsv", 
separator='\t') 

```

例如，如果我们有一个没有标题并由`;`分隔的数据集，我们将如下使用`readtable()`:

```
julia> df_random_dataset = readtable("random_dataset.txt",                                                                    header=false, separator=';') 

```

`readtable()`利用了 Julia 的多重分派功能，并通过不同的方法行为实现:

```
julia> methods(readtable)
3 methods for generic function readtable:
readtable(io::IO) at /home/anshul/.julia/v0.4/DataFrames/src/dataframe/io.jl:820
readtable(io::IO, nbytes::Integer) at /home/anshul/.julia/v0.4/DataFrames/src/dataframe/io.jl:820
readtable(pathname::AbstractString) at /home/anshul/.julia/v0.4/DataFrames/src/dataframe/io.jl:930

```

我们可以看到，`readtable()`函数有三种方法。

这些方法实现了一些高级选项，以减轻加载并支持各种数据格式:

*   在我们使用的 iris 示例中，我们有诸如萼片长度、萼片宽度等标题，这使得描述数据更加容易。但是标题并不总是在数据集中可用。`header`的默认值为`true`；因此，每当头不可用时，我们将参数作为 false 传递。
*   `separator::Char`:文件中的数据必须以表格结构的方式组织在文件中。这通常是通过使用`,`、`\t`、`;`，或者有时是这些的组合。`readtable()`通过文件的扩展名来猜测分隔符的类型，但是手动提供分隔符是一个很好的做法。
*   假设有丢失的值或其他值，我们希望 NA 替换它们。这是使用 nastrings 完成的。默认情况下，它接受空记录并用 NA 替换它们。
*   `truestrings::Vector{ASCIIString}`: This transforms the strings to Boolean, true. It is used when we want a set of strings to be treated as true in the dataset. By default, `True`, `true`, `T`, and `t` are transformed if no argument is given.

    *   这就像 truestrings 一样工作，但是将字符串转换为 Boolean，false。默认情况下，如果没有给定参数，`False`、`false`、`F`和`f`将被转换。

*   `nrows::Int`:如果我们只想让`readtable()`读取特定数量的行，我们使用 nrows 作为参数。默认情况下是`-1`，这意味着`readtable()`将读取整个文件。
*   如果我们想要我们的列有一些特定的名字，不同于标题中提到的，那么我们使用名字。这里，我们传递一个向量，其中包含我们想要使用的列的名称。默认情况下，它是`[]`，这意味着如果有头文件中的名字，就应该使用它们；否则，必须使用数字索引。
*   `eltypes::Vector{DataType}`:我们可以通过传递一个向量，使用 eltypes 来指定列的类型。如果没有传递任何东西，默认情况下它是一个空向量(`[]`)。
*   在数据集中，我们可能有带注释的记录。这些评论可以忽略。默认是`false`。
*   如果我们使用 allowcomments，我们还必须提到注释开始的字符(符号)。默认是`#`。
*   我们的数据集可能没有我们想要的那么完美。记录的两边可能包含空白字符。使用 ignorepadding 可以忽略这一点。默认情况下，这是真的。
*   我们的数据集可能有一些描述数据的行，它们的标题可能是我们不想要的，或者我们只想跳过前几行。这是由 skipstart 通过指定要跳过的行数来完成的。默认情况下，它为 0，将读取整个文件。
*   `skiprows::Vector{Int}`:如果想跳过数据中的某些特定行，则使用 skiprows。我们只需要指定想要跳过的向量中行的索引。默认情况下，它是`[]`，将读取整个文件。
*   如前所述，我们的数据集可能并不完美。如果我们从网上搜集数据或从其他来源提取数据，可能会有一些空白行。我们可以使用 skipblanks 跳过这些空行。默认情况下，这是正确的，但如果我们不想要它，我们可以选择其他方式。
*   `encoding::Symbol`:如果不是 UTF8，我们可以指定文件的编码。

### 将数据写入文件

我们可能还想输出我们的结果或转换数据集并将其存储在文件中。在 Julia 中，我们通过使用`writetable()`函数来实现这一点。它非常类似于我们在上一节中讨论的`readtable()`函数。

例如，我们想将`df_iris_sample`数据帧写入一个 CSV 文件:

```
julia> writetable("output_df_iris.csv", df_iris_sample)

```

这是使用默认参数集写入文件的方式。一个明显的区别是，我们传递的是我们想要写入的数据帧和我们想要写入的文件名。

`writetable()`也接受`readtable()`等各种说法。

我们也可以这样编写前面的语句，并定义分隔符:

```
julia> writetable("output_df_iris.csv", df_iris_sample, separator = ',')

```

类似地，我们可以在参数中使用标题和引号。

## 使用数据帧

我们将遵循或继承一些传统的策略来操纵数据。我们将在本节中介绍这些策略和方法，并讨论它们对数据科学的重要性。

### 了解数据帧连接

在处理多个数据集时，我们经常需要以特定的方式合并数据集，以使分析更容易或将其用于特定的函数。

我们将使用英国交通部发布的*道路安全数据*，该数据在 OGL 开放政府许可下公开。

数据集可以在这里找到:[https://data.gov.uk/dataset/road-accidents-safety-data](https://data.gov.uk/dataset/road-accidents-safety-data)。

我们将使用两个数据集:

*   道路安全:2015 年事故
*   道路安全:2015 年车辆

### 注意

`DfTRoadSafety_Accidents_2015`包含`Accident_Index`、`Location_Easting_OSGR`、`Location_Northing_OSGR`、`Longitude`、`Latitude`、`Police_Force`、`Accident_Severity`、`Number_of_Vehicles`、`Number_of_Casualties`、`Date`、`Day_of_Week`、`Time`等列。`DfTRoadSafety_Vehicles_2015`包含`Accident_Index`、`Vehicle_Reference`、`Vehicle_Type`、`Towing_and_Articulation`、`Vehicle_Manoeuvre`、`Vehicle_Location-Restricted_Lane`、`Junction_Location`、`Skidding_and_Overturning`、`Hit_Object_in_Carriageway`等列。

我们可以看到`Accident_Index`是一个常见的字段，也是唯一的。它被用作数据集中的索引。

首先，我们将使 DataFrames 包可用，然后我们将加载数据。我们使用前面讨论过的 readtable 函数将数据加载到两个不同的数据帧中:

```
julia> using DataFrames 

julia> DfTRoadSafety_Accidents_2015 = readtable("DfTRoadSafety_Accidents_2015.csv") 

julia> head(DfTRoadSafety_Accidents_2015) 

```

![Understanding DataFrames joins](graphics/image_02_004.jpg)

第一个数据集被加载到 DataFrame 中，我们尝试使用`head`获取关于该数据集的信息。它给出了几个起始列。

如果我们更想知道列名，我们可以使用`names`函数:

```
julia> names(DfTRoadSafety_Accidents_2015) 
32-element Array{Symbol,1}: 
 :_Accident_Index                             
 :Location_Easting_OSGR                       
 :Location_Northing_OSGR                      
 :Longitude                                   
 :Latitude                                    
 :Police_Force                                
 :Accident_Severity                           
 :Number_of_Vehicles                          
 :Number_of_Casualties                        
 :Date                                        
 :Day_of_Week                                 
 :Time                                        
 :Local_Authority_District_                   

 :x2nd_Road_Class                             
 :x2nd_Road_Number                            
 :Pedestrian_Crossing_Human_Control           
 :Pedestrian_Crossing_Physical_Facilities     
 :Light_Conditions                            
 :Weather_Conditions                          
 :Road_Surface_Conditions                     
 :Special_Conditions_at_Site                  
 :Carriageway_Hazards                         
 :Urban_or_Rural_Area                         
 :Did_Police_Officer_Attend_Scene_of_Accident 
 :LSOA_of_Accident_Location 

```

同样，我们将在数据帧中加载第二个数据集:

```
julia> DfTRoadSafety_Vehicles_2015 = readtable("DfTRoadSafety_Vehicles_2015.csv") 

```

第二数据集被加载到存储器中。

稍后我们将深入研究，但现在让我们在两个数据集之间进行完全连接。这两个数据集之间的连接将告诉我们哪起事故涉及哪辆车:

```
julia> DfTRoadSafety_Vehicles_2015 = readtable("DfTRoadSafety_Vehicles_2015.csv") 

julia> full_DfTRoadSafety_2015 = 
join(DfTRoadSafety_Accidents_2015, 
DfTRoadSafety_Vehicles_2015, 
on = :_Accident_Index)

```

![Understanding DataFrames joins](graphics/image_02_005.jpg)

我们可以看到完全连接已经生效。现在我们有了数据，它可以告诉我们事故发生的时间，车辆的位置，以及更多的细节。

好处是连接非常容易，非常快速，即使在大型数据集上也是如此。

我们已经了解了关系数据库中其他可用的连接。Julia 的 DataFrames 包也提供了这些连接:

*   **Inner join** :输出是数据帧，只包含那些在两个数据帧中都有键的行。
*   **Left join** :输出数据帧具有出现在第一个(左)数据帧中的键行，不管它们是否出现在第二个(右)数据帧中。
*   **右连接**:输出数据帧具有出现在第二个(右)数据帧中的键行，而不管它们是否出现在第一个(左)数据帧中。
*   **外部连接**:输出数据帧包含我们正在连接的第一个或第二个数据帧中出现的键的行。
*   **Semi join** :输出数据帧只有第一个(左)数据帧中的行，这些行的关键字同时出现在第一个(左)和第二个(右)数据帧中。输出仅包含第一个数据帧中的行。
*   **Anti join** :输出数据帧的关键字行出现在第一个(左)数据帧中，但相同关键字的行不出现在第二个(右)数据帧中。输出仅包含第一个数据帧中的行。
*   **交叉连接**:输出数据帧的行是第一个数据帧(左)和第二个数据帧(右)的行的笛卡尔乘积。

交叉连接不涉及键；因此它是这样使用的:

```
julia> cross_DfTRoadSafety_2014 = join(DfTRoadSafety_Accidents_2014, DfTRoadSafety_Vehicles_2014, kind = :cross) 

```

这里我们使用了`kind`参数来传递我们想要的连接类型。其他连接也使用该参数完成。

我们想要使用的连接类型是通过使用`kind`参数完成的。

让我们用一个更简单的数据集来理解这一点。我们将创建一个数据帧，并对其应用不同的连接:

```
julia> left_DfTRoadSafety_2014 = join(DfTRoadSafety_Accidents_2014, DfTRoadSafety_Vehicles_2014, on = :_Accident_Index, kind = :left) 

```

对于左连接，我们可以使用:

```
julia> Cities = ["Delhi","Amsterdam","Hamburg"][rand(1:3, 10)] 

julia> df1 = DataFrame(Any[[1:10], Cities, 
        rand(10)], [:ID, :City, :RandomValue1]) 

julia> df2 = DataFrame(ID = 1:10, City = Cities, 
        RandomValue2 = rand(100:110, 10))  

```

这创建了具有 10 行的两个数据帧。第一个数据帧 df1 有三列:`ID`、`City`和`RandomValue1`。第二个数据帧具有三列的 df2:`ID`、`City`和`RandomValue2`。

应用完全连接，我们可以使用:

```
julia> full_df1_df2 = join(df1,df2, 
                on = [:ID, :City]) 

```

我们使用了两列来应用连接。

这将产生:

![Understanding DataFrames joins](graphics/image_02_006.jpg)

使用`kind`参数也可以应用其他连接。让我们浏览一下旧的事故和车辆数据集。

使用`kind`的不同连接有:

```
julia> right_DfTRoadSafety_2014 = join(DfTRoadSafety_Accidents_2014, DfTRoadSafety_Vehicles_2014, on = :_Accident_Index, kind = :right) 

julia> inner_DfTRoadSafety_2014 = join(DfTRoadSafety_Accidents_2014, DfTRoadSafety_Vehicles_2014, on = :_Accident_Index, kind = :inner) 

julia> outer_DfTRoadSafety_2014 = join(DfTRoadSafety_Accidents_2014, DfTRoadSafety_Vehicles_2014, on = :_Accident_Index, kind = :outer) 

julia> semi_DfTRoadSafety_2014 = join(DfTRoadSafety_Accidents_2014, DfTRoadSafety_Vehicles_2014, on = :_Accident_Index, kind = :semi) 

julia> anti_DfTRoadSafety_2014 = join(DfTRoadSafety_Accidents_2014, DfTRoadSafety_Vehicles_2014, on = :_Accident_Index, kind = :anti) 

```

## 拆分-应用-组合策略

哈德利·韦翰(Wickham，Hadley)发表了一篇论文。"数据分析的分离-应用-组合策略."*统计软件杂志* 40.1 (2011): 1-29)，定义了数据分析的拆分-应用-组合策略。在这篇论文中，他解释了为什么将一个大问题分解成可管理的小块，独立地操作每一块，获得必要的结果，然后将所有的小块重新组合在一起是好的。

当数据集包含大量列，并且对于某些操作，所有列都不是必需的时，这是必需的。最好分割数据集，然后应用必要的函数；我们总是可以把数据集放回一起。

这是使用 by 函数通过三个参数完成的:

*   数据帧(这是我们将要分割的数据帧)
*   数据帧将在其上拆分的列名(或数字索引)
*   可以应用于数据帧的每个子集的函数

让我们尝试将 by 应用到我们相同的数据集:

![The Split-Apply-Combine strategy](graphics/B05321_02_07.jpg)

`aggregate()`功能提供了一种应用分割-应用-组合策略的替代方法。`aggregate()`函数使用同样的三个参数:

*   数据帧(这是我们将要分割的数据帧)
*   数据帧将在其上拆分的列名(或数字索引)
*   可以应用于数据帧的每个子集的函数

第三个参数中提供的函数应用于每一列，这在拆分数据帧时没有使用。

## 重塑数据

用例可能要求数据采用与我们当前不同的形式。为了促进这一点，Julia 提供了数据的整形。

让我们使用我们正在使用的数据集，但在此之前，让我们检查数据集的大小:

```
julia> size(DfTRoadSafety_Accidents_2014) 
(146322,32) 

```

我们可以看到有超过 100，000 行。尽管我们可以处理这些数据，但为了便于理解，让我们取一个更小的数据集。

RDataset 中提供的数据集总是很好的开始。为此，我们将使用经过测试的 iris 数据集。

我们将导入`RDatasets`和`DataFrames`(如果我们已经开始了一个新的终端会话):

```
julia> using RDatasets, DataFrames 

```

然后，我们将把虹膜数据集加载到一个`DataFrame`中。我们可以看到数据集有 150 行和 5 列:

![Reshaping the data](graphics/B05321_02_08.jpg)

现在我们使用`stack()`函数来重塑数据集。让我们不带任何参数使用它，除了 DataFrame。

Stack 的工作原理是为分类变量逐个创建包含所有信息的数据框架:

![Reshaping the data](graphics/B05321_02_09.jpg)

我们可以看到我们的数据集已经堆叠。这里我们已经堆叠了所有的列。我们还可以提供要堆叠的特定列:

```
Julia> iris_dataframe [:id] = 1:size(iris_dataframe, 1)  
# create a new column to track the id of the row 

Julia> iris_stack = (iris_dataframe,  [1:4]) 

```

第二个参数描述了我们想要堆叠的列。我们可以在结果中看到，第 1 列到第 4 列已经堆叠，这意味着我们已经将数据集重塑为一个新的数据帧:

```
Julia> iris_stack = stack(iris_dataframe,  [1:4]) 

Julia> size(iris_stack) 
(600,4) 
Julia> head(iris_stack) 

```

![Reshaping the data](graphics/image_02_010.jpg)

我们可以看到有一个新的列`:id`。这是堆叠数据帧的标识符。它的值会重复行重复的次数。

由于所有的列都包含在结果数据帧中，因此有些列是重复的。这些列实际上是该数据帧的标识符，由列(`id`)表示。除了标识符列(`:id`)，还有两列，`:variable`和`:values`。这些是实际包含堆叠值的列。

![Reshaping the data](graphics/image_02_011.jpg)

我们还可以提供第三个参数(可选)。这是值重复的列。利用这一点，我们可以指定包含哪个列和不包含哪个列。

![Reshaping the data](graphics/B05321_02_12.jpg)

`melt()`函数类似于堆栈函数，但有一些特殊的功能。这里我们需要指定标识符列，其余的是堆叠的:

```
Julia> iris_melt = stack(iris_dataframe, [1:4]) 

```

![Reshaping the data](graphics/B05321_02_13.jpg)

剩余的列堆叠在一起，假设它们包含测量变量。

与 stack 和 melt 相对的是 unstack，用于从长格式转换为宽格式。我们需要为 unstack 函数指定标识符列和变量/值列:

```
julia> unstack(iris_melt, :id, :variable, :value) 

```

![Reshaping the data](graphics/B05321_02_14.jpg)

如果剩余列是唯一的，则可以跳过拆分参数中的`:id`(标识符):

```
julia> unstack(iris_melt, :variable, :value) 

```

`meltdf`和`stackdf`是两个额外的功能，类似于熔化和堆叠，但也提供了对原始宽数据帧的查看:

```
Julia> iris_stackdf = stackdf(iris_dataframe) 

```

![Reshaping the data](graphics/B05321_02_15.jpg)

这似乎与堆栈函数非常相似，但是我们可以通过查看它们的存储表示来看出区别。

为了查看存储表示，使用了 dump。让我们将它应用于堆栈函数:

![Reshaping the data](graphics/B05321_02_16.jpg)

*   在这里，我们可以看到`:variable`的类型是`Array(Symbol,(600,))`
*   `:value`属于`DataArrays.DataArray{Float64,1}(600)`类型
*   标识符(`:Species`)的类型为`DataArrays.PooledDataArray{ASCIIString,UInt8,1}(600)`

现在，我们将看看`stackdf`的存储表示:

![Reshaping the data](graphics/B05321_02_17.jpg)

在这里，我们可以看到:

*   `:variable`属于`DataFrames.RepeatedVector{Symbol}`类型。变量重复 n 次，其中 n 指的是原始`AbstractDataFrame`中的行数。
*   `:value`属于`DataFrames.StackedVector`类型。这有助于查看堆叠在一起的列，就像在原始数据帧中一样。
*   标识符(`:Species`)的类型为`Species: DataFrames.RepeatedVector{ASCIIString}`。原始列重复 n 次，其中 n 是堆叠的列数。

使用这些抽象向量，我们现在能够创建视图，从而通过使用这个实现节省内存。

整形函数不提供执行聚合的功能。因此，为了执行聚合，使用了分割-应用-组合策略与整形的组合。

我们将使用`iris_stack`:

```
julia> iris_stack = stack(iris_dataframe) 

```

![Reshaping the data](graphics/B05321_02_18.jpg)

在这里，我们创建了一个新的列，它根据物种具有列的平均值。我们现在可以解散堆叠。

![Reshaping the data](graphics/B05321_02_19.jpg)

## 对数据集进行排序

排序是数据分析中最常用的技术之一。在 Julia 中，通过调用`sort`或`sort!`函数可以简化排序。

`sort`和`sort!`的区别在于`sort!`就地工作，对实际数组进行排序，而不是创建一个副本。

让我们对 iris 数据集使用`sort!`函数:

![Sorting a dataset](graphics/B05321_02_20.jpg)

我们可以看到列没有按照`[:SepalLength, :SepalWidth, :PetalLength, :PetalWidth]`排序。但这些实际上是根据:物种一栏排序的。

排序函数接受一些参数并提供一些特性。例如，要反向排序，我们有:

```
julia> sort!(iris_dataframe, rev = true) 

```

为了对某些特定的列进行排序，我们有:

```
julia> sort!(iris_dataframe, cols = [:SepalLength, :PetalLength]) 

```

我们也可以使用带有`sort!`的 by 函数，对数据帧或单列应用另一个函数。

![Sorting a dataset](graphics/B05321_02_21.jpg)

`order`用于指定一组列中特定列的排序。

## 公式——数学表达式的特殊数据类型

数据科学涉及各种统计公式，以从数据中获得洞察力。这些公式的创建和应用是数据科学的核心过程之一。它将输入变量用某种函数和数学表达式映射到输出。

Julia 通过在`DataFrame`包中提供一个公式类型来简化这个过程，这个公式类型与符号`~`一起使用。`~`是一个二元运算符。例如:

```
julia> formulaX = A ~ B + C

```

对于统计建模，建议使用 ModelMatrix，它构造一个矩阵{Float64}，使其更适合统计模型。Formula 还可以用于从 DataFrame 转换为 ModelFrame 对象，data frame 是它的包装器，以满足统计建模的需要。

用随机值创建数据帧:

![Formula - a special data type for mathematical expressions](graphics/B05321_02_22.jpg)

使用公式将其转换成一个`ModelFrame`对象:

![Formula - a special data type for mathematical expressions](graphics/B05321_02_23.jpg)

从一个`ModelFrame`创建一个`ModelMatrix`非常容易:

![Formula - a special data type for mathematical expressions](graphics/B05321_02_24.jpg)

有一个额外的列只包含`value = 1.0`。它用于回归模型以拟合截距项。

## 汇集数据

为了有效地分析巨大的数据集，使用了 PooledDataArray。DataArray 使用一种编码来表示 vector 的每个条目的完整字符串。这不是很高效，尤其是对于大型数据集和内存密集型算法。

我们的用例更多地处理涉及少量级别的因素:

![Pooling data](graphics/B05321_02_25.jpg)

使用小级别池中的索引而不是字符串来高效地表示数据。

![Pooling data](graphics/B05321_02_26.jpg)

`PooledDataArray`还为我们提供了使用级别功能找出因子级别的功能:

![Pooling data](graphics/B05321_02_27.jpg)

`PooledDataArray`甚至提供了一个紧凑的功能来高效地使用内存:

```
Julia> pooleddatavector = compact (pooleddatavector) 

```

然后，当因子不是在`PooledDataArray`列中编码而是在 DataArray 或 DataFrame 中编码时，它提供了一个用于转换单个列的池函数:

```
Julia>  pooleddatavector = pool(datavector) 

```

![Pooling data](graphics/B05321_02_28.jpg)

`PooledDataArray`有助于分类数据的分析，因为 ModelMatrix 中的列被视为 0-1 指示列。PooledDataArray 的每个级别都与一列相关联。

## 网页抓取

真实世界的用例还包括从网络上抓取数据进行分析。让我们构建一个小的网络抓取器来获取 Reddit 帖子。

为此，我们需要 JSON 和请求包:

```
julia> Pkg.add("JSON") 
julia> Pkg.add("Requests") 

# import the required libraries 
julia> using JSON, Requests 

# Use the reddit URL to fetch the data from 
julia> reddit_url = https://www.reddit.com/r/Julia/ 

# fetch the data and store it in a variable 
julia> response = get("$(reddit_url)/.json") 
Response(200 OK, 21 headers, 55426 bytes in body) 

# Parse the data received using JSON.parse 
julia> dataReceived = JSON.parse(Requests.text(response)) 
# Create the required objects 
julia> nextRecord = dataReceived["data"]["after"] 
julia> counter = length(dataReceived["data"]["children"]) 

```

在这里，我们定义了一个 URL，我们将从这里抓取数据。我们是从朱莉亚在 Reddit 上的版块抓取的。

然后，我们使用 Requests 包中的 get 函数从定义的 URL 获取内容。我们可以看到，响应 200 与数据相符:

```
julia> statuscode(response) 
200 

julia> HttpCommon.STATUS_CODES[200] 
"OK" 

```

然后，我们使用 Julia 的 JSON 包提供的 JSON 解析器解析收到的 JSON 数据。我们现在可以开始读唱片了。

![Web scraping](graphics/B05321_02_29.jpg)

我们可以将接收到的数据存储在数组或数据帧中(取决于用例和易用性)。这里，我们使用一个数组来存储解析后的数据。我们可以检查存储在数组中的数据。

![Web scraping](graphics/B05321_02_30.jpg)

假设我们只需要看到这些帖子的标题，就知道自己刮到了什么；我们只需要知道他们在哪一栏。

![Web scraping](graphics/B05321_02_31.jpg)

我们现在可以看到 Reddit 帖子的标题。但是如果我们有太多的列或者我们有一些丢失的值呢？数据框架肯定是一个更好的选择。



# 总结

在本章中，我们学习了什么是数据管理，以及为什么它对于数据科学是必要的。Julia 提供了使用 DataFrames.jl 包进行数据管理的功能，包括以下特性:

*   `NA`:Julia 中缺失的值由特定的数据类型 NA 表示。
*   `DataArray`:`DataFrames.jl`中提供的 DataArray 提供了一些特性，比如允许我们在数组中存储一些缺失的值。
*   数据帧是像电子表格一样的二维数据结构。它非常类似于 R 或 pandas 的 dataframes，并提供了许多表示和分析数据的功能。DataFrames 有许多非常适合数据分析和统计建模的特性。
*   数据集可以在不同的列中包含不同类型的数据。
*   记录与相同长度的不同列的同一行中的其他记录有关系。
*   可以给列加标签。标签有助于我们容易地熟悉数据并访问它，而不需要记住它们的数字索引。

我们学习了使用`readtable()`函数从文件导入数据和将数据导出到文件。`readtable()`函数在使用许多参数时提供了灵活性。

我们还探索了数据集的连接，比如 RDBMS 表。Julia 提供了各种各样的连接，我们可以根据我们的用例加以利用。

我们讨论了拆分-应用-组合策略，这是数据科学家部署的最广泛使用的技术之一，以及为什么需要它。我们使用 stack 和 melt (stackdf，meltdf)函数对数据进行了整形或透视，并探索了所涉及的各种可能性。我们还了解了`PooledDataArray`，并了解了高效内存管理为什么需要它。

我们了解了网络搜集，这有时是数据科学家收集数据的必备工具。我们还使用 Requests 包来获取 HTTP 响应。



# 参考文献

*   [http://julia.readthedocs.org/en/latest/manual/](http://julia.readthedocs.org/en/latest/manual/)
*   [http://dataframesjl.readthedocs.io/en/latest/](http://dataframesjl.readthedocs.io/en/latest/)
*   [https://data.gov.uk/dataset/road-accidents-safety-data](https://data.gov.uk/dataset/road-accidents-safety-data)
*   威克姆，哈德利。"数据分析的分离-应用-组合策略."*统计软件杂志* 40.1 (2011): 1-29