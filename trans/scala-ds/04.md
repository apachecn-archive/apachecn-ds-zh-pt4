

# 四、并行集合和未来

数据科学通常涉及处理中等或大量的数据。由于之前单个 CPU 速度的指数级增长已经放缓，而数据量继续增加，有效利用计算机必然需要并行计算。

在这一章中，我们将探讨在单台计算机上并行计算和数据处理的方法。几乎所有的新计算机都有不止一个处理单元，在这些核心上分配计算是加速中等规模计算的有效方法。

在单个芯片上并行计算适合于涉及千兆字节或几兆兆字节数据的计算。对于更大的数据流，我们必须求助于将计算并行分布在几台计算机上。我们将在[第十章](ch10.html "Chapter 10. Distributed Batch Processing with Spark")、*用 Spark* 讨论 Apache Spark，一个并行数据处理的框架。

在本书中，我们将探讨在单台机器上利用并行架构的三种常见方式:并行集合、未来和参与者。本章我们将考虑前两者，把对演员的研究留给[第九章](ch09.html "Chapter 9. Concurrency with Akka")，*与 Akka* 并发。

# 平行集合

并行集合提供了一种非常简单的方法来并行化独立的任务。熟悉 Scala 的读者会知道，很多任务都可以表述为集合上的操作，比如*映射*、*归约*、*过滤*，或者*分组通过*。并行集合是 Scala 集合的一种实现，它将这些操作并行化，在几个线程上运行。

先说个例子。我们要计算每个字母在句子中出现的频率:

```

scala> val sentence = "The quick brown fox jumped over the lazy dog"

sentence: String = The quick brown fox jumped ...

```

让我们先把我们的句子从一个字符串转换成一个字符向量:

```

scala> val characters = sentence.toVector

Vector[Char] = Vector(T, h, e,  , q, u, i, c, k, ...)

```

我们现在可以将`characters`转换成一个*平行的*向量，一个`ParVector`。为此，我们使用了`par`方法:

```

scala> val charactersPar = characters.par

ParVector[Char] = ParVector(T, h, e,  , q, u, i, c, k,  , ...)

```

集合支持与常规向量相同的操作，但是它们的方法是在几个线程上并行执行的。

让我们从过滤掉`charactersPar`中的空格开始:

```

scala> val lettersPar = charactersPar.filter { _ != ' ' }

ParVector[Char] = ParVector(T, h, e, q, u, i, c, k, ...)

```

注意 Scala 是如何隐藏执行细节的。`filter`操作是使用多线程执行的，您几乎没有注意到！除了我们将在下一节探讨的一些细节之外，并行向量的接口和行为与串行向量是相同的。

现在让我们使用`toLower`函数将字母变成小写:

```

scala> val lowerLettersPar = lettersPar.map { _.toLower }

ParVector[Char] = ParVector(t, h, e, q, u, i, c, k, ...)

```

和以前一样，并行应用了`map`方法。为了找到每个字母出现的频率，我们使用`groupBy`方法将字符分组到包含该字符所有出现的向量中:

```

scala> val intermediateMap = lowerLettersPar.groupBy(identity)

ParMap[Char,ParVector[Char]] = ParMap(e -> ParVector(e, e, e, e), ...)

```

注意`groupBy`方法是如何创建一个`ParMap`实例的，它是不可变映射的并行等价物。为了获得每个字母出现的次数，我们对`intermediateMap`进行了一个`mapValues`调用，用长度替换了每个向量:

```

scala> val occurenceNumber = intermediateMap.mapValues { _.length }

ParMap[Char,Int] = ParMap(e -> 4, x -> 1, n -> 1, j -> 1, ...)

```

恭喜你！我们编写了一个多线程算法，用于查找几行代码中每个字母的出现频率。您应该会发现修改它来查找文档中每个单词的出现频率很简单，这是分析文本数据时常见的预处理问题。

并行集合使得并行化一些操作流水线变得非常容易:我们所要做的就是在`characters`向量上调用`.par`。所有后续操作都是并行的。这使得从串行转换到并行实现非常容易。

## 平行收款的限制

并行集合的部分功能和吸引力在于它们提供了与串行集合相同的接口:它们有一个`map`方法、`foreach`方法、`filter`方法等等。总的来说，这些方法在并行集合上的工作方式与串行集合相同。然而，有一些值得注意的警告。最重要的一点与副作用有关。如果对并行集合的操作有副作用，这可能会导致争用情况:最终结果取决于线程执行操作的顺序。

当我们更新集合之外定义的变量时，集合中的副作用最常见。举一个意外行为的简单例子，让我们定义一个`count`变量，并使用一个并行范围将其递增一千倍:

```

scala> var count = 0

count: Int = 0

scala> (0 until 1000).par.foreach { i => count += 1 }

scala> count

count: Int = 874 // not 1000!

```

这里发生了什么？传递给`foreach`的函数有一个副作用:它增加了`count`，一个函数范围之外的变量。这是一个问题，因为`+=`操作符是两个操作的序列:

*   检索`count`的值并加 1
*   将结果分配回`count`

为了理解为什么这会导致意外的行为，让我们假设`foreach`循环已经在两个线程上并行化了。**线程 A** 可能会在 **832** 时读取**计数**变量，并加 1 给 **833** 。在有时间将 **833** 重新分配给**计数**之前，**线程 B** 读取**计数**，仍然在 **832** 处，并加 1 给 **833** 。**线程 A** 然后将 **833** 分配给**计数**。**线程 B** 然后将 **833** 分配给**计数**。我们已经运行了两次更新，但是计数只增加了一。问题的出现是因为`+=`可以分成两条指令:它不是*原子的*。这为线程提供了交叉操作的空间:

![Limitations of parallel collections](graphics/4795_race_condition.jpg)

竞争情况的剖析:线程 A 和线程 B 都试图同时更新`count`，导致其中一个更新被覆盖。`count`的最终值是 833 而不是 834。

为了给出一个由非原子性引起的问题的更现实的例子，让我们看一个不同的方法来计算每个字母在我们的句子中出现的频率。我们在循环之外定义了一个可变的`Char -> Int`哈希映射。每次我们遇到一个字母，我们在映射中增加相应的整数:

```

scala> import scala.collection.mutable

import scala.collection.mutable

scala> val occurenceNumber = mutable.Map.empty[Char, Int]

occurenceNumber: mutable.Map[Char,Int] = Map()

scala> lowerLettersPar.foreach { c => 

 occurenceNumber(c) = occurenceNumber.getOrElse(c, 0) + 1

}

scala> occurenceNumber('e') // Should be 4

Int = 2

```

出现这种差异是因为`foreach`循环中操作的非原子性。

一般来说，避免高阶函数对集合的副作用是一种很好的做法。它们使得代码更难理解，并且排除了从串行集合到并行集合的切换。避免暴露可变状态也是一个很好的实践:不可变对象可以在线程之间自由共享，并且不会受到副作用的影响。

并行收集的另一个限制出现在归约(或折叠)操作中。用于将项目组合在一起的函数必须是*关联的*。例如:

```

scala> (0 until 1000).par.reduce {_ - _ } // should be -499500

Int = 63620

```

*减去*运算符`–`，是不关联的。应用连续操作的顺序很重要:`(a – b) – c`与`a – (b – c)`不同。用于减少并行集合的函数必须是关联的，因为减少发生的顺序与集合的顺序无关。

## 错误处理

在单线程程序中，异常处理相对简单:如果出现异常，函数可以处理它或者升级它。当引入并行性时，这一点就不那么明显了:一个线程可能会失败，但其他线程可能会成功返回。

如果并行集合方法在任何元素上失败，就会抛出异常，就像串行集合方法一样:

```

scala> Vector(2, 0, 5).par.map { 10 / _ }

java.lang.ArithmeticException: / by zero

...

```

有些情况下，这不是我们想要的行为。例如，我们可能使用并行集合来并行检索大量网页。如果有几页无法读取，我们可能不会介意。

Scala 的`Try`类型是为可能抛出异常的沙盒代码而设计的。它与`Option`的相似之处在于它是一个单元素容器:

```

scala> import scala.util._

import scala.util._

scala> Try { 2 + 2 }

Try[Int] = Success(4)

```

与指示表达式是否有有用值的`Option`类型不同，`Try`类型指示表达式是否可以在不抛出异常的情况下执行。它具有以下两个值:

*   `Try { 2 + 2 } == Success(4)`如果`Try`语句中的表达式求值成功
*   `Try { 2 / 0 } == Failure(java.lang.ArithmeticException: / by zero)`如果`Try`块中的表达式导致异常

这用一个例子会更有意义。为了查看`Try`类型的运行情况，我们将尝试以容错方式获取网页。我们将使用内置的`Source.fromURL` 方法，该方法获取一个 web 页面并打开页面内容的迭代器。如果它无法获取网页，就会抛出一个错误:

```

scala> import scala.io.Source

import scala.io.Source

scala> val html = Source.fromURL("http://www.google.com")

scala.io.BufferedSource = non-empty iterator

scala> val html = Source.fromURL("garbage")

java.net.MalformedURLException: no protocol: garbage

...

```

我们可以将对`Source.fromURL`的调用包装在`Try`中，而不是让表达式传播出去，导致我们剩余的代码崩溃:

```

scala> Try { Source.fromURL("http://www.google.com") }

Try[BufferedSource] = Success(non-empty iterator)

scala> Try { Source.fromURL("garbage") }

Try[BufferedSource] = Failure(java.net.MalformedURLException: no protocol: garbage)

```

为了了解我们的`Try`语句的威力，现在让我们以容错方式并行检索一个 URL 列表:

```

scala> val URLs = Vector("http://www.google.com", 

 "http://www.bbc.co.uk",

 "not-a-url"

)

URLs: Vector[String] = Vector(http://www.google.com, http://www.bbc.co.uk, not-a-url)

scala> val pages = URLs.par.map { url =>

 url -> Try { Source.fromURL(url) } 

}

pages: ParVector[(String, Try[BufferedSource])] = ParVector((http://www.google.com,Success(non-empty iterator)), (http://www.bbc.co.uk,Success(non-empty iterator)), (not-a-url,Failure(java.net.MalformedURLException: no protocol: not-a-url)))

```

然后，我们可以使用一个`collect`语句对我们可以成功获取的页面进行操作。例如，要获得每页的字符数:

```

scala> pages.collect { case(url, Success(it)) => url -> it.size }

ParVector[(String, Int)] = ParVector((http://www.google.com,18976), (http://www.bbc.co.uk,132893))

```

通过充分利用 Scala 内置的`Try`类和并行集合，我们用几行代码就构建了一个容错的多线程 URL 检索器。(与无数的 Java/C++ 书籍相比，这些书籍在代码示例前加上“为了清晰起见，省略了错误处理”。)

### Tip

**Try 类型对比 try/catch 语句**

具有命令式或面向对象背景的程序员会更熟悉处理异常的 try/catch 块。我们可以通过将获取 URL 的代码包装在 try 块中来实现类似的功能，如果调用引发异常，则返回 null。

然而，除了更加冗长之外，返回 null 也不太令人满意:我们丢失了关于异常的所有信息，并且 null 不如`Failure(exception)`有表现力。此外，返回一个`Try[T]`类型会迫使调用者考虑函数失败的可能性，方法是将这种可能性编码到返回值的类型中。相比之下，只返回`T`和空值编码失败允许调用者忽略失败，增加了在程序中完全不同的点抛出令人困惑的`NullPointerException`的可能性。

简而言之，`Try[T]`只是另一种高阶类型，就像`Option[T]`或`List[T]`。像对待代码的其他部分一样对待失败的可能性增加了程序的一致性，并鼓励程序员明确地处理异常的可能性。

## 设置并行度

到目前为止，我们已经将视为黑盒:将`par`添加到一个普通的集合中，所有的操作都是并行执行的。通常，我们希望对任务的执行方式有更多的控制。

在内部，并行收集通过将操作分布在多个线程上来工作。由于线程共享内存，并行收集不需要复制任何数据。更改并行收集可用的线程数量将会更改用于执行任务的 CPU 数量。

并行集合有一个控制任务执行的`tasksupport`属性:

```

scala> val parRange = (0 to 100).par

parRange: ParRange = ParRange(0, 1, 2, 3, 4, 5,...

scala> parRange.tasksupport

TaskSupport = scala.collection.parallel.ExecutionContextTaskSupport@311a0b3e

scala> parRange.tasksupport.parallelismLevel

Int = 8 // Number of threads to be used

```

集合的任务支持对象是一个*执行上下文*，一个能够在独立线程中执行 Scala 表达式的抽象。默认情况下，Scala 2.11 中的执行上下文是一个*窃取工作的线程池*。当并行集合提交任务时，上下文将这些任务分配给它的线程。如果一个线程发现它已经完成了排队的任务，它将尝试从其他线程窃取未完成的任务。默认的执行上下文维护一个线程池，线程的数量等于 CPU 的数量。

通过改变任务支持，可以改变并行集合分配工作的线程的数量。例如，要在四个线程范围内并行执行操作:

```

scala> import scala.collection.parallel._

import scala.collection.parallel._

scala> parRange.tasksupport = new ForkJoinTaskSupport(

 new scala.concurrent.forkjoin.ForkJoinPool(4)

)

parRange.tasksupport: scala.collection.parallel.TaskSupport = scala.collection.parallel.ForkJoinTaskSupport@6e1134e1

scala> parRange.tasksupport.parallelismLevel

Int: 4

```

## 一个例子——平行收集的交叉验证

让我们应用到目前为止你所学到的知识来解决数据科学问题。机器学习流水线的许多部分都可以并行化。交叉验证就是其中之一。

我们在这里会对交叉验证做一个简单的描述，但是你可以参考*统计学习的要素*，作者*哈斯蒂*，*蒂布希拉尼*，以及*弗里德曼*进行更深入的讨论。

通常，监督机器学习问题涉及在训练集上训练算法。例如，当我们构建一个模型，根据一个人的身高和体重来计算他是男性的概率时，训练集是每个参与者的(身高、体重)数据，以及每行的男性/女性标签。一旦在训练集上训练了算法，我们就可以用它来对新数据进行分类。只有当训练集代表我们可能遇到的新数据时，这个过程才有意义。

训练集有有限数量的条目。因此，不可避免地，仅仅由于其有限的性质，它将具有不代表一般人口的特质。当预测一个新人是男是女时，这些特质将导致预测误差，超过算法对训练集本身的预测误差。交叉验证是一种工具，用于估计由不反映总体的训练集特性所引起的误差。

交叉验证的工作原理是将训练集分为两部分:一个较小的新训练集和一个交叉验证集。该算法在缩减的训练集上进行训练。然后，我们会看到该算法对交叉验证集的建模有多好。因为我们知道交叉验证集的正确答案，所以我们可以测量当显示新信息时我们的算法执行得有多好。我们用不同的交叉验证集多次重复这个过程。

有几种不同类型的交叉验证，不同之处在于我们如何选择交叉验证集。在这一章中，我们将关注重复的随机子采样:我们从训练数据中随机选择 *k* 行来形成交叉验证集。我们多次这样做，计算每个子样本的交叉验证误差。由于每次迭代都独立于之前的迭代，因此我们可以轻松地并行化这个过程。因此，它是并行收集的一个很好的候选对象。我们将在[第 12 章](ch12.html "Chapter 12. Distributed Machine Learning with MLlib")、*使用 MLlib* 的分布式机器学习中，查看交叉验证的替代形式 *k 倍交叉验证*。

我们将构建一个并行执行交叉验证的类。我鼓励你边走边写代码，但是你会在 GitHub([https://github.com/pbugnion/s4ds](https://github.com/pbugnion/s4ds))上找到对应于这些例子的源代码。我们将使用并行集合来处理内部循环中的并行性和 Breeze 数据类型。`build.sbt`文件与我们在[第二章](ch02.html "Chapter 2. Manipulating Data with Breeze")、*中使用的文件相同，使用 Breeze* 操作数据:

```

scalaVersion := "2.11.7"

libraryDependencies ++= Seq(

 "org.scalanlp" %% "breeze" % "0.11.2",

 "org.scalanlp" %% "breeze-natives" % "0.11.2"

)

```

我们将构建一个`RandomSubsample`类。该类公开了一个函数的类型别名`CVFunction`，该函数采用两个索引列表，第一个对应于精简的训练集，第二个对应于验证集，并返回一个对应于交叉验证错误的`Double`:

```
type CVFunction = (Seq[Int], Seq[Int]) => Double
```

`RandomSubsample`类将公开一个方法`mapSamples`，它接受一个`CVFunction`，反复传递给它不同的索引分区，并返回一个错误向量。这是类的样子:

```
// RandomSubsample.scala

import breeze.linalg._

import breeze.numerics._

/** Random subsample cross-validation

  * 

  * @param nElems Total number of elements in the training set.

  * @param nCrossValidation Number of elements to leave out of training set.

*/

class RandomSubsample(val nElems:Int, val nCrossValidation:Int) {

  type CVFunction = (Seq[Int], Seq[Int]) => Double

  require(nElems > nCrossValidation,

    "nCrossValidation, the number of elements " +

    "withheld, must be < nElems")

  private val indexList = DenseVector.range(0, nElems)

  /** Perform multiple random sub-sample CV runs on f

    *

    * @param nShuffles Number of random sub-sample runs.

    * @param f user-defined function mapping from a list of

    *   indices in the training set and a list of indices in the

    *   test-set to a double indicating the out-of sample score

    *   for this split.

    * @returns DenseVector of the CV error for each random split.

    */

  def mapSamples(nShuffles:Int)(f:CVFunction)

  :DenseVector[Double] = {

    val cvResults = (0 to nShuffles).par.map { i =>

      // Randomly split indices between test and training

      val shuffledIndices = breeze.linalg.shuffle(indexList)

      val Seq(testIndices, trainingIndices) =

        split(shuffledIndices, Seq(nCrossValidation))

 // Apply f for this split

      f(trainingIndices.toScalaVector, 

        testIndices.toScalaVector)

    }

    DenseVector(cvResults.toArray)

  }

}
```

让我们更详细地看看发生了什么，从传递给构造函数的参数开始:

```
class RandomSubsample(val nElems:Int, val nCrossValidation:Int)
```

我们传递训练集中的元素总数以及要在类构造函数中进行交叉验证的元素数量。因此，将 100 传递给`nElems`并将 20 传递给`nCrossValidation`意味着我们的训练集将拥有总数据的 80 个随机元素，而测试集将拥有 20 个元素。

然后我们构建一个包含所有在`0`和`nElems`之间的整数的列表:

```
private val indexList = DenseVector.range(0, nElems)
```

对于交叉验证的每次迭代，我们将打乱这个列表，并将第一个`nCrossValidation`元素作为我们的测试集中的行的索引，其余的作为我们的训练集中的行的索引。

我们的类公开了一个方法`mapSamples`，它接受两个约定的参数:`nShuffles`，执行随机子采样的次数，和`f`，一个`CVFunction`:

```
  def mapSamples(nShuffles:Int)(f:CVFunction):DenseVector[Double] 
```

有了这些设置，进行交叉验证的代码看似简单。我们生成一个从`0`到`nShuffles`的平行范围，对于该范围内的每个项目，生成一个新的训练测试分割，并计算交叉验证误差:

```
    val cvResults = (0 to nShuffles).par.map { i =>

      val shuffledIndices = breeze.linalg.shuffle(indexList)

      val Seq(testIndices, trainingIndices) = 

        split(shuffledIndices, Seq(nCrossValidation))

      f(trainingIndices.toScalaVector, testIndices.toScalaVector)

    }
```

这个函数唯一棘手的部分是将混洗的索引列表分成训练集的索引列表和测试集的索引列表。我们使用 Breeze 的`split`方法。它将一个向量作为它的第一个参数，将一个分割点列表作为它的第二个参数，并返回一个原始向量的片段列表。然后，我们使用模式匹配来提取各个部分。

最后，`mapSamples`将`cvResults`转换为 Breeze 矢量:

```
DenseVector(cvResults.toArray) 
```

让我们来看看实际情况。我们可以通过在第 2 章[和*中开发的逻辑回归示例上运行交叉验证来测试我们的类，使用 Breeze* 操作数据。在那一章中，我们开发了一个`LogisticRegression`类，它在构建时接受一个训练集(以`DenseMatrix`的形式)和一个目标(以`DenseVector`的形式)。然后，该类计算最能代表训练集的参数。我们将首先向`LogisticRegression`类添加两个方法，以使用训练好的模型来分类以前没有见过的例子:](ch02.html "Chapter 2. Manipulating Data with Breeze")

*   `predictProbabilitiesMany`方法使用训练好的模型来计算将目标变量设置为 1 的概率。在我们的例子中，这是男性的概率，给定身高和体重。
*   `classifyMany`方法将分类标签(1 或 0)分配给测试集的成员。如果`predictProbabilitiesMany`返回一个大于`0.5`的值，我们将赋值 1。

有了这两个函数，我们的`LogisticRegression`类就变成了:

```
// Logistic Regression.scala

class LogisticRegression(

  val training:DenseMatrix[Double],

  val target:DenseVector[Double]

) {

  ...

  /** Probability of classification for each row

    * in test set.

    */

  def predictProbabilitiesMany(test:DenseMatrix[Double])

  :DenseVector[Double] = {

    val xBeta = test * optimalCoefficients

    sigmoid(xBeta)

  }

  /** Predict the value of the target variable 

    * for each row in test set.

    */

  def classifyMany(test:DenseMatrix[Double])

  :DenseVector[Double] = {

    val probabilities = predictProbabilitiesMany(test)

    I((probabilities :> 0.5).toDenseVector)

  }

  ...

}
```

我们现在可以为我们的`RandomSubsample`类编写一个示例程序。我们将使用与第二章[、*中相同的身高体重数据，用 Breeze* 操作数据。数据预处理将是类似的。本章的代码示例提供了一个助手模块`HWData`，用于将身高体重数据加载到 Breeze vectors 中。数据本身位于本章代码示例的`data/` 目录中(可从 GitHub 的](ch02.html "Chapter 2. Manipulating Data with Breeze")[https://github.com/pbugnion/s4ds/tree/master/chap04](https://github.com/pbugnion/s4ds/tree/master/chap04)获得)。

对于每个新的子样本，我们创建一个新的`LogisticRegression` 实例，在训练集的子集上训练它，以获得这个训练测试分割的最佳系数，并使用`classifyMany`在这个分割中的交叉验证集上生成预测。然后，我们计算分类误差，并报告每个训练测试分割的平均分类误差:

```
// RandomSubsampleDemo.scala

import breeze.linalg._

import breeze.linalg.functions.manhattanDistance

import breeze.numerics._

import breeze.stats._

object RandomSubsampleDemo extends App {

  /* Load and pre-process data */

  val data = HWData.load

  val rescaledHeights:DenseVector[Double] =

    (data.heights - mean(data.heights)) / stddev(data.heights)

  val rescaledWeights:DenseVector[Double] =

    (data.weights - mean(data.weights)) / stddev(data.weights)

  val featureMatrix:DenseMatrix[Double] =

    DenseMatrix.horzcat(

      DenseMatrix.ones[Double](data.npoints, 1),

      rescaledHeights.toDenseMatrix.t,

      rescaledWeights.toDenseMatrix.t

    )

  val target:DenseVector[Double] = data.genders.values.map { 

    gender => if(gender == 'M') 1.0 else 0.0 

  }

  /* Cross-validation */

  val testSize = 20

  val cvCalculator = new RandomSubsample(data.npoints, testSize)

  // Start parallel CV loop

  val cvErrors = cvCalculator.mapSamples(1000) { 

    (trainingIndices, testIndices) =>

    val regressor = new LogisticRegression(

      data.featureMatrix(trainingIndices, ::).toDenseMatrix,

      data.target(trainingIndices).toDenseVector

    )

    // Predictions on test-set

    val genderPredictions = regressor.classifyMany(

      data.featureMatrix(testIndices, ::).toDenseMatrix

    )

    // Calculate number of mis-classified examples

    val dist = manhattanDistance(

      genderPredictions, data.target(testIndices)

    )

    // Calculate mis-classification rate

    dist / testSize.toDouble

  }

  println(s"Mean classification error: ${mean(cvErrors)}")

}
```

对身高体重数据运行这个程序给出了 10%的分类误差。

我们现在有了一个完全工作的并行交叉验证类。Scala 的并行范围使得在不同的线程中重复计算相同的函数变得简单。



# 未来

并行集合为并行操作提供了一个简单而强大的框架。然而，它们在一个方面受到限制:必须预先知道工作总量，并且每个线程必须执行相同的功能(可能在不同的输入上)。

假设我们想要编写一个程序，每隔几秒钟获取一个网页(或查询一个 web API)，并从这个网页中提取数据以供进一步处理。一个典型的例子可能涉及查询 web API 来维护特定股票价格的最新值。从外部网页获取数据通常需要几百毫秒。如果我们在主线程上执行这个操作，它将不必要地浪费 CPU 周期来等待 web 服务器的回复。

解决方案是将获取网页的代码封装在未来的*中*。未来是一个包含未来计算结果的单元素容器。当你创建一个未来时，为了避免阻塞主线程，其中的计算被卸载到另一个线程。当计算完成时，结果将被写入未来，从而可供主线程访问。

例如，我们将编写一个程序，查询“Markit on demand”API 来获取给定股票的价格。例如，谷歌股票当前价格的网址是 http://dev.markitondemand.com/MODApis/Api/v2/Quote?的[symbol=GOOG](http://dev.markitondemand.com/MODApis/Api/v2/Quote?symbol=GOOG) 。请将它粘贴到您的 web 浏览器的地址栏中。您将看到一个 XML 字符串，其中包含当前的股票价格。让我们以编程的方式获取它，而不是先求助于未来:

```

scala> import scala.io._

import scala.io_

scala> val url = "http://dev.markitondemand.com/MODApis/Api/v2/Quote?symbol=GOOG"

url: String = http://dev.markitondemand.com/MODApis/Api/v2/Quote?symbol=GOOG

scala> val response = Source.fromURL(url).mkString

response: String = <StockQuote><Status>SUCCESS</Status>

...

```

请注意，查询 API 需要一点时间。让我们现在做同样的事情，但是使用一个未来(现在不要担心导入，我们将进一步详细讨论它们的含义):

```

scala> import scala.concurrent._

import scala.concurrent._

scala> import scala.util._

import scala.util._

scala> import scala.concurrent.ExecutionContext.Implicits.global

import scala.concurrent.ExecutionContext.Implicits.global

scala> val response = Future { Source.fromURL(url).mkString }

response: Future[String] = Promise$DefaultPromise@3301801b

```

如果您运行这个，您会注意到在 API 有机会响应之前，控制立即返回到 shell。为了使这一点更加明显，让我们通过添加对`Thread.sleep`的调用来模拟一个慢速连接:

```

scala> val response = Future { 

 Thread.sleep(10000) // sleep for 10s

 Source.fromURL(url).mkString

}

response: Future[String] = Promise$DefaultPromise@231f98ef

```

当您运行这个命令时，您不需要等待十秒钟就能看到下一个提示:您立即重新获得了对 shell 的控制。未来的代码是异步执行的:它的执行独立于主程序流。

我们如何检索计算的结果？我们注意到`response`有类型`Future[String]`。我们可以通过查询未来的`isCompleted`属性来检查包装在未来中的计算是否已经完成:

```

scala> response.isCompleted

Boolean = true

```

未来公开一个包含计算结果的`value`属性:

```

scala> response.value

Option[Try[String]] = Some(Success(<StockQuote><Status>SUCCESS</Status>

...

```

未来的`value`属性具有类型`Option[Try[T]]`。我们已经看到了如何在并行集合的上下文中使用`Try`类型来优雅地处理异常。这里的用法是一样的。在未来完成之前，未来的`value`属性为`None`，如果未来运行成功，则设置为`Some(Success(value))`，如果出现异常，则设置为`Some(Failure(error))`。

重复调用`f.value`直到未来完成在 shell 中运行良好，但是它不能推广到更复杂的程序。相反，我们想告诉计算机在未来完成后做些什么:我们想给未来绑定一个*回调*函数。我们可以通过设置未来的`onComplete`属性来做到这一点。让我们告诉未来在它完成时打印 API 响应:

```

scala> response.onComplete {

 case Success(s) => println(s)

 case Failure(e) => println(s"Error fetching page: $e")

}

scala> 

// Wait for response to complete, then prints:

<StockQuote><Status>SUCCESS</Status><Name>Alphabet Inc</Name><Symbol>GOOGL</Symbol><LastPrice>695.22</LastPrice><Chan...

```

传递给到`onComplete`的函数在未来结束时运行。它接受一个包含未来结果的类型为`Try[T]`的参数。

### Tip

**故障正常:如何构建弹性应用**

通过包装它以`Try`类型运行的代码的输出，未来迫使客户代码考虑代码可能失败的可能性。客户端可以隔离失败的影响，以避免整个应用程序崩溃。例如，他们可能会记录异常。在 web API 查询的情况下，他们可能会添加有问题的 URL，以便以后再次查询。在数据库失败的情况下，他们可能回滚事务。

通过将失败视为一等公民，而不是通过附加在最后的异常控制流，我们可以构建更具弹性的应用程序。

## 未来组合——利用未来的结果

在前面的小节中，您了解了将回调绑定到未来的`onComplete` 方法。这有助于在未来完成时产生副作用。然而，它并没有让我们轻易地转换未来的回报价值。

继续我们的股票示例，假设我们想要将查询响应从字符串转换为 XML 对象。让我们首先将`scala-xml`库作为依赖项包含在`build.sbt`中:

```
libraryDependencies += "org.scala-lang" % "scala-xml" % "2.11.0-M4"
```

让我们重新启动控制台，重新导入对`scala.concurrent._`、`scala.concurrent.ExecutionContext.Implicits.global`和`scala.io._`的依赖。我们还想导入`XML`库:

```

scala> import scala.xml.XML

import scala.xml.XML

```

我们将使用与上一节相同的 URL:

[http://dev.markitondemand.com/MODApis/Api/v2/Quote?symbol=GOOG](http://dev.markitondemand.com/MODApis/Api/v2/Quote?symbol=GOOG)

有时把未来想象成一个集合是有用的，如果计算成功，它包含一个元素；如果计算失败，它包含零个元素。例如，如果 web API 已经被成功查询，我们的未来将包含一个字符串表示的响应。像 Scala 中的其他容器类型一样，futures 支持一个`map`方法，该方法将一个函数应用于 future 中包含的元素，返回一个新的 future，如果 future 中的计算失败，则不做任何事情。但是，对于一个可能还没有完成的计算来说，这意味着什么呢？像`onComplete`方法一样，map 方法在未来一完成就开始应用。

我们可以使用 future 的`map`方法异步地将转换应用于 future 的结果。让我们再次轮询“Markit on demand”API。这一次，我们将把结果解析为 XML，而不是打印出来。

```

scala> val strResponse = Future { 

 Thread.sleep(20000) // Sleep for 20s

 val res = Source.fromURL(url).mkString

 println("finished fetching url")

 res

}

strResponse: Future[String] = Promise$DefaultPromise@1dda9bc8

scala> val xmlResponse = strResponse.map { s =>

 println("applying string to xml transformation")

 XML.loadString(s) 

}

xmlResponse: Future[xml.Elem] = Promise$DefaultPromise@25d1262a

// wait while the remainder of the 20s elapses

finished fetching url

applying string to xml transformation

scala> xmlResponse.value

Option[Try[xml.Elem]] = Some(Success(<StockQuote><Status>SUCCESS</Status>...

```

通过登记未来的后续地图，我们为运行未来的执行者提供了一个路线图。

如果任何步骤失败，包含异常的失败的`Try`实例将被传播:

```

scala> val strResponse = Future { 

 Source.fromURL("empty").mkString 

}

scala> val xmlResponse = strResponse.map { 

 s => XML.loadString(s) 

}

scala> xmlResponse.value 

Option[Try[xml.Elem]] = Some(Failure(MalformedURLException: no protocol: empty))

```

如果你把一个失败的未来想象成一个空容器，这种行为是有意义的。当将映射应用于空列表时，它返回相同的空列表。类似地，当将映射应用于空的(失败的)未来时，将返回空的未来。

## 阻塞直至完成

获取股票价格的代码在 shell 中运行良好。然而，如果你把它粘贴到一个独立的程序中，你会注意到没有任何东西被打印出来，程序会立即结束。让我们看一个简单的例子:

```
// BlockDemo.scala

import scala.concurrent._

import scala.concurrent.ExecutionContext.Implicits.global

import scala.concurrent.duration._

object BlockDemo extends App {

  val f = Future { Thread.sleep(10000) }

  f.onComplete { _ => println("future completed") }

  // "future completed" is not printed

}
```

一旦主线程完成了它的任务，程序就停止运行，在这个例子中，它只涉及创建未来。特别是，从不打印行`"future completed"`。如果我们希望主线程等待未来执行，我们必须明确地告诉它阻塞执行，直到未来完成运行。这是使用`Await.ready`或`Await.result`方法完成的。这两种方法都阻塞主线程的执行，直到将来完成。我们可以通过添加下面这行代码使上面的程序正常工作:

```
Await.ready(f, 1 minute)
```

`Await`方法将未来作为第一个参数，将一个`Duration`对象作为第二个参数。如果未来的完成时间比指定的持续时间长，就会抛出一个`TimeoutException`。通过`Duration.Inf`设置无限超时。

`Await.ready`和`Await.result`的区别在于后者返回未来内部的值。特别是，如果未来导致一个异常，该异常将被抛出。相比之下，`Await.ready`返回未来本身。

一般来说，应该尽可能地避免阻塞:未来的全部意义是在后台线程中运行代码，以保持主执行线程的响应性。然而，一个常见的合法的阻塞用例是在程序的末尾。如果我们正在运行一个大规模的集成过程，我们可能会分派几个 futures 来查询 web APIs，从文本文件中读取数据，或者将数据插入数据库。将代码嵌入未来比顺序执行这些操作更具可伸缩性。然而，由于大部分密集的工作是在后台线程中运行的，所以当主线程完成时，我们还剩下许多未完成的任务。在这个阶段，封锁直到所有未来完成是有意义的。

## 用执行上下文控制并行执行

既然我们知道了如何定义未来，让我们看看如何控制它们的运行。特别是，在运行大量未来时，您可能希望控制要使用的线程数量。

当未来被定义时，它被直接或隐式地传递一个*执行上下文*。执行上下文是一个对象，它公开一个`execute`方法，该方法获取一段代码并运行它，可能是异步的。通过改变执行上下文，我们可以改变运行未来的“后端”。我们已经看到了如何使用执行上下文来控制并行集合的执行。

到目前为止，我们只是通过导入`scala.concurrent.ExecutionContext.Implicits.global`来使用默认的执行上下文。这是一个 fork / join 线程池，有多少底层 CPU 就有多少线程。

现在让我们定义一个使用十六个线程的新执行上下文:

```

scala> import java.util.concurrent.Executors

import java.util.concurrent.Executors

scala> val ec = ExecutionContext.fromExecutorService(

 Executors.newFixedThreadPool(16)

)

ec: ExecutionContextExecutorService = ExecutionContextImpl$$anon$1@1351ce60

```

定义了执行上下文后，我们可以在定义时将其显式传递给 futures:

```

scala> val f = Future { Thread.sleep(1000) } (ec)

f: Future[Unit] = Promise$DefaultPromise@458b456

```

或者，我们可以隐式定义执行上下文:

```

scala> implicit val context = ec

context: ExecutionContextExecutorService = ExecutionContextImpl$$anon$1@1351ce60

```

然后，在构建所有新未来时，将其作为隐式参数传递给它们:

```

scala> val f = Future { Thread.sleep(1000) }

f: Future[Unit] = Promise$DefaultPromise@3c4b7755

```

您可以关闭执行上下文来销毁线程池:

```

scala> ec.shutdown()

```

当一个执行上下文接收到一个关闭命令时，它将结束执行它当前的任务，但是将拒绝任何新的任务。

## 未来示例–股票价格获取器

让我们将本节中介绍的一些概念结合起来，构建一个命令行应用程序，提示用户输入股票名称并获取该股票的价值。问题是，为了保持 UI 的响应性，我们将使用未来来获取股票:

```
// StockPriceDemo.scala

import scala.concurrent._

import scala.concurrent.ExecutionContext.Implicits.global

import scala.io._

import scala.xml.XML

import scala.util._

object StockPriceDemo extends App {

 /* Construct URL for a stock symbol */

  def urlFor(stockSymbol:String) =

    ("http://dev.markitondemand.com/MODApis/Api/v2/Quote?" + 

     s"symbol=${stockSymbol}")

  /* Build a future that fetches the stock price */

  def fetchStockPrice(stockSymbol:String):Future[BigDecimal] = {

    val url = urlFor(stockSymbol)

    val strResponse = Future { Source.fromURL(url).mkString }

    val xmlResponse = strResponse.map { s => XML.loadString(s) }

    val price = xmlResponse.map { 

      r => BigDecimal((r \ "LastPrice").text) 

    }

    price

  }

  /* Command line interface */

  println("Enter symbol at prompt.")

  while (true) {

    val symbol = readLine("> ") // Wait for user input

    // When user puts in symbol, fetch data in background

    // thread and print to screen when complete

    fetchStockPrice(symbol).onComplete { res =>

      println()

      res match {

        case Success(price) => println(s"$symbol: USD $price")

        case Failure(e) => println(s"Error fetching  $symbol: $e")

      }

      print("> ") // Simulate the appearance of a new prompt

    }

  }

}
```

试着运行程序，输入一些股票的代码:

```

[info] Running StockPriceDemo

Enter symbol at prompt:

> GOOG

> MSFT

>

GOOG: USD 695.22

>

MSFT: USD 47.48

> AAPL

> 

AAPL: USD 111.01

```

让我们总结一下代码是如何工作的。当您输入一只股票时，主线程构建一个 future，从 API 获取股票信息，将其转换为 XML，并提取价格。我们使用`(r \ "LastPrice").text`从 XML 节点`r`中提取`LastPrice`标签内的文本。然后我们将这个值转换成一个大的十进制数。当转换完成后，通过`onComplete`绑定一个回调函数将结果打印到屏幕上。异常处理是通过我们使用`.map`方法处理转换来自然处理的。

通过包装获取未来股票价格的代码，我们释放了主线程来响应用户。这意味着用户界面不会被阻塞，例如，如果我们有一个缓慢的互联网连接。

这个例子有些做作，但是您可以轻松地包装更复杂的逻辑:例如，股票价格可以写入数据库，我们可以添加额外的命令来绘制股票价格随时间的变化。

在这一节中，我们仅仅触及了未来所能提供的皮毛。当我们在[第 7 章](ch07.html "Chapter 7. Web APIs")、*Web API*和[第 9 章](ch09.html "Chapter 9. Concurrency with Akka")、*与 Akka* 并发查看轮询 Web API 时，我们将更详细地回顾未来。

未来是数据科学家构建可扩展系统的工具箱中的一个关键部分。将昂贵的计算(无论是 CPU 时间还是墙时间)转移到后台线程可以极大地提高可伸缩性。出于这个原因，未来是许多 Scala 库的重要组成部分，如 **Akka** 和Play 框架。



# 总结

通过提供高级并发抽象，Scala 使得编写并行代码变得直观和简单。并行集合和未来构成了数据科学家工具箱中非常宝贵的一部分，允许他们以最小的努力并行化他们的代码。然而，虽然这些高级抽象消除了直接处理线程的需要，但理解 Scala 并发模型的内部是避免竞争条件的必要条件。

在下一章，我们将暂时搁置并发性，研究如何与 SQL 数据库交互。然而，这只是暂时的:未来将在本书的许多剩余章节中扮演重要角色。



# 参考文献

*亚历山大·普罗科佩*，*在 Scala 学习并发编程*。这是对 Scala 并发编程基础的详细介绍。特别是，它比本章更详细地探讨了并行集合和未来。

Daniel Westheide 的博客很好地介绍了许多 Scala 概念，尤其是:

*   **未来**:[http://danielwestheide . com/blog/2013/01/09/the-neophytes-guide-to-Scala-part-8-welcome-to-the-future . html](http://danielwestheide.com/blog/2013/01/09/the-neophytes-guide-to-scala-part-8-welcome-to-the-future.html)
*   **The Try****type**:[http://danielwestheide . com/blog/2012/12/26/The-neophytes-guide-to-Scala-part-6-error-handling-with-Try . html](http://danielwestheide.com/blog/2012/12/26/the-neophytes-guide-to-scala-part-6-error-handling-with-try.html)

关于交叉验证的讨论，请参见*T2【哈斯蒂】*、*蒂布拉尼*和*弗里德曼*的《统计学习的要素。