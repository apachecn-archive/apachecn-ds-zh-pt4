

# 十二、基于 MLlib 的分布式机器学习

机器学习描述了从数据进行预测的算法的构造。它是大多数数据科学管道的核心组件，通常被视为增加价值最多的组件:机器学习算法的准确性决定了数据科学努力的成功。可以说，这也是数据科学管道中最需要软件工程以外领域知识的部分:机器学习专家不仅要熟悉算法，还要熟悉统计学和商业领域。

选择和调整一个机器学习算法来解决一个特定的问题涉及到大量的探索性分析，以尝试和确定哪些功能是相关的，功能是如何关联的，数据集中是否有离群值，等等。设计合适的机器学习流水线是困难的。由于数据集的规模和对可扩展性的需求，又增加了一层复杂性，这是一个真正的挑战。

MLlib 有助于缓解这个难题。MLlib 是 Spark 的一个组件，在核心 Spark 库之上提供机器学习算法。它提供了一套学习算法，可以在分布式数据集上很好地并行化。

MLlib 已经发展成两个独立的层。MLlib 本身包含核心算法，而 **ml** ，也被称为*管道 API* 的，定义了将算法粘合在一起的 API，并提供了更高层次的抽象。这两个库在操作的数据类型上有所不同:原始的 MLlib 在引入数据帧之前，主要作用于特征向量的 rdd。管道 API 在数据帧上操作。

在这一章中，我们将研究较新的管道 API，仅当管道 API 中缺少该功能时才深入 MLlib。

本章并不试图教授我们提出的算法背后的机器学习基础知识。我们假设读者已经很好地掌握了机器学习工具和技术，至少在表面上理解了这里给出的算法是做什么的，我们尊重更好的作者对统计学习机制的深入解释(我们在本章末尾给出了几个参考文献)。

MLlib 是一个正在快速发展的丰富的库。这一章的目的不是给出库的完整概述。我们将通过构建一个机器学习管道来训练一个垃圾邮件过滤器，同时学习我们需要的 MLlib 部分。阅读完本章后，您将了解库的不同部分是如何组合在一起的，并且可以使用在线文档或更专业的书籍(请参见本章末尾的参考资料)来了解此处未涉及的 MLlib 部分。

# 介绍 ml lib–垃圾邮件分类

下面用一个具体的例子来介绍一下 MLlib 。我们将使用 Ling-Spam 数据集来查看垃圾邮件分类，我们在[第 10 章](ch10.html "Chapter 10. Distributed Batch Processing with Spark")、*Spark*分布式批处理中使用了该数据集。我们将创建一个垃圾邮件过滤器，它使用逻辑回归来估计给定邮件是垃圾邮件的概率。

我们将使用 Spark shell 运行示例，但是在本章的示例中，您会在`LogisticRegressionDemo.scala`中找到一个类似的程序。如果您没有安装 Spark，请参考第 10 章[，*Spark 分布式批处理*中的安装说明。](ch10.html "Chapter 10. Distributed Batch Processing with Spark")

让我们从加载 Ling-Spam 数据集中的电子邮件开始。如果你还没有用 Spark 对[第 10 章](ch10.html "Chapter 10. Distributed Batch Processing with Spark")、*分布式批处理进行此操作，根据你想要一个`tar.gz`文件还是一个`zip`文件，从[data.scala4datascience.com/ling-spam.tar.gz](http://data.scala4datascience.com/ling-spam.tar.gz)或[data.scala4datascience.com/ling-spam.zip](http://data.scala4datascience.com/ling-spam.zip)下载数据，并解压存档。这将创建一个`spam`目录和一个`ham`目录，分别包含垃圾邮件和垃圾邮件。*

让我们使用`wholeTextFiles`方法来加载垃圾邮件:

```

scala> val spamText = sc.wholeTextFiles("spam/*")

spamText: RDD[(String, String)] = spam/...

scala> val hamText = sc.wholeTextFiles("ham/*")

hamText: RDD[(String, String)] = ham/...

```

`wholeTextFiles`方法创建一个键-值 RDD，其中键是文件名，值是文件的内容:

```

scala> spamText.first

(String, String) =

(file:spam/spmsga1.txt,"Subject: great part-time summer job! ...")

scala> spamText.count

Long = 481

```

管道 API 中的算法处理数据帧。因此，我们必须将我们的键值 rdd 转换成数据帧。我们定义了一个新的 case 类`LabelledDocument`，它包含一个消息文本和一个类别标签，用于标识消息是`spam`还是`ham`:

```

scala> case class LabelledDocument(

 fileName:String, 

 text:String, 

 category:String

)

defined class LabelledDocument

scala> val spamDocuments = spamText.map {

 case (fileName, text) => 

 LabelledDocument(fileName, text, "spam")

}

spamDocuments: RDD[LabelledDocument] = MapPartitionsRDD[2] at map

scala> val hamDocuments = hamText.map {

 case (fileName, text) => 

 LabelledDocument(fileName, text, "ham")

}

hamDocuments: RDD[LabelledDocument] = MapPartitionsRDD[3] at map

```

为了创建模型，我们需要将所有文档放在一个数据帧中。因此，让我们取两个`LabelledDocument`rdd 的并集，并将其转换成一个数据帧。`union`方法将 rdd 连接在一起:

```

scala> val allDocuments = spamDocuments.union(hamDocuments)

allDocuments: RDD[LabelledDocument] = UnionRDD[4] at union

scala> val documentsDF = allDocuments.toDF

documentsDF: DataFrame = [fileName: string, text: string, category: string]

```

让我们做一些基本的检查，以验证我们已经加载了所有的文档。我们首先将数据帧保存在内存中，以避免从原始文本文件中重新创建它。

```

scala> documentsDF.persist

documentsDF.type = [fileName: string, text: string, category: string]

scala> documentsDF.show

+--------------------+--------------------+--------+

|            fileName|                text|category|

+--------------------+--------------------+--------+

|file:/Users/pasca...|Subject: great pa...|    spam|

|file:/Users/pasca...|Subject: auto ins...|    spam|

|file:/Users/pasca...|Subject: want bes...|    spam|

|file:/Users/pasca...|Subject: email 57...|    spam|

|file:/Users/pasca...|Subject: n't miss...|    spam|

|file:/Users/pasca...|Subject: amaze wo...|    spam|

|file:/Users/pasca...|Subject: help loa...|    spam|

|file:/Users/pasca...|Subject: beat irs...|    spam|

|file:/Users/pasca...|Subject: email 57...|    spam|

|file:/Users/pasca...|Subject: best , b...|    spam|

|...                                               |

+--------------------+--------------------+--------+

scala> documentsDF.groupBy("category").agg(count("*")).show

+--------+--------+

|category|COUNT(1)|

+--------+--------+

|    spam|     481|

|     ham|    2412|

+--------+--------+

```

现在，让我们将数据帧分为训练集和测试集。我们将使用测试集来验证我们构建的模型。现在，我们将只使用一次分割，在 70%的数据上训练模型，并在剩余的 30%上测试它。在下一节中，我们将看看交叉验证，它提供了更严格的方法来检查我们的模型的准确性。

我们可以使用 DataFrame 的`.randomSplit`方法实现 70-30 分割:

```

scala> val Array(trainDF, testDF) = documentsDF.randomSplit(

 Array(0.7, 0.3))

trainDF: DataFrame = [fileName: string, text: string, category: string]

testDF: DataFrame = [fileName: string, text: string, category: string]

```

`.randomSplit`方法接受一个权重数组，并返回一个数据帧数组，其大小大约由权重指定。例如，我们传递了权重`0.7`和`0.3`，表明任何给定的行都有 70%的机会在`trainDF`结束，30%的机会在`testDF`结束。注意，这意味着分割的数据帧不是固定大小的:`trainDF`大约是`documentsDF`大小的 70%，但不完全是:

```

scala> trainDF.count / documentsDF.count.toDouble

Double = 0.7013480815762184

```

如果需要固定大小的样本，使用 DataFrame 的`.sample`方法获得`trainDF`并过滤不在`trainDF`中的行的`documentDF`。

我们现在可以开始使用 MLlib 了。我们的分类尝试将包括对*术语频率向量*进行逻辑回归:我们将计算每个单词在每个消息中出现的频率，并将出现频率作为一个特征。在进入代码之前，让我们后退一步，讨论机器学习管道的结构。



# 管道组件

流水线由一组连接在一起的组件组成，因此一个组件产生的数据帧被用作下一个组件的输入。可用的组件分为两类:*变压器*和*估算器*。

## 变形金刚

**Transformers** 将一个数据帧转换成另一个数据帧，通常是通过添加一个或多个列。

垃圾邮件分类算法的第一步是将每封邮件拆分成一组单词。这叫做 **标记化**。我们可以使用 MLlib 提供的`Tokenizer` 转换器:

```

scala> import org.apache.spark.ml.feature._

import org.apache.spark.ml.feature._

scala> val tokenizer = new Tokenizer()

tokenizer: org.apache.spark.ml.feature.Tokenizer = tok_75559f60e8cf 

```

转换器的行为可以通过 getters 和 setters 来定制。获得可用参数列表的最简单方法是调用`.explainParams`方法:

```

scala> println(tokenizer.explainParams)

inputCol: input column name (undefined)

outputCol: output column name (default: tok_75559f60e8cf__output)

```

我们看到可以使用两个参数定制`Tokenizer`实例的行为:`inputCol`和`outputCol`，分别描述包含输入(要标记的字符串)和输出(单词数组)的列标题。我们可以使用`setInputCol`和`setOutputCol`方法设置这些参数。

我们将`inputCol`设置为`"text"`，因为这是我们在训练和测试数据帧中对列的称呼。我们将把`outputCol`设置为`"words"`:

```

scala> tokenizer.setInputCol("text").setOutputCol("words")

org.apache.spark.ml.feature.Tokenizer = tok_75559f60e8cf

```

在适当的时候，我们将把`tokenizer`集成到一个管道中，但是，现在，让我们只使用它来转换训练数据帧，以验证它是否正确工作。

```

scala> val tokenizedDF = tokenizer.transform(trainDF)

tokenizedDF: DataFrame = [fileName: string, text: string, category: string, words: array<string>]

scala> tokenizedDF.show

+--------------+----------------+--------+--------------------+

|      fileName|            text|category|               words|

+--------------+----------------+--------+--------------------+

|file:/Users...|Subject: auto...|    spam|[subject:, auto, ...|

|file:/Users...|Subject: want...|    spam|[subject:, want, ...|

|file:/Users...|Subject: n't ...|    spam|[subject:, n't, m...|

|file:/Users...|Subject: amaz...|    spam|[subject:, amaze,...|

|file:/Users...|Subject: help...|    spam|[subject:, help, ...|

|file:/Users...|Subject: beat...|    spam|[subject:, beat, ...|

|...                                                          |

+--------------+----------------+--------+--------------------+

```

`tokenizer`转换器产生一个新的 DataFrame，它有一个额外的列`words`，包含一个在`text`列中的单词数组。

显然，我们可以使用我们的 `tokenizer`用正确的模式转换任何数据帧。例如，我们可以在测试集上使用它。许多机器学习涉及在不同的数据集上调用相同(或非常相似)的管道。通过提供管道抽象，MLlib 有助于对由许多清理、转换和建模组件组成的复杂机器学习算法进行推理。

我们管道的下一步是计算每个单词在每个消息中出现的频率。我们最终将在算法中使用这些频率作为特征。我们将使用`HashingTF`转换器将每个消息的单词数组转换为词频向量。

`HashingTF`转换器从输入的可重复项中构建一个单词频率的稀疏向量。字数组中的每个元素都被转换成散列码。这个散列码被截断成一个介于 *0* 和一个大数 *n* 之间的值，即输出向量中元素的总数。术语频率向量就是被截断的散列出现的次数。

让我们手动运行一个例子来理解它是如何工作的。我们将计算`Array("the", "dog", "jumped", "over", "the")`的项频率向量。对于这个例子，让我们将稀疏输出向量中的元素数量 *n* 设置为 16。第一步是计算数组中每个元素的散列码。我们可以使用内置的`##`方法，它为任何对象计算散列码:

```

scala> val words = Array("the", "dog", "jumped", "over", "the")

words: Array[String] = Array(the, dog, jumped, over, the)

scala> val hashCodes = words.map { _.## }

hashCodes: Array[Int] = Array(114801, 99644, -1148867251, 3423444, 114801)

```

为了将散列码转换成有效的向量索引，我们将每个散列码的模乘以向量的大小(本例中为`16`):

```

scala> val indices = hashCodes.map { code => Math.abs(code % 16) }

indices: Array[Int] = Array(1, 12, 3, 4, 1)

```

然后，我们可以创建从索引到该索引出现次数的映射:

```

scala> val indexFrequency = indices.groupBy(identity).mapValues {

 _.size.toDouble

}

indexFrequency: Map[Int,Double] = Map(4 -> 1.0, 1 -> 2.0, 3 -> 1.0, 12 -> 1.0)

```

最后，我们可以将这个映射转换为一个稀疏向量，其中向量中每个元素的值就是这个特定索引出现的频率:

```

scala> import org.apache.spark.mllib.linalg._

import org.apache.spark.mllib.linalg._

scala> val termFrequencies = Vectors.sparse(16, indexFrequency.toSeq)

termFrequencies: linalg.Vector = (16,[1,3,4,12],[2.0,1.0,1.0,1.0])

```

注意，稀疏向量的`.toString`输出包含三个元素:向量的总大小，后跟两个列表:第一个是一系列索引，第二个是这些索引处的一系列值。

使用稀疏向量提供了一种紧凑而有效的方式来表示单词在消息中的出现频率，这正是`HashingTF`在幕后工作的方式。缺点是从单词到索引的映射不一定是唯一的:根据向量的长度截断散列码会将不同的字符串映射到同一个索引。这就是所谓的T2 碰撞。解决方法是使 *n* 足够大，以使碰撞的频率最小化。

### Tip

`HashingTF`类似于构建一个散列表(例如，Scala map ),它的键是单词，值是单词在消息中出现的次数，有一个重要的区别:它不试图处理哈希冲突。因此，如果两个单词映射到同一个散列，它们将具有错误的频率。与仅仅构造哈希表相比，使用这种算法有两个优点:

*   我们不需要在内存中保存一个不同单词的列表。
*   每封电子邮件都可以独立于所有其他邮件转换成一个向量:我们不必通过不同的分区来减少映射中的键集。这大大简化了以分布式方式将该算法应用于每封电子邮件的过程，因为我们可以独立地对每个分区应用`HashingTF`转换。

主要缺点是，我们必须使用能够有效利用稀疏表示的机器学习算法。这是逻辑回归的情况，我们将在这里使用。

如您所料，`HashingTF`转换器将输入和输出列作为参数。它还接受一个参数，该参数定义向量中不同哈希桶的数量。增加桶的数量会减少冲突的数量。实际上，推荐一个在![Transformers](graphics/4795_12_01.jpg)和![Transformers](graphics/4795_12_02.jpg)之间的值。

```

scala> val hashingTF = (new HashingTF()

 .setInputCol("words")

 .setOutputCol("features")

 .setNumFeatures(1048576))

hashingTF: org.apache.spark.ml.feature.HashingTF = hashingTF_3b78eca9595c

scala> val hashedDF = hashingTF.transform(tokenizedDF)

hashedDF: DataFrame = [fileName: string, text: string, category: string, words: array<string>, features: vector]

scala> hashedDF.select("features").show

+--------------------+

|            features|

+--------------------+

|(1048576,[0,33,36...|

|(1048576,[0,36,40...|

|(1048576,[0,33,34...|

|(1048576,[0,33,36...|

|(1048576,[0,33,34...|

|(1048576,[0,33,34...|

+--------------------+

```

`features`列中的每个元素都是一个稀疏向量:

```

scala> import org.apache.spark.sql.Row

import org.apache.spark.sql.Row

scala> val firstRow = hashedDF.select("features").first

firstRow: org.apache.spark.sql.Row = ...

scala> val Row(v:Vector) = firstRow

v: Vector = (1048576,[0,33,36,37,...],[1.0,3.0,4.0,1.0,...])

```

因此，我们可以将向量解释为:散列到元素`33`的单词出现三次，散列到元素`36`的单词出现四次，等等。

## 估计者

我们现在已经为逻辑回归准备好了特性。运行逻辑回归之前的最后一步是创建目标变量。我们将把数据帧中的`category`列转换成二进制 0/1 目标列。Spark 提供了一个`StringIndexer`类，用 doubles 替换一列中的一组字符串。一个`StringIndexer`不是一个转换器:它必须首先“适合”一组类别来计算从字符串到数值的映射。这引入了管道 API 中的第二类组件:*估计器*。

与“开箱即用”的变压器不同，估算器必须适合数据帧。对于我们的字符串索引器，拟合过程包括获得唯一字符串(`"spam"`和`"ham"`)的列表，并将每个字符串映射到一个 double。拟合过程输出可用于后续数据帧的变换。

```

scala> val indexer = (new StringIndexer()

 .setInputCol("category")

 .setOutputCol("label"))

indexer: org.apache.spark.ml.feature.StringIndexer = strIdx_16db03fd0546

scala> val indexTransform = indexer.fit(trainDF)

indexTransform: StringIndexerModel = strIdx_16db03fd0546

```

拟合过程产生的转换器有一个描述其应用的映射的`labels`属性:

```

scala> indexTransform.labels

Array[String] = Array(ham, spam)

```

每个标签将被映射到它在数组中的索引:因此，我们的转换器将`ham`映射到`0`并将`spam`映射到`1`:

```

scala> val labelledDF = indexTransform.transform(hashedDF)

labelledDF: org.apache.spark.sql.DataFrame = [fileName: string, text: string, category: string, words: array<string>, features: vector, label: double]

scala> labelledDF.select("category", "label").distinct.show

+--------+-----+

|category|label|

+--------+-----+

|     ham|  0.0|

|    spam|  1.0|

+--------+-----+

```

我们现在有了特征向量和正确格式的分类标签用于逻辑回归。用于执行逻辑回归的组件是估计器:它适合于训练数据帧以创建训练模型。然后，该模型可用于转换测试数据帧。

```

scala> import org.apache.spark.ml.classification.LogisticRegression

import org.apache.spark.ml.classification.LogisticRegression

scala> val classifier = new LogisticRegression().setMaxIter(50)

classifier: LogisticRegression = logreg_a5e921e7c1a1 

```

默认情况下，`LogisticRegression`估计器希望特性列被命名为`"features"`，标签列(目标)被命名为`"label"`。没有必要显式地设置它们，因为它们匹配由`hashingTF`和`indexer`设置的列名。可以设置几个参数来控制逻辑回归的工作方式:

```

scala> println(classifier.explainParams)

elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)

fitIntercept: whether to fit an intercept term (default: true)

labelCol: label column name (default: label)

maxIter: maximum number of iterations (>= 0) (default: 100, current: 50)

regParam: regularization parameter (>= 0) (default: 0.0)

threshold: threshold in binary classification prediction, in range [0, 1] (default: 0.5)

tol: the convergence tolerance for iterative algorithms (default: 1.0E-6)

...

```

现在，我们只需设置参数 T0。稍后，我们将查看其他参数的效果，例如正则化。现在让我们将分类器安装到`labelledDF`:

```

scala> val trainedClassifier = classifier.fit(labelledDF)

trainedClassifier: LogisticRegressionModel = logreg_353d18f6a5f0

```

这就产生了一个转换器，我们可以在带有`features`列的数据帧上使用它。转换器附加了一个`prediction`列和一个`probability`列。例如，我们可以使用`trainedClassifier`来转换`labelledDF`，训练集本身:

```

scala> val labelledDFWithPredictions = trainedClassifier.transform(

 labelledDF)

labelledDFWithPredictions: DataFrame = [fileName: string, ...

scala> labelledDFWithPredictions.select($"label", $"prediction").show

+-----+----------+

|label|prediction|

+-----+----------+

|  1.0|       1.0|

|  1.0|       1.0|

|  1.0|       1.0|

|  1.0|       1.0|

|  1.0|       1.0|

|  1.0|       1.0|

|  1.0|       1.0|

|  1.0|       1.0|

+-----+----------+

```

检查模型性能的一个快速方法是计算错误分类消息的数量:

```

scala> labelledDFWithPredictions.filter { 

 $"label" !== $"prediction" 

}.count

Long = 1

```

在这种情况下，除了训练集中的一条消息之外，逻辑回归成功地对每条消息进行了正确分类。考虑到垃圾邮件和合法电子邮件之间的大量特征和相对清晰的界限，这也许并不令人惊讶。

当然，对模型的真正测试不是它在训练集上的表现如何，而是它在测试集上的表现如何。为了测试这一点，我们可以将测试数据帧推过我们用来训练模型的相同阶段，用估计器生成的拟合变压器替换估计器。MLlib 提供了*管道*抽象来促进这一点:我们将转换器和估计器的有序列表包装在管道中。然后，将该流水线拟合到对应于训练集的数据帧。该装配产生一个`PipelineModel` 实例，相当于管道，但估计器被变压器所取代，如下图所示:

![Estimators](graphics/4795_12_03.jpg)

让我们为逻辑回归垃圾邮件过滤器构建管道:

```

scala> import org.apache.spark.ml.Pipeline

import org.apache.spark.ml.Pipeline

scala> val pipeline = new Pipeline().setStages(

 Array(indexer, tokenizer, hashingTF, classifier)

)

pipeline: Pipeline = pipeline_7488113e284d

```

一旦定义了管道，我们就使其适合保存训练集的数据帧:

```

scala> val fittedPipeline = pipeline.fit(trainDF)

fittedPipeline: org.apache.spark.ml.PipelineModel = pipeline_089525c6f100

```

将管道拟合到数据帧时，估算器和转换器的处理方式不同:

*   变压器应用于数据帧，并复制到管道模型中。
*   估计器被拟合到数据帧，产生一个变换器。然后将转换器应用于数据帧，并附加到管道模型。

我们现在可以将管道模型应用于测试集:

```

scala> val testDFWithPredictions = fittedPipeline.transform(testDF)

testDFWithPredictions: DataFrame = [fileName: string, ...

```

这为数据帧添加了一个 `prediction`列，其中包含我们的逻辑回归模型的预测。为了测量我们算法的性能，我们计算测试集上的分类误差:

```

scala> testDFWithPredictions.filter { 

 $"label" !== $"prediction" 

}.count

Long = 20

```

因此，我们的朴素逻辑回归算法，在没有模型选择或正则化的情况下，误分类了 2.3%的电子邮件。当然，您可能会得到稍微不同的结果，因为训练测试分割是随机的。

让我们将带有预测的训练和测试数据帧保存为`parquet`文件:

```

scala> import org.apache.spark.sql.SaveMode

import org.apache.spark.sql.SaveMode

scala> (labelledDFWithPredictions

 .select("fileName", "label", "prediction", "probability")

 .write.mode(SaveMode.Overwrite)

 .parquet("transformedTrain.parquet"))

scala> (testDFWithPredictions

 .select("fileName", "label", "prediction", "probability")

 .write.mode(SaveMode.Overwrite)

 .parquet("transformedTest.parquet"))

```

### Tip

在垃圾邮件分类中，误报比漏报严重得多:将合法邮件分类为垃圾邮件比让垃圾邮件通过要糟糕得多。考虑到这一点，我们可以提高分类的阈值:例如，只有得分为 0.7 或以上的邮件才会被分类为垃圾邮件。这就提出了选择正确阈值的明显问题。做到这一点的一种方法是调查在不同阈值的测试集中出现的假阳性率，并选择最低的阈值来给我们一个可接受的假阳性率。形象化的一个好方法是使用 ROC 曲线，我们将在下一个部分对此进行研究。



# 评估

不幸的是，从版本 1.5.2 开始，pipeline API 中用于评估模型质量的功能仍然有限。逻辑回归确实会输出一个包含几个评估指标的摘要(可以通过训练模型上的`summary`属性获得)，但是这些都是在训练集上计算的。通常，我们希望在训练集和单独的测试集上评估模型的性能。因此，我们将深入到底层 MLlib 层来访问评估指标。

MLlib 提供了一个模块`org.apache.spark.mllib.evaluation`，带有一组用于评估模型质量的类。这里我们将使用`BinaryClassificationMetrics`类，因为垃圾邮件分类是一个二元分类问题。其他评估类提供多类模型、回归模型和排名模型的度量。

和上一节一样，我们将在 shell 中说明这些概念，但是您会在本章的代码示例中的`ROC.scala`脚本中找到类似的代码。我们将使用 *breeze-viz* 来绘制曲线，因此，在启动 shell 时，我们必须确保相关的库在类路径中。我们将使用 SBT 汇编，如[第 10 章](ch10.html "Chapter 10. Distributed Batch Processing with Spark")、*Spark*分布式批处理中所述(具体来说，就是*构建和运行独立程序*一节)，来创建一个具有所需依赖关系的 JAR。然后，我们将把这个 JAR 传递给 Spark shell，允许我们导入 breeze-viz。让我们编写一个`build.sbt`文件，声明对 breeze-viz 的依赖关系:

```
// build.sbt

name := "spam_filter"

scalaVersion := "2.10.5"

libraryDependencies ++= Seq(

  "org.apache.spark" %% "spark-core" % "1.5.2" % "provided",

  "org.apache.spark" %% "spark-mllib" % "1.5.2" % "provided",

  "org.scalanlp" %% "breeze" % "0.11.2",

  "org.scalanlp" %% "breeze-viz" % "0.11.2",

  "org.scalanlp" %% "breeze-natives" % "0.11.2"

)
```

使用以下内容将依赖项打包到一个 jar 中:

```

$ sbt assembly

```

这将在`target/scala-2.10` /目录中创建一个名为`spam_filter-assembly-0.1-SNAPSHOT.jar`的 jar。要将这个 jar 包含在 Spark shell 中，用`--jars`命令行参数重新启动 shell:

```

$ spark-shell --jars=target/scala-2.10/spam_filter-assembly-0.1-SNAPSHOT.jar

```

要验证打包工作是否正常，请尝试导入`breeze.plot`:

```

scala> import breeze.plot._

import breeze.plot._

```

让我们加载带有预测的测试集，这是我们在上一节中创建的，并保存为一个`parquet`文件:

```

scala> val testDFWithPredictions = sqlContext.read.parquet(

 "transformedTest.parquet")

testDFWithPredictions: org.apache.spark.sql.DataFrame = [fileName: string, label: double, prediction: double, probability: vector]

```

`BinaryClassificationMetrics`对象需要一个`RDD[(Double, Double)]`对象，该对象包含成对的分数(由分类器分配的特定电子邮件是垃圾邮件的概率)和标签(电子邮件实际上是否是垃圾邮件)。我们可以从我们的数据帧中提取这个 RDD:

```

scala> import org.apache.spark.mllib.linalg.Vector

import org.apache.spark.mllib.linalg.Vector

scala> import org.apache.spark.sql.Row

import org.apache.spark.sql.Row

scala> val scoresLabels = testDFWithPredictions.select(

 "probability", "label").map {

 case Row(probability:Vector, label:Double) => 

 (probability(1), label)

}

org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[3] at map at <console>:23

scala> scoresLabels.take(5).foreach(println)

(0.9999999967713409,1.0)

(0.9999983827108793,1.0)

(0.9982059900606365,1.0)

(0.9999790713978142,1.0)

(0.9999999999999272,1.0)

```

我们现在可以构造`BinaryClassificationMetrics`实例:

```

scala> import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics

import mllib.evaluation.BinaryClassificationMetrics

scala> val bm = new BinaryClassificationMetrics(scoresLabels)

bm: BinaryClassificationMetrics = mllib.evaluation.BinaryClassificationMetrics@254ed9ba

```

`BinaryClassificationMetrics`对象包含许多用于评估分类模型性能的有用指标。我们再来看**接收机运行** **特性** ( **ROC** )曲线。

### Tip

**ROC 曲线**

想象一下，从 1.0 开始，我们假设特定电子邮件是垃圾邮件的概率阈值逐渐降低。显然，当阈值设置为 1.0 时，没有电子邮件会被归类为垃圾邮件。这意味着不会有**误报**(被我们错误地分类为垃圾邮件的垃圾邮件)，但也意味着不会有**真报**(被我们正确识别为垃圾邮件的垃圾邮件):所有垃圾邮件都将被错误地识别为垃圾邮件。

随着我们逐渐降低假设某封邮件是垃圾邮件的概率阈值，我们的垃圾邮件过滤器将有望开始识别大部分邮件为垃圾邮件。如果我们的算法设计得好，这些邮件中的绝大多数将是真正的垃圾邮件。因此，我们的阳性率增加了。随着我们逐渐降低阈值，我们开始将我们不太确定的邮件分类为垃圾邮件。这将增加被正确识别为垃圾邮件的邮件数量，但也会增加误报的数量。

对于每个阈值，ROC 曲线绘制了真阳性的比例与假阳性的比例。在最好的情况下，曲线总是 1:当所有垃圾邮件的得分为 1.0，所有垃圾邮件的得分为 0.0 时，就会出现这种情况。相比之下，最糟糕的情况发生在曲线是对角线 *P(真阳性)= P(假阳性)*时，这发生在我们的算法不比随机好的时候。一般来说，ROC 曲线落在两者之间，在对角线上方形成一个凸壳。这个壳越深，我们的算法就越好。

![Evaluation](graphics/4795_12_roc.jpg)

(左)表现比随机好得多的模型的 ROC 曲线:该曲线对于低假阳性率达到非常高的真阳性率。

(中间)表现明显优于随机模型的 ROC 曲线。

(右)模型的 ROC 曲线仅略好于随机:对于任何给定的阈值，真阳性率仅略大于假阳性率，这意味着近一半的例子被错误分类。

我们可以在我们的`BinaryClassificationMetrics`实例上使用`.roc`方法计算 ROC 曲线上的一系列点。这将为每个阈值返回(*假阳性*、*真阳性*)分数的`RDD[(Double, Double)]`。我们可以把它收集成一个数组:

```

scala> val rocArray = bm.roc.collect

rocArray: Array[(Double, Double)] = Array((0.0,0.0), (0.0,0.16793893129770993), ...

```

当然，一组数字并没有什么启发性，所以让我们用 breeze-viz 绘制 ROC 曲线。我们首先将数组对转换成两个数组，一个是假阳性，一个是真阳性:

```

scala> val falsePositives = rocArray.map { _._1 }

falsePositives: Array[Double] = Array(0.0, 0.0, 0.0, 0.0, 0.0, ...

scala> val truePositives = rocArray.map { _._2 }

truePositives: Array[Double] = Array(0.0, 0.16793893129770993, 0.19083969465...

```

让我们绘制这两个数组:

```

scala> import breeze.plot._

import breeze.plot.

scala> val f = Figure()

f: breeze.plot.Figure = breeze.plot.Figure@3aa746cd

scala> val p = f.subplot(0)

p: breeze.plot.Plot = breeze.plot.Plot@5ed1438a

scala> p += plot(falsePositives, truePositives)

p += plot(falsePositives, truePositives)

scala> p.xlabel = "false positives"

p.xlabel: String = false positives

scala> p.ylabel = "true positives"

p.ylabel: String = true positives

scala> p.title = "ROC"

p.title: String = ROC

scala> f.refresh

```

对于一个小的 x 值，ROC 曲线达到 *1.0* :也就是说，我们以相对较少的假阳性为代价检索到所有的真阳性。为了更准确地显示曲线，将 *x* 轴上的范围从 *0* 限制到 *0.1* 是有益的。

```

scala> p.xlim = (0.0, 0.1)

p.xlim: (Double, Double) = (0.0,0.1)

```

我们还需要告诉 breeze-viz 使用适当的刻度间距，这需要深入到 breeze-viz 下面的 JFreeChart 层:

```

scala> import org.jfree.chart.axis.NumberTickUnit

import org.jfree.chart.axis.NumberTickUnit

scala> p.xaxis.setTickUnit(new NumberTickUnit(0.01))

scala> p.yaxis.setTickUnit(new NumberTickUnit(0.1))

```

我们现在可以保存图表:

```

scala> f.saveas("roc.png")

```

这产生了下图，存储在`roc.png`中:

![Evaluation](graphics/4795_12_05.jpg)

基于逻辑回归的垃圾邮件分类 ROC 曲线。请注意，我们已经将假阳性轴限制在 0.1

通过查看图表，我们看到我们可以过滤掉 85%的垃圾邮件，而没有一个**误报**。当然，我们需要一个更大的测试集来真正验证这个假设。

图表对于真正理解模型的行为非常有用。然而，有时我们只是想要一个模型质量的单一度量。ROC 曲线下的面积可以是一个很好的度量:

```

scala> bm.areaUnderROC

res21: Double = 0.9983061235861147

```

这可以解释如下:给定从测试集中随机抽取的任意两个消息，其中一个是 ham，另一个是 spam，有 99.8%的概率，该模型将 spam 的可能性分配给 spam 消息比分配给 ham 消息更大。

模型质量的其他有用度量是特定阈值的精确度和召回率，或 F1 分数。所有这些都是由`BinaryClassificationMetrics`实例提供的。API 文档列出了可用的方法:[https://spark . Apache . org/docs/latest/API/Scala/index . html # org . Apache . spark . ml lib . evaluation . binary classification metrics](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.BinaryClassificationMetrics)。



# 逻辑回归中的正则化

机器学习的危险之一是过度拟合:算法不仅捕捉训练集中的信号，还捕捉由训练集的有限大小产生的统计噪声。

减轻逻辑回归中过度拟合的一种方法是使用正则化:我们在优化时对参数的大值施加惩罚。我们可以通过在成本函数中增加一个与参数大小成比例的罚值来做到这一点。形式上，我们将逻辑回归成本函数(在[第 2 章](ch02.html "Chapter 2. Manipulating Data with Breeze")、*用 Breeze* 处理数据中描述)重写为:

![Regularization in logistic regression](graphics/4795_12_06.jpg)

其中![Regularization in logistic regression](graphics/4795_12_07.jpg)是正态逻辑回归成本函数:

![Regularization in logistic regression](graphics/4795_12_08.jpg)

这里， *params* 为参数向量，![Regularization in logistic regression](graphics/4795_12_09.jpg)为第*I个训练样本的特征向量，如果第*I*第*个训练样本为垃圾，则![Regularization in logistic regression](graphics/4795_12_11.jpg)为 *1* ，否则为 *0* 。这与第 2 章[中介绍的逻辑回归成本函数完全相同，除了增加了正则化项![Regularization in logistic regression](graphics/4795_12_12.jpg)，参数向量的![Regularization in logistic regression](graphics/4795_12_13.jpg)范数。 *n* 最常见的值是 2，在这种情况下![Regularization in logistic regression](graphics/4795_12_14.jpg)就是参数向量的大小:](ch02.html "Chapter 2. Manipulating Data with Breeze")

![Regularization in logistic regression](graphics/4795_12_15.jpg)

额外的正则项驱动算法减少参数向量的大小。使用正则化时，所有要素都必须具有可比较的大小。这通常通过规范化特征来实现。默认情况下，MLlib 提供的逻辑回归估计器对所有要素进行归一化。这可以通过`setStandardization`参数关闭。

Spark 有两个超参数，可以通过调整来控制正则化:

*   正则化的类型，用`elasticNetParam`参数设置。值为 0 表示![Regularization in logistic regression](graphics/4795_12_16.jpg)正则化。
*   正则化程度(成本函数中的![Regularization in logistic regression](graphics/4795_12_17.jpg))，用`regParam`参数设置。正则化参数的高值表示强正则化。一般来说，过度拟合的危险越大，正则化参数应该越大。

让我们创建一个新的使用正则化的逻辑回归实例:

```

scala> val lrWithRegularization = (new LogisticRegression()

 .setMaxIter(50))

lrWithRegularization: LogisticRegression = logreg_16b65b325526

scala> lrWithRegularization.setElasticNetParam(0) lrWithRegularization.type = logreg_1e3584a59b3a

```

为了选择合适的![Regularization in logistic regression](graphics/4795_12_17.jpg)值，我们将管道拟合到训练集，并针对几个![Regularization in logistic regression](graphics/4795_12_17.jpg)值计算测试集的分类误差。在本章的后面，我们将学习 MLlib 中的交叉验证，它提供了一种更严格的选择超参数的方法。

```

scala> val lambdas = Array(0.0, 1.0E-12, 1.0E-10, 1.0E-8)

lambdas: Array[Double] = Array(0.0, 1.0E-12, 1.0E-10, 1.0E-8)

scala> lambdas foreach { lambda =>

 lrWithRegularization.setRegParam(lambda)

 val pipeline = new Pipeline().setStages(

 Array(indexer, tokenizer, hashingTF, lrWithRegularization))

 val model = pipeline.fit(trainDF)

 val transformedTest = model.transform(testDF)

 val classificationError = transformedTest.filter { 

 $"prediction" !== $"label"

 }.count

 println(s"$lambda => $classificationError")

}

0 => 20

1.0E-12 => 20

1.0E-10 => 20

1.0E-8 => 23

```

对于我们的示例，我们看到任何增加 L[2]正则化的尝试都会导致分类精度的降低。



# 交叉验证和模型选择

在前面的示例中，我们通过在训练时保留 30%的数据，并在这个子集上进行测试来验证我们的方法。这种方法并不特别严格:确切的结果根据随机的训练-测试分割而变化。此外，如果我们想要测试几个不同的超参数(或不同的模型)来选择最佳的一个，我们会在不知不觉中选择最能反映测试集中特定行的模型，而不是总体。

这可以通过*交叉验证*来克服。我们已经在[第四章](ch04.html "Chapter 4. Parallel Collections and Futures")、*平行收款和未来*中遇到了交叉验证。在那一章中，我们使用了随机子样本交叉验证，其中我们随机创建了训练测试分割。

在本章中，我们将使用 **k-fold 交叉验证**:我们将训练集分割成 *k* 个部分(其中， *k* 通常是 *10* 或 *3* ，使用 *k-1* 个部分作为训练集，最后一个部分作为测试集。训练/测试循环重复 *k* 次，每次保持不同的零件作为测试设置。

交叉验证通常用于为模型选择最佳的超参数集。为了说明选择合适的超参数，我们将回到我们的正则化逻辑回归的例子。我们将选择给我们最好的交叉验证分数的超参数，而不是我们自己直觉的超参数。

我们将探索如何设置正则化类型(通过`elasticNetParam`)和正则化程度(通过`regParam`)。找到好的参数值的一种粗略但有效的方法是执行网格搜索:我们为感兴趣的正则化参数的每一对值计算交叉验证分数。

我们可以使用 MLlib 的`ParamGridBuilder`构建一个参数网格。

```

scala> import org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}

import org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}

scala> val paramGridBuilder = new ParamGridBuilder()

paramGridBuilder: ParamGridBuilder = ParamGridBuilder@1dd694d0

```

为了向网格添加要优化的超参数，我们使用了`addGrid`方法:

```

scala> val lambdas = Array(0.0, 1.0E-12, 1.0E-10, 1.0E-8)

Array[Double] = Array(0.0, 1.0E-12, 1.0E-10, 1.0E-8)

scala> val elasticNetParams = Array(0.0, 1.0)

elasticNetParams: Array[Double] = Array(0.0, 1.0)

scala> paramGridBuilder.addGrid(

 lrWithRegularization.regParam, lambdas).addGrid(

 lrWithRegularization.elasticNetParam, elasticNetParams)

paramGridBuilder.type = ParamGridBuilder@1dd694d0

```

一旦添加了所有维度，我们就可以调用构建器上的`build`方法来构建网格:

```

scala> val paramGrid = paramGridBuilder.build

paramGrid: Array[org.apache.spark.ml.param.ParamMap] =

Array({

 logreg_f7dfb27bed7d-elasticNetParam: 0.0,

 logreg_f7dfb27bed7d-regParam: 0.0

}, {

 logreg_f7dfb27bed7d-elasticNetParam: 1.0,

 logreg_f7dfb27bed7d-regParam: 0.0

} ...)

scala> paramGrid.length

Int = 8

```

正如我们所看到的，网格只是在拟合之前传递给逻辑回归模型的参数集的一维数组。

设置交叉验证管道的下一步是定义比较模型性能的指标。在本章的前面，我们看到了如何使用`BinaryClassificationMetrics`来评估模型的质量。不幸的是，`BinaryClassificationMetrics`类是核心 MLLib API 的一部分，而不是新的管道 API，因此不(容易)兼容。管道 API 提供了一个`BinaryClassificationEvaluator`类。该类直接在数据帧上工作，因此非常适合管道 API 流:

```

scala> import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator

import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator

scala> val evaluator = new BinaryClassificationEvaluator()

evaluator: BinaryClassificationEvaluator = binEval_64b08538f1a2

scala> println(evaluator.explainParams)

labelCol: label column name (default: label)

metricName: metric name in evaluation (areaUnderROC|areaUnderPR) (default: areaUnderROC)

rawPredictionCol: raw prediction (a.k.a. confidence) column name (default: rawPrediction)

```

从参数列表中，我们看到`BinaryClassificationEvaluator`类支持两个度量:ROC 曲线下的面积和 precision-recall 曲线下的面积。它期望一个 DataFrame 作为输入，该 data frame 包含一个`label`列(模型事实)和一个`rawPrediction`列(包含电子邮件是垃圾邮件或火腿邮件的概率的列)。

我们现在有了运行交叉验证所需的所有参数。我们首先构建管道，然后将管道、评估器和运行交叉验证的参数数组传递给`CrossValidator`的实例:

```

scala> val pipeline = new Pipeline().setStages(Array(indexer, tokenizer, hashingTF, lrWithRegularization))

pipeline: Pipeline = pipeline_3ed29f72a4cc

scala> val crossval = (new CrossValidator()

 .setEstimator(pipeline)

 .setEvaluator(evaluator)

 .setEstimatorParamMaps(paramGrid)

 .setNumFolds(3))

crossval: CrossValidator = cv_5ebfa1143a9d 

```

我们现在将`crossval`调整到`trainDF`:

```

scala> val cvModel = crossval.fit(trainDF)

cvModel: CrossValidatorModel = cv_5ebfa1143a9d

```

这一步可能需要相当长的时间(单台机器需要一个多小时)。这将创建一个转换器`cvModel`，对应于逻辑回归对象，其参数最能代表`trainDF`。我们可以用它来预测测试数据帧上的分类误差:

```

scala> cvModel.transform(testDF).filter { 

 $"prediction" !== $"label" 

}.count

Long = 20

```

因此，交叉验证产生了一个模型，该模型的表现与没有超参数的原始朴素逻辑回归模型相同。`cvModel`还包含参数网格中每组参数的评估分数列表:

```

scala> cvModel.avgMetrics

Array[Double] = Array(0.996427805316161, ...)

```

将它与超参数联系起来的最简单的方法是用`cvModel.getEstimatorParamMaps`压缩它。这给出了(*超参数值*，*交叉验证分数*)对的列表:

```

scala> val params2score = cvModel.getEstimatorParamMaps.zip(

 cvModel.avgMetrics)

Array[(ml.param.ParamMap,Double)] = Array(({

 logreg_8f107aabb304-elasticNetParam: 0.0,

 logreg_8f107aabb304-regParam: 0.0

},0.996427805316161),...

scala> params2score.foreach {

 case (params, score) => 

 val lambda = params(lrWithRegularization.regParam)

 val elasticNetParam = params(

 lrWithRegularization.elasticNetParam)

 val l2Orl1 = if(elasticNetParam == 0.0) "L2" else "L1"

 println(s"$l2Orl1, $lambda => $score")

}

L2, 0.0 => 0.996427805316161

L1, 0.0 => 0.996427805316161

L2, 1.0E-12 => 0.9964278053175655

L1, 1.0E-12 => 0.9961429402772803

L2, 1.0E-10 => 0.9964382546369551

L1, 1.0E-10 => 0.9962223090037103

L2, 1.0E-8 => 0.9964159754613495

L1, 1.0E-8 => 0.9891008277659763

```

最佳超参数集对应于具有正则化参数`1E-10`的 L [2] 正则化，尽管这仅对应于 AUC 的微小改善。

这就完成了我们的垃圾邮件过滤器示例。我们已经成功地为这个特定的垃圾邮件数据集训练了一个垃圾邮件过滤器。为了获得更好的结果，人们可以尝试更好的特征提取:我们可以删除停用词或使用 TF-IDF 向量，而不仅仅是术语频率向量作为特征，我们可以添加额外的特征，如消息的长度，甚至是 *n-grams* 。我们还可以尝试非线性算法，比如随机森林。所有这些步骤都可以直接添加到管道中。



# 超越逻辑回归

在本章中，我们将集中在逻辑回归上，但 MLlib 提供了许多替代算法，可以更有效地捕捉数据中的非线性。管道 API 的一致性使得尝试不同的算法并观察它们的性能变得容易。pipeline API 提供了决策树、随机森林和梯度提升树用于分类，以及一个简单的前馈神经网络，该网络仍处于实验阶段。它提供了用于回归的 lasso 和 ridge 回归和决策树，以及用于降维的 PCA。

较低级别的 MLlib API 还提供了用于降维的主成分分析、包括 *k* 均值在内的几种聚类方法以及使用交替最小二乘法的潜在 Dirichlet 分配和推荐系统。



# 总结

MLlib 正面解决了设计可扩展机器学习算法的挑战。在本章中，我们用它来训练一个简单的可伸缩垃圾邮件过滤器。MLlib 是一个庞大的、快速发展的库。了解它能提供什么的最好方法是尝试移植您可能使用另一个库(如 scikit-learn)编写的代码。

在下一章中，我们将看看如何构建 web APIs 和交互式可视化来与世界其他地方分享我们的结果。



# 参考文献

最佳参考是在线文档，包括:

*   管道API:[http://spark.apache.org/docs/latest/ml-features.html](http://spark.apache.org/docs/latest/ml-features.html)
*   变形金刚完整列表:[http://spark . Apache . org/docs/latest/ml lib-guide . html # spark ml-high-level-APIs-for-ml-pipelines](http://spark.apache.org/docs/latest/mllib-guide.html#sparkml-high-level-apis-for-ml-pipelines)

*Spark 高级分析*，作者*桑迪·瑞扎*、*尤里·莱森*、*肖恩·欧文*和*乔希·威尔斯*提供了关于 Spark 机器学习的详细和最新介绍。

有几本书比我们在这里更详细地介绍了机器学习。我们在本书中多次提到*统计学习的要素*、作者*弗里德曼*、*蒂布拉尼*和*哈斯蒂*。这是目前可用的对机器学习的数学基础的最完整的介绍之一。

在 https://www.coursera.org/的[上，吴恩达的](https://www.coursera.org/)机器学习课程很好地介绍了机器学习。它使用 Octave/MATLAB 作为编程语言，但应该可以直接适应 Breeze 和 Scala。