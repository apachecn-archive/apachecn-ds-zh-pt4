<title>Chapter 2. Manipulating Data with Breeze</title><link href="epub.css" rel="stylesheet" type="text/css"> 

# 第二章。使用 Breeze 处理数据

总的来说，数据科学关注的是结构化数据的操作。大部分结构化数据集可以被视为表格数据:每一行代表一个特定的实例，列代表该实例的不同属性。表格表示的普遍存在解释了像 Microsoft Excel 这样的电子表格程序或像 SQL 数据库这样的工具的成功。

为了对数据科学家有用，语言必须支持对数据的列或表的操作。例如，Python 通过 NumPy 和 pandas 实现了这一点。不幸的是，Scala 中没有一个统一的数值计算生态系统可以与 Python 中的 SciPy 生态系统相媲美。

在本章中，我们将介绍 Breeze，这是一个用于快速线性代数和数据数组操作的库，以及科学计算和数据科学所需的许多其他功能。

# 代码示例

访问本书中代码示例的最简单方法是克隆 GitHub 库:

```

$ git clone 'https://github.com/pbugnion/s4ds'

```

每章的代码样本都在一个单独的文件夹中。你也可以在 GitHub 上在线浏览代码。

<title>Installing Breeze</title><link href="epub.css" rel="stylesheet" type="text/css"> 

# 安装 Breeze

如果你已经下载了这本书的代码示例，那么使用 Breeze 最简单的方法就是进入`chap02`目录，在命令行输入`sbt console`。这将打开一个 Scala 控制台，您可以在其中导入 Breeze。

如果你想构建一个独立的项目，安装 Breeze(以及任何 Scala 模块)最常见的方式是通过 SBT。要获取本章所需的依赖项，请将以下几行复制到一个名为`build.sbt`的文件中，注意在`scalaVersion`后留一个空行:

```
scalaVersion := "2.11.7"

libraryDependencies ++= Seq(

  "org.scalanlp" %% "breeze" % "0.11.2",

  "org.scalanlp" %% "breeze-natives" % "0.11.2"

)
```

通过在终端中键入`sbt console`，在与`build.sbt`文件相同的目录中打开一个 Scala 控制台。你可以通过从 Scala 提示符导入 Breeze 来检查 Breeze 是否正常工作:

```

scala> import breeze.linalg._

import breeze.linalg._

```

<title>Getting help on Breeze</title><link href="epub.css" rel="stylesheet" type="text/css"> 

# 获取关于 Breeze 的帮助

本章对 Breeze 进行了相当详细的介绍，但它并不旨在提供完整的 API 参考。

要获得 Breeze 功能的完整列表，请访问 GitHub 上的 Breeze Wiki 页面，网址为 https://github.com/scalanlp/breeze/wiki T2。这对于某些模块来说非常完整，而对于其他模块来说就不那么完整了。源代码([https://github.com/scalanlp/breeze/](https://github.com/scalanlp/breeze/))很详细，给出了很多信息。为了理解一个特定的函数是如何被使用的，看看这个函数的单元测试。

<title>Basic Breeze data types</title><link href="epub.css" rel="stylesheet" type="text/css"> 

# 基本 Breeze 数据类型

Breeze 是一个扩展库，提供快速简单的数据数组操作、优化例程、插值、线性代数、信号处理和数值积分。

Breeze 底层的基本线性代数运算依赖于`netlib-java`库，如果存在，它可以使用系统优化的 **BLAS** 和 **LAPACK** 库。因此，Breeze 中的线性代数运算通常非常快。Breeze 仍在快速发展中，因此可能有些不稳定。

## 矢量

Breeze 让操作一维和二维数据结构变得简单。为了开始，通过 SBT 打开一个 Scala 控制台并导入 Breeze:

```

$ sbt console

scala> import breeze.linalg._

import breeze.linalg._

```

让我们直入主题，定义一个矢量:

```

scala> val v = DenseVector(1.0, 2.0, 3.0)

breeze.linalg.DenseVector[Double] = DenseVector(1.0, 2.0, 3.0)

```

我们刚刚定义了一个三元素向量，`v`。向量只是数据的一维数组，暴露了为数字用途定制的方法。它们可以像其他 Scala 集合一样被索引:

```

scala> v(1)

Double = 2.0

```

它们支持带有标量的元素操作:

```

scala> v :* 2.0 // :* is 'element-wise multiplication'

breeze.linalg.DenseVector[Double] = DenseVector(2.0, 4.0, 6.0)

```

它们还支持另一个向量的元素操作:

```

scala> v :+ DenseVector(4.0, 5.0, 6.0) // :+ is 'element-wise addition'

breeze.linalg.DenseVector[Double] = DenseVector(5.0, 7.0, 9.0)

```

Breeze 让向量运算变得更直观，可读性也比原生的 Scala 更好。

请注意，Breeze 将拒绝(在编译时)将操作数强制转换为正确的类型:

```

scala> v :* 2 // element-wise multiplication by integer

<console>:15: error: could not find implicit value for parameter op:

...

```

如果向量长度不同，它还会拒绝(在运行时)将向量相加:

```

scala> v :+ DenseVector(8.0, 9.0)

java.lang.IllegalArgumentException: requirement failed: Vectors must have same length: 3 != 2

...

```

对于任何习惯使用 NumPy、MATLAB 或 r 的人来说，在 Breeze 中对向量进行基本操作是很自然的。

到目前为止，我们只看了基于元素的操作符。这些都以冒号为前缀。所有常见的疑点都出现了:`:+`、`:*`、`:-`、`:/`、`:%`(余数)、和`:^`(幂)以及布尔运算符。要查看完整的操作符列表，请查看针对 `DenseVector` 或`DenseMatrix` 的 API 文档([https://github . com/scalan LP/breeze/wiki/Linear-algebray-Cheat-Sheet](https://github.com/scalanlp/breeze/wiki/Linear-Algebra-Cheat-Sheet))。

除了基于元素的运算，Breeze vectors 还支持数学向量的运算，比如点积:

```

scala> val v2 = DenseVector(4.0, 5.0, 6.0)

breeze.linalg.DenseVector[Double] = DenseVector(4.0, 5.0, 6.0)

scala> v dot v2

Double = 32.0

```

### Tip

**元素操作符的陷阱**

除了我们到目前为止看到的用于元素加法和减法的`:+` 和`:-` 操作符，我们还可以使用更传统的`+`和`-`操作符:

```

scala> v + v2

breeze.linalg.DenseVector[Double] = DenseVector(5.0, 7.0, 9.0)

```

然而，当混合使用`:+`或`:*`和`:+`操作符时，必须非常小心操作符优先规则。`:+`和`:*`操作符的优先级很低，所以它们将最后被求值。这可能会导致一些违反直觉的行为:

```

scala> 2.0 :* v + v2 // !! equivalent to 2.0 :* (v + v2)

breeze.linalg.DenseVector[Double] = DenseVector(10.0, 14.0, 18.0)

```

相比之下，如果我们使用`:+`而不是`+`，那么运算符的数学优先级将得到尊重:

```

scala> 2.0 :* v :+ v2 // equivalent to (2.0 :* v) :+ v2

breeze.linalg.DenseVector[Double] = DenseVector(6.0, 9.0, 12.0)

```

总之，应该尽可能避免混合使用`:+`样式的操作符和`+`样式的操作符。

## 密集和稀疏向量与向量性状

到目前为止，我们看到的所有向量都是密集向量。Breeze 还支持稀疏向量。当处理大部分 T2 为零的数组时，使用稀疏向量可能计算效率更高。向量有足够的零来保证切换到稀疏表示的点很大程度上取决于操作的类型，因此您应该运行自己的基准来确定使用哪种类型。然而，一个好的启发是，如果你的向量有 90%是零，你可能会受益于使用稀疏表示。

Breeze 中的稀疏向量为`SparseVector`和`HashVector`类。这两种类型都支持许多与`DenseVector`相同的操作，但是使用不同的内部实现。`SparseVector`实例非常节省内存，但是添加非零元素很慢。`HashVector` 更加通用，代价是增加了内存占用和迭代非零元素的计算时间。除非你需要从你的应用程序中挤出最后一点内存，否则我推荐使用 T5。我们不会在本书中进一步讨论这些，但是如果需要的话，读者会发现它们很容易使用。`DenseVector`、`SparseVector`和`HashVector`都实现了`Vector`特征，为它们提供了一个公共接口。

### Tip

Breeze 仍处于实验阶段，在撰写本文时，还有些不稳定。我发现处理`Vector`特征的具体实现，比如 `DenseVector`或`SparseVector`，比直接处理`Vector`特征更可靠。在这一章中，我们将明确地把每一个向量输入为`DenseVector`。

## 矩阵

Breeze 允许以类似的方式构建和操作二维数组:

```

scala> val m = DenseMatrix((1.0, 2.0, 3.0), (4.0, 5.0, 6.0))

breeze.linalg.DenseMatrix[Double] =

1.0  2.0  3.0

4.0  5.0  6.0

scala> 2.0 :* m

breeze.linalg.DenseMatrix[Double] =

2.0  4.0   6.0

8.0  10.0  12.0

```

## 构建向量和矩阵

我们已经看到了如何通过将向量和矩阵的值传递给构造函数(或者更确切地说，传递给伴随对象的`apply`方法):`DenseVector(1.0, 2.0, 3.0)`来显式构建向量和矩阵。Breeze 提供了其他几种建立向量和矩阵的强大方法:

```

scala> DenseVector.ones[Double](5)

breeze.linalg.DenseVector[Double] = DenseVector(1.0, 1.0, 1.0, 1.0, 1.0)

scala> DenseVector.zeros[Int](3)

breeze.linalg.DenseVector[Int] = DenseVector(0, 0, 0)

```

`linspace`方法(在`breeze.linalg`包对象中可用)创建一个等距值的`Double`向量。例如，要创建一个在`0`和`1`之间均匀分布的 10 个值的向量，执行以下操作:

```

scala> linspace(0.0, 1.0, 10)

breeze.linalg.DenseVector[Double] = DenseVector(0.0, 0.1111111111111111, ..., 1.0)

```

`tabulate`方法让我们从函数中构造向量和矩阵:

```

scala> DenseVector.tabulate(4) { i => 5.0 * i }

breeze.linalg.DenseVector[Double] = DenseVector(0.0, 5.0, 10.0, 15.0)

scala> DenseMatrix.tabulate[Int](2, 3) { 

 (irow, icol) => irow*2 + icol 

}

breeze.linalg.DenseMatrix[Int] =

0  1  2

2  3  4

```

`DenseVector.tabulate`的第一个参数是向量的大小，第二个参数是返回向量在特定位置的值的函数。这对于创建数据范围非常有用。

`rand`函数让我们创建随机向量和矩阵:

```

scala> DenseVector.rand(2)

breeze.linalg.DenseVector[Double] = DenseVector(0.8072865137359484, 0.5566507203838562)

scala> DenseMatrix.rand(2, 3)

breeze.linalg.DenseMatrix[Double] =

0.5755491874682879   0.8142161471517582  0.9043780212739738

0.31530195124023974  0.2095094278911871  0.22069103504148346

```

最后，我们可以从 Scala 数组中构造向量:

```

scala> DenseVector(Array(2, 3, 4))

breeze.linalg.DenseVector[Int] = DenseVector(2, 3, 4)

```

为了从其他 Scala 集合中构造向量，你必须使用 *splat* 操作符，`:_ *`:

```

scala> val l = Seq(2, 3, 4)

l: Seq[Int] = List(2, 3, 4)

scala> DenseVector(l :_ *)

breeze.linalg.DenseVector[Int] = DenseVector(2, 3, 4)

```

## 高级索引和切片

我们已经看到如何通过索引来选择向量`v`中的特定元素，例如，`v(2)`。Breeze 还提供了几种强大的方法来选择矢量的部分。

让我们从创建一个矢量开始:

```

scala> val v = DenseVector.tabulate(5) { _.toDouble }

breeze.linalg.DenseVector[Double] = DenseVector(0.0, 1.0, 2.0, 3.0, 4.0)

```

与原生 Scala 集合不同，Breeze vectors 支持负索引:

```

scala> v(-1) // last element

Double = 4.0

```

Breeze 让我们使用范围来分割向量:

```

scala> v(1 to 3)

breeze.linalg.DenseVector[Double] = DenseVector(1.0, 2.0, 3.0)

scala v(1 until 3) // equivalent to Python v[1:3]

breeze.linalg.DenseVector[Double] = DenseVector(1.0, 2.0)

scala> v(v.length-1 to 0 by -1) // reverse view of v

breeze.linalg.DenseVector[Double] = DenseVector(4.0, 3.0, 2.0, 1.0, 0.0)

```

### Tip

通过范围索引返回原始向量的*视图*:当运行`val v2 = v(1 to 3)`时，没有数据被复制。这意味着切片效率极高。对一个巨大的向量进行切片，根本不会增加内存占用。这也意味着应该小心更新切片，因为它也将更新原始向量。我们将在本章的下一节讨论变异向量和矩阵。

Breeze 还允许我们从向量中选择任意一组元素:

```

scala> val vSlice = v(2, 4) // Select elements at index 2 and 4

breeze.linalg.SliceVector[Int,Double] = breeze.linalg.SliceVector@9c04d22

```

这创建了一个 `SliceVector`，其行为类似于`DenseVector`(两者都实现了`Vector`接口)，但实际上并没有为值分配内存:它只知道如何从其索引映射到其父向量中的值。人们应该把`vSlice`看作是`v`的一个具体的视图。我们可以通过将视图转换成`DenseVector`来具体化视图(给它自己的数据，而不是充当一个透镜来观察`v`:

```

scala> vSlice.toDenseVector

breeze.linalg.DenseVector[Double] = DenseVector(2.0, 4.0)

```

请注意，如果切片的元素超出界限，则只有在访问该元素时才会引发异常:

```

scala> val vSlice = v(2, 7) // there is no v(7)

breeze.linalg.SliceVector[Int,Double] = breeze.linalg.SliceVector@2a83f9d1

scala> vSlice(0) // valid since v(2) is still valid

Double = 2.0

scala> vSlice(1) // invalid since v(7) is out of bounds

java.lang.IndexOutOfBoundsException: 7 not in [-5,5)

 ...

```

最后，可以使用布尔数组索引向量。让我们从定义一个数组开始:

```

scala> val mask = DenseVector(true, false, false, true, true)

breeze.linalg.DenseVector[Boolean] = DenseVector(true, false, false, true, true)

```

然后，`v(mask)`产生包含`v`元素的视图，其中`mask`是`true`:

```

scala> v(mask).toDenseVector

breeze.linalg.DenseVector[Double] = DenseVector(0.0, 3.0, 4.0)

```

这可以用来过滤向量中的某些元素。例如，选择小于`3.0`的`v`的元素:

```

scala> val filtered = v(v :< 3.0) // :< is element-wise "less than"

breeze.linalg.SliceVector[Int,Double] = breeze.linalg.SliceVector@2b1edef3

scala> filtered.toDenseVector

breeze.linalg.DenseVector[Double] = DenseVector(0.0, 1.0, 2.0)

```

矩阵可以像向量一样被索引。矩阵索引函数有两个参数——第一个参数选择行，第二个参数选择列:

```

scala> val m = DenseMatrix((1.0, 2.0, 3.0), (5.0, 6.0, 7.0))

m: breeze.linalg.DenseMatrix[Double] =

1.0  2.0  3.0

5.0  6.0  7.0

scala> m(1, 2)

Double = 7.0

scala> m(1, -1)

Double = 7.0

scala> m(0 until 2, 0 until 2)

breeze.linalg.DenseMatrix[Double] =

1.0  2.0

5.0  6.0

```

您还可以混合使用不同的行和列切片类型:

```

scala> m(0 until 2, 0)

breeze.linalg.DenseVector[Double] = DenseVector(1.0, 5.0)

```

请注意，在这种情况下，Breeze 会传回向量。通常，切片会返回以下对象:

*   当单个索引作为行和列参数传递时的标量
*   当行参数是一个范围，列参数是单个索引时的向量
*   当列参数是一个范围而行参数是单个索引时的向量转置
*   一个矩阵

符号`::`可以用来表示沿着特定方向的每个元素的*。例如，我们可以选择`m`的第二列:*

```

scala> m(::, 1)

breeze.linalg.DenseVector[Double] = DenseVector(2.0, 6.0)

```

## 变异矢量和矩阵

向量和矩阵是可变的。上述中的大多数切片操作也可用于设置向量或矩阵的元素:

```

scala> val v = DenseVector(1.0, 2.0, 3.0)

v: breeze.linalg.DenseVector[Double] = DenseVector(1.0, 2.0, 3.0)

scala> v(1) = 22.0 // v is now DenseVector(1.0, 22.0, 3.0)

```

我们不局限于变异单一元素。事实上，上面概述的所有索引操作都可以用来设置向量或矩阵的元素。当改变向量或矩阵的切片时，使用元素赋值操作符`:=`:

```

scala> v(0 until 2) := DenseVector(50.0, 51.0) // set elements at position 0 and 1

breeze.linalg.DenseVector[Double] = DenseVector(50.0, 51.0)

scala> v

breeze.linalg.DenseVector[Double] = DenseVector(50.0, 51.0, 3.0)

```

赋值运算符`:=`的工作方式类似于 Breeze 中的其他元素运算符。如果右侧是标量，它将自动传播到给定形状的向量:

```

scala> v(0 until 2) := 0.0 // equivalent to v(0 until 2) := DenseVector(0.0, 0.0)

breeze.linalg.DenseVector[Double] = DenseVector(0.0, 0.0)

scala> v

breeze.linalg.DenseVector[Double] = DenseVector(0.0, 0.0, 3.0)

```

所有基于元素的操作符都有一个 update 对应物。例如，`:+=`操作符的行为类似于元素加法操作符`:+`，但也更新其左边的操作数:

```

scala> val v = DenseVector(1.0, 2.0, 3.0)

v: breeze.linalg.DenseVector[Double] = DenseVector(1.0, 2.0, 3.0)

scala> v :+= 4.0

breeze.linalg.DenseVector[Double] = DenseVector(5.0, 6.0, 7.0)

scala> v

breeze.linalg.DenseVector[Double] = DenseVector(5.0, 6.0, 7.0)

```

注意 update 操作符是如何就地更新向量并返回它的。

我们已经学习了如何在 Breeze 中分割矢量和矩阵，以创建原始数据的新视图。这些视图并不独立于创建它们的向量，更新视图将会更新基础向量，反之亦然。最好用一个例子来说明:

```

scala> val v = DenseVector.tabulate(6) { _.toDouble }

breeze.linalg.DenseVector[Double] = DenseVector(0.0, 1.0, 2.0, 3.0, 4.0, 5.0)

scala> val viewEvens = v(0 until v.length by 2)

breeze.linalg.DenseVector[Double] = DenseVector(0.0, 2.0, 4.0)

scala> viewEvens := 10.0 // mutate viewEvens

breeze.linalg.DenseVector[Double] = DenseVector(10.0, 10.0, 10.0)

scala> viewEvens

breeze.linalg.DenseVector[Double] = DenseVector(10.0, 10.0, 10.0)

scala> v  // v has also been mutated!

breeze.linalg.DenseVector[Double] = DenseVector(10.0, 1.0, 10.0, 3.0, 10.0, 5.0)

```

如果我们记住，当我们创建一个向量或矩阵时，我们是在创建一个底层数据数组的视图，而不是创建数据本身，那么很快就变得直观了:

![Mutating vectors and matrices](graphics/4795_02_01.jpg)

`v`向量的向量片`v(0 to 6 by 2)`只是`v`下的数组的不同视图。视图本身不包含任何数据。它只包含指向原始数组中数据的指针。在内部，视图只是存储为指向底层数据的指针和迭代该数据的方法:在这个切片的例子中，方法只是“从底层数据的第一个元素开始，分两步转到底层数据的第七个元素”。

当我们想要创建独立的数据副本时，Breeze 提供了一个`copy`功能。在前面的例子中，我们可以将`viewEvens`的副本构造为:

```

scala> val copyEvens = v(0 until v.length by 2).copy

breeze.linalg.DenseVector[Double] = DenseVector(10.0, 10.0, 10.0)

```

我们现在可以独立于 T1 更新 T3 和 T0 了。

## 矩阵乘法、转置和向量定向

到目前为止，我们主要关注了向量和矩阵的元素操作。现在让我们看看矩阵乘法和相关运算。

矩阵乘法运算符是`*`:

```

scala> val m1 = DenseMatrix((2.0, 3.0), (5.0, 6.0), (8.0, 9.0))

breeze.linalg.DenseMatrix[Double] =

2.0  3.0

5.0  6.0

8.0  9.0

scala> val m2 = DenseMatrix((10.0, 11.0), (12.0, 13.0))

breeze.linalg.DenseMatrix[Double] 

10.0  11.0

12.0  13.0

scala> m1 * m2

56.0   61.0

122.0  133.0

188.0  205.0

```

除了矩阵-矩阵乘法，我们还可以在矩阵和向量之间使用矩阵乘法运算符。Breeze 中的所有向量都是列向量。这意味着，当矩阵和向量相乘时，向量应该被视为( *n * 1* )矩阵。让我们看一个矩阵向量乘法的例子。我们希望进行以下操作:

![Matrix multiplication, transposition, and the orientation of vectors](graphics/4795_02_02.jpg)

```

scala> val v = DenseVector(1.0, 2.0)

breeze.linalg.DenseVector[Double] = DenseVector(1.0, 2.0)

scala> m1 * v 

breeze.linalg.DenseVector[Double] = DenseVector(8.0, 17.0, 26.0)

```

相比之下，如果我们想要:

![Matrix multiplication, transposition, and the orientation of vectors](graphics/4795_02_03.jpg)

我们必须将`v`转换成一个行向量。我们可以使用转置操作来完成这个:

```

scala> val vt = v.t

breeze.linalg.Transpose[breeze.linalg.DenseVector[Double]] = Transpose(DenseVector(1.0, 2.0))

scala> vt * m2

breeze.linalg.Transpose[breeze.linalg.DenseVector[Double]] = Transpose(DenseVector(34.0, 37.0))

```

注意`v.t`的类型是`Transpose[DenseVector[_]]`。就基于元素的操作而言，`Transpose[DenseVector[_]]`的行为与`DenseVector`非常相似，但是它不支持变异或切片。

## 数据预处理和特征工程

我们现在已经发现了 Breeze 的基本组件。在接下来的几节中，我们将把它们应用到真实的例子中，以理解它们是如何结合在一起形成数据科学的坚实基础的。

数据科学的一个重要部分涉及预处理数据集以构建有用的特征。让我们看一个这样的例子。为了遵循这个示例并访问数据，您需要下载这本书的代码示例([www.github.com/pbugnion/s4ds](http://www.github.com/pbugnion/s4ds))。

在本书随附的代码目录`chap02/data/`中，您会发现一个 CSV 文件，其中包含 181 名男性和女性的真实身高和体重以及自我报告的身高和体重。最初的数据集是作为身体形象研究的一部分收集的。更多信息请参考以下链接:[http://vincentarelbundock . github . io/rdata sets/doc/car/Davis . html](http://vincentarelbundock.github.io/Rdatasets/doc/car/Davis.html)。

随书提供的软件包中有一个帮助器函数，用于将数据加载到 Breeze 阵列中:

```

scala> val data = HWData.load

HWData [ 181 rows ]

scala> data.genders

breeze.linalg.Vector[Char] = DenseVector(M, F, F, M, ... )

```

`data` 对象包含五个向量，每个向量有 181 个元素长:

*   `data.genders`:描述参与者性别的`Char`向量
*   `data.heights`:参与者真实身高的矢量`Double`
*   `data.weights`:参与者真实权重的`Double`向量
*   `data.reportedHeights`:参与者自我报告身高的矢量`Double`
*   `data.reportedWeights`:参与者自报体重的`Double`向量

让我们从统计研究中的男女人数开始。我们将定义一个只包含`'M'`的数组，并与`data.genders`进行元素比较:

```

scala> val maleVector = DenseVector.fill(data.genders.length)('M')

breeze.linalg.DenseVector[Char] = DenseVector(M, M, M, M, M, M,... )

scala> val isMale = (data.genders :== maleVector)

breeze.linalg.DenseVector[Boolean] = DenseVector(true, false, false, true ...)

```

`isMale`向量与`data.genders`的长度相同。参与者为男性时为`true`，否则为`false`。我们可以使用这个布尔数组作为数据集中其他数组的掩码(记住，`vector(mask)`选择`vector`的元素，其中掩码是`true`)。让我们获取数据集中男性的身高:

```

scala> val maleHeights = data.heights(isMale)

breeze.linalg.SliceVector[Int,Double] = breeze.linalg.SliceVector@61717d42

scala> maleHeights.toDenseVector

breeze.linalg.DenseVector[Double] = DenseVector(182.0, 177.0, 170.0, ...

```

为了计算数据集中男性的数量，我们可以使用指标函数。这将一个布尔数组转换成一个双精度数组，将`false`映射到`0.0`，将`true`映射到`1.0`:

```

scala> import breeze.numerics._

import breeze.numerics._

scala> sum(I(isMale))

Double: 82.0

```

我们来计算一下实验中男女的 `mean`身高。我们可以使用`mean(v)`来计算向量的平均值，我们可以通过导入`breeze.stats._`来访问它:

```

scala> import breeze.stats._

import breeze.stats._

scala> mean(data.heights)

Double = 170.75690607734808

```

要计算男性的 `mean`身高，可以用我们的`isMale`数组切片`data.heights`；`data.heights(isMale)`是`data.heights`阵的视图，显示男子的所有身高值:

```

scala> mean(data.heights(isMale)) // mean male height

Double = 178.0121951219512

scala> mean(data.heights(!isMale)) // mean female height

Double = 164.74747474747474

```

作为一个更复杂的例子，让我们看看这个实验中男女真实体重和报道体重之间的差异。我们可以得到报告重量和真实重量之间的百分比差的数组:

```

scala> val discrepancy = (data.weights - data.reportedWeights) / data.weights

breeze.linalg.Vector[Double] = DenseVector(0.0, 0.1206896551724138, -0.018867924528301886, -0.029411764705882353, ... )

```

请注意 Breeze 的数学运算符过载如何让我们轻松优雅地操作数据数组。

我们现在可以计算男性的平均值和标准偏差:

```

scala> mean(discrepancy(isMale))

res6: Double = -0.008451852933123775

scala> stddev(discrepancy(isMale))

res8: Double = 0.031901519634244195

```

我们还可以计算高估自己身高的男性比例:

```

scala> val overReportMask = (data.reportedHeights :> data.heights).toDenseVector

breeze.linalg.DenseVector[Boolean] = DenseVector(false, false, false, false...

scala> sum(I(overReportMask :& isMale))

Double: 10.0

```

因此，有十个男人认为自己比实际身高高。元素级 AND 运算符`:&`返回一个向量，该向量对于其两个参数都为真的所有索引都为真。向量`overReportMask :& isMale`因此对所有男性参与者都是真实的，并且高估了他们的身高。

## Breeze–功能优化

学习了特性工程之后，现在让我们看看数据科学管道的另一端。通常，机器学习算法定义损失函数，该函数是一组参数的函数。损失函数值代表模型与数据的拟合程度。然后优化参数以最小化(或最大化)损失函数。

在[第十二章](ch12.html "Chapter 12. Distributed Machine Learning with MLlib")、*用 MLlib* 进行分布式机器学习中，我们会看一下 **MLlib** ，一个包含了很多知名算法的机器学习库。通常，我们不需要直接担心优化损失函数，因为我们可以依赖 MLlib 提供的机器学习算法。尽管如此，掌握最优化的基本知识还是很有用的。

Breeze 有一个`optimize`模块，其中包含寻找局部最小值的函数:

```

scala> import breeze.optimize._

import breeze.optimize._

```

让我们创建一个想要优化的玩具函数:

![Breeze – function optimization](graphics/4795_02_04.jpg)

我们可以用 Scala 表示这个函数如下:

```

scala> def f(xs:DenseVector[Double]) = sum(xs :^ 2.0)

f: (xs: breeze.linalg.DenseVector[Double])Double

```

大多数局部优化器也需要被优化函数的梯度。梯度是一个与函数参数维数相同的向量。在我们的例子中，梯度是:

![Breeze – function optimization](graphics/4795_02_05.jpg)

我们可以用一个函数来表示 Breeze 中的渐变，该函数采用一个向量参数并返回一个相同长度的向量:

```

scala> def gradf(xs:DenseVector[Double]) = 2.0 :* xs

gradf: (xs:breeze.linalg.DenseVector[Double])breeze.linalg.DenseVector[Double]

```

例如，在点`(1, 1, 1)`，我们有:

```

scala> val xs = DenseVector.ones[Double](3)

breeze.linalg.DenseVector[Double] = DenseVector(1.0, 1.0, 1.0)

scala> f(xs)

Double = 3.0

scala> gradf(xs)

breeze.linalg.DenseVector[Double] = DenseVector(2.0, 2.0, 2.0)

```

让我们设置一下优化问题。Breeze 的优化方法要求我们用一个方法`calculate`传递一个`DiffFunction`特征的实现。此方法必须返回函数及其梯度的元组:

```

scala> val optTrait = new DiffFunction[DenseVector[Double]] {

 def calculate(xs:DenseVector[Double]) = (f(xs), gradf(xs))

}

breeze.optimize.DiffFunction[breeze.linalg.DenseVector[Double]] = <function1>

```

我们现在准备运行优化。优化模块提供了一个`minimize`函数，它正是我们想要的。我们传递它`optTrait`和优化的起点:

```

scala> val minimum = minimize(optTrait, DenseVector(1.0, 1.0, 1.0))

breeze.linalg.DenseVector[Double] = DenseVector(0.0, 0.0, 0.0)

```

真正的最小值在`(0.0, 0.0, 0.0)`。因此，优化器会正确地找到最小值。

默认情况下，`minimize`函数使用 **L-BFGS** 方法运行优化。控制优化需要几个额外的参数。我们将在接下来的章节中探讨这些。

## 数值导数

在前面的例子中，我们明确指定了`f`的梯度。虽然这通常是很好的做法，但计算函数的梯度通常会很繁琐。Breeze 使用有限差分提供梯度近似函数。重复使用与上一节相同的目标函数`def f(xs:DenseVector[Double]) = sum(xs :^ 2.0)`:

```

scala> val approxOptTrait = new ApproximateGradientFunction(f)

breeze.optimize.ApproximateGradientFunction[Int,breeze.linalg.DenseVector[Double]] = <function1>

```

特征 `approxOptTrait`有一个`gradientAt`方法，返回一个点的梯度近似值:

```

scala> approxOptTrait.gradientAt(DenseVector.ones(3))

breeze.linalg.DenseVector[Double] = DenseVector(2.00001000001393, 2.00001000001393, 2.00001000001393)

```

请注意，这可能相当不准确。`ApproximateGradientFunction`构造函数接受一个`epsilon`可选参数，该参数控制计算有限差分时的步长。改变`epsilon`的值可以提高有限差分算法的精度。

`ApproximateGradientFunction`实例实现了`DiffFunction`特征。因此，它可以直接传递给`minimize`:

```

scala> minimize(approxOptTrait, DenseVector.ones[Double](3))

breeze.linalg.DenseVector[Double] = DenseVector(-5.000001063126813E-6, -5.000001063126813E-6, -5.000001063126813E-6)

```

这再次给出了一个接近于零的结果，但比我们显式指定梯度时要远一些。一般来说，解析计算函数的梯度比依赖 Breeze 的数值梯度要有效得多，也准确得多。在数据探索过程中最好只使用数值梯度，或者检查分析梯度。

## 正规化

`minimize` 函数采用许多与机器学习算法相关的可选参数。特别是，我们可以指示优化器在执行优化时使用正则化参数。正则化在损失函数中引入惩罚，以防止参数任意增长。这有助于避免过度拟合。我们将在[第 12 章](ch12.html "Chapter 12. Distributed Machine Learning with MLlib")、*使用 MLlib 的分布式机器学习*中更详细地讨论正则化。

例如，要将`L2Regularization`与超参数`0.5`一起使用:

```

scala> minimize(optTrait, DenseVector(1.0, 1.0, 1.0), L2Regularization(0.5))

breeze.linalg.DenseVector[Double] = DenseVector(0.0, 0.0, 0.0)

```

在这种情况下，正则化没有影响，因为参数最小为零。

要查看可以传递给`minimize`的可选参数的列表，请在线咨询Breeze 文档。

<title>An example – logistic regression</title><link href="epub.css" rel="stylesheet" type="text/css"> 

# 一个例子——逻辑回归

现在让我们假设我们想要构建一个分类器，它获取一个人的**身高**和**体重**，并为他们是**男性**还是**女性**分配一个概率。我们将重复使用本章前面介绍的身高和体重数据。让我们从绘制数据集开始:

![An example – logistic regression](graphics/chap02_height_weight.jpg)

181 名男性和女性的身高体重数据

分类有许多不同的算法。粗略地看一下数据，我们可以通过在图上画一条直线来大致区分男人和女人。因此，线性方法是分类的一种合理的初步尝试。在本节中，我们将使用逻辑回归来构建分类器。

逻辑回归的详细解释超出了本书的范围。不熟悉逻辑回归的读者可以参考*【哈斯蒂】**【蒂布拉尼】*和*弗里德曼*的*统计学习要素*。这里我们就简单总结一下。

逻辑回归使用以下 sigmoid 函数估计给定*身高*和*体重*属于*男性*的概率:

![An example – logistic regression](graphics/4795_02_06.jpg)

这里， *f* 是线性函数:

![An example – logistic regression](graphics/4795_02_07.jpg)

这里，![An example – logistic regression](graphics/4795_02_19.jpg)是我们需要使用训练集确定的一组参数。如果我们将身高和体重视为一个*特征=(身高，体重)*矩阵，我们可以将 sigmoid 内核 *f* 重写为*特征*矩阵与*参数*向量的矩阵乘法:

![An example – logistic regression](graphics/4795_02_08.jpg)

为了进一步简化这个表达式，通常添加一个虚拟特征，其值总是 *1* 到*特征*矩阵。然后，我们可以将 *params(0)* 乘以该特征，从而允许我们将整个 sigmoid 内核 *f* 写成单个矩阵向量乘法:

![An example – logistic regression](graphics/4795_02_09.jpg)

特征矩阵 *features* ，现在是一个( *181 * 3* 的矩阵，其中每一行都是特定参与者的 *(1，身高，体重)*。

为了找到参数的最优值，我们可以最大化似然函数， *L(params|features)* 。似然性将一组给定的参数值作为输入，并返回这些特定参数产生训练集的概率。对于一组参数和相关的概率函数 *P(男|特征 [i] )，*的可能性是:

![An example – logistic regression](graphics/4795_02_18.jpg)

如果我们神奇地提前知道了人口中每个人的性别，我们可以为男性指定 *P(男性)=1* ，为女性指定 *P(男性)=0* 。似然函数将会是 **1** 。相反，任何不确定性都会导致似然函数的减少。如果我们选择一组持续导致分类错误的参数(男性的低 *P(男性)*或女性的高 *P(男性)*)，则似然函数下降到 *0* 。

最大似然对应于最有可能描述观察数据的那些参数值。因此，为了找到最好地描述我们的训练集的参数，我们只需要找到最大化 *L(params|features)* 的参数。然而，最大化似然函数本身很少实现，因为它涉及到将许多小值相乘，这很快导致浮点下溢。最好是最大化似然的对数，它具有与似然相同的最大值。最后，由于大多数优化算法都是为了最小化一个函数而不是最大化它，我们将最小化![An example – logistic regression](graphics/4795_02_10.jpg)。

对于逻辑回归，这相当于最小化:

![An example – logistic regression](graphics/4795_02_add01.jpg)

这里，sum 遍历训练数据中的所有参与者，![An example – logistic regression](graphics/4795_02_16.jpg)是训练集中第 *i* 次观察的向量![An example – logistic regression](graphics/4795_02_12.jpg)，如果是男性，![An example – logistic regression](graphics/4795_02_17.jpg)是 *1* ，如果是女性， *0* 。

为了最小化*成本*函数，我们还必须知道它相对于参数的梯度。这是:

![An example – logistic regression](graphics/4795_02_21.jpg)

我们将通过身高和体重的平均值和标准差来重新衡量身高和体重。虽然这对于逻辑回归来说不是绝对必要的，但通常是很好的实践。它有助于优化，如果我们想要使用正则化方法或构建超线性特征(允许将男性和女性分开的边界是弯曲的而不是直线的特征)，这将是必要的。

对于这个例子，我们将离开 Scala shell，编写一个独立的 Scala 脚本。下面是完整的代码清单。如果这看起来令人生畏，不要担心。我们将在一分钟内把它分成易于管理的几个部分:

```

import breeze.linalg._

import breeze.numerics._

import breeze.optimize._

import breeze.stats._

object LogisticRegressionHWData extends App {

  val data = HWData.load

  // Rescale the features to have mean of 0.0 and s.d. of 1.0

  def rescaled(v:DenseVector[Double]) =

    (v - mean(v)) / stddev(v)

  val rescaledHeights = rescaled(data.heights)

  val rescaledWeights = rescaled(data.weights)

  // Build the feature matrix as a matrix with 

  //181 rows and 3 columns.

  val rescaledHeightsAsMatrix = rescaledHeights.toDenseMatrix.t

  val rescaledWeightsAsMatrix = rescaledWeights.toDenseMatrix.t

  val featureMatrix = DenseMatrix.horzcat(

    DenseMatrix.ones[Double](rescaledHeightsAsMatrix.rows, 1),

    rescaledHeightsAsMatrix,

    rescaledWeightsAsMatrix

  )

  println(s"Feature matrix size: ${featureMatrix.rows} x " +s"${featureMatrix.cols}")

  // Build the target variable to be 1.0 where a participant

  // is male, and 0.0 where the participant is female.

  val target = data.genders.values.map {

    gender => if(gender == 'M') 1.0 else 0.0

  }

  // Build the loss function ready for optimization.

  // We will worry about refactoring this to be more 

  // efficient later.

  def costFunction(parameters:DenseVector[Double]):Double = {

    val xBeta = featureMatrix * parameters

    val expXBeta = exp(xBeta)

    - sum((target :* xBeta) - log1p(expXBeta))

  }

  def costFunctionGradient(parameters:DenseVector[Double])

  :DenseVector[Double] = {

    val xBeta = featureMatrix * parameters

    val probs = sigmoid(xBeta)

    featureMatrix.t * (probs - target)

  }

  val f = new DiffFunction[DenseVector[Double]] {

    def calculate(parameters:DenseVector[Double]) =

      (costFunction(parameters), costFunctionGradient(parameters))

  }

  val optimalParameters = minimize(f, DenseVector(0.0, 0.0, 0.0))

  println(optimalParameters)

  // => DenseVector(-0.0751454743, 2.476293647, 2.23054540)

}
```

那是一口！让我们一步一步来。在明显的导入之后，我们从:

```
object LogisticRegressionHWData extends App {
```

通过扩展内置的`App`特征，我们告诉 Scala 将整个对象视为一个`main`函数。这就去掉了`def main(args:Array[String])`的样板。然后，我们加载数据并重新调整身高和体重，使`mean`为零，标准差为 1:

```
def rescaled(v:DenseVector[Double]) =

  (v - mean(v)) / stddev(v)

val rescaledHeights = rescaled(data.heights)

val rescaledWeights = rescaled(data.weights)
```

`rescaledHeights`和`rescaledWeights`向量将是我们模型的特征。我们现在可以为这个模型构建训练集矩阵。这是一个( *181 * 3* )矩阵，其中第 *i* 行是`(1, height(i), weight(i))`，对应第 *i* 个参与者的身高体重值。我们首先将`rescaledHeights`和`rescaledWeights`从向量转换成( *181 * 1* )矩阵

```
val rescaledHeightsAsMatrix = rescaledHeights.toDenseMatrix.t

val rescaledWeightsAsMatrix = rescaledWeights.toDenseMatrix.t
```

我们还必须创建一个( *181 * 1* )矩阵，只包含 *1* 作为虚拟特征。我们可以通过以下方式做到这一点:

```
DenseMatrix.ones[Double](rescaledHeightsAsMatrix.rows, 1)
```

我们现在需要将我们的三个( *181 * 1* )矩阵组合成一个单一的形状特征矩阵( *181 * 3* )。我们可以使用`horzcat`方法将三个矩阵连接在一起:

```
val featureMatrix = DenseMatrix.horzcat(

  DenseMatrix.ones[Double](rescaledHeightsAsMatrix.rows, 1),

  rescaledHeightsAsMatrix,

  rescaledWeightsAsMatrix

)
```

数据预处理阶段的最后一步是创建目标变量。我们需要将`data.genders`向量转换成 1 和 0 的向量。我们给男性赋值 1，给女性赋值 0。因此，我们的分类器将预测任何给定的人是男性的概率。我们将使用`.values.map`方法，该方法相当于 Scala 集合上的`.map`方法:

```
val target = data.genders.values.map {

  gender => if(gender == 'M') 1.0 else 0.0

}
```

请注意，我们也可以使用之前发现的指示器函数:

```
val maleVector = DenseVector.fill(data.genders.size)('M')

val target = I(data.genders :== maleVector)
```

这导致临时数组`maleVector`的分配，因此如果实验中有许多参与者，可能会增加程序的内存占用。

我们现在有了一个表示训练集的矩阵和一个表示目标变量的向量。我们可以写出我们想要最小化的损失函数。如前所述，我们将最小化![An example – logistic regression](graphics/4795_02_22.jpg)。损失函数将线性系数的一组值作为输入，并返回一个数字，指示这些线性系数的值与训练数据的拟合程度:

```
def costFunction(parameters:DenseVector[Double]):Double = {

  val xBeta = featureMatrix * parameters 

  val expXBeta = exp(xBeta)

  - sum((target :* xBeta) - log1p(expXBeta))

}
```

注意，我们使用`log1p(x)`来计算 *log(1+x)* 。这对于`x`的小值的下溢是鲁棒的。

让我们探讨一下成本函数:

```
costFunction(DenseVector(0.0, 0.0, 0.0)) // 125.45963968135031

costFunction(DenseVector(0.0, 0.1, 0.1)) // 113.33336518036882

costFunction(DenseVector(0.0, -0.1, -0.1)) // 139.17134594294433
```

我们可以看到，对于稍微为正值的身高和体重参数，成本函数稍微低一些。这表明，对于稍微为正值的身高和体重，似然函数更大。这反过来暗示(正如我们从情节中预期的那样)比平均水平更高更重的人更有可能是男性。

我们还需要一个函数来计算损失函数的梯度，因为这将有助于优化:

```
def costFunctionGradient(parameters:DenseVector[Double])

:DenseVector[Double] = {

  val xBeta = featureMatrix * parameters 

  val probs = sigmoid(xBeta)

  featureMatrix.t * (probs - target)

}
```

定义了损失函数和梯度后，我们现在可以设置优化了:

```
 val f = new DiffFunction[DenseVector[Double]] {

   def calculate(parameters:DenseVector[Double]) = 

     (costFunction(parameters), costFunctionGradient(parameters))

 }
```

现在剩下的就是运行优化了。逻辑回归的成本函数是凸的(它有一个单一的最小值)，因此优化的起点原则上是不相关的。在实践中，通常从处处为零的系数向量开始(相当于给每个参与者分配 0.5 的男性概率):

```
  val optimalParameters = minimize(f, DenseVector(0.0, 0.0, 0.0))
```

这将返回最佳参数的向量:

```
DenseVector(-0.0751454743, 2.476293647, 2.23054540)
```

我们如何解释最佳参数的值？身高和体重的系数都是正的，这表明更高更重的人更有可能是男性。

我们还可以直接从系数中得到判定边界(将更可能属于女性的(身高、体重)对与更可能属于男性的(身高、体重)对分开的线)。决策界限是:

![An example – logistic regression](graphics/4795_02_13.jpg)![An example – logistic regression](graphics/chap02_height_weight_line.jpg)

身高和体重数据(按平均值移动并按标准差重新调整)。橙色线是逻辑回归决策边界。逻辑回归预测界限以上的个体为男性。

<title>Towards re-usable code</title><link href="epub.css" rel="stylesheet" type="text/css"> 

# 走向可重用代码

在前面的小节中，我们在一个脚本中执行了所有的计算。虽然这对于数据探索来说很好，但这意味着我们不能重用我们已经构建的逻辑回归代码。在本节中，我们将开始构建一个机器学习库，您可以在不同的项目中重用它。

我们将逻辑回归算法分解到它自己的类中。我们构造了一个`LogisticRegression`类:

```
import breeze.linalg._

import breeze.numerics._

import breeze.optimize._

class LogisticRegression(

    val training:DenseMatrix[Double], 

    val target:DenseVector[Double])

{
```

该类将表示训练集的矩阵和表示目标变量的向量作为输入。请注意我们是如何将它们分配给`vals`的，这意味着它们是在类创建时设置的，并且将保持不变，直到类被销毁。当然，`DenseMatrix`和`DenseVector`对象是可变的，所以`training`和`target`指向的值可能会改变。由于编程最佳实践规定可变状态使得对程序行为的推理变得困难，我们将避免利用这种可变性。

让我们添加一个计算成本函数及其梯度的方法:

```
  def costFunctionAndGradient(coefficients:DenseVector[Double])

  :(Double, DenseVector[Double]) = {

    val xBeta = training * coefficients

    val expXBeta = exp(xBeta)

    val cost = - sum((target :* xBeta) - log1p(expXBeta))

    val probs = sigmoid(xBeta)

    val grad = training.t * (probs - target)

    (cost, grad)

  }
```

现在，我们已经设置好运行优化，以计算最好地再现训练集的系数。在传统的面向对象语言中，我们可能会定义一个返回系数的`DenseVector`的`getOptimalCoefficients`方法。然而，Scala 更加优雅。因为我们已经将`training`和`target`属性定义为`vals`，所以最佳系数的值只有一个可能的集合。因此，我们可以定义一个保存最佳系数的`val optimalCoefficients = ???`类属性。这样做的问题是，它会在构造实例时强制进行所有的计算。这对于用户来说是意想不到的，并且可能是浪费的:例如，如果用户只对访问成本函数感兴趣，那么最小化它所花费的时间将会被浪费。解决办法是用一个`lazy val`。只有当客户端代码请求时，才会计算该值:

```
lazy val optimalCoefficients = ???
```

为了帮助计算系数，我们将定义一个私有助手方法:

```
private def calculateOptimalCoefficients

:DenseVector[Double] = {

  val f = new DiffFunction[DenseVector[Double]] {

    def calculate(parameters:DenseVector[Double]) = 

      costFunctionAndGradient(parameters)

  }

  minimize(f, DenseVector.zeros[Double](training.cols))

}

lazy val optimalCoefficients = calculateOptimalCoefficients
```

我们将逻辑回归重构为自己的类，可以在不同的项目中重用。

如果我们计划重用身高体重数据，我们可以类似地将其重构为一个自己的类，以方便数据加载、功能扩展和我们经常重用的任何其他功能。

<title>Alternatives to Breeze</title><link href="epub.css" rel="stylesheet" type="text/css"> 

# 微风的替代品

Breeze 是用于线性代数和数值计算的功能最丰富、最容易使用的 Scala 框架。但是，不要相信我的话:用其他库来试验表格数据。我特别推荐尝试一下 *Saddle* ，它提供了一个`Frame`对象，类似于 pandas 或 r 中的数据框，在 Java 世界里， *Apache Commons 数学库*提供了一个非常丰富的数值计算工具包。在[第 10 章](ch10.html "Chapter 10. Distributed Batch Processing with Spark")、*使用 Spark 的分布式批处理*、[第 11 章](ch11.html "Chapter 11. Spark SQL and DataFrames")、 *Spark SQL 和 DataFrames* 以及[第 12 章](ch12.html "Chapter 12. Distributed Machine Learning with MLlib")、*使用 MLlib 的分布式机器学习*中，我们将探索 *Spark* 和 *MLlib* ，它们允许用户运行分布式机器学习算法。

<title>Summary</title><link href="epub.css" rel="stylesheet" type="text/css"> 

# 总结

我们对 Breeze 的简要概述到此结束。我们已经学习了如何操作基本的 Breeze 数据类型，如何将它们用于线性代数，以及如何执行凸优化。然后，我们使用我们的知识来清理一个真实的数据集，并对其执行逻辑回归。

在下一章，我们将讨论 breeze-viz，一个 Scala 绘图库。

<title>References</title><link href="epub.css" rel="stylesheet" type="text/css"> 

# 参考文献

*统计学习的要素*，作者*哈斯蒂*、*蒂布希拉尼*和*弗里德曼*，对机器学习的数学基础进行了清晰、实用的描述。任何渴望不只是盲目地将机器学习算法作为黑盒来应用的人，都应该有一本这本书。

*Scala for Machine Learning* ，作者 *Patrick R. Nicholas* ，描述了许多有用的机器学习算法在 Scala 中的实际实现。

Breeze 文档([https://github.com/scalanlp/breeze/wiki/Quickstart](https://github.com/scalanlp/breeze/wiki/Quickstart))、API 文档([http://www.scalanlp.org/api/breeze/#package](http://www.scalanlp.org/api/breeze/#package))和源代码([https://github.com/scalanlp/breeze](https://github.com/scalanlp/breeze))提供了 Breeze 上最新的文档来源。