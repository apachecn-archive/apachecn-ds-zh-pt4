

# Bash 函数和数据可视化

到目前为止，我们一直在交互地使用 bash，并且不得不依赖 bash `history`来完成我们所做的事情。如果有一种便携的方式来共享和存储您想要运行的命令，那不是很好吗？这个功能是以由 shell 函数组成的 shell 脚本的形式存在的。

我们将在命令行扩展我们在[第 1 章](d26c5d26-6302-4b9d-b6ce-62b1ab13db0d.xhtml)、*数据科学中讲述的历史，并设置它*。终端起源于纯文本设备，并发展为对简单绘图原语的图形支持，例如在表格数据中呈现封闭的单元格。终端图形的顶峰是由 DEC 分别以 SIXEL 和 REGIS 图形的形式提供画布和矢量图形支持。随着物理终端成为过去，轻量级终端模拟器退化为纯文本的。alacritty、wsltty、xterm、mlterm、st、iTerm2 和 hterm 仿真器复兴了终端仿真器的图形支持。

我们推荐 Windows 用户使用支持 SIXEL 的 wsltty，Linux 用户使用支持 SIXEL 的 xterm 或 mlterm，以及 macOS 上支持 PNG 渲染的 iTerm2(将来可能会添加 SIXEL 支持)。

使用推荐的终端模拟器，我们将在终端中展示画布风格的图形呈现，当然，还包括对哑终端的文本模式支持。我们将只提到 ascii 艺术库的存在，`aalib` ( **ascii 艺术库**)，`libcaca`，以及试图仅使用字体字符向终端呈现图形的盲文字体。在这里，我们将使用 SIXEL for Linux/Windows 和 PNG for macOS，并将所有高级选项的哑终端输出留给读者作为一次冒险。在本章中，我们将讨论以下主题:

*   如何执行脚本
*   函数自变量/参数
*   高级 shell 脚本
*   如何将您的终端配置为图形模式
*   数据挖掘可绘制的数据
*   用 gnuplot 绘制数据



# 我的第一个 shell 脚本

我们的第一个 shell 脚本将涵盖如何告诉计算机运行 shell 脚本的基础知识。



# 她砰，她砰！

我们不是在谈论那首流行的瑞奇·马丁的歌。我们正在讨论每个 bash 脚本需要什么才能运行。如果您使用过其他编程语言，您可能会注意到第一行总是以`#!`开头。这告诉系统使用哪个解释器。例如，如果你以前使用过 Python，你可能在脚本中见过`#!/usr/bin/env python2.7`。有了 bash，也没什么不同。让我们继续创建一个名为`hello_world.sh`的新文件，并输入以下内容:

```
#!/bin/bash
# A function to greet everyone
greet_everyone() {
  echo Hello, World!
}
greet_yourself() {
  echo Hello, ${USER}
}
greet_everyone
greet_yourself
```

文件编辑器是互联网上新出现的热门话题。比如搜索`vim`对`emacs`或者`nano`对`pico`。如果你没有最喜欢的编辑，我们不会强迫你选择，但你应该用一个非常非常的方法来找到你的一个真正的编辑。

继续将该文件保存为`hello_world.sh`，然后让我们使脚本可执行:

```
chmod +x hello_world.sh
```

现在，您可以像这样运行脚本:

```
./hello_world.sh
```

我们来分析一下。第一行是我们提到的 shebang。我们的函数叫做`greet_everyone`和`greet_yourself`。在花括号`{ }`中，我们可以运行任意多的命令。最后，在它下面调用函数。另外，请注意脚本中的`${USER}`变量。您可能想知道 bash 是如何智能地打印出您的用户名，而无需您定义它。每个 bash 环境都有一组您可以查看的预配置变量。继续运行`printenv`命令，看看有什么可用的。

这是伟大的，如果我们想问候整个世界，并使用您的用户名。但是，如果我们想更进一步呢？



# 函数参数、位置参数和 IFS

函数参数、位置参数和**if**(**内部字段分隔符**)是 bash 中高级的列表处理机制。我们将依次介绍它们，以确保对 shell 如何与它们交互有一个基本的了解。



# 宝贝，再提示我一次

我们讨论了如何调用我们的函数，但是我们如何提示用户输入呢？计算机不能读懂你的思想——它只能读懂你的键盘输入！为了让 bash 读取输入，您必须使用(您猜到了)`read`命令。让我们扩展我们函数的功能。继续用以下代码修改上一节中的`hello_world.sh`脚本:

```
#!/bin/bash
# A function to greet everyone
echo Who would you like to greet?
read name
greet_yourself() {
  echo Hello, ${1:-$USER}!
}
greet_yourself $name
```

我们已经添加了`read name`代码，在`greet_yourself`函数中用`${1:-$USER}`替换了`${USER}`变量，并在`greet_yourself $name`函数调用中添加了第一个参数。当`$name`被传递给`greet_yourself`函数时，它被赋给`$1`变量。那个`${1:-$USER}`魔变是说展开`$1`；如果为空，则替换为`$USER`,如果只按下`enter`键而没有提供用户名，则保留我们原始函数的相同输出行为。再次运行以查看以下内容:

![](assets/32e846b5-c3ab-410b-b248-70fe7b413b65.png)

让我们只关注我们的功能。将以下代码粘贴到您的 shell 中:

```
<<EOF cat >greetlib.sh
greet_yourself() {
  echo Hello, \${1:-\$USER}!
}
EOF
```

这是一种创建`greetlib.sh`文件的奇特方法。这里的`<<EOF`是文档重定向，表示我们想要指定标准输入到`cat`，并将其标准输出重定向到`greetlib.sh`。第一行之后的所有内容都是 shell 解释的内容，它们将被连接到输出文件的末尾，直到`EOF`被读取。Shell 解释的内容意味着变量被替换为当前 shell 环境中的值，我们用`\$`对 shell 变量进行了转义，这样它们将作为`$`呈现在`greetlib.sh`文件中，而不会被解释为实际值。最后，我们可以将函数放入当前的 shell 环境中并调用它。我们将在下一节中练习。



# 馈入功能输入！

我们的 shell 函数接受称为位置参数的参数，它相当于 POSIX C 运行时的 ARGV。函数参数根据其数值位置自动分配给以下形式的变量:`$1, $2, $3, .., $9`。`$0`变量存在，但是包含用于调用 shell 的名称。一些好奇的人可能想知道第九次论证后会发生什么。我们需要使用完整的变量解引用语法，分别用于第十个和第十一个变量`${10}`和`${11}`。那么这一切看起来像什么呢？看看这个:

```
greet_yourself() {
  echo Hello, ${1:-$USER}!
}
. ./greetlib.sh
greet_yourself “Joey”
```

`.`操作符用于在您当前的执行环境中读取和评估一个 shell 脚本，就好像您已经在命令行中键入了所有的`greetlib.sh`并按下了`enter`键。这调用了第一个位置参数`"Joey"`分配给`$1`的`greet_yourself`函数。为了向前跳跃，我们有位置参数的类型:选项(在本章的结尾涉及)和自变量。选项有长、短两种形式，分别用单连字符或双连字符标识。短选项是单个字符，长选项是描述要设置的值的完整语义词。如果一个参数在其值的开头需要一个文字连字符，则需要用双连字符来区分它和选项。假设，这是天书看起来是这样的:

```
greet_yourself --capitalize --name="Joey"
greet_yourself --lowercase -- -RoBoT1
```

这些示例展示了如何将选项和参数传递给函数，因为选项只是位置参数。在第一个问候调用中，我们将`--capitalize`赋给第一个位置参数`$1`，将`--name=”Joey”`赋给第二个位置参数`$2`。在第二个问候呼叫中，我们将`--lowercase`分配给`$1`，将`--`分配给`$2`，将`-RoBoT1`分配给`$3`。我们的函数是基本的，缺乏将`--capitalize`和`--lowercase`选项作为函数特性进行处理的能力。我们假设第一个问候调用应该输出`"JOEY"`，第二个问候应该输出`-robot1`。有些人可能想知道命令如何区分以连字符开头的选项和参数，比如`-RoBoT1`。裸露的双连字符`--`表示所有后面的位置参数都将被视为参数，而不是选项。同样，我们将在本章末尾深入探讨选项处理，但是一次显示所有的函数调用是最简单的。



# 掉进 IFS 和 bash 数组的兔子洞

位置参数是根据 shell 脚本、函数或`set`命令的参数创建的。将单词分配给位置变量是通过沿着 IFS 变量中包含的任何分隔符拆分未加引号的字符串来完成的。IFS 变量默认为字符串，由空格、制表符和换行符组成。因为 IFS 是一个变量，所以可以修改这个变量，这在迭代非空格分隔的文本时很有用:

```
IFS=:
for P in $PATH ; do
 echo $P
done
unset IFS
```

前面的代码举例说明了如何用冒号分隔符分割 PATH 变量(最少由`/bin:/usr/bin`组成),以便可以操作每个路径段。我们希望读者能够推断出这对于迭代逗号分隔的列表或类似的简单分隔的数据集是如何有用的。

由于修改位置参数的限制，bash 4 引入了数组。如果您的 shell 脚本变得足够复杂而需要数组，我们鼓励您考虑升级到成熟的脚本语言，比如 Perl、Python 或 Ruby，它们更适合处理 bash 本身不支持的各种列表迭代。深入研究一下，bash 数组是零索引的，并且使用特殊的语法`${ARRAY[#]}`来访问，其中的符号`#`应该由整数数组索引或者特殊的值`@`或者`*`来代替，它们代表转换成字符串的带引号的元素或者不带引号的元素。下面是 bash 数组的一些示例代码:

```
TMP_PATH=/bin:/usr/bin:/sbin:/usr/sbin
IFS=:
PATH_ARRAY=($TMP_PATH)
unset IFS
echo First element - ${PATH_ARRAY}
echo First element - ${PATH_ARRAY[0]}
echo Second element - ${PATH_ARRAY[1]}
echo All elements - ${PATH_ARRAY[*]}
echo All elements - ${PATH_ARRAY[@]}
```



# 高级 shell 脚本魔术

这是这一章的黑魔法部分。它将通过学习前面的课程和特性，并把它们转换成一个小程序来演示高级 shell 脚本。



# 这里有龙，你们要小心

一段简单的介绍性代码对于感受一种语言的风格是很好的，但是我们将引入一些黑魔法，以一些复杂的实用函数的形式，这些函数在日常情况下会很有帮助。我们将使用一个`lineinfile`函数将任意文本插入到一个文件中——这不是一个全功能的应用，只是足以帮助确保一些简单的文本被注入到一个文件中。第二个功能是`ncz`，利用 bash IP 网络(是的，bash4 可以在你的发行版中支持 IP 网络 YMMV)来执行一个套接字测试，相当于`netcat -z`所做的。此外，它还展示了如何通过解析简单的参数标志来使函数像命令行程序一样运行。



# 文本文件的文本注入

我们将创建一个可以将文本注入现有文件的函数。这是我们的函数:

```
lineinfile() {
 FILE=$1 ; shift
 LINE=”^$1$” ; shift
 CONTEXT=”$1.*” ; shift
 MODE=${1:-add} ; shift
 case “${MODE}” in
  add)
   grep -s “${LINE}” “${FILE}” || sed -i -e “s/\(${CONTEXT}\)/\1\n${LINE}/” “${FILE}”
   ;;
  del)
   grep -s “${LINE}” “${FILE}” || sed -i -e “/${LINE}/d” “${FILE}”
   ;;
 esac
}
```

预期用途如下:

```
lineinfile <filename> <string> <insert-after-context-string> <add | [del]>
```

`lineinfile`从标准的`function() {}`定义模板开始。它将传递给函数`$1`的第一个位置参数读入`FILE`变量，并移动位置参数，使每个参数的索引减 1，因此`$2`变为`$1`，`$3`变为`$2`，依此类推。第二个参数被赋给了变量`LINE`，我们用正则表达式的行首`^`和行尾`$`分隔符作为前缀，表示被注入的字符串必须匹配一整行(抱歉，这个简单的函数中没有高级正则表达式支持)。第三个参数查找上下文，这样我们就可以在上下文后面插入该行。同样，无法在上下文之前指定注入，如果上下文存在，就在上下文之后指定注入。第四个参数是我们的`lineinfile`函数的操作模式，要么是`add`(添加文本是默认行为)，要么是删除(使用`del`模式)。



# Bash 网络的乐趣和利润！

有时，我们需要与网络服务或 API 进行交互。在这里，我们将介绍一些测试 TCP 端点的完整代码，这对于检查 API 服务是否在监听和可用非常有用。这段代码可以粘贴到您的终端中，或者保存到一个文件中，并使用`.`操作符加载到您的 shell 环境中:

```
ncz() {
 OPTIND=1 ; while getopts ":hv" opt; do
  case ${opt} in
   v) VERBOSE=true
    ;;
   h|\?) printf "Usage: $0 [-v] <host | host:port>" ; return
    ;;
  esac
 done
 shift $(($OPTIND - 1))
 HOST=${1%:*}
 PORT=${1#*:}
 PORT=${2:-$PORT}
 (exec 6<>/dev/tcp/${HOST}/${PORT} 2>&1)
 RC=$?
 case "${VERBOSE}${RC}" in
  true0) printf "open\n";;
  true*) printf "closed\n";;
 esac
 return $RC
}
```

现在，这段代码有一些小魔法。`getopts`是一个函数，根据 POSIX 处理将位置参数解析成选项，并将下一个选项分配给指定的变量，在本例中为 opt。它支持短、长选项，选项可以有参数；参数将存储在`OPTARG`中。这个例子使用了一个普通的选项字符串`:hv`。冒号字符表示无效的选项标志应该用问号字符`?`来表示。`h`选项用于我们的帮助标志，而`v`用于我们设置`VERBOSE`标志。`while`循环调用`getopts`函数，该函数修改位置参数。当`getopts`函数完成时，需要将处理过的位置参数移出，这样我们就可以将非选项作为函数参数。`OPTIND`是被解析的最后一个选项的索引，因此从中减去 1，并将位置参数移动该量，可以确保在位置参数中只保留正确的参数。

代码试图支持接受形式为`host:port`或`host port`的参数。对单参数或双参数参数的支持是通过始终使用第二个参数作为端口来处理的，如果没有第二个参数，则默认使用前缀和后缀移除来拆分冒号字符上的第一个参数。`HOST=${1%:*}`赋值试图通过扩展第一个位置参数从`host:port`参数中提取一个主机组件，去掉所有尾随字符(`%`是一个反向替换匹配)到第一个冒号字符(`host:port`之间的分隔符)，这样我们只剩下变量的主机部分。如果反向匹配失败，表明没有端口组件，将分配未修改的扩展`$1`。为了得到端口，我们看第二个参数。如果它不存在，我们通过剥离`$1`的`host:`部分，缺省使用从第一个位置参数中提取的端口。

真正的黑魔法包括文件描述符和 bash 的 IP 网络支持。我们在 subshell 中打开文件描述符 6。我们将由`/dev/tcp/$HOST/$PORT`创建的套接字的输入/输出附加到这个文件描述符上。写入文件描述符的任何内容都将通过 TCP 套接字发送到`tcp://$HOST:$PORT`，任何响应都可以从同一个文件描述符中读取。由于网络连接可能出错，我们捕获对`RC`(return code 的简称)变量开放的套接字的返回代码。然后，我们根据详细的选项标志和返回代码的状态来评估是否需要输出，根据返回代码打印成功/失败。在 C 程序中，返回代码 0 表示成功，因此`true0`表示函数已经调用请求详细模式，并且成功建立了套接字连接。最后，从函数返回返回代码，以便可以通过 shell 管道评估远程套接字的状态。

下面是对前面解释的不言自明的调用:

```
ncz google.com:80 && echo "yay!! Interwebz are up!" || echo "booh! No kitties for us!"
```



# 从哑终端到魅终端

我们将使用 gnuplot 在我们的终端中呈现哑文本图形和画布风格的图形。首先，我们需要一些 gnuplot 启动的基本配置。将以下内容放入`~/.gnuplot`:

```
set term dumb
```

接下来，我们需要一个包装 gnuplot 的包装器来获得一些漂亮的图形输出。这个包装器查看当前 shell 的`GNUTERM`环境变量，并对终端的宽度和高度进行一些计算，以便 gnuplot 知道它有多大的窗口。包装器将使用为我们的终端指定的图形功能来更新我们的`~/.gnuplot`配置。我们不打算深入研究包装器，只是将它作为另一个命令使用。这是:

```
__gnuplot() {
 SIZE=$(stty size 2>/dev/null)
 SIZE=${SIZE:-$(tput lines) $(tput cols)}
 COLS=${SIZE#* }
 ROWS=${SIZE% *}
 XPX=${XPX:-13}
 YPX=${YPX:-24}
 COLUMNS=${COLUMNS:-${COLS}}
 LINES=$((${LINES:-${ROWS}}-3))
 case "${GNUTERM%% *}" in
 dumb) X=${COLUMNS} ; Y=${LINES} ; DCS_GUARD="cat" ;;
 png) X=$((XPX*COLUMNS)) ; Y=$((YPX*LINES)) ;
DCS_GUARD="imgcat";;
 sixelgd) X=$((XPX*COLUMNS)) ; Y=$((YPX*LINES));;
 esac
 sed -i "s/^set term[[:space:]][^[:space:]]*/set term ${GNUTERM%%
*}/" ~/.gnuplot
 GNUTERM="${GNUTERM} size $X,$Y" \gnuplot "$@" | ${DCS_GUARD:-cat}
}
alias barchart="FUNCNAME=barchart __barchart"
__barchart() {
 local STACKED
 local DATA
 OPTIND=1 ; while getopts ":hf:s" opt; do
 case ${opt} in
 f) [ -r "${OPTARG}" ] && DATA=$(printf '$data <<EOD\n' ; cat "${OPTARG}" ; printf 'EOD\n')
 ;;
 s) STACKED="; set style histogram rowstacked ; set boxwidth 0.75"
 ;;
 h|\?) printf "Usage: ${FUNCNAME} [-s] [-f <file>] <gnuplot commands\n"
 return
 ;;
 esac
 done
 shift $(($OPTIND - 1))
 {
 cat <<-EOF
 $DATA
 set key autotitle columnheader outside
 set style data histograms ${STACKED}
 set style fill solid border lt -1
 set xtics rotate by -45
 EOF
 printf "%s" "$@"
 } | gnuplot
}
```

根据您的操作系统和终端，您需要为您的终端指定正确的图形后端。

使用 wsltty 的 Windows 用户和使用 mlterm 或 xterm 的 Linux 用户应该设置以下环境变量:

```
export GNUTERM=sixelgd
```

iTerm2 的 macOS 用户应该使用这个环境变量:

```
export GNUTERM=png
```

让我们验证我们能够绘制一个图形化的测试模式。如果你的哑终端不支持图形模式，我们包括一个文本模式测试。

对于图形测试，运行以下命令:

```
gnuplot -e "set terminal $GNUTERM background rgb 'white'; test"
```

这应该会产生如下所示的图形终端输出:

![](assets/f360f088-ca0a-4844-b573-c8ca23660da6.png)

对测试输出的一些快速标注对于设计输出图形很重要。测试图形最右侧的线型缩写为`lt`，为图中绘制的控制点(或点)提供可视标记，例如，*、+和 x。线宽缩写为`lw`，位于左下方，设置绘制线的线宽。

如果您的终端不支持图形模式，可以使用文本打印。调用文本测试:

```
GNUTERM=dumb \gnuplot
gnuplot> test
gnuplot> exit
```

这应该会产生如下的终端输出:

![](assets/82efbc34-3db3-4731-809c-4972c4515e58.png)

最后，我们需要一个`alias`来调用带有`GNUTERM`环境变量的函数，该变量被设置为可接受的图形后端。运行下面的别名，将`GNUTERM`变量设置为适合您的终端的值:

```
alias gnuplot="GNUTERM=$GNUTERM __gnuplot"
```



# 谁，什么，哪里，为什么，如何？

让我们回到我们的书籍数据，并开始削减到有趣的位。让我们来看一点数据:

```
head amazon_reviews_us_Digital_Ebook_Purchase_v1_00.tsv
```

它吐出了一堆很长的数据。让我们再试一次—也许我们真的只关心标题，所以让我们试试这个:

```
head -n1 amazon_reviews_us_Digital_Ebook_Purchase_v1_00.tsv
```

因为有很多文本，所以让我们删除文本字段，通过删除`product_title`、`review_headline`和`review_body`来关注数字数据，它们对应于字段 6、13 和 14。既然我们看到的是伪大数据，让我们获取所有数字或布尔标志字段，并转储所有文本评论(我们可以让自然语言处理人员来分析)，尝试一下:

```
cat amazon_reviews_us_Digital_Ebook_Purchase_v1_00.tsv | cut -d $'\t' -f 4,8-12,15 > test.tsv
```

就这样，我们将数据大小从 6.3 GB 减少到 383 MB，这更易于管理。现在，让我们将其导入 SQL 数据库，使汇总表格数据像 SQL 查询一样简单:

```
sqlite3 aws-ebook-reviews.sq3 <<EOF
.mode csv
.separator "\t"
.import test.tsv reviews
EOF
```

让我们找出评论最多的产品:

```
sqlite3 -header -column aws-ebook-reviews.sq3 " select product_id as ID, strftime('%Y-%m', review_date) DATE, star_rating as STAR, count(product_id) as COUNT from reviews group by ID order by COUNT desc limit 10"
```

应显示以下输出(计数可能不同):

```
ID     DATE STAR    COUNT
---------- ---------- ---------- ----------
B00L9B7IKE 2015-01 5      54534
B005ZOBNOI 2013-09 5      50581
B006LSZECO 2013-09 3      45467
B00BAXFECK 2013-10 5      34253
B003WUYPPG 2013-09 3      30890
B00DPM7TIG 2014-05 4      28234
B00JYWUHO4 2014-10 1      26722
B0089LOG02 2013-09 5      26155
B00CNQ7HAU 2013-10 5      24454
B004CFA9RS 2013-09 5      23677
```

54，000 条评论似乎是我们可以绘制一些有趣数据的东西，所以让我们专注于产品 ID `B00L9B7IKE`。对于绘图，我们知道我们正在查看哪个产品 ID，所以让我们调整我们的查询，不报告产品 ID，只关注日期、星级和计数:

```
sqlite3 -header -column aws-ebook-reviews.sq3 " select strftime('%Y-%m', review_date) DATE, star_rating as STAR, count(star_rating) as COUNT from reviews where product_id = 'B00L9B7IKE' group by DATE, STAR"
```

将显示以下输出:

```
DATE    STAR COUNT
---------- ---------- ----------
2015-01   1 30
2015-01   2 44
2015-01   3 108
2015-01   4 304
2015-01   5 822
2015-02   1 290
2015-02   2 352
2015-02   3 818
2015-02   4 2040
2015-02   5 3466
2015-03   1 446
2015-03   2 554
2015-03   3 1294
2015-03   4 3186
2015-03   5 5092
2015-04   1 466
2015-04   2 508
2015-04   3 1178
2015-04   4 2550
2015-04   5 3806
2015-05   1 442
2015-05   2 538
2015-05   3 1152
2015-05   4 2174
2015-05   5 3058
2015-06   1 382
2015-06   2 428
2015-06   3 952
2015-06   4 1920
2015-06   5 2898
2015-07   1 388
2015-07   2 484
2015-07   3 972
2015-07   4 2122
2015-07   5 3004
2015-08   1 374
2015-08   2 458
2015-08   3 884
2015-08   4 1762
2015-08   5 2788
```

这是我见过的一些可绘制的数据。我们可以跟踪每天或每月有多少评论，当我们绘制图表时，我们可以寻找异常情况，例如某一天五星评论的异常数量，而前几天没有这么突出。

我们的数据仍然不完全正确；对于绘图，我们希望在一行中按日期对星级进行分组，因此我们需要对数据进行另一次转换。我们还删除了`-`列选项，这样我们就可以得到压缩的输出，当我们准备好将数据传递给 gnuplot 时，我们可以通过`tr`来处理这个输出。我们还将把这个输出保存到`clusterchart.dat`中，这样我们的绘图命令就简单明了了:

```
sqlite3 -header aws-ebook-reviews.sq3 "select DATE, MAX(CASE WHEN STAR='1' THEN COUNT END) as '1STAR', MAX(CASE WHEN STAR='2' THEN COUNT END) as '2STAR', MAX(CASE WHEN STAR='3' THEN COUNT END) as '3STAR', MAX(CASE WHEN STAR='4' THEN COUNT END) as '4STAR', MAX(CASE WHEN STAR='5' THEN COUNT END) as '5STAR', SUM(COUNT) as TOTAL from ( select strftime('%Y-%m', review_date) DATE, star_rating as STAR, count(star_rating) as COUNT from reviews where product_id = 'B00L9B7IKE' group by DATE, STAR) results group by DATE" | tr '|' '\t' > clusterchart.dat
cat clusterchart.dat
```

最后，这里是我们用 gnuplot 绘图的压缩输出:

```
DATE  1STAR 2STAR  3STAR 4STAR 5STAR  TOTAL
2015-01 30   44 108 304   822 1308
2015-02 290   352 818 2040  3466 6966
2015-03 446   554 1294 3186  5092 10572
2015-04 466   508 1178 2550  3806 8508
2015-05 442   538 1152 2174  3058 7364
2015-06 382   428 952 1920  2898 6580
2015-07 388   484 972 2122  3004 6970
2015-08 374   458 884 1762  2788 6266
```



# 进入心灵的眼睛

让我们看看这是什么样子。运行以下代码:

```
gnuplot -e "set style data histograms ; set style fill solid border lt -1 ; plot 'clusterchart.dat' using 2:xtic(1) ti col, '' u 3 ti col, '' u 4 ti col, '' u 5 ti col, '' u 6 ti col"
```

这将在您的终端中产生以下内容:

![](assets/bb22fb88-dc2a-4844-89f6-40bb2eb7f1b7.png)

让我们做完全相同的操作，但是输出`dumb`输出:

```
GNUTERM=dumb gnuplot -e "set style data histograms ; set style fill solid border lt -1 ; plot 'clusterchart.dat' using 2:xtic(1) ti col, '' u 3 ti col, '' u 4 ti col, '' u 5 ti col, '' u 6 ti col"
```

我们得到一个基于文本的输出:

![](assets/e7cfea49-063b-4a16-bd4a-d70bc566458c.png)

要分解我们所做的工作，请查看以下代码:

```
GNUTERM=dumb gnuplot -e "set style data histograms ; set style fill solid border lt -1 ; plot 'clusterchart.dat' using 2:xtic(1) ti col, '' u 3 ti col, '' u 4 ti col, '' u 5 ti col, '' u 6 ti col"
```

第一步是设置`GNUTERM`，它应该默认为我们在`~/.bash_profile`中设置的。这告诉我们的 gnuplot 包装器使用哪个输出后端。对于`GNUTERM=dumb`，这将是一个文本后端。下一部分是带有`-e`表达式的`gnuplot`论证。表达式是`gnuplot`语法。我们首先用`set style data histograms`将我们的图设置为直方图，而不是线形图。接下来，我们通过将条形颜色设置为带有实线边框的整体填充来指定条形颜色，并使用线型`-1`作为默认线型。在我们定义了我们的绘图样式之后，我们告诉 gnuplot 用`plot 'clusterchart.dat'`来绘制我们的数据。每个要绘制的逗号分隔参数代表`clusterchart.dat`中每行数据要绘制的一列。我们指定绘图中的第一列应该使用第二列数据，并使用第一列数据作为我们的 x 标签，如`2:xtic(1) ti col`所示。

我们图中的第二列使用相同的`clusterchart.dat`作为输入，用两个连接的单引号表示相同的值，并指定第三个数据列用于分笔成交点数据。第三列、第四列和第五列使用与第二列相同的符号，这是为了表示对`clusterchart.dat`的重用，并指定提取 y 轴刻度数据的数据列。

如果我们想更有趣一点，我们可以使用行堆叠而不是聚集条形图，这样我们可以更紧凑地可视化我们的数据。试试这个:

```
barchart -s -f clusterchart.dat 'plot for [i=2:6] $data using i:xtic(1)'
```

我们得到一个堆积条形图:

![](assets/9e5dfc76-990e-4092-89cb-6656d7d648f2.png)

现在，如果我们想看到百分比，我们可以在堆叠模式下使用我们的`barchart`包装器。很高兴看到不同数据段之间的差异。尝试调用以下代码:

```
barchart -s -f clusterchart.dat 'plot for [i=2:6] $data using (100.*column(i)/column(7)):xtic(1) title column(i)'
```

它产生以下输出:

![](assets/0a907dd3-adbb-4195-adba-75a14599e1b8.png)

这是在堆叠模式(`-s`)下使用我们的条形图包装器，并指定我们的`clusterchart.dat`输入文件，用 gnuplot 脚本作为最后一个参数。对于 gnuplot，我们告诉它为`i=2`到`6`执行一次迭代绘图。条形图包装器将`$data`变量设置为`clusterchart.dat`的内容。using 参数将我们的分数乘以`100`来创建条形图中每个元素`i`占`7`列总数的百分比。`xtic(1)`正在将`xtic`标记标题设置为一列中绘制的每行数据的第 1 列内容。在这个例子中，我们需要添加`column(i)`标题来将键标题正确地设置到列标题中，而不是使用最后引用的`column(7)`标题。



# 摘要

有了重用 bash 代码的能力，可以将一组脚本拼凑在一起，以提高命令行的效率。凭借可视化结果的能力，您可以更快地查看数据集并执行数据挖掘任务。

在下一章，我们将更深入地研究 bash 控制流，以创建更丰富的功能。