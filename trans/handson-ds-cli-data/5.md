

# 五、循环、函数和字符串处理

有时候，神奇的一行程序不足以操作数据。循环和条件使我们能够以有趣的方式迭代数据，而不拘泥于默认行为。

Bash 将非二进制文件和流视为字符集合。我们通常认为这些字符是由某种空格分隔的字符串组。命令行世界中一些最有用和最常用的工具就是搜索和操作这些字符串的工具，这是有道理的。

本章将涵盖以下主题:

*   `for`循环
*   `while`循环
*   文件测试条件
*   数字比较
*   字符串 case 语句
*   使用正则表达式和`grep`进行搜索和过滤
*   使用`awk`、`sed`和`tr`的字符串转换
*   使用`sort`和`uniq`对字符串列表进行排序

在这个过程中，我们将看到如何将一个程序的结果传输到另一个程序中，以获得我们想要的结果。



# 一次，两次，三次一位女士循环

很少有命令行工具内置了隐式循环和条件。通常，任务只在输入流的每一行上操作，然后终止。shell 提供了足够的控制流和条件来解决许多复杂的问题，弥补了命令行工具在数据操作方面的不足。

全能的`for`循环是一个常见的循环习语，然而 bash 的`for`循环对于更传统语言的用户来说可能会有点陌生。`for`循环允许你遍历一个单词列表，并将每个单词分配给一个变量进行处理。例如，(双关语):

![](assets/ada257e1-0797-4f71-b0f6-a8b281d81153.png)

通常，我们希望在我们的`for`循环中有一个更传统的数字范围。生成数字范围的`POSIX`方法是使用`seq`命令，如在`seq -- $(seq 1 1 5)`中，它将生成从 1(第一个参数)到 5(第三个参数)的数字，步长为 1(第二个参数)。

在下面的例子中，你会注意到我们使用了括号扩展、`{}`和圆括号、`()`。更多关于这两者的信息，请查看 https://ss64.com/bash/syntax-brackets.html 的[。](https://ss64.com/bash/syntax-brackets.html)

现代版本的`bash`对此提供了一个简单的简写:

![](assets/17774fa8-f1c3-44c6-b4fd-fdf1f1f63607.png)

我们还可以设置序列的增量:

![](assets/2ed52b37-5d53-40ba-878d-a7ab14d4cf4d.png)

或者，我们可以使用`bash`支持的类似 C 的语法:

![](assets/b4aa359d-7e15-48f5-a7de-fba201b5b3f7.png)

我们可能需要循环指定的次数，但是我们也可以传递子命令的结果来生成要循环的内容列表。例如，我们可能想对当前目录中的每个文件做些什么:

![](assets/f8cf46e8-8f49-4489-9544-1512e3610085.png)

通常，我们可能想要测试一个或多个条件，尤其是在循环中。像大多数语言一样，Bash 有一个`if-then`结构:

![](assets/bc85b83b-d991-43b1-b387-add64e2200f9.png)

括号内的语句是一个测试，bash 包含一组特殊的测试，比如针对常见任务的`-f`。以下是一些最常见的问题:

| **测试类型** | **参数** | **描述** |
| 文件系统 | `-O` | `True`如果文件存在，并且归有效用户 ID 所有 |
| 文件系统 | `-f` | `True`如果文件存在并且是常规文件 |
| 文件系统 | `-G` | `True`如果文件存在并且由有效的组 ID 拥有 |
| 文件系统 | `-r` | `True`如果文件存在且可读 |
| 文件系统 | `-w` | `True`如果文件存在且可写 |
| 文件系统 | `-x` | `True`如果文件存在且可执行 |
| 文件系统 | `-s` | `True`如果文件存在且大小大于零 |
| 文件系统 | `-h` | 如果文件存在并且是一个符号链接 |
| 算术 | `<=` | 小于等于 |
| 算术 | `>=` | 大于等于 |
| 算术 | `<` | 不到 |
| 算术 | `>` | 大于 |
| 算术 | `!=` | 不相等 |
| 算术 | `=` | 平等的 |

像其他语言一样，我们也可以包含`else-if`测试，最后还有一个`else if`没有其他的匹配:

![](assets/48ae89f3-e5f2-4ffd-93e3-75e7711430ff.png)

尽管存在`if-else`构造，但是大多数 shell 脚本使用了`&& (AND)`和`|| (OR)`的管道语义。我们在[第 3 章](ea035d0b-e34a-481c-87f4-53c45869e4a3.xhtml)、*获取和处理数据以及分离处理和终端多路复用器*中简要提到了这一点，但这里有一个更详细的示例:

```sh
[ 0 = 1 ] && echo "a" || ([0==2] && echo b || echo c)
[ -f /myconfig ] && read_params /myconfig
```



# 正如我们所知，这是世界末日

让我们探索另外两个帮助迭代的选项。只要控制`while`循环的命令成功退出，`while`结构就允许重复执行一系列或一组命令。让我们看一个例子:

假设我想在一个脚本中打印四次`"hello!"`字符串——不多也不少。我们可以通过以下方式做到这一点:

![](assets/88518703-1714-4788-904c-b7a3ba02a38d.png)

让我们保存并运行这个脚本，看看会发生什么。

不要忘记`chmod -x`这些脚本，使它们可执行。

执行该脚本会产生以下结果:

![](assets/00080cc2-726b-4440-98c5-a1d875db5c32.png)

注意，在脚本中，我们创建了一个名为`i="0"`的变量。这将变量`i`设置为零。你看到`while [ $i -lt 4 ]`街区了吗？这允许我们在`i`变量小于`4`整数时运行循环。继续研究一下这段代码，以便更好地理解。此外，您可以通过`man [`了解更多信息。

在我们的 while 脚本中，我们一直数到 4 才输出结果。让我们使用`until`构造来递减计数并提供`goodbye!`输出:

![](assets/be4e8256-218b-4c48-a3bd-5a219b2650fc.png)

让我们保存并运行这个脚本，看看会发生什么:

![](assets/bbc9c002-41c4-481c-b557-1878fe92d685.png)



# 简单的例子

通常，使用测试操作符`[`进行字符串比较。这在 bash 中是不明智的，因为有一种更方便的字符串比较格式，使用`case`语句。这里有一个简单的例子:

```sh

 testcase() {
 for VAR; do
 case “${VAR}” in
         '') echo “empty”;;
         a) echo “a”;;
        b) echo “b”;;
        c) echo “c”;;
        *) echo “not a, b, c”;;
 esac
 done
 }
 testcase '' foo a bar b c d
```

`testcase`函数让我们通过将`case`语句包装在一个`for`循环中来测试它，该循环将每个函数参数分配给`VAR`变量，然后执行`case`语句。使用`foo a bar b c d`参数，我们可以得到以下输出:

```sh
 empty
 not a, b, c
 a
 not a, b, c
 b
 c
 d

```



# 不要理会魔术师转移你的注意力

循环对于以迭代的方式处理数据序列非常有用，但是有时候，当你做所有的工作时，你会得到很多不相关的输出。进入我们的小魔术师:输出重定向算子，`*>*`。该操作符将输出定向到指定的文件或文件描述符。我们已经讨论过文件描述符，它们是操作系统用来标识已经打开的文件句柄的整数，默认情况下每个进程有三个打开的句柄:`stdin`、`stdout`和`stderr`。由`fd#`表示的默认文件描述符是`fd0`标准输入、`fd1`标准输出和`fd2`标准错误。默认情况下，`*>*`操作符重定向`stdout`，相当于`1>`，除非它前面有一个整数文件描述符。在我们迷失在我们所指的内容之前，让我们看一些输出重定向的例子:

```sh
ls /
ls / >/dev/null
ls /foobar 2>/dev/null
ls / /foobar >stdout_and_stderr.log 2>&1
ls / /foobar >stdout.log 2>stderr.log
ls / /foobar 2>&1 >/dev/null
```

普通信息被发送到标准输出，并在终端窗口中显示为文本。这就是`ls /`如何向您的终端显示根文件系统的内容。在第二次调用中，我们使用`>`来指示`stdout`应该被重定向到`/dev/null`，这将丢弃输出。第三个向`dev/null`发送错误消息，因此它们不会呈现到终端。第四个例子将`stdout`重定向到一个名为`stdout_and_stderr.log`的文件，然后用`&1`将`stderr`复制到与`stdout`相同的位置。第五个示例将`stdout`拆分为`stdout.log`并将`stderr`拆分为`stderr.log`。第六个例子不是将`stderr`重定向到`/dev/null`，而是将`stderr`重定向到`stdout`在赋值时指向的地方——终端，然后`stdout`被重定向到`/dev/null`。这表明操作符的顺序很重要，应注意确保赋值按定义顺序进行。最后要指出的一点是，因为`stdout`是一个文件描述符，而不是终端，所以可以将其他输出定向到终端，并将`stdout`定向到另一个不会导致终端输出的文件描述符。

有三个不常用的重定向操作符:`<`用于输入重定向，`>>`用于输出追加重定向，`<<`用于`HEREDOC`。输入重定向用于将数据输入管道，如下所示:

```sh
cat <stdout.log | grep lines

```

这会将`stdout.log`读入到`cat`命令的标准输入中，该命令会将其输出写入管道操作员。输入重定向实际上没有更多的内容，因为管道隐式地将前一个命令的`stdout`设置为下一个命令的标准输入。我们还提到了追加操作符`>>`，有必要指出的是`>`重定向操作符在写入之前将文件截断为零内容。如果需要在两次运行之间保存数据，就不需要这种行为。为了澄清，这截断了`keys.log`中的数据:

```sh
grep keyword > keys.log
```

另一个选项是追加以下内容:

```sh
grep keyword >> keys.log
```

最后，`heredoc`操作符，`<<`，它用一个预定义的文本流书代替标准输入，该文本流书以一个跟在`<< KEYWORD`后面的关键字结尾。例如，以下示例可用于截断一个`options.conf`文件，并将三个选项值写入该文件:

```sh
cat <<EOF >options.conf
option=true
option2=false
option3=cat
EOF
```



# 正则表达式和 grep

你要反复面对的一个关键任务是匹配特定的文本模式。匹配可能很简单，只需在文本正文中找到特定字符串的一个实例，也可能复杂得多。匹配文本的一个很好的工具是正则表达式语言。正则表达式是表达特定类型的字符串匹配模式的抽象方式。

与普遍的看法相反，正则表达式不能匹配您可能想要匹配的所有内容。它们仅限于某些类型的匹配，根据正则表达式实现的特殊风格，它们的能力可能会多一点或少一点。作为一项学术实践，人们可能会试图准确描述你能匹配什么，不能匹配什么。这是一个非常有趣的尝试，切入了理论计算机科学的核心。但我们不会在这里这样做:我们在这里做实际的事情！

首先，您需要找到一种方法来测试您的正则表达式。网上有几个工具可以让你交互式地测试你的匹配。本节末尾列出了几个好的例子。当然，这是一个命令行手册，您可以通过将测试文本放入一个文件并使用`grep`来自己测试匹配。Grep 是一个程序，它接受一个正则表达式，并在输入流中发出与该正则表达式匹配的行(默认情况下，它会在该行的任何子字符串与正则表达式匹配的地方发出行)。



# 精确匹配

正则表达式本身就是一个字符串。有几个字符是保留的，也就是说，当它们出现在字符串中时，它们有特殊的含义。`regex`中的任何非保留字符必须完全匹配，按照它出现的顺序。值得注意的是，一个仅仅是普通字符的`regex`必须与整个字符串完全匹配。

你可以用一个`regex`做多件事。有时，您可能需要匹配整个目标字符串。其他时候，您可能希望查找目标字符串的子字符串是否匹配以及匹配的位置。

以下是`regex`模式匹配的表格:

| **正则表达式** | **字符串** | **火柴？** | **匹配子串？** |
| 字母表 | 字母表 | 是 | 是 |
| 字母表 | 加快收寄投递系统 | 不 | 是(abcd) |
| 字母表 | 极好的 | 不 | 不 |

让我们在测试数据集的评论标题中寻找与`aardvark`字符串的精确匹配:

```sh
 zcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | cut -f13 | grep aardvark 
```

红色突出显示的内容是匹配的内容:

![](assets/23b0669d-2c44-4eab-93c6-9d9d9315f664.png)



# 字符集

在一个精确的字符串之后，您可能希望匹配一对字符中的一个，而不是一个精确的字符。为此，我们使用`characters []`括号将我们可能想要匹配的字符列表括起来。我们只能匹配括号内的一个可能的字符。

以下是`regex`模式匹配的表格:

| **正则表达式** | **字符串** | **火柴？** | **匹配子串？** |
| `ab[cd]` | `abc` | 是 | 是 |
| `ab[cd]` | `abcd` | 不 | 是(abcd) |
| `ab[cd]` | `abe` | 不 | 不 |

让我们看看在我们的审查数据中是否有大写的`aardvark`的例子:

```sh
zcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | cut -f13 | grep [Aa]ardvark
```

红色突出显示的内容是匹配的内容:

![](assets/c901a393-5b7d-40c3-b4d0-fe629d6545c9.png)



# 在 I(或其他任何东西)上画点

点字符`.`是一个单字符通配符。它可以搭配任何东西。还有一些受限的通配符只匹配特定类型的字符:`\d`匹配一个数字，`\w`匹配任何字母数字字符或下划线，`\s`匹配空格。

以下是`regex`模式匹配的表格:

| **正则表达式** | **字符串** | **火柴？** | **匹配子串？** |
| `\s..ick` | 诀窍是 | 是 | 是 |
| `...` | `abcd` | 不 | 是(abcd) |
| `abc\ddef` | `abc_def` | 不 | 不 |

我们可以使用一个点来完成对大写字母 A(或任何开始我们的`ardvark`字符串的东西)的最后一次搜索:

```sh
zcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | cut -f13 | grep .ardvark
```

红色突出显示的内容是匹配的内容:

![](assets/d292d85e-ddff-49c1-a060-c797d3556100.png)



# 捕获组

我们可以用括号把几组字符分开。虽然这些组本身并不十分有用，但是它们可以与其他操作符结合起来做非常有用的事情。我们称这些组为捕获组，因为`regex`引擎捕获组内匹配的内容。稍后，您可以使用捕获的内容来匹配其他内容。

在后面的`awk`部分，我们将展示一些使用捕获组的例子。



# 非此即彼，非此即彼

竖线字符`|`，让我们匹配某样东西。我们可以通过使用捕获组来描绘这对开始的位置。调用以下内容:

```sh
zcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | cut -f13 | grep -E '(aardvark|giraffe)'
```

红色突出显示的内容是匹配的内容:

![](assets/6480d26b-d9f3-4f7e-addb-5041be827137.png)



# 重复

有三个常用的操作符让我们匹配重复。它们是问号、`?`、加号、`+`和星号、`*`。

问号`?`与它所应用的事物(角色、集合或群组)的`0`或`1`实例完全匹配。调用以下内容:

```sh
zcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | cut -f13 | grep -E '(a)?ardvark' 
```

红色突出显示的内容是匹配的内容:

![](assets/4a31491c-6988-4137-b270-b5205d76d60e.png)

加号运算符`+`匹配一个或多个事物，星号运算符`*`匹配`0`或多个事物。调用以下内容:

```sh
zcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | cut -f13 | grep -E 'aaaaaaa(a)*' | head -n 3
```

它产生以下输出:

![](assets/df2cda4b-b1c1-4a2a-8a76-b78999c0c692.png)



# 其他操作员

你可以用`regex`匹配很多东西，`regex`的每个实现都有点不一样。我建议查看这些资源，了解每种`regex`的完整治疗方法，以及您可以利用它们做些什么:

*   一个伟大的，全面的网站，有许多例子:[https://www.regular-expressions.info/](https://www.regular-expressions.info/)
*   一个测试和调试不同类型`regex`:[https://regex101.com/](https://regex101.com/)的站点
*   另一个`regex`考点:[https://www.regexpal.com/](https://www.regexpal.com/)
*   其他人创建的`regex`实例库:[http://www.regexlib.com](http://www.regexlib.com)



# 把所有的放在一起

概括一下，我们有以下操作员:

| **操作员** | **使用** |
| `Brackets []` | 要匹配的指定字符集 |
| `Capture Group ()` | 对字符进行分组，并提取后来匹配的内容 |
| 或者`&#124;` | 符合两件事中的一件 |
| `?` | 匹配零次或一次 |
| `+` | 匹配一次或多次 |
| `*` | 匹配零次或多次 |



# awk、sed 和 tr

在本节中，我们将了解`awk`、`sed`和`tr`。



# awk

`awk`(包括`gnu`实现，`gawk`)是为流文本处理、数据提取和报告而设计的。一个`awk`程序的结构是一组匹配的模式，以及当这些模式匹配时要采取的行动:

```sh
pattern {action}
pattern {action}
pattern {action}
…
```

对于每一条记录(通常是传递给`awk`的每一行文本)，测试每一个模式，看记录是否匹配，如果匹配，就采取行动。此外，每个记录被一个分隔符(缺省情况下是任何空格)自动分割成一个字段列表。如果没有给定，默认操作是打印记录。默认模式是匹配所有内容。有两种特殊的模式，`BEGIN`和`END`，它们分别只在处理任何记录之前或之后进行匹配。

非常擅长对输入流进行某种数学运算，这一点我们将在本书后面讨论。对于字符串，`awk`非常擅长在复杂条件下过滤输入流，对输入数据进行转换，以及这些事情的组合。

对复杂条件进行过滤就像提供过滤条件作为模式和默认动作一样简单(也就是说，什么也不做)。默认情况下，`awk`将打印出整行。例如，我们可能希望通过匹配正则表达式来模拟 grep:

```sh
zcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | cut -f13 | awk '/aardvark/'
```

前面的代码产生了这样的结果:

![](assets/ebf9e265-3ffd-4e1d-aba3-bcd60ea6c6e7.png)

这里，正斜杠表示里面的字符串是一个`regex`。我们甚至可以在这里去掉`cut`，因为`awk`本身可以寻找标签字段分隔符。如果我们这样做，我们需要告诉`awk`我们正在寻找适当字段的子字符串。特殊变量`$1`、`$2`等代表每条记录的字段。`$0`是整个记录。调用以下内容:

```sh
zcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | awk -F"\t" '$13 ~ /aardvark/'
```

前面的代码产生了这样的结果:

![](assets/0be2ce9f-7e36-44b3-867a-a8707bba9734.png)

我们在这里打印了整个记录，因为我们没有提前剪切它，我们告诉`awk`使用默认设置，即打印整个记录。当我们在评论描述中匹配`aardvark`时，也许我们想打印出标题，字段`6`。我们必须向过滤器添加一个非默认操作:

```sh
> zcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | awk -F"\t" '$13 ~ /aardvark/ {print $6}'
```

前面的代码生成以下输出:

![](assets/64f4b185-df59-4540-bebc-9e24b7817197.png)

我们还可以挑选出我们想要的字段，重新排序，并用我们在`BEGIN`模式中定义的不同字段分隔符打印出来:

```sh
> zcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | awk -F"\t" 'BEGIN {OFS=";"} ; $13 ~ /aardvark/ {print $6, $2, $3}'
```

在终端中，前面的代码如下所示:

![](assets/dd9317e4-7700-4761-9633-b0b38182733b.png)

更多关于`awk`的信息可以在[https://www.gnu.org/software/gawk/manual/gawk.html](https://www.gnu.org/software/gawk/manual/gawk.html)找到。



# 一项 Linux 指令

`sed`是用于逐行流编辑的`awk`的替代。`sed`最常见的用途之一是方便`regex`的更换。例如，我们可以在评论描述中找到包含`aardvark`的字符串，并用`giraffe`替换它们:

```sh
zcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | cut -f13 | awk '/aardvark/' | sed 's/aardvark/giraffe/g' 
```

前面的代码应该输出以下内容:

![](assets/567245f3-acb2-4465-be62-ceb3e62cd023.png)

`sed`也可以删除匹配某个图案的线条:

```sh
zcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | cut -f13 | awk '/aardvark/' | sed '/ant/d'
```

上述代码会产生以下输出:

![](assets/b3975028-dff4-4139-81e5-bb8425379ce7.png)

除了更复杂的流处理之外，Sed 还有将近 30 个命令。

有关 sed 的更多信息，请访问 https://www.gnu.org/software/sed/manual/sed.html。



# tr

`tr`命令比`awk`或`sed`稍微简单一些，但有时它正是我们所需要的:`tr`翻译或删除流中的字符。

假设我们真的很讨厌字母`a`，我们想把它们都换成`b`。有了`tr`，这就简单了:

```sh
zcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | cut -f13 | awk '/aardvark/' | tr 'a' 'b' 
```

上述代码会产生以下输出:

![](assets/825ec6c8-1621-4d4a-ac2f-33f2484ad312.png)



# 排序和唯一

在`awk`、`sed`、`tr`、`sort`、`uniq`之后，一切将变得轻而易举。



# 分类

`sort`，嗯，对一串字符串(或者数字)进行排序。它不会删除重复项，而是保留它们。默认情况下，`sort`按字母顺序排列。

我们可以从示例数据的几行(使用 head)中通过管道传输一列数据(使用`cut`)来查看`sort`的运行情况:

```sh
zcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | head -n 10 | cut -f13 | sort
```

上述代码会产生以下输出:

![](assets/2f690674-0a78-4f50-84ab-1212b346b303.png)

如果你传递给`sort`一个`-n`标志，它会以数字形式`sort`代替:

```sh
zcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | head -n 10 | tail -n +2 | cut -f13,8 | sort -n
```

上述代码会产生以下输出:

![](assets/43d738f9-6aa3-461a-8045-84dedd6a3871.png)

有时，您可能希望只对部分数据进行排序。这样，您可以开始像对待数据库一样对待这些数据流。您可以使用`-k`选项按列对数据进行排序，如果您的数据不是由制表符分隔的，还可以使用`-t`选项。例如，我们可以利用这一点来查找投票最有帮助的评论:

```sh
zcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | head -n 50000 | tail -n +2 | sort -t$'\t' -k9n,9  | tail -n 1
```

前面的代码产生大量输出:

![](assets/9673d4fc-1004-47d1-95fc-e623312d4002.png)

这里，我们通过`-k9n`、`9`选项从列`9`到列`9`(只有一列)进行排序，并通过`n`进行数字排序。

您也可以对多列进行排序。假设我们想先按列`9`降序排序，然后按列`10`升序排序:

```sh
zcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | head -n 50000 | tail -n +2 | sort -t$'\t' -k9nr,9 -k10n,10  | tail -n 1
```

上述代码产生以下输出:

![](assets/91fb911a-2eca-48e5-b168-92f0ee848968.png)

在本例中，我们发现有用票数最少但总票数最多的评论是平局。



# uniq

是一个有趣的小程序，通常只是删除数据流中相邻的相同行。我们将它与`sort`放在一起，因为通常情况下，您会看到它与从`sort`传输来的数据一起使用，以计算数据流中的唯一值:

```sh
zcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | head -n 50000 | tail -n +2 | cut -f8 | sort | uniq
```

它产生以下计数序列:

![](assets/076eac1e-ac25-49aa-ae3e-8ee71e2f8056.png)

我们可以看到唯一可能的星级是`1`到`5`。

`uniq`还有一些其他用途，但这是目前为止`uniq`的主要用途。



# 摘要

在这一章中，我们讨论了 bash 控制结构的广度，并深入研究了输入/输出重定向。可以利用这些特性来增强您的命令行功能，并启用循环处理数据的小脚本，而不必求助于成熟的编程语言来进行一些简单的数据处理。

我们还研究了很多分割字符和字符串的方法。虽然单独使用字符串操作可能涵盖了许多用例，但我们通常希望更深入地研究这些流所表示的数据，以提取有用的信息。

在下一章中，我们将通过使用命令行和作为数据库的数据流来实现这一点。