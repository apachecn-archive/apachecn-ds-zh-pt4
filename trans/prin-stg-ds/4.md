  

# *第四章*

# 数据驱动的组织

## 简介

前两章描述了在组织中实现数据科学时要考虑的一些技术方面。然而，仅仅关注分析数据的技术细节还不足以为组织创造价值。数据科学经理需要管理人员、系统和流程，以发展数据驱动的组织。

决策者有时甚至会忽略最有用和最美观的可视化效果，即使分析是合理的。如*第 2 章“良好的数据科学*中所述，使用最佳实践的数据科学只是创建价值驱动型组织的起点。确保管理者使用结果的一个关键方面是培养一种数据驱动的文化，这需要管理人。

为了使数据科学蓬勃发展，组织需要有一套完善的 IT 系统来存储和分析数据并呈现结果。有各种各样的数据科学工具可用，每种工具在分析价值链中扮演不同的角色。

每个数据科学项目都从问题定义开始，问题定义被转化为数据和代码来定义解决方案。这个问题被注入数据漩涡，直到找到解决方案。数据科学的过程讨论了创建数据产品的工作流程。

这最后一章讨论了成为数据驱动型组织的三个方面。为了战略性地实现数据科学，需要协调人员、系统和流程，以优化可从可用信息中提取的价值。接下来的三个部分将讨论数据科学的这些方面。这本书以一些关于数据科学的理论和伦理限制的讨论结束。

## 人

当讨论与数据驱动的组织相关的人员时，我们不应该只提到创建数据产品的专家。数据科学团队的成员具备图 1.3 中*康威图所示的能力。他们还需要能够向同事或客户传达他们的工作成果，并说服他们实现这些发现。*

数据科学不仅仅发生在专业团队中。每个数据项目都有一个内部或外部客户，他们有一个问题需要解决。数据科学团队和他们产品的用户一起工作来改善组织。这意味着数据科学家需要了解组织行为和变革管理的基本原则，并成为一名优秀的沟通者。反过来，数据科学的接受者需要有足够的数据素养来理解如何解释和使用结果。

### 数据科学团队

当代民间传说把数据科学家描绘成一个有点社交笨拙的天才。电影中的极客将能量饮料和垃圾食品转换成计算机代码，只需敲几下键盘就能解决一个复杂的问题。虽然大部分数据科学依赖于高技能个人的才能，但从数据中创造价值的战略方法更多的是团队合作，而不是一个天才的领域。理想的数据科学团队结合了完成任务所需的所有技能和专业知识。

康威图将数据科学团队的技术技能可视化。为了能够将结果嵌入到组织中，除了技术能力之外，数据科学家还需要人际技能。这些软技能不是康威图表的一部分，因为它们在所有职业中都很常见。他们的缺席并不意味着他们不那么重要。*数据科学文化*讨论数据驱动的文化方面。

事实上，数据科学家需要在编写代码方面具有成熟的能力，但这并不意味着数据科学职能部门自然会成为信息技术(it)团队的一部分。编写代码传统上被视为 IT 专业人员的一项能力。这个群体之外的任何人，如果想最大限度地发挥他们所获得的硬件和软件的能力，通常会被贴上“影子 IT”的标签。

咨询公司 Gartner 定期发布关于他们如何看待计算未来的预测。几年前，他们认为很大一部分 IT 支出将发生在传统的职责范围之外。*高德纳。(2011).Gartner 公布了 2012 年及以后 IT 组织和用户的主要预测(新闻稿)*。随着大多数职能变得越来越依赖数字技术，传统的 IT 技能分布在整个组织中。从数据科学的角度来看，只有 IT 专业人员编写代码的想法确实是不正确的，因为开发电子表格与开发软件没有太大区别。

将所有 IT 管理集中在一个团队中就像让人力资源(HR)经理进行所有绩效评估或负责招聘公司的所有人员。就像人力资源一样，信息技术技能需要分散，以最大化我们可以从现有基础设施中提取的价值。

数据科学行业正在疯狂地寻找所谓的独角兽，即在康威图表中拥有所有三种技能的人。实现这一理想的最有效方法是教现有的主题专家编写代码。这种方法培养了具有领域知识的数据科学家，并提高了数据素养。拥抱影子 IT 精神并在组织中分配编码技能是发展数据驱动组织的一部分。

数据科学在组织中有两种定位。团队可以嵌入到产品或服务组中，也可以是服务于组织所有部分的专门团队。较小的组织最有可能有一个专门的团队为组织服务。集中式数据科学团队的一个缺点是，它在运营经理和数据专家之间制造了距离，这使得结果的实现变得复杂。大型组织的工作负载足以证明需要一个以上的数据科学知识中心。运营团队所具备的数据科学能力使他们置身于行动之中，从而能够快速响应运营需求。这种方法的缺点是专业知识在整个组织中是分散的( *Caffo，Peng，& Leek (2018)* )。

### 数据科学消费者

创建数据驱动型组织的主要障碍是，并非每个人都完全理解复杂分析的结果。数据科学家负责生成美学报告和可视化，以确保用户掌握最终产品。当专业人员无法理解分析时，结果将被忽略，他们将恢复对问题的直觉理解。

统计数据往往是反直觉的，一些人对数据科学家的数学魔法缺乏信任。马克·吐温推广了“谎言、该死的谎言和统计数字”这句话。统计数据的复杂性使其成为一种理想的宣传工具，如今我们称之为假新闻。当接收者的数据素养较低时，用统计数据撒谎是很容易的。赫夫博士(1985)。如何用统计撒谎(转载)。哈蒙兹沃斯:企鹅图书。

不幸的是，物理和社会世界本质上是随机的。除了这种不确定性，所有的测量都会引入一定程度的随机误差。因此，统计是理解现实的最有效的方法。我们永远无法用任意的数学精度来理解世界，只能依靠统计描述。我们所能拥有的关于世界的最完美的知识是统计学。当统计学被恰当地应用时，马克·吐温的那句话应该反过来说:“真理、绝对真理和统计学”。

这一事实对数据科学成果的消费者提出了要求。数据素养是一种天生的数学技能，但不幸的是，许多人在成长过程中害怕所有科学中最美好的东西。这并不意味着所有员工都需要学习数学课程。数据科学家需要创造美学产品，这些产品只需要对世界的常识性理解。不幸的是，这仅适用于最简单的业务问题。

如果我们不在自然智能上投资，走向人工智能是徒劳的。实现数据科学战略需要在专业发展方面进行投资，以提高数据素养。为了让复杂的数据科学发挥价值，整个组织都需要具备适当级别的数据素养。

数据素养是识别、定位、解释和评估定量和定性信息并交流结果的能力。数据素养的范围涵盖了在*流程部分*中描述的整个数据科学工作流。数据素养课程由几个能力领域组成。

员工需要能够获取信息，并了解数据是如何管理的。从事分析的员工需要精通研究技能，知道如何处理数据。数据素养的第三个方面是解释统计数据的技能。可视化信息和向决策者提供证据是最后两项数据能力(*澳大利亚公共服务委员会)。(2018).数据素养技能。检索于 2019 年 3 月 2 日，发自*——【https://www.apsc.gov.au/data-literacy-skills】。

员工需要具备数据能力的程度取决于他们在组织中的职位。我们期望技术专业人员比管理人员具有更高水平的数据素养。

依靠电子工具来查询数据意味着数据素养与数字素养齐头并进。用户需要精通计算机，能够自信地使用各种工具。当代商业智能工具已经简化了提取和建模多组数据所需的技能水平。然而，将数字技能与数据技能隔离会导致问题，因为用户会因错误的方法或缺乏验证而得出错误的结论，正如在 *Conway 的危险地带*中所讨论的。

数据科学消费者不仅是数据科学家的同事或顾问的客户，他们还是组织的产品和服务的消费者。企业和政府机构喜欢发布统计数据，向他们的客户或社区展示他们有多棒。传达准确的统计数据是培养组织与其利益相关者之间信任的有效方式。然而，这种方法只有在目标人群有足够的数据素养来理解信息时才有效。大多数数据通信是由高智商的专业人士产生的，他们发现很难理解他们教育程度较低的同胞的局限性。

欧盟发布了公民数字能力框架。这份文件认识到数字扫盲对最大限度地参与社会的重要性。本文档将信息素养、沟通和协作能力、创建数字内容的能力、数字安全和解决问题作为其五个能力领域进行了讨论。( *Carretero，s .、Vuorikari，r .、Punie，y .、欧盟委员会、&联合研究中心。(2017).DigComp 2.1 面向公民的数字能力框架，包含八个熟练水平和使用示例*。

弥合数据科学及其消费者之间的数据素养差距需要朝两个方向努力。首先，分析师需要善于沟通，并以令人信服且直截了当的语言传达他们的信息，如*第 2 章，良好数据科学*中所讨论的。其次，数据科学的消费者需要接受足够的教育，以帮助他们在复杂的统计世界中导航。

### 数据科学文化

数据革命让一些组织意识到他们数据丰富，但信息贫乏。这些组织中的管理人员意识到，他们持有大量只使用一次的数据。数据科学的流行在很大程度上是由使用这些黑暗数据并变得更加数据驱动的愿望所推动的。

实现数据科学战略最复杂的方面是将我们的分析结果与日常业务活动相结合。在数据驱动型组织中，使用信息解决问题是其文化的一部分。从表面上看，这可以通过更新现有的操作程序以包括分析数据来实现，但这种转变也有很强的人为因素。

数百个已发表的文化定义说明了组织文化概念的复杂性。造成这种混乱的主要原因是，文化常常被定义为抽象的术语，没有实证的方法来研究它们。讨论文化最务实、最有成效的方式是审视其现象，而不是试图定义其本质。现象学的方法调查一种文化的可见方面，以了解一些不可见的方面。

*图 4.1* 中的图像使用了众所周知的冰山类比，列出了组织文化的一些可见和不可见的现象。该模型有助于解释数据科学文化在实践中意味着什么，以及如何识别或创建它。(*麦克沙恩，s .，&特拉瓦里奥尼，T. (2005 年)。环太平洋地区的组织行为。).北莱德新南威尔士州:麦格劳-希尔*。

![Figure 4.1: Phenomena of Organizational Culture.](Images/B15100_04_01.jpg)

###### 图 4.1:组织文化现象。

在我们对一个组织的数据文化发表任何有意义的看法之前，我们需要理解人工制品。人工制品是可以观察、研究和/或测量的文化的可见表达。关注文化的有形方面也使改变它们变得更容易，因为我们可以修改我们可以衡量的东西。

一个组织的物理结构是最具体的人工制品。办公室是表达组织文化的物理结构。办公室是一个格子迷宫，还是提供一个开放和协作的团队工作空间？办公室也是一个通过艺术作品和海报传播信息的地方。数据驱动的组织在墙上或内联网上显示可视化和其他分析结果，以告知员工令人兴奋的信息。

一个组织就像一个部落，有自己特定的仪式和典礼。“仪式”这个词经常被保留给一种无意义的、重复的活动。仪式和典礼不仅仅是无用的活动，它们是人类社会生活的重要组成部分。此外，在宗教领域之外，仪式是给社会生活添加结构的不可或缺的工具。新员工入职是一个将求职者转变为雇员的初始仪式。这个仪式向新手提供了一个关于他们新工作场所文化的强烈信号。数据驱动的组织向新员工介绍相关的数据结构和流程，以便获取和分析这些信息。

组织内部的故事和传说是非正式会议期间办公室里流传的不成文的故事。这些故事被一代又一代的员工传承和修改。如果一个组织是数据驱动的，那么这些故事中至少有一些会包括关于数据的故事，以及如何使用数据做一些有价值的事情。在数据驱动的组织中，员工不仅通过正式报告与数据交流，而且还在非正式场合引用数据。

文化的最后一个人工制品是一个组织的语言。报告、备忘录、电子邮件等中表达的员工语言是数据影响决策程度的有力指标。商业报告、投资建议和任何其他正式文件都应该以数据为基础。

要评估一个组织受数据驱动的程度，你应该成为一名兼职人类学家，利用参与观察来评估这四种文化人工制品。这些人工制品包含的对数据的引用越多，组织就越受数据驱动。

组织文化的信念、价值观和假设比可见的人工制品更难衡量或观察。心理测量调查可以提供一些见解，但在企业环境中，这些往往衡量政治上正确的观点，而不是员工的实际态度。员工通常会用他们认为应该是这样的话来回应，而不是用事实是怎样的话来回应。

组织文化的无形方面和有形的人工制品有着双向的因果关系。文化中的无形元素影响着我们的行为和交流方式，因此艺术品是文化的产物。这个机制也反过来起作用，因为人工制品改变了我们的信仰、价值观和态度。

当听到经理们说出“文化变革”这个词时，全球员工的集体意识都会不寒而栗。大多数文化变革项目之所以失败，是因为管理者本身没有展示出他们渴望的价值观。将企业文化转变为一位经理在一篇鼓舞人心的文章中读到的某种理想，在最好的情况下也注定会失败。

改变一个组织中员工的价值观和信仰是极其困难的，并且经常会导致抵制。在大多数情况下，让员工参加发展会议来发展人为的价值观是没有多大成效的。改变一个组织文化最简单的方法就是改善可见的标志。文化的无形方面将缓慢但肯定地改变它们自己，以适应嵌入在人工制品中的信息。物理结构改变了员工之间的互动方式。随着更多新员工的招聘，接受新入职培训的员工比例会越来越高。组织的正式和非正式语言中包含的数据引用越多，它就越会成为其文化的一部分。

数据驱动的经理可以通过修改组织文化的人工制品，并向它们注入报告和可视化来改变组织。人工制品越是引用数据和分析，信念、价值观和假设就越是由数据驱动。

## 系统

就像任何其他职业一样，数据科学家需要一套合适的工具来从数据中创造价值。市场上有大量的数据科学解决方案，其中许多是开源软件。数据科学工作流的每个方面都有专门的工具。

没有必要讨论现有的众多软件包。许多优秀的网站评论各种产品。本节提供了一些关于使用电子表格与编写代码和商业智能平台的想法。

电子表格是分析数据的通用工具，数据已经扩散到业务的几乎每个方面。然而，这种通用工具不太适合从事复杂的数据科学。电子表格的一个明显优势是，它们将数据、代码和输出包含在一个方便的文件中。这种便利是有代价的，因为它降低了分析的可靠性。任何曾经不喜欢对电子表格进行逆向工程的人都会理解电子表格的局限性。在电子表格中，哪个单元格是另一个单元格的结果，哪个是原始数据，这一点并不清楚。许多组织使用电子表格作为公司数据的单一来源，如果需要共享信息，应该避免使用电子表格。数据科学的最佳实践是分离数据、代码和输出。

如前所述，培育数据科学独角兽的最佳方式是教主题专家编写分析代码。写 R 或者 Python 之类的代码，就像写一个如何分析数据的使用说明书。任何懂这种语言的人都能知道你是如何得出结论的。现代数据科学语言可以生成打印质量的可视化效果，并可以以多种格式输出结果，包括电子表格或独立应用程序。

数据科学编码的黄金标准是有文化的编程。这种技术将代码与散文结合起来，使算法能够被完全理解。所有计算语言都包括添加注释的能力。文化编程是这种技术的进一步发展。文化编程的结果通常是一份报告或一套演示幻灯片。

每种语言都有自己的方法将文本和代码结合起来。RMarkdown 、 **Jupyter 笔记本**和 **Org Mode** 是进行文字编程的流行系统。一旦代码编写完成，只需按一下按钮，计算机就会生成一份包含最新统计数据和图形的新报告。根据读者的专业知识，您可以选择在结果中包含或排除代码。

最后，商业智能工具对于传播数据科学项目的结果很有用，但是对于进行详细的分析却不是很有用。像 **Power BI** 这样的平台是一个很好的可视化分析结果的系统，因为它提供了非常灵活的方式来分割数据和可视化结果。该平台的分析能力不是很高，但可以通过在 Python 或 R 中插入代码来补充其能力。

## 流程

*第 2 章，良好的数据科学，*提到了数据科学中的治理要求，以确保项目的结果是合理的。从数据中创造价值的过程遵循一个从原始数据到完成项目的迭代工作流程。(*威克姆 h .&格罗勒蒙德 G. (2016)。数据科学:导入、整理、转换、可视化和建模数据。在*——【https://r4ds.had.co.nz/】有售。工作流程从定义一个需要解决的问题开始，如图*图 4.2* 所示。下一步是加载数据并将其转换成适合所需分析的格式。数据科学工作流程包含一个由探索、建模和思考组成的循环，该循环将一直重复，直到问题得到解决或被证明无法解决。

![Figure 4.2: Data science workflow](Images/B15100_04_02.jpg)

###### 图 4.2:数据科学工作流程

数据项目的工作流程独立于所考虑的数据科学连续体的各个方面。同样的原则适用于所有类型的分析。对于较大的项目，建议采用正式的项目管理方法来控制时间、预算和质量。

以下部分描述了数据科学工作流三个阶段中每个阶段的一些显著方面，并展示了一个关于向董事会报告水质的案例研究。(*普雷沃斯，P. (2015)。可视化水质:饮用水系统性能的图形指数。在厄兹沃特。阿德莱德:澳大利亚水协会*。

### 定义

数据科学项目的第一步是定义问题。这第一步描述了正在考虑的问题和期望的未来状态。问题定义不应该具体提及可用的数据或可能的方法，而应该局限于手头的问题。一个组织可以寻求优化生产设施、降低能耗、监控效率、了解客户等等。一个简明的问题定义是必要的，以确保一个项目不偏离其最初的目的，或者当问题变得明显无法解决时，它被取消。

正如在*有用的数据科学部分*中所讨论的，数据科学项目的成果可以是可操作的情报，也可以是对业务流程的更好理解。

问题定义以对当前情况的描述开始，并清楚地确定哪个方面需要改进或更深刻的理解。问题陈述以对理想情况的总结结束。例如，一家自来水公司每月向董事会报告水质结果。这份报告包含了大量实验室测试结果的表格。董事会成员不是技术专家，不完全理解他们的意思。报告的另一部分显示了水质投诉，但没有指出它们与水质结果的关系。委员会已经要求以可视化方式报告水质性能，将可用数据整合到一个简洁的概览中。

项目的定义以解决问题的可能方法和实现解决方案所需的数据源的描述结束。假设所有需要的数据来源都可用，分析过程就可以开始了。

在案例研究中，分析师决定对供水系统的每个不同方面使用一个性能指数。水质指数是一个无量纲数，反映了与理想情况相比的性能水平。

### 准备

在进行任何分析之前，需要将可用的数据加载并转换成所需的格式。有影响力的数据科学家 Hadley Wickham 将这一过程称为整理数据(*Wickham and grole mund(2016)*)。有趣的是，项目的这个阶段可能会消耗高达 80%的工作，这取决于可用数据和所需数据之间的差异。

数据科学的最佳实践是记录项目中考虑的每个数据集。数据手册记录从源中提取的每个字段，以确保理解创建数据的上下文。

![Figure 4.3: Data science case study: available data](Images/B15100_04_03.jpg)

###### 图 4.3:数据科学案例研究:可用数据

对于自来水公司案例研究，有几个数据源可用，如下表所示。数据科学家需要决定这些来源中的哪一个能够解决问题。在本例中，来自集水区的数据仅在纸上可用，这使得难以通过算法对其进行分析。将这一来源转换为电子数据需要一个单独的项目。其他数据来源可以通过电子方式获得，并可用于该项目。

### 明白

一旦数据以整齐的格式可用，理解数据的过程就可以开始了。分析阶段包括三个阶段的循环，即数据漩涡，这个循环会一直重复，直到达到所需的结果，或者有证据表明无法达到目标。这三个阶段是探索、建模和反思。

*   **探索**:开始分析数据的最好方法是探索数据，了解它与现实的关系。生成描述性统计数据，如平均值、范围和相关性，可以快速洞察数据。然而，仅仅依靠数值分析可能具有欺骗性，因为非常不同的数据集可能会产生相同的值。来自 AutoDesk 的贾斯汀·马特伊卡和乔治·菲兹莫里斯展示了完全不同的数据集如何拥有几乎相同的汇总统计数据。这六个可视化中的每一个都显示这些数据集有非常不同的模式。然而，当分析该数据而不将其可视化时， *x* 和 *y* 的平均值以及它们的相关性对于所有六个子集几乎是相同的。在他们的论文中，他们提出了一种算法，可以用相同的汇总值生成每种可能的模式，图中显示了其中的六种模式。( *Matejka，j .，& Fitzmaurice，G. (2017)。相同的统计，不同的图形:通过模拟退火生成具有不同外观和相同统计的数据集。在 2017 年 CHI 计算系统中人的因素会议论文集- CHI '17(第 1290-1294 页)。美国科罗拉多州丹佛市:美国计算机学会出版社*——[https://doi.org/10.1145/3025453.3025912](https://doi.org/10.1145/3025453.3025912)。

![](Images/B15100_04_04.jpg)

###### 图 4.4:具有非常相似的汇总统计数据的六种模式

使用可视化来探索数据的另一个原因是揭示**异常**，例如不自然的**尖峰**或**异常值**。物理测量值的突然增加和减少通常是由测量或数据传输问题引起的，而不是实际变化。需要去除这些尖峰，以确保分析的可靠性。社会数据中的异常，如调查，可能是为所有答案提供相同问题的主题，如前一章所讨论的。

检测异常值和异常值，并将其从数据集中移除，可以提高分析的可靠性。并非数据集中的所有异常都是可疑的，在删除数据之前应该小心。应记录删除任何异常数据的原因，以便分析保持可重现性。

案例研究中的探索性分析包括为所有相关数据生成时间序列图，以了解统计分布。最大值和最小值是什么？这些观察值的可变性有多大？这些以及其他基本统计数据提供了对所用数据形态的洞察。

*   **模型**:在分析师很好地掌握了所考虑的变量之后，实际的分析就可以开始了。建模包括将问题陈述转化为数学和代码，如*第 3 章，战略数据科学*所述。世界的每一个模型都受到其中所包含的假设的限制。统计学家乔治·博克斯因声明“所有现实模型都是错误的，但有些是有用的”而闻名。由于数据科学就是从我们的数据中获得有意义的见解，以做出经过计算的商业决策，因此我们只需要一个有用的模型。当对数据建模时，最初的研究问题总是需要被记住。没有特定目的地探索和分析数据会很快导致错误的结论。仅仅因为两个变量相关并不意味着存在逻辑关系。一个明确定义的问题陈述和方法可以防止数据挖掘。数据的可用性和提取这些信息的便利性使得任何人都可以很容易地找到不同信息来源之间的关系。在分析数据时，一个很好的通用规则是，当你可以很容易地证实你的假设时，不要相信你的方法。如果是这种情况，通过不同的方法使用三角测量有助于验证结果。本案例研究中的建模包括开发一个扣分系统。完美的水质几乎总是由参数的下限和上限来定义。完美的水没有颜色，有最低水平的氯，等等。这些信息构成了积分系统的基础。例如，当水有可测量的颜色时，指数会减少一定的点数。为模型中的每个参数设计了决策规则。
*   **Reflect** :在分析的结果可以交流之前，领域专家需要审查结果，以确保它们有意义，并且确实解决了定义中陈述的问题。反思阶段还应该包括客户，以确保问题陈述的解决令他们满意。可视化是一种通过揭示明显的模式来确定结果是否有意义的快速方法。另一个反映结果的强大技术是敏感性分析。这种技术包括改变一些假设来测试模型的预期响应。数学模型通常很复杂，变量之间的关系不清楚。敏感性分析通过对某些变量使用极值来帮助理解这些关系，然后观察对模型的影响。关于案例研究，建模需要对所选模型进行大量反思，并需要对数据漩涡进行多次迭代。制定绩效指数是一种平衡行为，以确保每个参数都有适当的权重。该索引的目的是为董事会提供重要信息，以便他们在会议期间提出有针对性的问题。反思阶段总是需要反思目的，并确保达到目的。

### 交流

数据科学项目的最后一个阶段，也可以说是最困难的阶段，是将结果传达给用户。在大多数情况下，数据产品的用户并不是对数据和数学有深刻理解的专家。数据科学家和他们产品的用户之间的技能差异需要仔细交流结果。

![Figure 4.5: Water System Index visualization](Images/B15100_04_05.jpg)

###### 图 4.5:水系指数可视化

详细的报告和可视化不仅需要提供对结果的准确描述，还需要能够说服读者。成功传达问题的解决方案的最关键的方面是确保结果的消费者理解它们并愿意使用它们来解决问题。正如在*定义*一节中所讨论的，数据科学是一个系统化的过程，也是一个涉及管理组织内部变化的文化过程。

本案例研究的结果是自来水公司服务区域内所有水处理厂的空间可视化。图表上的每个圆圈使用从红色到绿色的发散方案来可视化指数的结果。圆圈的大小与每个城镇的客户数量的对数成比例，以强调较大系统的重要性。为了实现再现性，点击圆圈为用户提供所有内部工作和原始数据，以便可以识别不执行的根本原因。

## 数据科学的局限性

当阅读网络和文献中的一些文章时，数据科学可以解决的问题似乎是无限的。然而，计算分析所能达到的目标在理论和实践上都有局限性。除了对我们能做什么的限制，对我们应该做什么也有道德上的限制。这最后一部分反映了数据科学的一些边界。

### 计算的极限

计算的局限性涉及到一些复杂而深刻的哲学问题，这些问题涉及到人类知识的局限性。这个问题的简短介绍着眼于测量物理和社会过程的限制，以及算法的局限性。

*   **Limitations of Measurement**: The first limitation relates to the fact that our collection of data will always be an incomplete description of reality. In a physical system, choose which points to measure, at which frequency, by which method, and so on. We need to make a lot of choices before we can access data. Even more so with social data, all our measurements are only indirect expressions of the reality we seek to explain.

    正如在*声音数据科学*一节中所讨论的，测量从来都不是它所描述的现实的完美副本。没有原始数据这种东西，因为所有的测量都使用对它所代表的现实的假设。数据的这些局限性限制了我们对未来的了解。所有预测都使用相同的原理来实现一个结果。过去数据中的模式被用来推断当前的情况和可能的未来。然而，由于我们的数据总是不完整的，这些模型将很快大幅产生。

    从空间角度来看，由于数据的内在差距，像天气这样的复杂系统将永远无法进行长期预测。动态系统高度依赖于初始条件。随着时间的推移，微小的测量误差将被放大，从而无法进行长期预测。社会系统甚至比动态的物理系统更复杂。尽管大数据在模拟人类行为方面相当成功，但它无法提供我们行为的广泛模型。亚马逊或许能够预测我最有可能购买哪个品牌的笔记本电脑，但他们对我主动提供给他们的信息无能为力。虽然原则上有可能测量所有的东西，但是这样做的简单成本却令人望而却步。现实的某些方面本质上很难衡量。一个看似简单的参数，比如病原体的存在，却需要付出很大的努力才能确定。即使我们成功地测量了大量的数据，处理这些信息的计算成本也需要与预期的收益合理地联系起来。

*   算法的局限性:解决问题的计算方法是一种强有力的方法，可以回答不久前我们甚至不敢问的问题。然而，有些特定的问题，即使是最聪明的算法也无法解决。一个内在难题的例子是旅行推销员。一个组织的销售人员需要走访许多城市。销售人员寻求最大限度地减少他们花在路上的时间，因此他们需要知道所有城镇之间最短的可能路线。虽然有一些算法可以解决这个问题，但是它们只能提供估计值。确定实际最短路径需要大量的计算时间。如果问题包含足够多的城市，找到解决方案所需的计算时间可能会比宇宙的年龄还要长。
*   **超越限制**:这些限制中的一些可能在未来被规避，但其中一些问题是没有解决方案的基本问题。信息不完整的问题永远不会完全解决，因为实际困难是不可克服的。在过去的五十年里，计算机的能力呈指数级增长，量子计算将是能力的下一次飞跃。然而，算法复杂性的问题将不会被想象中最快的量子计算机解决。本节列出的局限性是深刻的，就我们目前的观点来看，是不容置疑的。这些限制并没有阻止我们利用数据做更多的事情，而这些事情是大多数组织目前无法做到的。即使在用计算分析解决问题的约束下，我们仍然可以用算法完成许多事情。数据科学的局限性不仅延伸到数据科学能做什么，也延伸到它应该做什么。分析数据是人类固有的活动，这意味着它总是有一个伦理维度。数据科学的道德规范对我们收集什么信息、我们如何传播这些信息以及我们如何处理分析结果设置了限制。

### 伦理数据科学

技术赋予人类的能力远远超出了我们天生的能力。机器让我们变得更强大，但它们会对人和环境造成身体伤害。电脑让我们变得更聪明，但它们也会造成社会损害。伴随着这种强大的力量而来的是巨大的责任。Donald Knuth 是最初的计算机大师之一，也是计算机科学领域一位有影响力的学者。克努特在接受《纽约时报》( *Roberts，S. (2018))采访时，从伦理的角度质疑了数据科学的局限性。硅谷的尤达。纽约时报。2019 年 2 月 25 日检索自*——[https://www . nytimes . com/2018/12/17/science/Donald-knuth-computers-algorithms-programming . html](https://www.nytimes.com/2018/12/17/science/donald-knuth-computers-algorithms-programming.html)。

“我担心算法在世界上变得过于突出...一开始，计算机科学家担心没有人在听我们说话。现在我担心听的人太多了。”

Knuth 并不是唯一一个担心算法如何影响我们生活的人。尽管算法本身在伦理上总是中立的，但由此产生的行为确实会产生后果。在*有用的数据科学*部分，我们将数据科学定义为影响现实的工具。算法可以对世界产生真正的影响，这意味着它们是伦理的主体。

本节提供了一些道德准则，管理者可以在任何关于数据的特定使用是否符合道德的讨论中使用。*第 2 章*、*好的数据科学、*将好的数据科学定义为有用、合理、美观。也许我们需要在这个繁琐的问题上增加第四个方面，并坚持数据科学也需要符合伦理。

当代数据分析方法的力量可能导致不良后果，这意味着数据科学的结果具有道德含义。数据伦理是本书的最后一部分，因为它创建了所有活动发生的边界条件。本节讨论了数据的道德使用框架，以及从业者如何将道德原则应用到他们的工作中。

收集、存储和分析与人类相关的数据需要符合道德规范。这种说法几乎是一种同义反复，但最近数字公司背叛客户信任的大量例子表明，有必要反思这个问题。数字消费者的隐私被多次侵犯，一些算法可能会伤害消费者。数据科学的伦理超越了隐私，因为算法的结果会对我们的生活产生负面影响。算法可以加强歧视，减少自由市场中买家的权力。数学毁灭武器:大数据如何增加不平等并威胁民主。纽约:皇冠。

伦理是一个模糊的术语，尤其是对于那些更喜欢解释客观数字而不是处理主观道德推理的数据科学家来说。数据科学的伦理是数据科学本身无法解决的问题之一。没有算法可以帮助我们决定某件事是否道德。伦理问题最好通过沉思和辩论来解决。哲学家们已经为伦理推理提出了几个相互竞争的模型，但没有一个模型得到了接近普遍的接受。

伦理视角与法律视角密切相关，但它们不一定相同。从一个行为是合法的这一事实，你不能断定它也是道德的，反之亦然。技术变革的速度比立法变革快得多，这意味着需要对数据科学进行伦理反思。鉴于数据的法律框架因国家而异，甚至在国家内部的州与州之间也有所不同，本节仅讨论伦理数据科学的原则。

在传统的社会研究中，收集、储存和解释描述人们生活的信息的伦理已经得到了很好的发展。社会科学家发展了这些原则来回应不道德研究的负面经验。根据*布瑞曼和&贝尔(2011)的说法，适用于数据科学的三个关键伦理原则。商业研究中的伦理。商业研究方法(第三版。)牛津:牛津大学出版社*，具体如下:

*   **Informed Consent**: In social research, all subjects must consent to their data being collected and analyzed. When we ask people to complete surveys, subjects can choose which information they provide, or abstain from providing information about themselves. The principle of informed consent ensures that participants are neither deceived nor coerced into surrendering information about their personal lives.

    知情同意既适用于商业运作，也适用于学术研究。最近备受瞩目的脸书案例反驳了这一观点，并表明脸书社区希望所有政府、研究人员和企业在收集任何个人信息时都征得同意。知情同意依赖于三个条件。首先，需要告知信息收集的主体。第二，同意必须在没有不当影响的情况下自愿给予。最后，同意的人必须有同意的能力，这要求他们能够理解选择加入的后果。新闻中发表的许多道德违规都与违反知情同意的这三个条件有关。

*   **避免收集数据中的伤害**:在社会研究中，收集数据中的伤害包括对参与者的任何身体或心理后果，如他们的发展或自尊、诱发压力以及给职业前景或未来就业带来风险。隐私是关于这个原则的最重要的关注点。大多数国家都有完善的隐私立法来定义组织如何处理数据。保护隐私最常见的方法之一是匿名化数据。使数据匿名包括从个人识别信息中剥离数据，如姓名和地址。聚合数据是删除个人数据的方法之一。通过将数据聚合到组中，与个人的任何联系似乎都被消除了。然而，当这些聚集的数据集与其他数据集组合时，单个条目可以(原则上)被分解。在一个数据可用性和规模不断增长的时代，匿名变得几乎无法保证。保护隐私和从数据中获取社会利益之间存在矛盾。(*奥珀曼，I. (2017)。数据共享框架(技术白皮书)。悉尼:澳大利亚计算机学会*。
*   **Doing Justice**: Doing justice to participants implies that any analysis and interpretation of information about customers reflects their interests. Doing justice to the subjects of the analysis means algorithmic fairness. This concept expresses the risk of potential harm to people or the natural environment through the way the data is analyzed.

    算法公平存在于两个领域。机器学习算法使用过去的信息来预测可能的未来。因为过去的这个基础，任何机器学习算法都会放大训练数据内部存在的任何偏差。例如，在 LinkedIn 上搜索工程职位候选人的招聘算法很可能存在性别偏见，因为过去的社会偏好男性工程师。

    算法公平性的第二个方面与数据科学主体和使用算法的组织之间的权力不平衡有关。在线商店可以使用机器学习来为每个访问他们网站的访问者提供不同的价格。算法可以最大化客户为服务支付的金额。尽管完全合法，但这只是由于买卖双方力量的不平衡才成为可能。

    算法公平是业界和媒体讨论最多的话题。随着我们进入以前未知的领域，机器学习的新能力将要求社会重新思考其道德和法律框架。

*   **Don't Be Creepy:** These three principles provide a starting point for starting a discussion about ethical data science. Ethical principles, instead of values and fixed rules, are a useful tool to help clarify any potential ethical issues in a data science project.

    这三个原则可以总结成一个简单的原则:“不要让人毛骨悚然”。当你有一个数据科学提案，但不确定它的伦理地位时，也许你应该问几个朋友，他们对成为这项分析的对象有何感受。