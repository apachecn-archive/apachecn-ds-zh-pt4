        

# 十、用于数据应用的 Python

我们已经在本书的前几章中使用了数据，包括数据收集和一些统计计算。不过，所有这些案例中的样本都很小。为了在数百万条记录的数据集上运行数据分析和训练机器学习模型，研究人员建立了一个独特的 Python 包生态系统。

在这一介绍性章节中，我们不会编写太多代码，相反，我们将概述数据科学生态系统的基础包和工具，我们将在本书的这一部分中使用它们，包括以下内容:

*   面向数据科学的 Python 简介
*   探索数字
*   了解Pandas
*   尝试 SciPy 和 scikit-学习
*   了解 Jupyter

        

# 技术要求

本章的代码使用了两个包— `numpy`和`pandas`，这两个包都包含在默认的 Anaconda 发行版中。本章的笔记本在资源库的`Chapter10`文件夹中([https://github . com/packt publishing/Learn-Python-by-Building-Data-Science-Applications](https://github.com/PacktPublishing/Learn-Python-by-Building-Data-Science-Applications))。

        

# 面向数据科学的 Python 简介

数据分析的基本任务是概括多个(可能是许多)数据点的数据集的一些趋势和共享属性。想象一下在标准的 Python 发行版中会是什么样子:你会有一个列表，比如说，`Person`个对象，每个对象都有自己的值。要运行一些聚合统计数据，我们必须遍历每个对象，提取其属性，并计算统计数据。如果我们需要进行一些度量，代码会很快变得很大，难以维护。

相反，数据分析中的许多计算可以矢量化。在这里，矢量化是一个奇特的术语，表示相同的循环将在 C 中运行，而不是在 Python 中运行，这将速度提高了几个数量级。...

        

# 探索数字

NumPy 是一个围绕数字数组的概念构建的库，数字数组是多维的、基于索引的(类似于列表)数据集合，它(不像列表)保证存储值的类型保持一致和预定义，比如二维整数数组或一维浮点数组。它基于 C 代码，与基本 Python 相比，允许我们将计算速度提高几个数量级。即使在相对较小的数据集上，性能差距也是惊人的，对于大型数据集和复杂算法，性能差距会呈指数级增长。NumPy 能够处理几百万行数据，并且主要受操作内存而不是 CPU 的限制。

让我们用一个例子来说明这种惊人的性能差异。假设我们需要成对地总结三个值列表。在纯 Python 中，代码将类似于以下代码:

```jl
>>> A, B, C = [1,2,3,4,5]*1000, [2,3,4,5,6]*1000, [10,9,8,7,6]*1000

>>> %timeit result = [sum(row) for row in zip(A,B,C)]
635 µs ± 14.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
```

现在，让我们使用 NumPy 做同样的事情，如下所示:

1.  首先，我们使用`np.array`函数将所有三个列表转换成 NumPy 数组(它接受任何 iterable 作为输入)。代码如下:

```jl
import numpy as np

Anp = np.array(A)
Bnp = np.array(B)
Cnp = np.array(C)
```

2.  现在，我们总结一下:

```jl
>>> %timeit result2 = Anp + Bnp + Cnp
4.67 µs ± 22.4 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)

>>> 4.67 / 635
0.00735
```

它花费的时间不到普通 Python 的 1%!现在，想象一下在更复杂的操作中我们会得到什么，其中操作的数量随着数据点的数量呈指数增长！

在前面的例子中，我们执行了向量化的加法，在本例中，`+`符号表示矩阵求和。对于更复杂的操作，例如`if` 开关，我们必须使用 NumPy 内置的多个函数和方法，例如用于矢量化`if` / `else`操作的`numpy.where`函数。尽管如此，仍然可以在矩阵的每个单元格、行或列上运行定制的 Python 函数，但是通常情况下，这段代码会比使用 NumPy 的本地操作慢得多。

这种矢量化的代码需要一种稍微不同的思维方式，因为您的代码通常运行在矩阵的行或列上，而不是单个值上。因此，为了获得良好的性能，通常不建议编写自己的纯 Python 代码，当然，循环通常是不允许的。相反，大多数问题通常可以使用典型的操作来重新定义，这些操作已经变得可用和有效。

随着神经网络和其他计算密集型算法的兴起，科学家和开发人员正在挑战性能的极限；最近，宣布了一个新的包——CuPy——旨在成为 NumPy 的插件替代品，基于利用图形板而不是 CPU。假设您的计算机有一个很好的现代图形卡，它可以实现更令人印象深刻的性能，而 NumPy 上的代码几乎没有变化。

在这一节中，我们必须了解 NumPy，它是 Python 数据科学生态系统的基础包。NumPy 是围绕同一数据类型的多维数组的概念构建的。这样，大多数数学运算和矩阵变换都可以以矢量化的形式执行。这种数据处理的矢量化方法对于任何类型的数据操作都很好，但是 NumPy 只能支持数值操作。为了处理更广泛的数据类型并为矩阵提供更简单、更人性化的接口，我们将转到`pandas`。

        

# 从Pandas开始

当然，并不是所有的数据和数据分析都是数字的。为了解决这个问题，受 R 语言的 dataframe 对象的启发，Wes McKinney 在 2008 年创建了另一个包——`pandas`。虽然它严重依赖 NumPy 进行数值计算，但它的核心接口对象是 dataframes(二维多类型表)和 series(一维数组)。与 NumPy 矩阵相比，数据帧不要求所有数据都是同一类型。相反，它们允许您将数值与布尔值、字符串、`DateTimes`和任何其他任意 Python 对象混合。但是，它确实要求(并强制)数据类型在垂直方向上保持一致——在相同的列中。与 NumPy 相比，它还允许 dataframe 列...

        

# 尝试 SciPy 和 scikit-学习

SciPy 包基本上开启了科学 Python 的整个时代。由研究人员 Travis Oliphant、Pearu Peterson 和 Eric Jones 于 2001 年创建，它是作为基本和通用科学技术的集合而形成的。随着时间的推移，这个包不断发展，现在提供了用于科学分析的通用工具和流行技术。它的子模块包括线性代数、积分、最优化、插值、统计等等。

随着机器学习的兴起，SciPy 对应的子模块越来越复杂。在某种程度上，它变得如此之大，以至于决定将其作为一个单独的、独立的包重新引入。作为其起源的标志，该包保留了其名称，早期定义为 SciPy kit-learn。由于其简单统一的接口和种类繁多的模型，`scikit-learn`很快成为 Python 中机器学习的主要工具，其模型接口本质上是一种行业标准。事实上，许多其他包，如`xgboost`和`fbprophet`，为它们的模型复制了`scikit-learn`模型接口，允许我们快速交换和堆叠不同的机器学习算法。

作为机器学习的基础包，`scikit-learn`提供了这个工具:

*   数据准备—定标器和变压器
*   模型选择——交叉验证、超参数优化、管道等等
*   多个指标和得分/损失函数
*   降维
*   集群化
*   多模型回归和分类

假设数据是类似于 NumPy 数组的二维结构，因此 NumPy 数组本身和 pandas 数据帧都可以工作。我们将在 [第十三章](c6bd4bea-7b67-46bf-bdf9-761f8b400f75.xhtml)*训练一个机器学习模型*和[第十四章](b4957b91-3bef-4fee-9d47-fc00bb3ed779.xhtml)*改进你的模型——管道和实验*中使用`scikit-learn`来建立一个预测模型。

对于任何给定的领域——经济、社会科学、博弈论、物理学、冶金学、基因组学、心理学、神经科学和历史——都有数百个科学 Python 包，这个列表可以一直列下去。然而，这些包中的绝大多数都有着共同的起源，因为它们都使用 NumPy 数组作为数据结构，并在操作的核心使用来自 SciPy 和`scikit-learn`的函数。但是对于 Python 数据科学的普及来说至关重要的包的列表是不完整的，如果没有提到所有这些代码的关键环境—Jupyter。

        

# 了解 Jupyter

最后还有朱庇特。我们已经熟悉了这个工具，因为它被证明对于简单例子的教学和学习 Python 是非常宝贵的，但是它对于数据科学尤其有价值；鉴于其丰富的媒体和可视化功能，Jupyter 是一个优秀的数据分析环境。它允许快速迭代和试验，支持 markdown 文档和富媒体——图像、情节、交互式小部件、视频等等。当然，Jupyter 是 100%开源免费的。

Jupyter 也是语言不可知论者。目前，有一些语言可以和 Jupyter 一起使用，包括 Ruby、C、Rust、R 等等。它还支持第三方插件，例如 GeoJSON 的传单和地图框查看器...

        

# 摘要

在这一章中，我们讨论了 Python 数据科学栈的基础 NumPy、pandas、SciPy、`scikit-learn`和 Jupyter 库。通过这样做，我们能够收集对这个生态系统的理解，为什么和何时我们需要所有这些包，以及它们如何相互关联。了解它们之间的关系有助于导航和搜索要使用的特定功能或工具。

我们还谈到了为什么基于 NumPy 的计算如此之快，以及为什么这导致了数据驱动开发的不同哲学。我们进一步展示了 pandas 如何通过支持大量数据格式和类型来补充 NumPy 数组，SciPy 和`scikit-learn`建立在这些数据结构上，使我们能够快速训练和使用机器学习模型。最后，我们讨论了为什么 Jupyter 在这个过程中起着如此重要的作用，以及 Jupyter 笔记本的当前发展和新的用例。

在接下来的章节中，从下一章开始，我们将使用我们提到的所有包和工具来处理数据和构建数据驱动的项目。具体来说，在下一章中，我们将探索和处理我们在[第七章](232fe2da-7fa8-4d76-b5fc-d4bf80535e86.xhtml)、*用BeaultifulSoup 4* 从网络上抓取的二战战役数据，以便为数据分析和可视化做好准备。

        

# 问题

1.  为什么要使用特殊的包栈进行数据分析？
2.  为什么 NumPy 计算比普通 Python 快？
3.  使用Pandas over NumPy 的用例及好处是什么？
4.  `sklearn`代表什么？