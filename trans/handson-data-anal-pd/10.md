

# 七、金融分析——比特币和股票市场

是时候改变思路，开发一个应用了。在本章中，我们将通过对比特币和股票市场进行分析来探索一个金融应用。这一章建立在我们到目前为止所学的一切之上——我们将从互联网上提取数据；进行一些探索性的数据分析；用`pandas`、`seaborn`和`matplotlib`创建可视化效果；使用`pandas`计算分析金融工具表现的重要指标；体验一下构建模型的过程。请注意，我们在这里并不是要学习财务分析，而是介绍我们在本书中学到的技能如何应用于财务分析。

这一章也背离了本书中的标准工作流程。到目前为止，我们一直将 Python 作为一种函数式编程语言来使用。不过 Python 也支持**面向对象编程** ( **OOP** )。这意味着我们可以构建类来执行我们需要执行的主要任务，在本章中如下:从互联网收集数据(用`StockReader`类)，可视化金融资产(用`Visualizer`类)，计算金融指标(用`StockAnalyzer`类)，以及建模金融数据(用`StockModeler`类)。因为我们需要大量的代码来使分析过程清晰并易于重现，所以我们将构建一个 Python 包来容纳这些类。代码将在文本中重现，并照常解释；然而，我们不需要自己键入/运行它——确保阅读本章的*章节材料*部分，以便正确设置。

这一章很有挑战性，可能需要重读几遍；然而，它将教授最佳实践，在这里获得的技能将极大地提高您的编码技能，这将很快得到回报。一个主要的收获应该是 OOP 在打包分析任务方面非常有帮助。每堂课都应该有一个明确的目的，并且有详细的记录。如果我们有许多类，我们应该将它们分散在不同的文件中，并制作一个包。这使得其他人很容易安装/使用它们，我们也很容易标准化项目中某些任务的执行方式。例如，我们不应该让项目中的每个合作者编写自己的函数来连接数据库。标准化的、记录良好的代码将会省去很多麻烦。

本章将涵盖以下主题:

*   构建 Python 包
*   收集财务数据
*   进行探索性数据分析
*   对金融工具进行技术分析
*   使用历史数据模拟性能

# 章节材料

对于这一章，我们将创建自己的股票分析包。这使得我们发布代码和其他人使用我们的代码变得非常容易。这个包的最终产品在 GitHub 上的[https://GitHub . com/stef molin/stock-analysis/tree/2nd _ edition](https://github.com/stefmolin/stock-analysis/tree/2nd_edition)。Python 的包管理器`pip`，能够从 GitHub 安装包，也可以在本地构建包；这就给我们留下了以下两个选择之一来决定我们要如何继续下去:

*   如果我们不打算编辑自己使用的源代码，就从 GitHub 安装。
*   派生并克隆存储库，然后将其安装在我们的机器上，以便修改代码。

如果我们希望直接从 GitHub 安装，我们不需要在这里做任何事情，因为这是我们在 [*第 1 章*](B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015) 、*数据分析简介*中设置环境时安装的；但是，作为参考，我们将执行以下操作来从 GitHub 安装软件包:

```
(book_env) $ pip3 install \
git+https://github.com/stefmolin/stock-analysis.git@2nd_edition
```

小费

URL 的`@2nd_edition`部分告诉`pip`安装标记为`2nd_edition`的版本。要在特定的分支上安装代码版本，用`@<branch_name>`代替。例如，如果我们想要在一个叫做`dev`的分支上开发代码，我们使用`@dev`。当然，首先一定要检查分支是否存在。我们还可以以同样的方式使用提交散列来获取特定的提交。更多信息可在[https://pip.pypa.io/en/latest/reference/pip_install/#git](https://pip.pypa.io/en/latest/reference/pip_install/#git)获得。

为了在可编辑模式下本地安装——这意味着任何更改都将自动反映在本地，而不必重新安装——我们使用了`-e`标志。在我们在 [*第 1 章*](B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015) 、*数据分析简介*中创建的虚拟环境中，从命令行运行以下程序，以实现此目的。注意，这将克隆包的最新版本，它可能与文本中的版本不同(带有`2nd_edition`标签的版本):

```
(book_env) $ git clone \
git@github.com:stefmolin/stock-analysis.git
(book_env) $ pip3 install -r stock-analysis/requirements.txt
(book_env) $ pip3 install -e stock-analysis
```

重要说明

这个例子在 SSH 上使用了`git clone`;如果还没有设置 SSH 密钥，那么通过使用 URL 的变体来克隆 HTTPS。或者，首先按照 GitHub 上的说明生成 SSH 密钥。如果您对克隆带有`2nd_edition`标签的版本感兴趣，请参考这篇堆栈溢出帖子:[https://Stack Overflow . com/questions/2028 07 26/how-to-git-clone-a-specific-tag](https://stackoverflow.com/questions/20280726/how-to-git-clone-a-specific-tag)。

我们将在本章中使用这个包。本书知识库中这一章的目录有我们将用于实际分析的`financial_analysis.ipynb`笔记本，可以在[https://github . com/stef molin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/tree/master/ch _ 07](https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/tree/master/ch_07)找到。`data/`文件夹包含备份文件，以防发布后数据来源发生变化，或者用`StockReader`类收集数据时出现错误；如果发生这种情况，只需阅读 CSV 文件并遵循本章的其余部分。类似地，`exercises/`文件夹包含练习的备份文件。

重要说明

如果我们在使用 Jupyter 笔记本时更改了以可编辑模式安装的包中的文件，我们将需要重新启动我们的内核或打开一个新的 Python shell 并重新导入该包。这是因为 Python 会在导入后缓存它。其他选项包括使用`importlib.reload()`或 IPython `autoreload`扩展([https://IPython . readthe docs . io/en/stable/config/extensions/auto reload . html](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html))。

# 构建 Python 包

构建包被认为是良好的编码实践，因为它允许编写模块化代码和重用。**模块化代码**是由许多更小的片段编写的代码，用于更广泛的应用，不需要知道任务中涉及的所有底层实现细节。例如，当我们使用`matplotlib`来绘制一些东西时，我们不需要知道我们调用的函数中的代码到底在做什么——只需要知道在它的基础上将构建什么输入和输出就足够了。

## 包装结构

一个**模块**是 Python 代码的一个单文件，可以导入； [*第四章*](B16834_04_Final_SK_ePub.xhtml#_idTextAnchor082) 、*聚合Pandas数据帧*和 [*第六章*](B16834_06_Final_SK_ePub.xhtml#_idTextAnchor125) 、*用 Seaborn 绘图和定制技术*都是模块。一个**包**是组织成目录的模块集合。包也可以被导入，但是当我们导入一个包时，我们可以访问其中的某些模块，所以我们不需要单独导入每个模块。这也允许我们构建从彼此导入的模块，而不需要维护单个非常大的模块。

要将模块转换成包，我们遵循以下步骤:

1.  用包的名称创建一个目录(本章使用`stock_analysis`)。
2.  将模块放在上述目录中。
3.  添加一个包含任何 Python 代码的`__init__.py`文件，以便在导入包时运行(这个文件可以是——通常是——空的)。
4.  在包的顶层目录(这里是`stock_analysis`)的同一层创建一个`setup.py`文件，这个文件会给`pip`如何安装包的指令。参见*延伸阅读*部分，了解关于创建此的信息。

一旦前面提到的步骤完成，就可以用`pip`安装软件包了。注意，虽然我们的包只包含一个目录，但是我们可以构建一个包含任意多个子包的包。这些子包的创建就像我们创建一个包一样，只是它们不需要一个`setup.py`文件:

1.  在主包目录中(或者在其他子包中)为子包创建一个目录。
2.  将子包的模块放在这个目录中。
3.  添加`__init__.py`文件，其中包含导入子包时应该运行的代码(可以为空)。

包含单个子包的包的目录层次结构如下所示:

```
repo_folder
|-- <package_name>
|   |-- __init__.py
|   |-- some_module.py
|   `-- <subpackage_name>
|       |-- __init__.py
|       |-- another_module.py
|       `-- last_module.py
`-- setup.py
```

构建包时需要注意的其他一些事情包括:

*   为存储库编写一个**自述文件**文件，以便其他人知道它包含什么(参见[https://www.makeareadme.com/](https://www.makeareadme.com/))。
*   **林挺**代码，以符合编码标准并分析代码可能存在的错误(在检查`pylint`包)。
*   添加测试，以确保代码的更改不会破坏任何东西，并且代码做了它应该做的事情(看看在[https://docs.pytest.org/en/latest/](https://docs.pytest.org/en/latest/)的`pytest`包)。

## 股票分析包概述

在这一章中，我们将使用我们到目前为止讨论过的各种 Python 包以及 Python 标准库来创建一个名为`stock_analysis`的 Python 包。该包位于`stock-analysis`仓库(【https://github.com/stefmolin/stock-analysis】T4)中，其排列如下:

![Figure 7.1 – Structure of the stock-analysis repository
](image/Figure_7.1_B16834.jpg)

图 7.1–股票分析库的结构

我们包中的模块将包含定制类，用于对资产进行技术分析。**类**应该为单一目的而设计；如果出现问题，这使得构建、使用和调试更加容易。因此，我们将构建几个类，以涵盖我们财务分析的各个方面。我们将需要一个用于以下目的的和的类:

![Figure 7.2 – Main themes and classes for the stock_analysis package
](image/Figure_7.2_B16834.jpg)

图 7.2–股票分析包的主要主题和类

可视化包中模块之间的交互以及每个类提供的功能会很有帮助。为此，我们可以构建**统一建模语言** ( **UML** )图。

## UML 图表

**UML 图**显示了关于类具有哪些属性和方法以及类如何与其他类相关的信息。我们可以在下图中看到，所有模块都依赖于`utils.py`来实现效用函数:

![Figure 7.3 – Module dependencies in the stock_analysis package
](image/Figure_7.3_B16834.jpg)

图 7.3-stock _ analysis 包中的模块依赖关系

小费

`pylint`包附带了`pyreverse`，它制作 UML 图。如果安装了`graphviz`([http://www.graphviz.org/download/](http://www.graphviz.org/download/))，从命令行运行下面的代码会为模块之间的关系生成一个 PNG 文件，并为类生成一个 UML 图(假设存储库被克隆并且`pylint`被安装):`pyreverse -o png stock_analysis`

`stock_analysis`包中的类的 UML 图如下所示:

![Figure 7.4 – UML diagrams for classes in the stock_analysis package
](image/Figure_7.4_B16834.jpg)

图 7.4–stock _ analysis 包中类的 UML 图

每个框的顶部部分包含类名；中间部分包含该类的属性；而底部包含该类中定义的任何方法。注意从`AssetGroupVisualizer`和`StockVisualizer`类指向`Visualizer`类的箭头？这意味着两者都是一种类型的`Visualizer`。与`Visualizer`类相比，`AssetGroupVisualizer`和`StockVisualizer`类中显示的方法在这些类中有不同的定义。我们将在*探索性数据分析*部分更深入地讨论这一点。在本章的剩余部分，我们将更详细地查看`stock_analysis`包中的每个类，并使用它们的功能来执行金融资产的技术分析。

# 收集财务数据

回到 [*第 2 章*](B16834_02_Final_SK_ePub.xhtml#_idTextAnchor035) ，*使用Pandas数据帧*，以及 [*第 3 章*](B16834_03_Final_SK_ePub.xhtml#_idTextAnchor061) ，*与Pandas数据争论*，我们使用 API 收集数据；然而，还有其他方法可以从互联网上收集数据。我们可以使用 **web 抓取**来从 HTML 页面本身提取数据，这是`pandas`通过`pd.read_html()`函数提供的——它为在页面上找到的每个 HTML 表格返回一个数据帧。对于经济和金融数据，另一个选择是`pandas_datareader`包，`stock_analysis`包中的`StockReader`类使用它来收集金融数据。

重要说明

如果本章中使用的数据源发生了变化，或者您在使用`StockReader`类收集数据时遇到了错误，可以读取`data/`文件夹中的 CSV 文件作为替换，以便跟随文本；例如:

`pd.read_csv('data/bitcoin.csv', index_col='date',` `parse_dates=True)`

## stock reader 类

由于我们将在相同的日期范围内收集各种资产的数据，创建一个隐藏所有实现细节的类是有意义的，因此避免了大量的复制和粘贴(以及潜在的错误)。为此，我们将构建`StockReader`类，这将使为比特币、股票和股票市场指数收集数据变得更加容易。我们可以简单地通过提供我们分析所需的日期范围来创建一个`StockReader`类的实例，然后使用它提供的方法来获取我们想要的任何数据。下面的 UML 图提供了实现的高级概述:

![Figure 7.5 – UML diagram for the StockReader class
](image/Figure_7.5_B16834.jpg)

图 7.5–stock reader 类的 UML 图

UML 图告诉我们，`StockReader`类为可用的 ticker(`available_tickers`)提供了一个属性，并且可以执行以下操作:

*   用`get_bitcoin_data()`方法拉所需货币的比特币数据。
*   用`get_forex_rates()`方法提取每日外汇汇率数据。
*   用`get_index_data()`方法提取股票市场指数(如标准普尔 500)的数据。
*   查找特定指数的股票代码(股票市场代码)(例如，在 Yahoo！财务)用`get_index_ticker()`法。
*   用`get_risk_free_rate_of_return()`法收集无风险收益率。
*   用`get_ticker_data()`方法提取股票市场上某个股票的数据(比如网飞的 NFLX)。

既然我们理解了为什么我们需要这个类，并且对它的结构有了一个高层次的概述，我们可以继续看代码了。由于`stock_analysis/stock_reader.py`模块中有很多代码需要复习，我们就把文件一段一段的分解。请注意，这可能会改变缩进层次，所以请参考文件本身的完整版本。

模块的第一行是模块的**文档串**。如果我们在模块本身上运行`help()`，它将出现在顶部附近。这描述了我们模块的目的。紧随其后的是我们将需要的任何进口:

```
"""Gather select stock data."""
import datetime as dt
import re
import pandas as pd
import pandas_datareader.data as web
from .utils import label_sanitizer
```

请注意，`import`语句按照 **PEP 8** (Python 风格指南，可在 https://www . Python . org/dev/peps/PEP-0008/)分为三组，声明它们应该按照以下顺序:

1.  标准库导入(`datetime`和`re`)
2.  第三方库(`pandas`和`pandas_datareader`)
3.  从`stock_analysis`包(`.utils`)中的另一个模块相对导入

在导入之后，我们定义了`StockReader`类。首先，我们创建一个字典，将索引的代码映射到`_index_tickers`中的描述性名称。注意，我们的类也有一个 docstring，它定义了它的用途。这里，我们将只复制几个可用的报价器:

```
class StockReader:
    """Class for reading financial data from websites."""
    _index_tickers = {'S&P 500': '^GSPC', 'Dow Jones': '^DJI',
                      'NASDAQ': '^IXIC'}
```

当构建一个类时，有许多特殊的方法(俗称*邓德方法*，因为它们的名字以双下划线开始和结束)我们可以提供给定制类的行为，当它与语言操作符一起使用时:

*   初始化一个对象(`__init__()`)。
*   使对象在排序时具有可比性(`__eq__()`、`__lt__()`、`__gt__()`等)。
*   对对象执行算术运算(`__add__()`、`__sub__()`、`__mul__()`等等)。
*   能够在上面使用`len()`等内置 Python 函数(`__len__()`)。
*   获取对象的字符串表示，用于`print()`函数(`__repr__()`和`__str__()`)。
*   支持迭代和索引(`__getitem__()`、`__iter__()`、`__next__()`)。

令人欣慰的是，我们不必在每次创建一个类时都编写所有这些功能。在大多数情况下，我们只需要在创建对象时运行的`__init__()`方法。(关于特殊方法的更多信息可以在[https://dbader.org/blog/python-dunder-methods](https://dbader.org/blog/python-dunder-methods)和[https://docs . python . org/3/reference/data model . html # special-method-names 找到。](https://docs.python.org/3/reference/datamodel.html#special-method-names.)

`StockReader`类的对象持有收集数据的开始和结束日期，所以我们把它放在`__init__()`方法中。我们解析调用者传入的日期，以允许使用任何日期分隔符；例如，我们将能够处理 Python `datetime`对象的输入；`'YYYYMMDD'`形式的字符串；或者使用任何与非数字正则表达式(`\D`)匹配的分隔符表示日期的字符串，例如`'YYYY|MM|DD'`或`'YYYY/MM/DD'`。分隔符(如果有的话)被替换为空字符串，这样我们就可以在方法中使用`'YYYYMMDD'`格式构建日期时间。此外，如果调用者给我们的开始日期等于或晚于结束日期，我们将引发一个`ValueError`:

```
    def __init__(self, start, end=None):
        """
        Create a `StockReader` object for reading across 
        a given date range.
        Parameters:
            - start: The first date to include, as a datetime 
              object or a string in the format 'YYYYMMDD'.
            - end: The last date to include, as a datetime
              object or string in the format 'YYYYMMDD'.
              Defaults to today if not provided.
        """
        self.start, self.end = map(
            lambda x: x.strftime('%Y%m%d')\
                if isinstance(x, dt.date)\
                else re.sub(r'\D', '', x),
            [start, end or dt.date.today()]
        )
        if self.start >= self.end:
            raise ValueError('`start` must be before `end`')
```

注意，我们没有在`__init__()`方法中定义`_index_tickers`，该方法在创建该对象时被调用，因为对于从该类创建的所有对象，我们只需要该信息的一个副本。`_index_tickers`类属性是私有的(按照惯例，用前面的下划线表示)，除非这个类的用户知道它的名字，否则他们不会轻易找到它(注意方法也可以是私有的)。这样做的目的是为了保护它(虽然不能保证)，也是因为用户不直接需要它(这是为了类的内部工作)。相反，我们将提供一个可以作为属性访问的**属性**，以及一个获取映射到字典中给定键的值的类方法。

小费

**类方法**是可以在类本身上使用的方法，不需要事先创建类的实例。这与我们到目前为止看到的实例方法形成了对比。**实例方法**与一个类的实例一起使用，用于特定于该实例的动作。我们通常不需要类方法，但是如果我们有一个类的所有实例共享的数据，那么创建一个类方法比创建一个实例方法更有意义。

因为`_index_tickers`是私有的，我们想为我们类的用户提供一个简单的方法来查看什么是可用的。因此，我们将为`_index_tickers`的键创建一个属性。为此，我们使用了`@property`装饰器。装饰器是包装其他函数的函数，允许在内部函数执行之前和/或之后执行额外的代码。这个类大量使用了 decoratorss:我们将使用一些已经编写好的 decorator(`@property`和`@classmethod`)，并编写一个我们自己的 decorator 来清理和标准化收集数据的方法的结果(`@label_sanitizer`)。要使用装饰器，我们将它放在函数或方法定义之上:

```
    @property
    def available_tickers(self):
        """Indices whose tickers are supported."""
        return list(self._index_tickers.keys())
```

此外，我们提供了一种使用类方法获取 ticker 的方法，因为我们的 ticker 存储在一个类变量中。按照惯例，类方法接收`cls`作为它们的第一个参数，而实例方法接收`self`:

```
    @classmethod
    def get_index_ticker(cls, index):
        """
        Get the ticker of the specified index, if known.
        Parameters:
            - index: The name of the index; check 
              `available_tickers` for full list which includes:
                - 'S&P 500' for S&P 500,
                - 'Dow Jones' for Dow Jones Industrial Average,
                - 'NASDAQ' for NASDAQ Composite Index
        Returns: 
            The ticker as a string if known, otherwise `None`.
        """
        try:
            index = index.upper()
        except AttributeError:
            raise ValueError('`index` must be a string')
        return cls._index_tickers.get(index, None)
```

小费

如果我们想禁止代码中的某些行为，我们可以检查它们和我们认为合适的`raise`错误；这允许我们提供更多信息性的错误消息，或者在重新引发错误之前，简单地用一些额外的动作伴随特定的错误(通过使用不带表达式的`raise`)。相反，如果我们希望在出错时运行某些代码，我们使用一个`try...except`块:我们用`try`包围可能出错的代码，并在`except`子句中放入如果出错该做什么。

当我们到达*金融工具的技术分析*部分时，我们将需要无风险回报率来计算一些指标。这是没有财务损失风险的投资回报率；实际上，我们使用 10 年期美国国债。由于这个比率将取决于我们正在分析的日期范围，我们将把这个功能添加到`StockReader`类中，避免我们自己去查找。我们将使用`pandas_datareader`包从圣路易斯的美联储银行([https://fred.stlouisfed.org/series/DGS10](https://fred.stlouisfed.org/series/DGS10))收集这些数据，提供选项返回我们正在研究的日期范围内的每日汇率(以分析数据本身)或仅返回最后一个日期(如果我们需要一个单一值进行计算):

```
    def get_risk_free_rate_of_return(self, last=True):
        """
        Get risk-free rate of return w/ 10-year US T-bill 
        from FRED (https://fred.stlouisfed.org/series/DGS10)
        Parameter:
            - last: If `True`, return the rate on the last
              date in the date range else, return a `Series` 
              object for the rate each day in the date range.
        Returns:
            A single value or a `pandas.Series` object.
        """
        data = web.DataReader(
            'DGS10', 'fred', start=self.start, end=self.end
        )
        data.index.rename('date', inplace=True)
        data = data.squeeze()
        return data.asof(self.end) \
            if last and isinstance(data, pd.Series) else data
```

剩下的方法代码被替换为`pass`，它告诉 Python 不要做任何事情(并提醒我们稍后更新它)，这样代码就可以像复制时一样工作。我们将在下一节中编写以下方法:

```
    @label_sanitizer
    def get_ticker_data(self, ticker):
        pass    
    def get_index_data(self, index):
        pass
    def get_bitcoin_data(self, currency_code):
        pass
    @label_sanitizer 
    def get_forex_rates(self, from_currency, to_currency,
                        **kwargs):
        pass
```

重要说明

因为我们不打算看外汇汇率，所以我们不会在本章中讨论`get_forex_rates()`方法；然而，这个方法提供了一个如何使用`pandas_datareader`包的额外例子，所以我鼓励您看一看。注意，为了使用这个方法，你需要从 https://www.alphavantage.co/support/#api-key 的[的 AlphaVantage 获得一个免费的 API 密匙。](https://www.alphavantage.co/support/#api-key)

`get_ticker_data()`和`get_forex_rates()`方法都用`@label_sanitizer`修饰，它将我们从各种来源收到的数据排列到同一个列名称，这样我们就不必在以后清理它们。在`stock_analysis/utils.py`模块中定义了`@label_sanitizer`装饰器。正如我们之前所做的，让我们从查看 docstring 和`utils`模块的导入开始:

```
"""Utility functions for stock analysis."""
from functools import wraps
import re
import pandas as pd
```

接下来，我们有`_sanitize_label()`函数，它将清理单个标签。注意，我们在函数名前面加了一个下划线，因为我们不打算让我们的包的用户直接使用它——它是供我们的装饰者使用的:

```
def _sanitize_label(label):
    """
    Clean up a label by removing non-letter, non-space 
    characters and putting in all lowercase with underscores
    replacing spaces.
    Parameters:
        - label: The text you want to fix.
    Returns: 
        The sanitized label.
    """
    return re.sub(r'[^\w\s]', '', label)\
        .lower().replace(' ', '_')
```

最后，我们定义了`@label_sanitizer`装饰器，这是一个清理从互联网上获得的数据中的列和索引名称的函数。如果没有这个装饰器，我们收集的数据中的列名可能会包含意外的字符，比如星号或空格，使它们变得难以处理。通过使用 decorator，这些方法将总是返回一个名称被清除的数据帧，为我们节省了一个步骤:

```
def label_sanitizer(method):
    """
    Decorator around a method that returns a dataframe to
    clean up all labels in said dataframe (column names and 
    index name) by using `_sanitize_label()`.
    Parameters:
        - method: The method to wrap.
    Returns: 
        A decorated method or function.
    """
    @wraps(method) # keep original docstring for help()
    def method_wrapper(self, *args, **kwargs):
        df = method(self, *args, **kwargs)
        # fix the column names
        df.columns = [
            _sanitize_label(col) for col in df.columns
        ]
        # fix the index name
        df.index.rename(
            _sanitize_label(df.index.name), inplace=True
        )
        return df
    return method_wrapper
```

注意，在`label_sanitizer()`函数的定义中还有一个装饰器。来自标准库中`functools`模块的`@wraps`装饰器给被装饰的函数/方法赋予了它之前拥有的相同的 docstring 这是必要的，因为装饰实际上创建了一个新的函数/方法，从而使`help()`变得毫无用处，除非我们进行干预。

小费

使用`@label_sanitizer`语法是**语法糖**，这意味着与定义方法然后编写`method = label_sanitizer(method)`相比，它更容易表达。然而，两者都是有效的。

现在我们理解了 decorators，我们准备好完成构建`StockReader`类。注意，我们还将为`stock_analysis`包中的其他类使用和创建额外的装饰器，所以在继续之前，请确保您对它们感到满意。

## 从雅虎收集历史数据。金融

我们数据收集的基础将是`get_ticker_data()`方法。它使用`pandas_datareader`包从 Yahoo！金融:

```
@label_sanitizer
def get_ticker_data(self, ticker):
    """
    Get historical OHLC data for given date range and ticker.
    Parameter:
        - ticker: The stock symbol to lookup as a string.
    Returns: A `pandas.DataFrame` object with the stock data.
    """
    return web.get_data_yahoo(ticker, self.start, self.end)
```

重要说明

`pandas_datareader`和雅虎之间一直存在问题。过去的 Finance API，导致`pandas_datareader`开发者通过`web.DataReader()`函数([https://pandas-datareader . readthe docs . io/en/latest/whatsnew . html # v 0-6-0-January-24-2018](https://pandas-datareader.readthedocs.io/en/latest/whatsnew.html#v0-6-0-january-24-2018))不赞成支持它；相反，我们不得不使用他们的变通方法:`web.get_data_yahoo()`。

为了收集股票市场指数的数据，我们可以使用`get_index_data()`方法，该方法首先查找指数的股票代码，然后调用我们刚刚定义的`get_ticker_data()`方法。注意，由于`get_ticker_data()`方法是用`@label_sanitizer`装饰的，因此`get_index_data()`方法不需要`@label_sanitizer`装饰器:

```
def get_index_data(self, index):
    """
    Get historical OHLC data from Yahoo! Finance
    for the chosen index for given date range.
    Parameter:
        - index: String representing the index you want
          data for, supported indices include:
            - 'S&P 500' for S&P 500,
            - 'Dow Jones' for Dow Jones Industrial Average,
            - 'NASDAQ' for NASDAQ Composite Index
    Returns: 
        A `pandas.DataFrame` object with the index data.
    """
    if index not in self.available_tickers:
        raise ValueError(
            'Index not supported. Available tickers'
            f"are: {', '.join(self.available_tickers)}"
        )
    return self.get_ticker_data(self.get_index_ticker(index))
```

雅虎！金融也为比特币提供数据；然而，我们必须选择一种货币来使用。`get_bitcoin_data()`方法接受一个货币代码来创建在 Yahoo！金融(例如，BTC-美元表示以美元表示的比特币数据)。数据的实际收集再次由`get_ticker_data()`方法处理:

```
def get_bitcoin_data(self, currency_code):
    """
    Get bitcoin historical OHLC data for given date range. 
    Parameter:
        - currency_code: The currency to collect the bitcoin
          data in, e.g. USD or GBP.
    Returns: 
        A `pandas.DataFrame` object with the bitcoin data.
    """
    return self\
        .get_ticker_data(f'BTC-{currency_code}')\
        .loc[self.start:self.end] # clip dates
```

至此，`StockReader`类已经可以使用了，所以让我们从`financial_analysis.ipynb`笔记本开始，导入将用于本章剩余部分的`stock_analysis`包:

```
>>> import stock_analysis
```

当我们导入`stock_analysis`包时，Python 运行`stock_analysis/__init__.py`文件:

```
"""Classes for making technical stock analysis easier."""
from .stock_analyzer import StockAnalyzer, AssetGroupAnalyzer
from .stock_modeler import StockModeler
from .stock_reader import StockReader
from .stock_visualizer import \
    StockVisualizer, AssetGroupVisualizer
```

重要说明

`stock_analysis/__init__.py`文件中的代码使我们更容易访问包的类——例如，不必运行`stock_analysis.stock_reader.StockReader()`,我们只需运行`stock_analysis.StockReader()`来创建一个`StockReader`对象。

接下来，我们将通过提供它将收集的数据的开始和(可选的)结束日期来创建`StockReader`类的一个实例。我们将使用 2019-2020 年的数据。注意，当我们运行这段代码时，Python 正在调用`StockReader.__init__()`方法:

```
>>> reader = \
...     stock_analysis.StockReader('2019-01-01', '2020-12-31')
```

现在，我们将收集**脸书、苹果、亚马逊、网飞、谷歌** ( **FAANG** )、S & P 500、比特币数据。因为我们正在处理的所有股票都是以美元定价的，所以我们将要求以美元为单位的比特币数据。请注意，我们使用生成器表达式和多重赋值来获取每个 FAANG 股票的数据帧:

```
>>> fb, aapl, amzn, nflx, goog = (
...     reader.get_ticker_data(ticker)
...     for ticker in ['FB', 'AAPL', 'AMZN', 'NFLX', 'GOOG']
... )
>>> sp = reader.get_index_data('S&P 500')
>>> bitcoin = reader.get_bitcoin_data('USD') 
```

小费

确保运行`help(stock_analysis.StockReader)`或`help(reader)`来查看所有定义了的方法和属性。输出清楚地表明哪些方法是不同部分中的类方法，属性将在**数据描述符**部分的底部列出。这是熟悉新代码的重要一步。

# 探索性数据分析

现在我们有了数据，我们想熟悉它。正如我们在 [*第 5 章*](B16834_05_Final_SK_ePub.xhtml#_idTextAnchor106) 、*使用 Pandas 和 Matplotlib* 和 [*可视化数据第 6 章*](B16834_06_Final_SK_ePub.xhtml#_idTextAnchor125) 、*使用 Seaborn 和定制技术进行绘图*中所看到的，创建良好的可视化需要了解`matplotlib`，以及——取决于数据格式和可视化的最终目标— `seaborn`。正如我们对`StockReader`类所做的那样，我们希望使单个资产和资产组的可视化变得更容易，所以我们并不期望我们包的用户(也许还有我们的合作者)精通`matplotlib`和`seaborn`，我们将围绕这个功能创建包装器。这意味着该软件包的用户只需能够使用`stock_analysis`软件包来可视化他们的财务数据。此外，我们能够为可视化的外观设置标准，并避免为我们想要进行的每个新分析复制和粘贴大量代码，这带来了一致性和效率的提高。

为了使所有这些成为可能，我们在`stock_analysis/stock_visualizer.py`中有了`Visualizer`类。该文件中有三个类:

*   `Visualizer`:这是定义`Visualizer`对象功能的基类。大多数方法都是**抽象**，意味着从这个超类(父类)继承的子类(子类)将需要覆盖它们并实现代码；这些定义了一个对象应该做什么，而不涉及细节。
*   这是我们将用来可视化单个资产的子类。
*   `AssetGroupVisualizer`:这是我们将使用`groupby()`操作来可视化多个资产的子类。

在我们讨论这些类的代码之前，让我们来看一下`stock_analysis/utils.py`文件中的一些额外的函数，这将有助于创建这些资产组并为 EDA 目的描述它们。对于这些函数，我们需要导入`pandas`:

```
import pandas as pd
```

`group_stocks()`函数接收一个字典，该字典将资产的名称映射到该资产的数据帧，并输出一个新的数据帧，该数据帧包含来自输入数据帧的所有数据和一个新列，表示该数据属于哪个资产:

```
def group_stocks(mapping):
    """
    Create a new dataframe with many assets and a new column 
    indicating the asset that row's data belongs to.
    Parameters:
        - mapping: A key-value mapping of the form 
                   {asset_name: asset_df}
    Returns: 
        A new `pandas.DataFrame` object
    """
    group_df = pd.DataFrame()
    for stock, stock_data in mapping.items():
        df = stock_data.copy(deep=True)
        df['name'] = stock
        group_df = group_df.append(df, sort=True)
    group_df.index = pd.to_datetime(group_df.index)
    return group_df
```

由于我们将在整个包中拥有许多方法和函数，这些方法和函数需要特定格式的数据帧，我们将构建一个新的装饰器:`@validate_df`。这个装饰器检查一个给定方法或函数的输入是一个类型为`DataFrame`的对象，并且它至少拥有由装饰器的`columns`参数指定的列。我们将提供列作为一个`set`对象。这允许我们检查我们必须拥有的列和输入数据中的列之间的集合差异(参见 [*第 4 章*](B16834_04_Final_SK_ePub.xhtml#_idTextAnchor082) ，*聚集Pandas数据帧*，查看集合操作)。如果数据帧具有我们请求的列(至少)，那么设置的差将为空，这意味着数据帧通过了测试。如果违反了这两个条件中的任何一个，这个装饰者将抛出一个`ValueError`。

让我们看看这在`stock_analysis/utils.py`文件中是如何定义的:

```
def validate_df(columns, instance_method=True):
    """
    Decorator that raises a `ValueError` if input isn't a
    `DataFrame` or doesn't contain the proper columns. Note 
    the `DataFrame` must be the first positional argument
    passed to this method.
    Parameters:
        - columns: A set of required column names.
          For example, {'open', 'high', 'low', 'close'}.
        - instance_method: Whether or not the item being
          decorated is an instance method. Pass `False` to 
          decorate static methods and functions.
    Returns:
        A decorated method or function.
    """
    def method_wrapper(method):
        @wraps(method)
        def validate_wrapper(self, *args, **kwargs):
            # functions and static methods don't pass self so
            # self is the 1st positional argument in that case
            df = (self, *args)[0 if not instance_method else 1]
            if not isinstance(df, pd.DataFrame):
                raise ValueError(
                    'Must pass in a pandas `DataFrame`'
                )
            if columns.difference(df.columns):
                raise ValueError(
                    'Dataframe must contain the following'
                    f' columns: {columns}'
                )
            return method(self, *args, **kwargs)
        return validate_wrapper
    return method_wrapper
```

使用`group_stocks()`功能组成的组可以使用和`describe_group()`功能在单个输出中描述。`group_stocks()`函数添加了一个`describe_group()`寻找的名为`name`的列，所以我们使用`@validate_df`装饰器来确保在尝试运行函数之前格式是正确的:

```
@validate_df(columns={'name'}, instance_method=False)
def describe_group(data):
    """
    Run `describe()` on the asset group.
    Parameters:
        - data: Grouped data resulting from `group_stocks()`
    Returns: 
        The transpose of the grouped description statistics.
    """
    return data.groupby('name').describe().T
```

让我们使用和`group_stocks()`函数为我们的分析创建一些资产组:

```
>>> from stock_analysis.utils import \
...     group_stocks, describe_group
>>> faang = group_stocks({
...     'Facebook': fb, 'Apple': aapl, 'Amazon': amzn, 
...     'Netflix': nflx, 'Google': goog
... })
>>> faang_sp = group_stocks({
...     'Facebook': fb, 'Apple': aapl, 'Amazon': amzn, 
...     'Netflix': nflx, 'Google': goog, 'S&P 500': sp
... })
>>> all_assets = group_stocks({
...     'Bitcoin': bitcoin, 'S&P 500': sp, 'Facebook': fb, 
...     'Apple': aapl, 'Amazon': amzn, 'Netflix': nflx, 
...     'Google': goog
... })
```

与在每个数据帧上单独运行相比，使用这些组，`describe()`的输出可以提供更多的比较信息。`describe_group()`函数处理`describe()`和`groupby()`的运行。这使得查看跨资产的收盘价汇总更加容易:

```
>>> describe_group(all_assets).loc['close',]
```

一眼就能看出，比特币的数据比其他的都多。这是因为价格每天都在变化，而对于股票，我们只能看到交易日的数据。另一件我们可以从中收集到的东西是规模；比特币不仅波动性更大，而且价值也远高于其他任何东西:

![Figure 7.6 – Summary statistics for the closing price per financial instrument
](image/Figure_7.6_B16834.jpg)

图 7.6–每个金融工具收盘价的汇总统计

如果我们不想单独看资产，我们可以把它们组合成一个投资组合，我们可以把它当作一个单一的资产。`stock_analysis/utils.py`中的`make_portfolio()`函数按日期对数据进行分组，并对所有列求和，得出我们投资组合的总股价和交易量:

```
@validate_df(columns=set(), instance_method=False)
def make_portfolio(data, date_level='date'):
    """
    Make a portfolio of assets by grouping by date and 
    summing all columns.
    Note: the caller is responsible for making sure the 
    dates line up across assets and handling when they don't.
    """
    return data.groupby(level=date_level).sum()
```

该函数假设资产以相同的频率进行交易。比特币一周每天都有交易，而股市没有。出于这个原因，如果我们的投资组合是比特币和股票市场的混合，我们就必须在使用这个函数之前决定如何处理这种差异；参考我们在 [*第三章*](B16834_03_Final_SK_ePub.xhtml#_idTextAnchor061) 、*与Pandas*的数据争论中关于重新索引的讨论，寻找一个可能的策略。我们将在本章结尾的练习中使用该函数来构建 FAANG 股票的投资组合，这些股票都以相同的频率进行交易，以观察盘后交易对 FAANG 股票整体的影响。

## 可视化工具类系列

正如我们从前面章节中了解到的那样，可视化将使我们的分析更加容易，所以让我们开始讨论`stock_analysis/stock_visualizer.py`中的`Visualizer`类。首先，我们将定义我们的基类，`Visualizer`。下面的 UML 图告诉我们这是我们的基类，因为它有指向它的箭头。这些箭头源自子类(`AssetGroupVisualizer`和`StockVisualizer`):

![Figure 7.7 – Visualizer class hierarchy
](image/Figure_7.7_B16834.jpg)

图 7.7–可视化工具类层次结构

*图 7.7* 也告诉了我们将在本节中为每个类定义的方法。这包括将盘后交易的影响(`after_hours_trades()`)和资产价格随时间的演变(`evolution_over_time()`)可视化的方法，我们将使用这些方法来直观地比较资产。

我们用 docstring 和 imports 启动模块。对于我们的可视化，我们将需要`matplotlib`、`numpy`、`pandas`和`seaborn`，以及`mplfinance`(一个用于金融可视化的`matplotlib`衍生包):

```
"""Visualize financial instruments."""
import math
import matplotlib.pyplot as plt
import mplfinance as mpf
import numpy as np
import pandas as pd
import seaborn as sns
from .utils import validate_df
```

接下来，我们从定义`Visualizer`类开始。这个类将保存数据，这些数据将被用于可视化，所以我们把它放在`__init__()`方法中:

```
class Visualizer:
    """Base visualizer class not intended for direct use."""
    @validate_df(columns={'open', 'high', 'low', 'close'})
    def __init__(self, df):
        """Store the input data as an attribute."""
        self.data = df
```

这个基类将为我们提供**静态方法**，用于向绘图添加参考线以及添加阴影区域，而不需要记住我们需要调用哪个`matplotlib`函数来定位；静态方法不依赖于数据的类。我们定义了使用`@staticmethod`装饰器添加水平线或垂直线(以及其间的任何东西)的`add_reference_line()`方法；注意我们没有将`self`或`cls`作为第一个参数:

```
    @staticmethod
    def add_reference_line(ax, x=None, y=None, **kwargs):
        """
        Static method for adding reference lines to plots.
        Parameters:
            - ax: `Axes` object to add the reference line to.
            - x, y: The x, y value to draw the line at as a 
              single value or numpy array-like structure.
                - For horizontal: pass only `y`
                - For vertical: pass only `x`
                - For AB line: pass both `x` and `y`
            - kwargs: Additional keyword args. to pass down.
        Returns:
            The matplotlib `Axes` object passed in.
        """
        try:
            # numpy array-like structures -> AB line
            if x.shape and y.shape:
                ax.plot(x, y, **kwargs)
        except:
            # error triggers if x or y isn't array-like
            try:
                if not x and not y:
                    raise ValueError(
                        'You must provide an `x` or a `y`'
                    )
                elif x and not y:
                    ax.axvline(x, **kwargs) # vertical line
                elif not x and y:
                    ax.axhline(y, **kwargs) # horizontal line
            except:
                raise ValueError(
                    'If providing only `x` or `y`, '
                    'it must be a single value'
                )
        ax.legend()
        return ax
```

小费

关于类方法、静态方法和抽象方法的更多信息，参见*延伸阅读*部分。

向图中添加阴影区域的`shade_region()`静态方法类似于`add_reference_line()`静态方法:

```
    @staticmethod
    def shade_region(ax, x=tuple(), y=tuple(), **kwargs):
        """
        Static method for shading a region on a plot.
        Parameters:
            - ax: `Axes` object to add the shaded region to.
            - x: Tuple with the `xmin` and `xmax` bounds for 
              the rectangle drawn vertically.
            - y: Tuple with the `ymin` and `ymax` bounds for 
              the rectangle drawn horizontally.
            - kwargs: Additional keyword args. to pass down.
        Returns: 
            The matplotlib `Axes` object passed in.
        """
        if not x and not y:
            raise ValueError(
                'You must provide an x or a y min/max tuple'
            )
        elif x and y:
            raise ValueError('You can only provide x or y.')
        elif x and not y:
            ax.axvspan(*x, **kwargs) # vertical region
        elif not x and y:
            ax.axhspan(*y, **kwargs) # horizontal region
        return ax
```

因为我们希望我们的绘图功能能够灵活，我们将定义一个静态方法，使我们能够轻松地绘制一个或多个项目，而不需要事先检查项目的数量。这将在我们使用`Visualizer`类作为基础构建的类中使用:

```
    @staticmethod
    def _iter_handler(items):
        """
        Static method for making a list out of an item if 
        it isn't a list or tuple already.
        Parameters:
            - items: The variable to make sure it is a list.
        Returns: The input as a list or tuple.
        """
        if not isinstance(items, (list, tuple)):
            items = [items]
        return items
```

我们希望支持单个资产和资产组的窗口功能；然而，它的实现会有所不同，所以我们将在超类中定义一个**抽象方法**(一个没有实现的方法)，子类将覆盖它以提供实现:

```
    def _window_calc(self, column, periods, name, func, 
                     named_arg, **kwargs):
        """
        To be implemented by subclasses. Defines how to add 
        lines resulting from window calculations.
        """
        raise NotImplementedError('To be implemented by '
                                  'subclasses.')
```

这允许我们定义依赖于`_window_calc()`的功能，但不需要知道的确切实现，只需要知道结果。`moving_average()`方法使用`_window_calc()`将移动平均线添加到图中:

```
    def moving_average(self, column, periods, **kwargs):
        """
        Add line(s) for the moving average of a column.
        Parameters:
            - column: The name of the column to plot.
            - periods: The rule or list of rules for 
              resampling, like '20D' for 20-day periods.
            - kwargs: Additional arguments to pass down.
        Returns: A matplotlib `Axes` object.
        """
        return self._window_calc(
            column, periods, name='MA', named_arg='rule',
            func=pd.DataFrame.resample, **kwargs
        )
```

以类似的方式，我们定义了`exp_smoothing()`方法，该方法将使用`_window_calc()`将指数平滑的移动平均线添加到图中:

```
    def exp_smoothing(self, column, periods, **kwargs):
        """
        Add line(s) for the exponentially smoothed moving 
        average of a column.
        Parameters:
            - column: The name of the column to plot.
            - periods: The span or list of spans for,
              smoothing like 20 for 20-day periods.
            - kwargs: Additional arguments to pass down.
        Returns: 
            A matplotlib `Axes` object.
        """
        return self._window_calc(
            column, periods, name='EWMA',
            func=pd.DataFrame.ewm, named_arg='span', **kwargs
        )
```

注意，虽然我们有方法将移动平均线和指数平滑移动平均线加到一个柱形图上，但是它们都调用`_window_calc()`，这里没有定义。这是因为每个子类都有自己的`_window_calc()`实现，而它们将继承顶级方法，无需覆盖`moving_average()`或`exp_smoothing()`。

重要说明

请记住，以单下划线(`_`)开头的方法是 Python 版本的**私有方法**——它们仍然可以在这个类之外被访问，但是当我们在那个类的对象上运行`help()`时，它们不会出现。我们创建了`_window_calc()`作为私有方法，因为`Visualizer`类的用户只需要调用`moving_average()`和`exp_smoothing()`。

最后，我们将为所有子类的方法添加占位符。这些是抽象方法，将由每个子类单独定义，因为根据我们是可视化单个资产还是一组资产，实现会有所不同。为了简洁起见，下面的是这个类中定义的抽象方法的子集:

```
    def evolution_over_time(self, column, **kwargs):
        """Creates line plots."""
        raise NotImplementedError('To be implemented by '
                                  'subclasses.')
    def after_hours_trades(self):
        """Show the effect of after-hours trading."""
        raise NotImplementedError('To be implemented by '
                                  'subclasses.')
    def pairplot(self, **kwargs):
        """Create pairplots."""
        raise NotImplementedError('To be implemented by '
                                  'subclasses.')
```

如有必要，子类还将定义它们独有的任何方法和/或覆盖`Visualizer`类的实现。任何他们没有覆盖的东西，他们都会继承。通过使用**继承**，我们可以根据所有`Visualizers`应该做什么来定义一个宽泛的类，比如`Visualizer`，然后有更具体的版本，比如`StockVisualizer`类，它只处理单个资产。

## 可视化股票

让我们通过继承`Visualizer`来启动的`StockVisualizer`类；我们将选择不覆盖`__init__()`方法，因为`StockVisualizer`类只有一个 dataframe 作为属性。相反，我们将为需要添加(该类特有的)或覆盖的方法提供实现。

重要说明

为了简洁起见，我们将只讨论功能的一个子集；但是，我强烈建议您通读完整的代码库，并测试笔记本的功能。

我们将覆盖的第一个方法是`evolution_over_time()`，它将创建一个随时间变化的柱形图:

```
class StockVisualizer(Visualizer):
    """Visualizer for a single stock."""
    def evolution_over_time(self, column, **kwargs):
        """
        Visualize the evolution over time of a column.
        Parameters:
            - column: The name of the column to visualize.
            - kwargs: Additional arguments to pass down.
        Returns:
            A matplotlib `Axes` object.
        """
        return self.data.plot.line(y=column, **kwargs)
```

接下来，我们将使用`mplfinance`创建一个**烛台图**，这是一种将 OHLC 数据可视化的方式。OHLC 时间序列的每一行都将绘制成一个烛台。当烛台为黑色时，资产的收盘价小于的开盘价(它失去了价值)；当烛台为白色时，资产的收盘价高于开盘价，如下图所示:

![Figure 7.8 – Understanding a candlestick plot
](image/Figure_7.8_B16834.jpg)

图 7.8–理解蜡烛图

`candlestick()`方法还提供了对数据进行重采样、显示交易量和绘制特定日期范围的选项:

```
    def candlestick(self, date_range=None, resample=None, 
                    volume=False, **kwargs):
        """
        Create a candlestick plot for the OHLC data.
        Parameters:
            - date_range: String or `slice()` of dates to 
              pass to `loc[]`, if `None` the plot will be 
              for the full range of the data.
            - resample: The offset to use for resampling 
              the data, if desired.
            - volume: Whether to show a bar plot for volume 
              traded under the candlesticks
            - kwargs: Keyword args for `mplfinance.plot()`
        """
        if not date_range:
            date_range = slice(
                self.data.index.min(), self.data.index.max()
            )
        plot_data = self.data.loc[date_range]
        if resample:
            agg_dict = {
                'open': 'first', 'close': 'last',
                'high': 'max', 'low': 'min', 'volume': 'sum'
            }
            plot_data = plot_data.resample(resample).agg({
                col: agg_dict[col] for col in plot_data.columns
                if col in agg_dict
            })
        mpf.plot(
            plot_data, type='candle', volume=volume, **kwargs
        )
```

现在，我们添加了`after_hours_trades()`方法，这有助于我们可视化盘后交易对单个资产的影响，红色柱表示亏损，绿色柱表示盈利:

```
    def after_hours_trades(self):
        """
        Visualize the effect of after-hours trading.
        Returns: A matplotlib `Axes` object.
        """
        after_hours = self.data.open - self.data.close.shift()
        monthly_effect = after_hours.resample('1M').sum()
        fig, axes = plt.subplots(1, 2, figsize=(15, 3))
        after_hours.plot(
            ax=axes[0],
            title='After-hours trading\n'
                  '(Open Price - Prior Day\'s Close)'
        ).set_ylabel('price')
        monthly_effect.index = \
            monthly_effect.index.strftime('%Y-%b')
        monthly_effect.plot(
            ax=axes[1], kind='bar', rot=90,
            title='After-hours trading monthly effect',
            color=np.where(monthly_effect >= 0, 'g', 'r')
        ).axhline(0, color='black', linewidth=1)
        axes[1].set_ylabel('price')
        return axes
```

接下来，我们将添加一个静态方法，允许我们填充我们选择的的两条曲线之间的区域。`fill_between()`方法将使用`plt.fill_between()`根据哪条曲线更高将该区域涂成绿色或红色:

```
    @staticmethod
    def fill_between(y1, y2, title, label_higher, label_lower, 
                     figsize, legend_x):
        """
        Visualize the difference between assets.
        Parameters:
            - y1, y2: Data to plot, filling y2 - y1.
            - title: The title for the plot.
            - label_higher: Label for when y2 > y1.
            - label_lower: Label for when y2 <= y1.
            - figsize: (width, height) for the plot dimensions.
            - legend_x: Where to place legend below the plot.
        Returns: A matplotlib `Axes` object.
        """
        is_higher = y2 - y1 > 0
        fig = plt.figure(figsize=figsize)
        for exclude_mask, color, label in zip(
 (is_higher, np.invert(is_higher)),
 ('g', 'r'),
 (label_higher, label_lower)
 ):
 plt.fill_between(
 y2.index, y2, y1, figure=fig,
 where=exclude_mask, color=color, label=label
 )
        plt.suptitle(title)
        plt.legend(
            bbox_to_anchor=(legend_x, -0.1),
            framealpha=0, ncol=2
        )
        for spine in ['top', 'right']:
            fig.axes[0].spines[spine].set_visible(False)
        return fig.axes[0]
```

`open_to_close()`方法将帮助我们通过`fill_between()`静态方法可视化开盘价和收盘价之间的每日差异。如果的收盘价高于开盘价，我们将该区域涂成绿色，如果收盘价高于开盘价，我们将该区域涂成红色:

```
    def open_to_close(self, figsize=(10, 4)):
        """
        Visualize the daily change in price from open to close.
        Parameters:
            - figsize: (width, height) of plot
        Returns:
            A matplotlib `Axes` object.
        """
        ax = self.fill_between(
            self.data.open, self.data.close, 
            figsize=figsize, legend_x=0.67,
            title='Daily price change (open to close)',
            label_higher='price rose', label_lower='price fell'
        )
        ax.set_ylabel('price')
        return ax
```

除了可视化单个资产的开盘价和收盘价之间的差异之外，我们还希望比较资产之间的价格。再次使用`fill_between()`,`fill_between_other()`方法将帮助我们可视化我们为其创建可视化工具的资产和另一个资产之间的差异。当可视化工具的资产高于其他资产时，我们将把的差异颜色设置为绿色，当它低于其他资产时，将设置为红色:

```
    def fill_between_other(self, other_df, figsize=(10, 4)):
        """
        Visualize difference in closing price between assets.
        Parameters:
            - other_df: The other asset's data.
            - figsize: (width, height) for the plot.
        Returns: 
            A matplotlib `Axes` object.
        """
        ax = self.fill_between(
            other_df.open, self.data.close, figsize=figsize, 
            legend_x=0.7, label_higher='asset is higher', 
            label_lower='asset is lower', 
            title='Differential between asset price '
                  '(this - other)'
        )
        ax.set_ylabel('price')
        return ax
```

现在终于到了覆盖`_window_calc()`方法的时候了，该方法定义了如何基于单个资产的窗口计算来添加参考线。请注意我们如何使用`pipe()`方法(在 [*第 4 章*](B16834_04_Final_SK_ePub.xhtml#_idTextAnchor082) 、*聚合Pandas数据帧*中介绍)使我们的窗口计算图与不同的函数一起工作，以及使用`_iter_handler()`方法使我们的循环工作，而不必检查我们是否有一条以上的参考线要绘制:

```
    def _window_calc(self, column, periods, name, func, 
                     named_arg, **kwargs):
        """
        Helper method for plotting a series and adding
        reference lines using a window calculation.
        Parameters:
            - column: The name of the column to plot.
            - periods: The rule/span or list of them to pass 
              to the resampling/smoothing function, like '20D'
              for 20-day periods (resampling) or 20 for a 
              20-day span (smoothing)
            - name: The name of the window calculation (to 
              show in the legend).
            - func: The window calculation function.
            - named_arg: The name of the argument `periods` 
              is being passed as.
            - kwargs: Additional arguments to pass down.
        Returns:
            A matplotlib `Axes` object.
        """
        ax = self.data.plot(y=column, **kwargs)
        for period in self._iter_handler(periods):
            self.data[column].pipe(
 func, **{named_arg: period}
 ).mean().plot(
                ax=ax, linestyle='--',
                label=f"""{period if isinstance(
                    period, str
                ) else str(period) + 'D'} {name}"""
            )
        plt.legend()
        return ax
```

到目前为止，每个可视化都关注单个资产的数据；然而，有时我们希望能够可视化资产之间的关系，因此我们将围绕来自`seaborn`的`jointplot()`函数构建一个包装器:

```
    def jointplot(self, other, column, **kwargs):
        """
        Generate a seaborn jointplot for given column in 
        this asset compared to another asset.
        Parameters:
            - other: The other asset's dataframe.
            - column: Column to use for the comparison.
            - kwargs: Keyword arguments to pass down.
        Returns: A seaborn jointplot
        """
        return sns.jointplot(
            x=self.data[column], y=other[column], **kwargs
        )
```

查看资产之间关系的另一种方式是关联矩阵。`DataFrame`对象有一个`corrwith()`方法，该方法将计算每个列与另一个数据帧中相同列(按名称)之间的相关系数。正如我们在前几章看到的，这并没有填充热图所需的矩阵；确切地说，是对角线。`correlation_heatmap()`方法为`sns.heatmap()`函数创建一个矩阵，并用相关系数填充对角线；然后，它确保只有对角线使用遮罩显示。此外，在计算相关性时，我们将使用每根柱的每日百分比变化来处理规模差异(例如，苹果股价和亚马逊股价之间的差异):

```
    def correlation_heatmap(self, other):
        """
        Plot the correlations between this asset and another
        one with a heatmap.
        Parameters:
            - other: The other dataframe.
        Returns: A seaborn heatmap
        """
        corrs = \
            self.data.pct_change().corrwith(other.pct_change())
        corrs = corrs[~pd.isnull(corrs)]
        size = len(corrs)
        matrix = np.zeros((size, size), float)
        for i, corr in zip(range(size), corrs):
            matrix[i][i] = corr
        # create mask to only show diagonal
        mask = np.ones_like(matrix)
        np.fill_diagonal(mask, 0)
        return sns.heatmap(
            matrix, annot=True, center=0, vmin=-1, vmax=1,
            mask=mask, xticklabels=self.data.columns, 
            yticklabels=self.data.columns
        )
```

现在我们理解了`StockVisualizer`类中的一些可用功能，我们可以开始我们的探索性分析了。让我们创建一个`StockVisualizer`对象来对网飞股票数据执行一些 EDA:

```
>>> %matplotlib inline
>>> import matplotlib.pyplot as plt
>>> netflix_viz = stock_analysis.StockVisualizer(nflx)
```

一旦我们用网飞数据帧初始化了我们的`StockVisualizer`对象，我们就可以生成许多不同的绘图类型。我们不会讨论这个对象让我们做的所有事情的例子(我会让您自己去试验)，但让我们来看看一段时间内的收盘价和一些移动平均线，以研究趋势:

```
>>> ax = netflix_viz.moving_average('close', ['30D', '90D'])
>>> netflix_viz.shade_region(
...     ax, x=('2019-10-01', '2020-07-01'), 
...     color='blue', alpha=0.1
... )
>>> ax.set(title='Netflix Closing Price', ylabel='price ($)')
```

这些移动平均线给了我们一个平滑的股价曲线。请注意，在阴影区域，90 天移动平均线就像是股价的天花板:

![Figure 7.9 – Netflix stock price with moving averages
](image/Figure_7.9_B16834.jpg)

图 7.9-网飞股票价格和移动平均线

交易者根据手头的任务尝试不同时期的移动平均线，比如预测上涨趋势(股价上涨)和在下跌趋势(股价下跌)前计划退出。其他用途包括计算自动**支持**和**阻力**水平(我们首先在 [*第 6 章*](B16834_06_Final_SK_ePub.xhtml#_idTextAnchor125) 、*用 Seaborn 和定制技术*绘图中看到)，分别通过找到从下方支撑数据的移动平均线部分或作为数据上限的部分。当股价接近支撑位时，价格往往具有足够的吸引力，人们会购买，从而提高价格(从支撑位向阻力位移动)。然而，当股票到达阻力时，它往往会鼓励人们卖出，使股价下跌(远离阻力，走向支撑)。

*图 7.10* 显示了支持(绿色)和阻力(红色)分别作为股价的下限和上限的例子；一旦价格触及这些界限中的任何一个，由于股票的买方/卖方采取行动，价格往往会向相反方向反弹:

![Figure 7.10 – Example support and resistance for Netflix stock in 2018
](image/Figure_7.10_B16834.jpg)

图 7.10-2018 年网飞股票的支撑和阻力示例

通常，**指数加权移动平均线**(**【EWMA】**)可以提供更好的趋势，因为我们可以额外强调最近的值。让我们看看指数平滑法如何处理我们的数据:

```
>>> ax = netflix_viz.exp_smoothing('close', [30, 90]) 
>>> netflix_viz.shade_region(
...     ax, x=('2020-04-01', '2020-10-01'),
...     color='blue', alpha=0.1
... )
>>> ax.set(title='Netflix Closing Price', ylabel='price ($)')
```

90 天 EWMA 似乎是阴影区域的支撑位:

![Figure 7.11 – Netflix stock price with EWMAs
](image/Figure_7.11_B16834.jpg)

图 7.11-网飞股票价格与 EWMAs

小费

笔记本包含一个使用小部件的移动平均线和 EWMA 的交互式可视化单元。我们可以使用这些类型的可视化来确定计算的最佳窗口。请注意，使用此单元格可能需要一些额外的设置，但这些都记录在笔记本中单元格的正上方。

在 [*第五章*](B16834_05_Final_SK_ePub.xhtml#_idTextAnchor106) 、*用 Pandas 和 Matplotlib* 可视化数据的练习中，我们编写了代码，用于生成一个可视化图形，表示盘后交易对脸书的影响；`StockVisualizer`类也有这个功能。让我们用`after_hours_trades()`的方法来看看网飞的表现如何:

```
>>> netflix_viz.after_hours_trades()
```

就盘后交易而言，网飞 2019 年第三季度表现不佳:

![Figure 7.12 – Visualizing the effect of after-hours trading on Netflix stock
](image/Figure_7.12_B16834.jpg)

图 7.12–可视化盘后交易对网飞股票的影响

我们可以用蜡烛图来研究 OHLC 的数据。让我们用`candlestick()`方法为网飞创建一个柱状图，以及交易量柱状图。我们还会将数据重新取样为 2 周的间隔，以提高烛台的可见性:

```
>>> netflix_viz.candlestick(
...     resample='2W', volume=True, xrotation=90, 
...     datetime_format='%Y-%b –'
... )
```

记得从*图 7.8* 中得知，当烛台的主体是白色的时候，意味着股票增值了。请注意，在大多数情况下，交易量的激增伴随着股票价值的增加:

![Figure 7.13 – Candlestick plot with trading volume
](image/Figure_7.13_B16834.jpg)

图 7.13-交易量的蜡烛图

小费

交易员使用蜡烛图来寻找和分析资产表现的模式，这可以用来做出交易决策。查看这篇文章，了解蜡烛图的介绍和交易者寻找的一些常见模式:[https://www . investopedia . com/trading/烛台图表是什么/](https://www.investopedia.com/trading/candlestick-charting-what-is-it/) 。

在继续之前，我们需要重置我们的绘图样式。`mplfinance`包为它的情节设置了许多可用的样式选项，所以现在让我们回到我们熟悉的样式:

```
>>> import matplotlib as mpl
>>> mpl.rcdefaults()
>>> %matplotlib inline
```

在前几章中，我们已经单独研究了一支股票(脸书),所以让我们换个方向，将网飞与其他股票进行比较。让我们使用`jointplot()`方法来看看网飞与标准普尔 500 相比如何:

```
>>> netflix_viz.jointplot(sp, 'close')
```

如果我们看一下图，它们似乎是弱正相关的。通过金融分析，我们可以计算出一个叫做**贝塔**的指标，它表明一项资产与一个指数的相关性，比如标准普尔 500 指数。我们将在本章后面的*金融工具的技术分析*部分计算贝塔系数:

![Figure 7.14 – Comparing Netflix to the S&P 500
](image/Figure_7.14_B16834.jpg)

图 7.14-网飞和标准普尔 500 的比较

我们可以使用`correlation_heatmap()`方法将网飞和亚马逊之间的相关性可视化为热图，使用每个列的每日百分比变化:

```
>>> netflix_viz.correlation_heatmap(amzn)
```

网飞和亚马逊有微弱的正相关，但只是在 OHLC 的数据上:

![Figure 7.15 – Correlation heatmap between Netflix and Amazon
](image/Figure_7.15_B16834.jpg)

图 7.15-网飞和亚马逊之间的关联热图

最后，我们可以使用`fill_between_other()`方法来查看另一项资产相对于网飞的价格是如何上涨(或下跌)的。我们将网飞与特斯拉进行比较，看看一只股票超越另一只股票的例子:

```
>>> tsla = reader.get_ticker_data('TSLA')
>>> change_date = (tsla.close > nflx.close).idxmax()
>>> ax = netflix_viz.fill_between_other(tsla)
>>> netflix_viz.add_reference_line(
...     ax, x=change_date, color='k', linestyle=':', alpha=0.5,
...     label=f'TSLA > NFLX {change_date:%Y-%m-%d}'
... )
```

请注意，阴影区域在接近参考线时高度会缩小，这是网飞股票和特斯拉股票之间的差值随着时间的推移而减小。在 2020 年 11 月 11 日，随着特斯拉超过网飞，阴影区域的颜色发生变化(从绿色变为红色),并且随着特斯拉扩大差距，阴影区域的高度开始增加:

![Figure 7.16 – Stock price differential between Netflix and Tesla
](image/Figure_7.16_B16834.jpg)

图 7.16-网飞和特斯拉之间的股价差异

到目前为止，我们已经讨论了可视化单个资产——在本例中是网飞——所以让我们继续，看看我们如何使用`AssetGroupVisualizer`类跨资产组执行一些 EDA。

## 可视化多项资产

正如我们之前对所做的，我们将从继承`Visualizer`类开始，并编写我们的 docstring。注意，`AssetGroupVisualizer`类也跟踪用于`groupby()`操作的列，所以我们覆盖了`__init__()`方法；因为这种改变是对已有内容的补充，所以我们也调用超类的`__init__()`方法:

```
class AssetGroupVisualizer(Visualizer):
    """Visualizes groups of assets in a single dataframe."""
    # override for group visuals
 def __init__(self, df, group_by='name'):
 """This object keeps track of the group by column."""
 super().__init__(df)
 self.group_by = group_by
```

接下来，我们定义了`evolution_over_time()`方法，在单个绘图中为组中的所有资产绘制相同的列，以便进行比较。由于我们的数据是不同的形式，这次我们将使用`seaborn`:

```
    def evolution_over_time(self, column, **kwargs):
        """
        Visualize the evolution over time for all assets.
        Parameters:
            - column: The name of the column to visualize.
            - kwargs: Additional arguments to pass down.
        Returns: A matplotlib `Axes` object.
        """
        if 'ax' not in kwargs:
            fig, ax = plt.subplots(1, 1, figsize=(10, 4))
        else:
            ax = kwargs.pop('ax')
        return sns.lineplot(
            x=self.data.index, y=column, hue=self.group_by,
            data=self.data, ax=ax, **kwargs
        )
```

当使用`seaborn`或者只策划单一资产时，我们不必担心的布局我们的支线剧情；然而，对于其他一些资产组可视化，我们需要一种方法来自动确定一个合理的子情节布局。为此，我们将添加`_get_layout()`方法，该方法将为给定数量的子剧情(由组中唯一资产的数量决定)生成我们需要的`Figure`和`Axes`对象:

```
    def _get_layout(self):
        """
        Helper method for getting an autolayout of subplots.
        Returns: `Figure` and `Axes` objects to plot with.
        """
        subplots_needed = self.data[self.group_by].nunique()
        rows = math.ceil(subplots_needed / 2)
        fig, axes = \
            plt.subplots(rows, 2, figsize=(15, 5 * rows))
        if rows > 1:
            axes = axes.flatten()
        if subplots_needed < len(axes):
            # remove excess axes from autolayout
            for i in range(subplots_needed, len(axes)):
                # can't use comprehension here
                fig.delaxes(axes[i])
        return fig, axes
```

现在，我们需要定义`_window_calc()`将如何与团队合作。我们将需要使用我们的`_get_layout()`方法为组中的每个资产构建支线剧情:

```
    def _window_calc(self, column, periods, name, func,  
                     named_arg, **kwargs):
        """
        Helper method for plotting a series and adding
        reference lines using a window calculation.
        Parameters:
            - column: The name of the column to plot.
            - periods: The rule/span or list of them to pass 
              to the resampling/smoothing function, like '20D' 
              for 20-day periods (resampling) or 20 for a 
              20-day span (smoothing)
            - name: The name of the window calculation (to 
              show in the legend).
            - func: The window calculation function.
            - named_arg: The name of the argument `periods` 
              is being passed as.
            - kwargs: Additional arguments to pass down.
        Returns: 
            A matplotlib `Axes` object.
        """
        fig, axes = self._get_layout()
        for ax, asset_name in zip(
            axes, self.data[self.group_by].unique()
        ):
            subset = self.data.query(
                f'{self.group_by} == "{asset_name}"'
            )
            ax = subset.plot(
                y=column, ax=ax, label=asset_name, **kwargs
            )
            for period in self._iter_handler(periods):
                subset[column].pipe(
                    func, **{named_arg: period}
                ).mean().plot(
                    ax=ax, linestyle='--',
                    label=f"""{period if isinstance(
                        period, str
                    ) else str(period) + 'D'} {name}"""
                )
            ax.legend()
         plt.tight_layout()
         return ax
```

我们可以覆盖`after_hours_trades()`到,使用支线剧情和迭代组中的资产来可视化盘后交易对一组资产的影响:

```
    def after_hours_trades(self):
        """
        Visualize the effect of after-hours trading.
        Returns: A matplotlib `Axes` object.
        """
        num_categories = self.data[self.group_by].nunique()
        fig, axes = plt.subplots(
            num_categories, 2, figsize=(15, 3 * num_categories)
        )
        for ax, (name, data) in zip(
            axes, self.data.groupby(self.group_by)
        ):
            after_hours = data.open - data.close.shift()
            monthly_effect = after_hours.resample('1M').sum()
            after_hours.plot(
                ax=ax[0], 
                title=f'{name} Open Price - Prior Day\'s Close'
            ).set_ylabel('price')
            monthly_effect.index = \
                monthly_effect.index.strftime('%Y-%b')
            monthly_effect.plot(
                ax=ax[1], kind='bar', rot=90,
                color=np.where(monthly_effect >= 0, 'g', 'r'),
                title=f'{name} after-hours trading '
                      'monthly effect'
            ).axhline(0, color='black', linewidth=1)
            ax[1].set_ylabel('price')
        plt.tight_layout()
        return axes
```

使用`StockVisualizer`类的,我们能够生成两个资产收盘价之间的联合图，但是在这里我们可以覆盖`pairplot()`,以允许我们查看组中资产收盘价之间的关系:

```
    def pairplot(self, **kwargs):
        """
        Generate a seaborn pairplot for this asset group.
        Parameters:
            - kwargs: Keyword arguments to pass down.
        Returns: A seaborn pairplot
        """
        return sns.pairplot(
            self.data.pivot_table(
                values='close', index=self.data.index, 
                columns=self.group_by
            ), diag_kind='kde', **kwargs
        )
```

最后，我们添加了`heatmap()`方法，该方法生成该组中所有资产的收盘价之间相关性的热图:

```
    def heatmap(self, pct_change=True, **kwargs):
        """
        Generate a heatmap for correlations between assets.
        Parameters:
            - pct_change: Whether to show the correlations 
              of the daily percent change in price.
            - kwargs: Keyword arguments to pass down.
        Returns: A seaborn heatmap
        """
        pivot = self.data.pivot_table(
            values='close', index=self.data.index, 
            columns=self.group_by
        )
        if pct_change:
            pivot = pivot.pct_change()
        return sns.heatmap(
            pivot.corr(), annot=True, center=0, 
            vmin=-1, vmax=1, **kwargs
        )
```

我们可以使用和`heatmap()`方法来比较不同资产的每日百分比变化。这将处理资产之间的规模差异(谷歌和亚马逊的股价比脸书和苹果高得多，这意味着几美元的收益对脸书和苹果来说意味着更多):

```
>>> all_assets_viz = \
...     stock_analysis.AssetGroupVisualizer(all_assets)
>>> all_assets_viz.heatmap()
```

苹果-标准普尔 500 和脸书-谷歌的相关性最强，比特币与任何东西都没有相关性:

![Figure 7.17 – Correlations between asset prices
](image/Figure_7.17_B16834.jpg)

图 7.17–资产价格之间的相关性

为了简洁起见，我不会展示可视化资产组的所有方法，这将导致大量的绘图，我将让您在笔记本上查看和尝试。但是，让我们结合这些`Visualizers`来看看我们所有的资产是如何随着时间的推移而演变的:

```
>>> faang_sp_viz = \
...     stock_analysis.AssetGroupVisualizer(faang_sp)
>>> bitcoin_viz = stock_analysis.StockVisualizer(bitcoin)
>>> fig, axes = plt.subplots(1, 2, figsize=(15, 5))
>>> faang_sp_viz.evolution_over_time(
...     'close', ax=axes[0], style=faang_sp_viz.group_by
... )
>>> bitcoin_viz.evolution_over_time(
...     'close', ax=axes[1], label='Bitcoin'
... )
```

请注意，比特币在 2020 年获得了巨大的收益(查看*y*-轴上的比例)，亚马逊在 2020 年也有很大的增长:

![Figure 7.18 – Evolution of asset price over time
](image/Figure_7.18_B16834.jpg)

图 7.18–资产价格随时间的演变

现在，我们对数据有了很好的感觉，我们准备查看一些度量标准。请注意，虽然我们只查看和使用了代码的一个子集，但我鼓励您使用本章的笔记本来尝试一下`Visualizer`类中的所有方法；这些练习也将提供一个额外的机会来使用它们。

# 金融工具的技术分析

通过对资产进行技术分析，可以计算出各种指标(如累积回报和波动性)来比较各种资产。如同本章的前两节一样，我们将编写一个包含类的模块来帮助我们。我们将需要对单个资产进行技术分析的`StockAnalyzer`类和对一组资产进行技术分析的`AssetGroupAnalyzer`类。这些类在`stock_analysis/stock_analyzer.py`文件中。

与其他模块一样，我们将从 docstring 和 imports 开始:

```
"""Classes for technical analysis of assets."""
import math
from .utils import validate_df
```

## 股票分析器类

对于分析单个资产，我们将构建`StockAnalyzer`类，它计算给定资产的度量。下面的 UML 图显示了它提供的所有指标:

![Figure 7.19 – Structure of the StockAnalyzer class
](image/Figure_7.19_B16834.jpg)

图 7.19-股票分析器类的结构

一个`StockAnalyzer`实例将用我们想要对其执行技术分析的资产的数据进行初始化。这意味着我们的`__init__()`方法需要接受数据作为参数:

```
class StockAnalyzer:
    """Provides metrics for technical analysis of a stock."""
    @validate_df(columns={'open', 'high', 'low', 'close'})
    def __init__(self, df):
        """Create a `StockAnalyzer` object with OHLC data"""
        self.data = df
```

我们技术分析的大部分计算将依赖于股票的收盘价，所以我们不需要在所有方法中编写`self.data.close`，而是创建一个属性，这样我们就可以用`self.close`来访问它。这使得我们的代码更简洁，更容易理解:

```
    @property
    def close(self):
        """Get the close column of the data."""
        return self.data.close
```

一些计算也需要`close`列的百分比变化，所以我们也将创建一个属性以便于访问:

```
    @property
    def pct_change(self):
        """Get the percent change of the close column."""
        return self.close.pct_change()
```

因为我们将使用**支点**来计算支撑位和阻力位，支点【】是数据中最后一天的最高价、最低价和收盘价的平均值，所以我们也将为它创建一个属性:

```
    @property
    def pivot_point(self):
        """Calculate the pivot point."""
        return (self.last_close + self.last_high
                + self.last_low) / 3
```

请注意，我们还使用了其他属性— `self.last_close`、`self.last_high`和`self.last_low`—我们使用`last()`方法对数据进行定义，然后选择有问题的列并使用`iat[]`获得价格:

```
    @property
    def last_close(self):
        """Get the value of the last close in the data."""
        return self.data.last('1D').close.iat[0]
    @property
    def last_high(self):
        """Get the value of the last high in the data."""
        return self.data.last('1D').high.iat[0]
    @property
    def last_low(self):
        """Get the value of the last low in the data."""
        return self.data.last('1D').low.iat[0]
```

现在，我们有了计算支持和阻力所需的一切。我们将在三个不同的级别计算每一个级别，其中第一个级别最接近收盘价，第三个级别最远。因此，第一级将是限制性最强的一级，第三级将是限制性最弱的一级。我们将`resistance()`方法定义如下，允许调用者指定要计算的级别:

```
    def resistance(self, level=1):
        """Calculate the resistance at the given level."""
        if level == 1:
            res = (2 * self.pivot_point) - self.last_low
        elif level == 2:
            res = self.pivot_point \
                  + (self.last_high - self.last_low)
        elif level == 3:
            res = self.last_high \
                  + 2 * (self.pivot_point - self.last_low)
        else:
            raise ValueError('Not a valid level.')
        return res
```

`support()`方法是以类似方式定义的:

```
    def support(self, level=1):
        """Calculate the support at the given level."""
        if level == 1:
            sup = (2 * self.pivot_point) - self.last_high
        elif level == 2:
            sup = self.pivot_point \
                  - (self.last_high - self.last_low)
        elif level == 3:
            sup = self.last_low \
                  - 2 * (self.last_high - self.pivot_point)
        else:
            raise ValueError('Not a valid level.')
        return sup
```

接下来，我们将致力于创建分析资产波动性的方法。首先，我们将计算收盘价百分比变化的日标准差，为此我们需要指定交易周期的数量。为了确保我们不能使用比数据中更多的交易周期，我们将定义一个具有最大值的属性用于此参数:

```
    @property
    def _max_periods(self):
        """Get the number of trading periods in the data."""
        return self.data.shape[0]
```

现在有了最大值，我们可以定义`daily_std()`方法，它计算每日百分比变化的每日标准偏差:

```
    def daily_std(self, periods=252):
        """
        Calculate daily standard deviation of percent change.
        Parameters:
            - periods: The number of periods to use for the
              calculation; default is 252 for the trading days 
              in a year. Note if you provide a number greater  
              than the number of trading periods in the data,
              `self._max_periods` will be used instead.
        Returns: The standard deviation
        """
        return self.pct_change\
            [min(periods, self._max_periods) * -1:].std()
```

虽然`daily_std()`本身是有用的，但我们可以更进一步，通过将每日标准差乘以一年中交易周期数的平方根来计算年化波动率，我们假设交易周期数为 252:

```
    def annualized_volatility(self):
        """Calculate the annualized volatility."""
        return self.daily_std() * math.sqrt(252)
```

此外，我们可以通过使用`rolling()`方法来查看滚动波动率:

```
    def volatility(self, periods=252):
        """Calculate the rolling volatility.
        Parameters:
            - periods: The number of periods to use for the 
              calculation; default is 252 for the trading  
              days in a year. Note if you provide a number  
              greater than the number of trading periods in the
              data, `self._max_periods` will be used instead.
        Returns: A `pandas.Series` object.
        """
        periods = min(periods, self._max_periods)
        return self.close.rolling(periods).std()\
               / math.sqrt(periods)
```

我们经常想要比较资产，所以我们提供了`corr_with()`方法，使用每日百分比变化来计算它们之间的相关性:

```
    def corr_with(self, other):
        """Calculate the correlations between dataframes.
        Parameters:
            - other: The other dataframe.
        Returns: A `pandas.Series` object
        """
        return \
            self.data.pct_change().corrwith(other.pct_change())
```

接下来，我们定义一些用于比较资产分散程度的指标。在 [*第 1 章*](B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015) 、*数据分析简介*中，我们讨论了变异系数(`cv()`方法)和分位离散系数(`qcd()`方法)，我们可以使用这两种方法来实现这一点，我们将在此添加这两种方法:

```
    def cv(self):
        """
        Calculate the coefficient of variation for the asset.
        The lower this is, the better the risk/return tradeoff.
        """
        return self.close.std() / self.close.mean()
    def qcd(self):
        """Calculate the quantile coefficient of dispersion."""
        q1, q3 = self.close.quantile([0.25, 0.75])
        return (q3 - q1) / (q3 + q1) 
```

此外，我们希望有一种方法来量化资产相对于指数的波动性，例如标准普尔 500，为此我们计算**贝塔**——资产回报的协方差和指数回报与资产回报方差的比率。我们添加了`beta()`方法，它允许用户指定用作基准的索引:

```
    def beta(self, index):
        """
        Calculate the beta of the asset.
        Parameters:
            - index: The data for the index to compare to.
        Returns: 
            Beta, a float.
        """
        index_change = index.close.pct_change()
        beta = self.pct_change.cov(index_change)\
               / index_change.var()
        return beta
```

接下来，我们定义一个方法来计算一个资产作为一个系列的累积回报。这被定义为 1 加上收盘价百分比变化的累积乘积:

```
    def cumulative_returns(self):
        """Calculate cumulative returns for plotting."""
        return (1 + self.pct_change).cumprod()
```

我们想要支持的下几个指标需要计算投资组合的回报。为简单起见，我们将假设每股没有分布，因此投资组合的回报是在数据覆盖的时间期间从起始价格到终止价格的百分比变化。我们将把它定义为一个静态方法，因为我们需要为一个索引计算它，而不仅仅是存储在`self.data`中的数据:

```
    @staticmethod
    def portfolio_return(df):
        """
        Calculate return assuming no distribution per share.
        Parameters:
            - df: The asset's dataframe.
        Returns: The return, as a float.
        """
        start, end = df.close[0], df.close[-1]
        return (end - start) / start
```

贝塔让我们能够将资产的波动性与指数进行比较，**阿尔法**让我们能够将资产的回报与指数的回报进行比较。要做到这一点，我们还需要无风险收益率，即没有财务损失风险的投资的收益率；在实践中，我们使用美国国库券来实现这一点。计算 alpha 需要计算指数和资产的投资组合回报，以及 beta:

```
    def alpha(self, index, r_f):
        """
        Calculates the asset's alpha.
        Parameters:
            - index: The index to compare to.
            - r_f: The risk-free rate of return.
        Returns: Alpha, as a float.
        """
        r_f /= 100
        r_m = self.portfolio_return(index)
        beta = self.beta(index)
        r = self.portfolio_return(self.data)
        alpha = r - r_f - beta * (r_m - r_f)
        return alpha
```

小费

在将结果存储回`r_f`之前，前面的代码片段中的`r_f /= 100`将`r_f`除以`100`。这是`r_f = r_f / 100`的简写。Python 也为其他算术函数提供了这些操作符——例如，`+=`、`-=`、`*=`和`%=`。

我们还想添加方法，它将告诉我们资产是处于**熊市**还是**牛市**，这意味着在过去的两个月中，它的股价分别下跌或上涨了20%或更多:

```
    def is_bear_market(self):
        """
        Determine if a stock is in a bear market, meaning its
        return in the last 2 months is a decline of 20% or more
        """
        return \
            self.portfolio_return(self.data.last('2M')) <= -.2
    def is_bull_market(self):
        """
        Determine if a stock is in a bull market, meaning its
        return in the last 2 months is an increase of >= 20%.
        """
        return \
            self.portfolio_return(self.data.last('2M')) >= .2
```

最后，我们将添加一个用于计算**夏普比率**的方法，该方法告诉我们，对于我们承担的投资波动，我们获得的回报超过了无风险回报率:

```
    def sharpe_ratio(self, r_f):
        """
        Calculates the asset's Sharpe ratio.
        Parameters:
            - r_f: The risk-free rate of return.
        Returns: 
            The Sharpe ratio, as a float.
        """
        return (
            self.cumulative_returns().last('1D').iat[0] - r_f
        ) / self.cumulative_returns().std()
```

花一些时间来消化本模块中的代码，因为我们将继续构建我们已经讨论过的内容。我们不会在技术分析中使用所有这些指标，但是我鼓励你在本章的笔记本中尝试一下。

## AssetGroupAnalyzer 类

我们将在本节中使用的所有计算都是在的`StockAnalyzer`类中定义的；然而，我们不必为我们想要比较的每个资产运行这些，我们还将创建能够为一组资产提供这些度量的`AssetGroupAnalyzer`类(在同一个模块中)。

`StockAnalyzer`和`AssetGroupAnalyzer`类将共享它们的大部分功能，这为用继承来设计它们提供了有力的论据；然而，有时候——就像在这种情况下——构图可能更有意义。当对象包含其他类的实例时，称为**合成**。这个设计决策留给我们下面这个非常简单的`AssetGroupAnalyzer`类的 UML 图:

![Figure 7.20 – Structure of the AssetGroupAnalyzer class
](image/Figure_7.20_B16834.jpg)

图 7.20-AssetGroupAnalyzer 类的结构

我们通过提供资产的数据帧和分组列的名称来创建一个`AssetGroupAnalyzer`实例(如果不是`name`)。在初始化时，调用`_composition_handler()`方法来创建一个`StockAnalyzer`对象的字典(每个资产一个):

```
class AssetGroupAnalyzer:
    """Analyzes many assets in a dataframe."""
    @validate_df(columns={'open', 'high', 'low', 'close'})
    def __init__(self, df, group_by='name'):
        """
        Create an `AssetGroupAnalyzer` object with a 
        dataframe of OHLC data and column to group by.
        """
        self.data = df 
 if group_by not in self.data.columns:
 raise ValueError(
 f'`group_by` column "{group_by}" not in df.'
 ) 
 self.group_by = group_by
 self.analyzers = self._composition_handler()
    def _composition_handler(self):
        """
        Create a dictionary mapping each group to its analyzer,
        taking advantage of composition instead of inheritance.
        """
        return {
 group: StockAnalyzer(data)
 for group, data in self.data.groupby(self.group_by)
 }
```

`AssetGroupAnalyzer`类只有一个公共方法`analyze()`——所有实际的计算都委托给存储在`analyzers`属性中的`StockAnalyzer`对象:

```
    def analyze(self, func_name, **kwargs):
        """
        Run a `StockAnalyzer` method on all assets.
        Parameters:
            - func_name: The name of the method to run.
            - kwargs: Additional arguments to pass down.
        Returns: 
            A dictionary mapping each asset to the result 
            of the calculation of that function.
        """
        if not hasattr(StockAnalyzer, func_name):
            raise ValueError(
                f'StockAnalyzer has no "{func_name}" method.'
            )
        if not kwargs:
            kwargs = {}
        return {
 group: getattr(analyzer, func_name)(**kwargs)
 for group, analyzer in self.analyzers.items()
 }
```

有了继承，在这种情况下，所有的方法都必须被覆盖，因为它们不能处理`groupby()`操作。相反，使用组合，所有需要做的就是为每个资产创建`StockAnalyzer`对象，并使用字典理解进行计算。另一件有趣的事情是，通过使用`getattr()`，不需要镜像`AssetGroupAnalyzer`类中的方法，因为`analyze()`可以使用`StockAnalyzer`对象通过名称获取方法。

## 比较资产

让我们使用的`AssetGroupAnalyzer`类来比较我们已经收集数据的所有资产。和前面的章节一样，我们不会在这里使用`StockAnalyzer`类中的所有方法，所以请务必自己尝试一下:

```
>>> all_assets_analyzer = \
...     stock_analysis.AssetGroupAnalyzer(all_assets)
```

记得从 [*第一章*](B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015) 、*数据分析简介*中得知**变异系数** ( **CV** )是标准差与均值之比；这有助于我们比较资产收盘价的变化，即使它们的平均值大小不同(例如，亚马逊和苹果)。CV 也可用于比较投资的波动性和预期回报，并量化风险回报权衡。让我们用 CV 来看看哪种资产的收盘价分布最广:

```
>>> all_assets_analyzer.analyze('cv')
{'Amazon': 0.2658012522278963,
 'Apple': 0.36991905161737615,
 'Bitcoin': 0.43597652683008137,
 'Facebook': 0.19056336194852783,
 'Google': 0.15038618497328074,
 'Netflix': 0.20344854330432688,
 'S&P 500': 0.09536374658108937}
```

比特币的利差最大，这大概并不奇怪。可以使用每日百分比变化来计算年化波动率，而不是使用收盘价。这包括计算过去一年百分比变化的标准偏差，并将乘以一年中交易天数的平方根(代码假设为 252)。通过使用百分比变化，价格(相对于资产价格)的巨大变化将受到更严厉的惩罚。使用年化波动率，脸书看起来比我们使用 CV 时更不稳定(尽管仍然不是最不稳定的):

```
>>> all_assets_analyzer.analyze('annualized_volatility')
{'Amazon': 0.3851099077041784,
 'Apple': 0.4670809643500882,
 'Bitcoin': 0.4635140114227397,
 'Facebook': 0.45943066572169544,
 'Google': 0.3833720603377728,
 'Netflix': 0.4626772090887299,
 'S&P 500': 0.34491195196047003}
```

假设所有资产在数据集结束时都获得了价值，让我们检查一下是否有任何资产进入了**牛市**，这意味着资产在过去 2 个月的回报率为 20%或更高:

```
>>> all_assets_analyzer.analyze('is_bull_market')
{'Amazon': False,
 'Apple': True,
 'Bitcoin': True,
 'Facebook': False,
 'Google': False,
 'Netflix': False,
 'S&P 500': False}
```

看起来苹果和比特币在 2020 年度过了相当长的 11 月和 12 月。其他资产似乎表现不佳；然而，他们都没有处于熊市(我们可以通过将`'is_bear_market'`传递给`analyze()`来确认这一点)。另一种分析波动性的方法是通过计算**贝塔**将资产与指数进行比较。大于 1 的正值表示波动率高于指数，而小于-1 的负值表示与指数成反比:

```
>>> all_assets_analyzer.analyze('beta', index=sp)
{'Amazon': 0.7563691182389207,
 'Apple': 1.173273501105916,
 'Bitcoin': 0.3716024282483362,
 'Facebook': 1.024592821854751,
 'Google': 0.98620762504024,
 'Netflix': 0.7408228073823271,
 'S&P 500': 1.0000000000000002}
```

使用之前结果的 betas，我们可以看到，与标准普尔 500 相比，苹果是最不稳定的，这意味着如果这是我们的投资组合(暂时不考虑比特币)，加入苹果会增加投资组合的风险。然而，我们知道比特币与标准普尔 500 并不相关(参见*图 7.17* 中的相关热图)，所以这个低 beta 是误导性的。

我们要看的最后一个指标是 **alpha** ，它用于比较投资对市场的回报。计算 alpha 需要我们传入无风险收益率(`r_f`)；我们通常用美国国库券的回报来表示这个数字。利率可在[https://www . treasury . gov/resource-center/data-chart-center/interest-rates/pages/textview . aspx 查询？数据=产量](https://www.treasury.gov/resource-center/data-chart-center/interest-rates/pages/TextView.aspx?data=yield)；或者，我们可以使用我们的`StockReader`对象(`reader`)来为我们收集它。让我们使用标准普尔 500 指数来比较资产的阿尔法值:

```
>>> r_f = reader.get_risk_free_rate_of_return() # 0.93
>>> all_assets_analyzer.analyze('alpha', index=sp, r_f=r_f)
{'Amazon': 0.7383391908270172,
 'Apple': 1.7801122522388666,
 'Bitcoin': 6.355297988074054,
 'Facebook': 0.5048625273190841,
 'Google': 0.18537197824248092,
 'Netflix': 0.6500392764754642,
 'S&P 500': -1.1102230246251565e-16}
```

一切都战胜了标准普尔 500，它本质上是一个由 500 只股票组成的投资组合，由于**多样化**，风险和回报都较低。这给我们带来了累积回报，它显示了我们投资的每一美元的回报。为了使这个情节在黑白文本中更容易理解，我们将创建一个定制的`Cycler`对象([https://matplotlib.org/cycler/](https://matplotlib.org/cycler/))，它可以改变颜色和线条样式:

```
>>> from cycler import cycler
>>> bw_viz_cycler = (
...     cycler(color=[plt.get_cmap('tab10')(x/10)
...                   for x in range(10)])
...     + cycler(linestyle=['dashed', 'solid', 'dashdot',
...                         'dotted', 'solid'] * 2))
>>> fig, axes = plt.subplots(1, 2, figsize=(15, 5))
>>> axes[0].set_prop_cycle(bw_viz_cycler)
>>> cumulative_returns = \
...     all_assets_analyzer.analyze('cumulative_returns')
>>> for name, data in cumulative_returns.items():
...     data.plot(
...         ax=axes[1] if name == 'Bitcoin' else axes[0], 
...         label=name, legend=True
...     )
>>> fig.suptitle('Cumulative Returns')
```

尽管在 2020 年初经历了挣扎，所有的资产都增值了。请注意，比特币支线剧情的*y*-轴从 0 到 7(右侧支线剧情)，而股票市场支线剧情(左侧)覆盖了该范围的一半:

![Figure 7.21 – Cumulative returns for all assets
](image/Figure_7.21_B16834.jpg)

图 7.21–所有资产的累积回报

现在我们已经很好地理解了如何分析金融工具，让我们试着预测未来的表现。

# 使用历史数据模拟性能

本节的目标是让我们体验一下如何构建一些模型；因此，下面的例子并不意味着是最好的可能模型，而是一个简单且相对快速的学习实现。同样，`stock_analysis`包有一个类用于这个部分的任务:`StockModeler`。

重要说明

为了全面理解本节的统计元素和一般的建模，我们需要对统计学有一个扎实的理解；然而，本次讨论的目的是展示如何将建模技术应用于金融数据，而无需纠结于底层数学。

## stock modeler 类

`StockModeler`类将使我们更容易构建和评估一些简单的金融模型，而不需要直接与`statsmodels`包交互。此外，我们将减少使用我们创建的方法生成模型所需的步骤数量。下面的 UML 图显示这是一个相当简单的类。注意我们没有属性，因为`StockModeler`是一个**静态类**(意味着我们没有实例化它):

![Figure 7.22 – Structure of the StockModeler class
](image/Figure_7.22_B16834.jpg)

图 7.22-stock modeler 类的结构

在`stock_analysis/stock_modeler.py`中定义了`StockModeler`类,它有构建模型和对它们的性能做一些初步分析的方法。像往常一样，我们用 docstring 和 imports 启动模块:

```
"""Simple time series modeling for stocks."""
import matplotlib.pyplot as plt
import pandas as pd
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.seasonal import seasonal_decompose
import statsmodels.api as sm
from .utils import validate_df
```

接下来，我们将启动`StockModeler`类，如果有人试图实例化它，就会引发一个错误:

```
class StockModeler:
    """Static methods for modeling stocks."""
    def __init__(self):
        raise NotImplementedError(
            "This class must be used statically: " 
            "don't instantiate it."
        )
```

我们希望这个类支持的任务之一是时间序列分解，这一点  we 在 [*第一章*](B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015) 、*数据分析简介*中讨论过。我们从`statsmodels`中导入了`seasonal_decompose()`函数，所以我们只需在我们的`decompose()`方法中对收盘价调用它:

```
    @staticmethod
    @validate_df(columns={'close'}, instance_method=False)
    def decompose(df, period, model='additive'):
        """
        Decompose the closing price of the stock into 
        trend, seasonal, and remainder components.
        Parameters:
            - df: The dataframe containing the stock closing
              price as `close` and with a time index.
            - period: The number of periods in the frequency.
            - model: How to compute the decomposition
              ('additive' or 'multiplicative')
        Returns:
            A `statsmodels` decomposition object.
        """
        return seasonal_decompose(
            df.close, model=model, period=period
        )
```

注意我们有两个用于`decompose()`方法的装饰器。最顶层的装饰器是应用在它下面的结果上的。在本例中，我们有以下内容:

```
staticmethod(
    validate_df(
        decompose, columns={'close'}, instance_method=False
    )
)
```

此外，我们希望支持创建 ARIMA 模型，这一点我们在第 1 章 、*数据分析简介*中也讨论过。ARIMA 模型使用 *ARIMA(p，d，q)* 符号，其中 *p* 是 AR 模型的时滞(或阶)数， *d* 是从数据(I 模型)中减去的过去值数， *q* 是 MA 模型中使用的周期数。因此， *ARIMA(1，1，1)* 是一个自回归部分有一个时间滞后的模型，数据差分一次，一个 1 周期移动平均线。如果订单中有任何零，我们可以消除它们—例如， *ARIMA(1，0，1)* 等价于 *ARMA(1，1)* ， *ARIMA(0，0，3)* 等价于 *MA(3)* 。季节性 ARIMA 模型写作 *ARIMA(p，D，q)(P，D，Q)* m，其中 *m* 是季节性模型中的周期数，而 *P* 、 *D* 和 *Q* 是季节性 ARIMA 模型的订单。`StockModeler.arima()`方法不支持季节性成分(为了简单起见)，并且将 *p* 、 *d* 和 *q* 作为参数，但是为了避免混淆，我们将根据它们所代表的 ARIMA 特征来命名它们——例如，`ar`代表自回归( *p* )。此外，我们将让我们的静态方法在返回模型之前提供拟合模型的选项:

```
    @staticmethod
    @validate_df(columns={'close'}, instance_method=False)
    def arima(df, *, ar, i, ma, fit=True, freq='B'):
        """
        Create an ARIMA object for modeling time series.
        Parameters:
            - df: The dataframe containing the stock closing
              price as `close` and with a time index.
            - ar: The autoregressive order (p).
            - i: The differenced order (q).
            - ma: The moving average order (d).
            - fit: Whether to return the fitted model
            - freq: Frequency of the time series
        Returns: 
            A `statsmodels` ARIMA object which you can use 
            to fit and predict.
        """
        arima_model = ARIMA(
            df.close.asfreq(freq).fillna(method='ffill'), 
            order=(ar, i, ma)
        )
        return arima_model.fit() if fit else arima_model
```

小费

注意，方法签名(`df, *, ar, i, ma, ...`)中有一个星号(`*`)。当调用该方法时，这将强制在其后面列出的参数作为关键字参数提供。这是一个很好的方法来确保谁使用它是明确的他们想要什么。

为此，我们需要一种方法来评估 ARIMA 模型的预测，所以我们将添加`arima_predictions()`静态方法。我们还将提供选项，让将的预测作为`Series`对象或绘图返回:

```
    @staticmethod
    @validate_df(columns={'close'}, instance_method=False)
    def arima_predictions(df, arima_model_fitted, start, end,       
                          plot=True, **kwargs):
        """
        Get ARIMA predictions as a `Series` object or plot.
        Parameters:
            - df: The dataframe for the stock.
            - arima_model_fitted: The fitted ARIMA model.
            - start: The start date for the predictions.
            - end: The end date for the predictions.
            - plot: Whether to plot the result, default is
              `True` meaning the plot is returned instead of
              the `Series` object containing the predictions.
            - kwargs: Additional arguments to pass down.
        Returns: 
            A matplotlib `Axes` object or predictions 
            depending on the value of the `plot` argument.
        """
        predictions = \
            arima_model_fitted.predict(start=start, end=end)
        if plot:
            ax = df.close.plot(**kwargs)
            predictions.plot(
                ax=ax, style='r:', label='arima predictions'
            )
            ax.legend()
        return ax if plot else predictions
```

类似于我们为 ARIMA 模型建立的，我们也将提供`regression()`方法来建立收盘价的线性回归模型，滞后为 1。为此，我们将再次使用`statsmodels`(在 [*第九章*](B16834_09_Final_SK_ePub.xhtml#_idTextAnchor188) ，*Python 中的机器学习入门*，我们将使用`scikit-learn`进行线性回归代替):

```
    @staticmethod
    @validate_df(columns={'close'}, instance_method=False)
    def regression(df):
        """
        Create linear regression of time series with lag=1.
        Parameters:
            - df: The dataframe with the stock data.
        Returns: 
            X, Y, and the fitted model
        """
        X = df.close.shift().dropna()
        Y = df.close[1:]
        return X, Y, sm.OLS(Y, X).fit()
```

与`arima_predictions()`方法一样，我们希望提供一种方法来检查来自模型的预测，无论是作为`Series`对象还是作为绘图。与 ARIMA 模型不同，它一次只能预测一个值。因此，我们将在最后一个收盘价的后一天开始我们的预测，并迭代使用上一个预测来预测下一个。为了处理这一切，我们将编写`regression_predictions()`方法:

```
    @staticmethod
    @validate_df(columns={'close'}, instance_method=False)
    def regression_predictions(df, model, start, end, 
                               plot=True, **kwargs):
        """
        Get linear regression predictions as a `pandas.Series`
        object or plot.
        Parameters:
            - df: The dataframe for the stock.
            - model: The fitted linear regression model.
            - start: The start date for the predictions.
            - end: The end date for the predictions.
            - plot: Whether to plot the result, default is
              `True` meaning the plot is returned instead of
              the `Series` object containing the predictions.
            - kwargs: Additional arguments to pass down.
        Returns: 
            A matplotlib `Axes` object or predictions 
            depending on the value of the `plot` argument.
        """
        predictions = pd.Series(
            index=pd.date_range(start, end), name='close'
        )
        last = df.last('1D').close
        for i, date in enumerate(predictions.index):
            if not i:
                pred = model.predict(last)
            else:
                pred = model.predict(predictions.iloc[i - 1])
            predictions.loc[date] = pred[0]
        if plot:
            ax = df.close.plot(**kwargs)
            predictions.plot(
                ax=ax, style='r:', 
                label='regression predictions'
            )
            ax.legend()
        return ax if plot else predictions
```

最后，对于ARIMA 和线性回归模型，我们希望可视化预测中的误差，或**残差**。拟合的模型都有一个`resid`属性，它将给出残差；我们只需要将它们绘制成散点图来检查它们的方差，绘制成 KDE 来检查它们的均值。为此，我们将添加`plot_residuals()`方法:

```
    @staticmethod
    def plot_residuals(model_fitted, freq='B'):
        """
        Visualize the residuals from the model.
        Parameters:
            - model_fitted: The fitted model
            - freq: Frequency that the predictions were 
              made on. Default is 'B' (business day).
        Returns: 
            A matplotlib `Axes` object.
        """
        fig, axes = plt.subplots(1, 2, figsize=(15, 5))
        residuals = pd.Series(
            model_fitted.resid.asfreq(freq), name='residuals'
        )
        residuals.plot(
            style='bo', ax=axes[0], title='Residuals'
        )
        axes[0].set(xlabel='Date', ylabel='Residual')
        residuals.plot(
            kind='kde', ax=axes[1], title='Residuals KDE'
        )
        axes[1].set_xlabel('Residual')
        return axes
```

现在，让带的`StockModeler`类兜一圈，再次使用网飞的数据。

## 时间序列分解

正如在 [*第一章*](B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015) 、*数据分析介绍*中提到的，时间序列可以利用指定的频率分解成趋势、季节和余数成分。这可以通过`statsmodels`包来实现，其中`StockModeler.decompose()`正在使用:

```
>>> from stock_analysis import StockModeler
>>> decomposition = StockModeler.decompose(nflx, 20)
>>> fig = decomposition.plot()
>>> fig.suptitle(
...     'Netflix Stock Price Time Series Decomposition', y=1
... )
>>> fig.set_figheight(6)
>>> fig.set_figwidth(10)
>>> fig.tight_layout()
```

这将返回网飞的分解图，频率为 20 个交易日:

![Figure 7.23 – Time series decomposition of Netflix's stock price over time
](image/Figure_7.23_B16834.jpg)

图 7.23-网飞股票价格随时间的时间序列分解

对于更复杂的模型，我们可以分解，然后围绕组件构建我们的模型。然而，这已经超出了本章的范围，所以让我们继续讨论 ARIMA 模型。

## ARIMA

正如我们在第一章[](B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015)**数据分析简介*中讨论的，ARIMA 模型有自回归、差分、移动平均分量。它们也可以使用`statsmodels`包来构建，而`StockModeler.arima()`方法正在使用这个包；该方法根据提供的规格返回股票的拟合 ARIMA 模型。这里，我们将使用`%%capture`魔法来避免打印任何由 ARIMA 模型拟合触发的警告，因为我们正在制作一个简单的模型来探索功能:*

```
>>> %%capture
>>> arima_model = StockModeler.arima(nflx, ar=10, i=1, ma=5)
```

小费

我们选择这些值是因为它们在合理的时间内运行。在实践中，我们可以使用在 [*第 5 章*](B16834_05_Final_SK_ePub.xhtml#_idTextAnchor106) 、*用 Pandas 和 Matplotlib* 可视化数据中介绍的`pandas.plotting`模块中的`autocorrelation_plot()`函数，来帮助为`ar`找到一个好的值。

一旦模型被拟合，我们就可以用模型的`summary()`方法获得关于它的信息:

```
>>> print(arima_model.summary())
```

摘要是相当广泛的，并且当我们试图解释它时，我们应该阅读文档；不过，这篇文章很可能是更容易消化的介绍:[https://medium . com/analytics-vid hya/interpreting-ARMA-model-results-in-stats models-for-absolute-初学者-a4d22253ad1c](https://medium.com/analytics-vidhya/interpreting-arma-model-results-in-statsmodels-for-absolute-beginners-a4d22253ad1c) 。请注意，解释本摘要需要对统计数据有扎实的理解:

![Figure 7.24 – Summary of our ARIMA model
](image/Figure_7.24_B16834.jpg)

图 7.24–我们的 ARIMA 模型总结

出于我们的目的，分析模型的一种更简单的方法是查看**残差**，或者观察值和模型预测值之间的差异。残差的均值应该为 0，并且始终具有相等的方差，这意味着它们不应该依赖于自变量(在本例中是日期)。后一个要求是简称为**同伦性**；当这个假设不满足时，模型给出的估计就不是最优的。`StockModeler.plot_residuals()`方法有助于直观地检查这一点:

```
>>> StockModeler.plot_residuals(arima_model)
```

虽然残差的中心为 0(右侧子图)，但它们是**异方差的**——注意它们的方差看起来如何随着时间的推移而增加(左侧子图):

![Figure 7.25 – Evaluating the residuals of our ARIMA model
](image/Figure_7.25_B16834.jpg)

图 7.25-评估我们的 ARIMA 模型的残差

小费

当我们在*图 7.24* 中查看模型摘要时，`statsmodels`使用 0.05 的默认显著性水平对异方差性进行了统计测试。检验统计值标记为**异方差(H)** ，p 值标记为 **Prob(H)(双侧)**。请注意，结果具有统计显著性(p 值小于或等于显著性水平)，这意味着我们的残差不太可能是同伦的。

作为构建 ARIMA 模型的替代方案，`StockModeler`类还为我们提供了使用线性回归对金融工具的收盘价建模的选项。

## 用统计模型进行线性回归

`StockModeler.regression()`方法使用`statsmodels`为收盘价格建立一个线性回归模型，作为前一天收盘价的函数:

```
>>> X, Y, lm = StockModeler.regression(nflx)
>>> print(lm.summary())
```

再一次，`summary()`方法给出了模型拟合的统计数据:

![Figure 7.26 – Summary of our linear regression model
](image/Figure_7.26_B16834.jpg)

图 7.26–我们的线性回归模型总结

小费

看看这篇文章，获得一些如何解释摘要的指导:[https://medium . com/swlh/interpreting-linear-regression-through-stats models-summary-4796d 359035 a](https://medium.com/swlh/interpreting-linear-regression-through-statsmodels-summary-4796d359035a)。

调整后的 R2 让这个模型看起来非常好因为它接近 1(在 [*第九章*](B16834_09_Final_SK_ePub.xhtml#_idTextAnchor188) ，*Python 中的机器学习入门*，我们会进一步讨论这个度量)；然而，我们知道这仅仅是因为股票数据高度自相关，所以让我们再来看看残差:

```
>>> StockModeler.plot_residuals(lm)
```

这个模型也有异方差的问题:

![Figure 7.27 – Evaluating the residuals of our linear regression model
](image/Figure_7.27_B16834.jpg)

图 7.27-评估线性回归模型的残差

现在让我们看看ARIMA 模型或线性回归模型在预测网飞股票的收盘价方面表现更好。

## 比较模型

为了比较我们的模型，我们需要在一些新数据上测试它们的预测。让我们收集 2021 年 1 月前两周网飞股票的每日收盘价，并使用`StockModeler`类中的预测方法来可视化我们的模型预测与现实:

```
>>> import datetime as dt
>>> start = dt.date(2021, 1, 1)
>>> end = dt.date(2021, 1, 14)
>>> jan = stock_analysis.StockReader(start, end)\
...     .get_ticker_data('NFLX')
>>> fig, axes = plt.subplots(1, 2, figsize=(15, 5))
>>> arima_ax = StockModeler.arima_predictions(
...     nflx, arima_model, start=start, end=end, 
...     ax=axes[0], title='ARIMA', color='b'
... )
>>> jan.close.plot(
...     ax=arima_ax, style='b--', label='actual close'
... )
>>> arima_ax.legend()
>>> arima_ax.set_ylabel('price ($)')
>>> linear_reg = StockModeler.regression_predictions(
...     nflx, lm, start=start, end=end,
...     ax=axes[1], title='Linear Regression', color='b'
... )
>>> jan.close.plot(
...     ax=linear_reg, style='b--', label='actual close'
... )
>>> linear_reg.legend()
>>> linear_reg.set_ylabel('price ($)')
```

ARIMA 模型的预测看起来更符合我们的预期，但是，鉴于股票市场的不可预测性，这两个模型都与 2021 年 1 月前两周的实际情况相去甚远:

![Figure 7.28 – Model predictions versus reality
](image/Figure_7.28_B16834.jpg)

图 7.28–模型预测与现实对比

正如我们所见，预测股票表现并不容易，即使是几天。有很多数据没有被这些模型捕获,比如新闻报道、法规和管理的变化等等。无论一个模型看起来有多适合，都不要相信预测，因为这些都是推断，而且有很多不可解释的随机性。

为了进一步说明这一点，请看下面一组使用随机漫步和股票数据生成的图。只有一个是真实数据，但是哪个呢？答案跟随着情节，所以在看之前一定要猜一猜:

![Figure 7.29 – Real or fake stock data?
](image/Figure_7.29_B16834.jpg)

图 7.29-真实或虚假的股票数据？

这些时间序列每一个都源于同一点(微软 2019 年 7 月 1 日收盘价)，但是只有 **A** 是真实的股票数据——**B**、 **C** 、 **D** 都是随机游走。很难(或不可能)讲，对吧？

# 总结

在本章中，我们看到了如何为我们的分析应用构建 Python 包，从而使其他人能够轻松地执行他们自己的分析并重现我们的分析，以及让我们能够为未来的分析创建可重复的工作流。

我们在本章中创建的`stock_analysis`包包含了从互联网上收集股票数据的类(`StockReader`)；可视化个人资产或资产组(`Visualizer`家族)；计算单个资产或一组资产的指标进行比较(分别为`StockAnalyzer`和`AssetGroupAnalyzer`)；以及利用分解、ARIMA 和线性回归的时间序列建模(`StockModeler`)。我们也第一次看到在`StockModeler`类中使用`statsmodels`包。这一章向我们展示了我们在本书中已经介绍过的`pandas`、`matplotlib`、`seaborn`和`numpy`功能是如何结合在一起的，以及这些库是如何与定制应用的其他包协调工作的。我强烈建议你重读`stock_analysis`包中的代码，并测试一些我们在本章中没有提到的方法，以确保你理解了这些概念。

在下一章中，我们将开发另一个应用，学习如何为登录尝试构建一个模拟器，并尝试基于规则的异常检测。

# 练习

使用`stock_analysis`包完成以下练习。除非另有说明，否则使用 2019 年到 2020 年底的数据。如果用`StockReader`类收集数据有任何问题，备份 CSV 文件在`exercises/`目录中提供:

1.  使用`StockAnalyzer`和`StockVisualizer`类，计算并绘制网飞收盘价的三个支撑位和阻力位。
2.  With the `StockVisualizer` class, look at the effect of after-hours trading on the FAANG stocks:

    a)作为个股

    b)使用来自`stock_analysis.utils`模块的`make_portfolio()`函数作为投资组合

3.  使用`StockVisualizer.open_to_close()`方法，创建一个填充 FAANG 股票的开盘价(作为一个投资组合)和收盘价之间区域的图，如果价格下跌，用红色填充，如果价格上涨，用绿色填充。作为奖励，对比特币和标准普尔 500 指数的投资组合也是如此。
4.  共同基金和**交易所交易基金** ( **交易所交易基金**)是由许多资产组成的基金。它们旨在降低风险，因此基金的波动性将低于组成基金的资产的波动性。(关于它们有何不同的信息，请访问[https://www . investopedia . com/articles/exchange traded funds/08/ETF-mutual-fund-difference . ASP](https://www.investopedia.com/articles/exchangetradedfunds/08/etf-mutual-fund-difference.asp)。)使用年化波动率和`AssetGroupAnalyzer`类别，将你选择的一只共同基金或 ETF 与其三只最大的股票(按成分)进行比较。
5.  编写一个函数，返回一行数据帧，其中包含列`alpha`、`beta`、`sharpe_ratio`、`annualized_volatility`、`is_bear_market`和`is_bull_market`，每个列都包含使用`StockAnalyzer`类对给定股票运行各自方法的结果。在`AssetGroupAnalyzer.analyze()`方法中使用的字典理解和`getattr()`函数将会很有用。
6.  使用`StockModeler`类，根据 2019 年 1 月 1 日至 2020 年 11 月 30 日的 S & P 500 数据建立一个 ARIMA 模型，并使用它来预测 2020 年 12 月的表现。请务必检查残差，并将预测性能与实际性能进行比较。
7.  为 alpha vantage([https://www.alphavantage.co/support/#api-key](https://www.alphavantage.co/support/#api-key))请求一个 API 密钥，并使用`get_forex_rates()`方法在您为前面的练习收集数据而创建的同一个`StockReader`对象上收集美元对日元的每日汇率。使用从 2019 年 2 月到 2020 年 1 月的数据构建一个蜡烛图，以 1 周为间隔进行重新采样。提示:为了提供日期范围，请看一下标准库中的`slice()`函数([https://docs.python.org/3/library/functions.html#slice](https://docs.python.org/3/library/functions.html#slice))。

# 延伸阅读

请查阅以下资源，了解本章内容的更多信息:

*   *Python 的函数装饰器指南*:[https://www . the deship . com/patterns/guide-to-Python-function-decorators/](https://www.thecodeship.com/patterns/guide-to-python-function-decorators/)
*   *阿尔法*:https://www.investopedia.com/terms/a/alpha.asp
*   *Python 中的类和继承介绍*:[http://www . jesshamrick . com/2011/05/18/An-Introduction-to-Classes-and-Inheritance-in-Python/](http://www.jesshamrick.com/2011/05/18/an-introduction-to-classes-and-inheritance-in-python/)
*   *贝塔*:【https://www.investopedia.com/terms/b/beta.asp】T2
*   *变异系数(CV)*:[https://www . investopedia . com/terms/c/coefficientoffvariation . ASP](https://www.investopedia.com/terms/c/coefficientofvariation.asp)
*   *类(Python 文档)*:【https://docs.python.org/3/tutorial/classes.html 
*   *盘后交易如何影响股价*:[https://www . investopedia . com/ask/answers/05/saleafthours . ASP](https://www.investopedia.com/ask/answers/05/saleafterhours.asp)
*   *如何创建 Python 包*:[https://www . Python central . io/How-to-Create-a-Python-Package/](https://www.pythoncentral.io/how-to-create-a-python-package/)
*   *如何用 Python 创建时间序列预测的 ARIMA 模型*:[https://machine learning mastery . com/ARIMA-for-Time-Series-Forecasting-with-Python/](https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/)
*   *使用 statsmodels 在 Python 中进行线性回归*:【https://datatofish.com/statsmodels-linear-regression/ 
*   *面向对象编程*:【https://python.swaroopch.com/oop.html】T2
*   *随机漫步*:【https://en.wikipedia.org/wiki/Random_walk】T2
*   *股票分析*:【https://www.investopedia.com/terms/s/stock-analysis.asp 
*   *支持和阻力基础知识*:[https://www . investopedia . com/trading/Support-and-Resistance-Basics/](https://www.investopedia.com/trading/support-and-resistance-basics/)
*   *技术分析*:【https://www.investopedia.com/technical-analysis-4689657 
*   *关于如何在 Python 中使用静态、类或抽象方法的权威指南*:[https://Julien . danjou . info/guide-Python-static-class-abstract-methods/](https://julien.danjou.info/guide-python-static-class-abstract-methods/)
*   *编写安装脚本*:【https://docs.python.org/3/distutils/setupscript.html T3*