

# *第八章*:基于规则的异常检测

是时候抓住一些试图使用**暴力攻击**访问网站的黑客了——试图用一堆用户名和密码组合登录，直到他们获得访问权。这种类型的攻击非常嘈杂，因此它为我们的**异常检测**提供了大量数据点，异常检测是指寻找从我们认为不是典型活动的进程中生成的数据的过程。黑客将被模拟，不会像他们在现实生活中那样狡猾，但它会给我们很大的异常检测的机会。

我们将创建一个包来处理登录尝试的模拟，以便为本章生成数据。知道如何模拟是我们工具箱中的一项基本技能。有时候，很难用精确的数学解来解决问题；然而，定义系统的小组件如何工作可能很容易。在这些情况下，我们可以对小组件进行建模，并从整体上模拟系统的行为。模拟的结果给了我们一个近似的解决方案，可能足以满足我们的目的。

我们将利用基于规则的异常检测来识别模拟数据中的可疑活动。在本章结束时，我们将了解如何使用从各种概率分布中生成的随机数来模拟数据，更多地接触 Python 标准库，获得构建 Python 包的额外经验，练习执行探索性数据分析，并了解异常检测。

本章将涵盖以下主题:

*   模拟登录尝试为章节创建数据集
*   执行探索性数据分析以理解模拟数据
*   使用规则和基线进行异常检测

# 章节材料

我们将构建一个模拟包来生成本章的数据；它位于 GitHub 上的[https://GitHub . com/stef molin/log in-attempt-simulator/tree/2nd _ edition](https://github.com/stefmolin/login-attempt-simulator/tree/2nd_edition)。这个包是我们在 [*第一章*](B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015) ，*数据分析简介*中设置环境时从 GitHub 安装的；但是，您可以按照 [*第七章*](B16834_07_Final_SK_ePub.xhtml#_idTextAnchor146) 、*金融分析——比特币和股市*中的说明，安装一个您可以编辑的软件包版本。

本章的存储库可以在[https://github . com/stef molin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/tree/master/ch _ 08](https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/tree/master/ch_08)找到，其中包含我们将用于实际分析的笔记本(`anomaly_detection.ipynb`)、我们将在`logs/`文件夹中使用的数据文件、`user_data/`文件夹中用于模拟的数据以及`simulate.py`文件，后者包含一个 Python 脚本，我们可以在命令行上运行该脚本来模拟本章的数据。

# 模拟登录尝试

由于我们不容易从漏洞中找到登录尝试数据(由于其敏感性，通常不会共享)，我们将对其进行模拟。模拟需要对统计建模、估计某些事件的概率以及识别适当的假设进行必要的简化有很强的理解。为了运行模拟，我们将构建一个 Python 包(`login_attempt_simulator`)来模拟一个登录过程，该过程需要正确的用户名和密码(不需要任何额外的身份验证措施，例如双因素身份验证)和一个可以在命令行上运行的脚本(`simulate.py`)，这两者我们都将在本节中讨论。

## 假设

在我们进入处理模拟的代码之前，我们需要理解这些假设。当我们进行模拟时，不可能控制每一个可能的变量，所以我们必须确定一些简化的假设来开始。

模拟器对网站的有效用户做出以下假设:

*   有效用户根据**泊松过程**以每小时的速度到来，这取决于一周中的某一天和一天中的某个时间。泊松过程将每单位时间(我们的模拟将使用一小时)的到达时间建模为平均为λ(λ)的泊松分布。间期时间呈指数分布，平均值为 1/λ。
*   有效用户通过 1-3 个 IP 地址(使用互联网的每台设备的唯一标识符)进行连接，这些 IP 地址包含 4 个范围在[0，255]内的随机整数，用句点分隔。两个有效用户共享一个 IP 地址是可能的，尽管可能性极小。
*   Valid users are unlikely to make many mistakes while entering their credentials.

    重要说明

    到达间隔时间具有**无记忆**属性，这意味着两次连续到达之间的时间与下一次到达的时间无关。

模拟器对黑客做出以下假设:

*   黑客试图通过只测试几个用户名-密码组合来避免帐户锁定，而不是全面的**字典攻击**(对于每个用户，尝试黑客在他们维护的可能密码字典中的每个密码)。然而，他们不会在尝试之间增加延迟。
*   由于黑客不想造成拒绝服务，他们限制了攻击的数量，一次只尝试一次。
*   黑客知道系统中存在的账户数量，也很清楚用户名的格式，但他们猜测的是准确的用户名。他们会选择尝试猜测所有 133 个用户名，或其中的某个子集。
*   每一次攻击都是独立的，这意味着每一次攻击都有一个单独的黑客来执行，而且一个黑客从来不会攻击超过一次。
*   黑客不会分享关于哪个用户名和密码组合是正确的信息。
*   袭击发生的时间是随机的。
*   每个黑客将使用一个单一的 IP 地址，它是以与合法用户相同的方式生成的。然而，我们的模拟器能够改变这个 IP 地址，我们将在第 11 章 、*的 [*中查看这一功能，以使这一场景更具挑战性。*](B16834_11_Final_SK_ePub.xhtml#_idTextAnchor237)*
*   尽管可能性极小，但黑客有可能与合法用户拥有相同的 IP 地址。黑客甚至可能是合法用户。

我们也在抽象出一些密码猜测的复杂性；相反，我们使用随机数来确定密码是否被正确猜测——这意味着我们没有考虑网站如何存储密码，可能是明文(希望不是)、哈希(明文密码的不可逆转换，允许在不存储实际密码的情况下进行验证)或加盐哈希(请参考*进一步阅读*部分的相关文章)。在实践中，黑客可以访问存储的密码，并找出他们离线的内容(参见本章末尾的*进一步阅读*部分中关于彩虹表的文章)，在这种情况下，本章讨论的技术不会有所帮助，因为日志不会有他们尝试的记录。记住，这个模拟中的黑客非常显眼。

## 登录 _ 尝试 _ 模拟器包

这个包比前一章的`stock_analysis`包要轻得多；我们只有三个文件:

```
login_attempt_simulator
|-- __init__.py
|-- login_attempt_simulator.py
`-- utils.py
```

我们将在下面几节中逐一介绍这些文件。请注意，为了简洁起见，已经删除了部分文档字符串；查看文件本身以获得完整的文档。

### 助手功能

让我们从`utils.py`函数开始讨论，它是我们模拟器类的助手。首先，我们为模块创建 docstring 并处理我们的导入:

```
"""Utility functions for the login attempt simulator."""
import ipaddress
import itertools
import json
import random
import string
```

接下来，我们定义了`make_user_base()`函数，它为我们的 web 应用程序提供了用户基础。它通过将英文字母表中的一个小写字母与函数内列表中的每个姓氏组合起来，创建了一个用户名文件，并添加了一些管理帐户；这导致了 133 个账户的用户基础。通过写入文件，我们可以确保不必在每次运行模拟时都生成该文件，而只需从文件中读取即可在将来进行模拟:

```
def make_user_base(out_file):
    """Generate a user base and save it to a file."""
    with open(out_file, 'w') as user_base:
        for first, last in itertools.product(
            string.ascii_lowercase, 
            ['smith', 'jones', 'kim', 'lopez', 'brown']
        ): # makes 130 accounts
            user_base.write(first + last + '\n')
        # adds 3 more accounts
        for account in ['admin', 'master', 'dba']: 
            user_base.write(account + '\n')
```

因为我们将需要在模拟器中使用这个用户基础，所以我们还编写了一个函数来将用户基础文件读入一个列表。`get_valid_users()`函数将`make_user_base()`函数写的文件读回 Python 列表:

```
def get_valid_users(user_base_file):
    """Read in users from the user base file."""
    with open(user_base_file, 'r') as file:
        return [user.strip() for user in file.readlines()]
```

`random_ip_generator()`函数从形式为`xxx.xxx.xxx.xxx`的随机数中创建 IP 地址，其中`x`是一个在[0，255]范围内的整数。我们使用来自 Python 标准库的`ipaddress`模块(【https://docs.python.org/3/library/ipaddress.html】T4)来避免分配私有 IP 地址:

```
def random_ip_generator():
    """Randomly generate a fake IP address."""
    try:
        ip_address = ipaddress.IPv4Address('%d.%d.%d.%d' %
            tuple(random.randint(0, 255) for _ in range(4))
        )
    except ipaddress.AddressValueError:
        ip_address = random_ip_generator()
    return str(ip_address) if ip_address.is_global \
        else random_ip_generator()
```

我们的每个用户将有几个 IP 地址，他们试图登录。`assign_ip_addresses()`函数将 1-3 个随机 IP 地址映射到每个用户，创建一个字典:

```
def assign_ip_addresses(user_list):
    """Assign users 1-3 fake IP addresses."""
    return {
        user: [
            random_ip_generator()
            for _ in range(random.randint(1, 3))
        ] for user in user_list
    }
```

`save_user_ips()`和`read_user_ips()`函数将用户-IP 地址映射保存到一个 JSON 文件，并分别将其读回字典文件:

```
def save_user_ips(user_ip_dict, file):
    """Save the user-IP address mapping to a JSON file."""
    with open(file, 'w') as file:
        json.dump(user_ip_dict, file)
def read_user_ips(file):
    """Read in the JSON file of the user-IP address mapping."""
    with open(file, 'r') as file:
        return json.loads(file.read())
```

小费

Python 标准库有很多有用的模块，我们可能不会经常用到，但绝对值得了解。在这里，我们使用`json`模块将字典保存到 JSON 文件中，并在以后读取它们。我们使用`ipaddress`模块来处理 IP 地址，使用`string`模块来获取字母表中的字符，而无需将它们全部输入。

### LoginAttemptSimulator 类

文件`login_attempt_simulator.py`中的`LoginAttemptSimulator`类处理所有随机数生成逻辑执行模拟的繁重工作。像往常一样，我们从模块 docstring 和 imports 开始:

```
"""Simulator of login attempts from valid users and hackers."""
import calendar
import datetime as dt
from functools import partial
import math
import random
import string
import numpy as np
import pandas as pd
from .utils import random_ip_generator, read_user_ips
```

接下来，我们开始用 docstring 定义`LoginAttemptSimulator`类，以及一些用于存储常量的类变量。我们这样做是为了避免幻数(代码中似乎没有意义的数字)和我们将在多个地方使用的字符串的拼写错误。请注意，这些消息仅用于我们的日志；web 应用程序不会向最终用户显示身份验证尝试失败的原因(也不应该显示):

```
class LoginAttemptSimulator:
    """Simulate login attempts from valid users + attackers."""
    ATTEMPTS_BEFORE_LOCKOUT = 3
    ACCOUNT_LOCKED = 'error_account_locked'
    WRONG_USERNAME = 'error_wrong_username'
    WRONG_PASSWORD = 'error_wrong_password'
```

重要说明

请注意我们是如何使用类变量来存储常量的，比如错误消息，这样我们就不会在代码中冒输入错误的风险。这意味着每次我们使用这些错误消息时，文本都是相同的，这将保持数据的整洁。在 Python 中，常量通常都是大写的([https://www.python.org/dev/peps/pep-0008/#constants](https://www.python.org/dev/peps/pep-0008/#constants))。

`__init__()`方法将处理模拟器的设置，例如从指定的文件中读取用户基础，初始化日志，存储成功概率，并根据需要确定模拟的开始和结束日期:

```
    def __init__(self, user_base_json_file, start, end=None, *,
                 attacker_success_probs=[.25, .45],
                 valid_user_success_probs=[.87, .93, .95],
                 seed=None):
        # user, ip address dictionary
        self.user_base = read_user_ips(user_base_json_file)
        self.users = [user for user in self.user_base.keys()]
        self.start = start
        self.end = end if end else self.start + \
            dt.timedelta(days=random.uniform(1, 50))
        self.hacker_success_likelihoods = \
            attacker_success_probs
        self.valid_user_success_likelihoods = \
            valid_user_success_probs
        self.log = pd.DataFrame(columns=[
            'datetime', 'source_ip', 'username',
            'success', 'failure_reason'
        ])
        self.hack_log = \
            pd.DataFrame(columns=['start', 'end', 'source_ip'])
        self.locked_accounts = []
        # set seeds for random numbers from random and numpy:
        random.seed(seed)
        np.random.seed(seed)
```

`_record()`方法将每次尝试的结果附加到日志中，注明它来自的 IP 地址、用户名、时间、是否成功以及失败的原因(如果有的话):

```
    def _record(self, when, source_ip, username, success, 
                failure_reason):
        """
        Record the outcome of a login attempt.
        Parameters:
            - when: The datetime of the event.
            - source_ip: IP address the attempt came from.
            - username: The username used in the attempt.
            - success: Whether the attempt succeeded (Boolean).
            - failure_reason: Reason for the failure.
        Returns: 
            None, the `log` attribute is updated.
        """
        self.log = self.log.append({
            'datetime': when, 
            'source_ip': source_ip, 
            'username': username, 
            'success': success, 
            'failure_reason': failure_reason
        }, ignore_index=True)
```

`_attempt_login()`方法处理确定登录尝试是否成功的逻辑:

![Figure 8.1 – Simulation logic
](image/Figure_8.1_B16834.jpg)

图 8.1–模拟逻辑

我们提供输入正确用户名的概率(`username_accuracy`)和每次尝试成功输入密码的概率(`success_likelihoods`)。尝试次数是账户锁定前允许的尝试次数和成功概率列表长度的最小值(`success_likelihoods`)。使用**分支**(来自`functools`)将每次尝试的结果传递给`_record()`，这允许我们创建将某些参数固定为特定值的函数(因此我们不必连续传递相同的值):

```
    def _attempt_login(self, when, source_ip, username,
                       username_accuracy, success_likelihoods):
        """
        Simulates a login attempt, allowing for account
        lockouts, and recording the results.
        Parameters:
            - when: The datetime to start trying.
            - source_ip: IP address the attempt came from. 
            - username: The username being used in the attempt.
            - username_accuracy: Prob. username is correct.
            - success_likelihoods: List of probabilities that 
              password is correct (one per attempt).
        Returns:
            The datetime after trying.
        """
        current = when
        recorder = partial(self._record, source_ip=source_ip)
        if random.random() > username_accuracy:
            correct_username = username
            username = self._distort_username(username)
        if username not in self.locked_accounts:
            tries = len(success_likelihoods)
            for i in range(
                min(tries, self.ATTEMPTS_BEFORE_LOCKOUT)
            ):
                current += dt.timedelta(seconds=1)
                if username not in self.users:
                    recorder(
                        when=current, username=username, 
                        success=False,
                        failure_reason=self.WRONG_USERNAME
                    )
                    if random.random() <= username_accuracy:
                        username = correct_username
                    continue
                if random.random() <= success_likelihoods[i]:
                    recorder(
                        when=current, username=username,
                        success=True, failure_reason=None
                    )
                    break
                else:
                    recorder(
                        when=current, username=username, 
                        success=False,
                        failure_reason=self.WRONG_PASSWORD
                    )
            else:
                if tries >= self.ATTEMPTS_BEFORE_LOCKOUT \
                and username in self.users:
                    self.locked_accounts.append(username)
        else:
            recorder(
                when=current, username=username, success=False,
                failure_reason=self.ACCOUNT_LOCKED
            )
            if random.random() >= .5: # unlock account randomly
                self.locked_accounts.remove(username)
        return current
```

`_valid_user_attempts_login()`和`_hacker_attempts_login()`方法是`_attempt_login()`方法的包装器，分别处理有效用户和黑客的概率调整。请注意，虽然两者都使用高斯(正态)分布来确定用户名的准确性，但有效用户的分布具有更高的平均值和更低的标准差，这意味着他们在尝试登录时更有可能提供正确的用户名。这是因为，虽然合法用户可能会输入错误(偶尔)，但黑客们猜测:

```
    def _hacker_attempts_login(self, when, source_ip,
                               username):
        """Simulates a login attempt from an attacker."""
        return self._attempt_login(
            when=when, source_ip=source_ip, username=username,
            username_accuracy=random.gauss(mu=0.35, sigma=0.5),
            success_likelihoods=self.hacker_success_likelihoods
        )
    def _valid_user_attempts_login(self, when, username):
        """Simulates a login attempt from a valid user."""
        return self._attempt_login(
            when=when, username=username,
            source_ip=random.choice(self.user_base[username]),
            username_accuracy=\
                random.gauss(mu=1.01, sigma=0.01),
            success_likelihoods=\
                self.valid_user_success_likelihoods
        )
```

当模拟器确定不会正确提供用户名时，它调用`_distort_username()`方法，该方法随机决定从有效用户名中省略一个字母，或者用另一个字母替换其中一个字母。虽然黑客输入不正确的用户名是因为他们在猜测(不是因为打字错误)，但我们抽象出了这个细节，以便使用一个函数来为合法用户和黑客引入用户名错误:

```
    @staticmethod
    def _distort_username(username):
        """
        Alters the username to allow for wrong username login 
        failures. Randomly removes a letter or replaces a 
        letter in a valid username.
        """
        username = list(username)
        change_index = random.randint(0, len(username) - 1)
        if random.random() < .5: # remove random letter
            username.pop(change_index)
        else: # randomly replace a single letter
            username[change_index] = \
                random.choice(string.ascii_lowercase)
        return ''.join(username)
```

我们使用`_valid_user_arrivals()`方法生成在给定时间内到达的用户数量，并分别使用泊松和指数分布计算到达间隔时间:

```
    @staticmethod
    def _valid_user_arrivals(when):
        """
        Static method for simulating Poisson process of 
        arrivals (users wanting to log in). Lambda for the 
        Poisson varies depending upon the day and time of week.
        """
        is_weekday = when.weekday() not in (
            calendar.SATURDAY, calendar.SUNDAY
        )
        late_night = when.hour < 5 or when.hour >= 11
        work_time = is_weekday \
                    and (when.hour >= 9 or when.hour <= 17)
        if work_time:
 # hours 9-5 on work days get higher lambda 
 poisson_lambda = random.triangular(1.5, 5, 2.75)
 elif late_night:
 # hours in middle of night get lower lambda
 poisson_lambda = random.uniform(0.0, 5.0)
 else:
 poisson_lambda = random.uniform(1.5, 4.25)
 hourly_arrivals = np.random.poisson(poisson_lambda)
 interarrival_times = np.random.exponential(
 1/poisson_lambda, size=hourly_arrivals
 )
        return hourly_arrivals, interarrival_times
```

重要说明

我们使用`numpy`而不是`random`从指数分布中生成随机数，因为我们可以一次请求多个值(由泊松过程确定的每个小时到达一个值)。另外，注意`random`不提供泊松分布，所以我们需要`numpy`。

我们的模拟使用了许多不同的分布，所以看看它们是什么样子会很有帮助。下面的子图展示了我们正在使用的每个发行版的例子。请注意，泊松分布的绘制方式不同。这是因为泊松分布是离散的。出于这个原因，我们经常用它来建模到达——在这里，我们用它来建模试图登录的用户的到达。离散分布有一个**概率质量函数** ( **PMF** )代替**概率密度函数** ( **PDF** )的:

![Figure 8.2 – Distributions used in the simulation
](image/Figure_8.2_B16834.jpg)

图 8.2–模拟中使用的分布

`_hack()`方法为黑客生成一个随机的 IP 地址，对给定的用户列表进行暴力攻击:

```
    def _hack(self, when, user_list, vary_ips):
        """
        Simulate an attack by a random hacker.
        Parameters:
            - when: The datetime to start the attack.
            - user_list: The list of users to try to hack.
            - vary_ips: Whether or not to vary the IP address.
        Returns:
            Initial IP address and the end time for recording.
        """
        hacker_ip = random_ip_generator()
        random.shuffle(user_list)
        for user in user_list:
            when = self._hacker_attempts_login(
                when=when, username=user,
                source_ip=random_ip_generator() if vary_ips \
                    else hacker_ip
            )
        return hacker_ip, when
```

既然我们已经有了用来执行模拟的主要部分的功能，我们编写`simulate()`方法来把它们放在一起:

```
    def simulate(self, *, attack_prob, try_all_users_prob,
                 vary_ips):
        """
        Simulate login attempts.
        Parameters:
            - attack_probs: Probability of attack in given hour
            - try_all_users_prob: Prob. hacker will try to 
              guess credentials for all users vs random subset.
            - vary_ips: Whether to vary the IP address.
        """
        hours_in_date_range = math.floor(
            (self.end - self.start).total_seconds() / 60 / 60
        )
        for offset in range(hours_in_date_range + 1):
            current = self.start + dt.timedelta(hours=offset)
            # simulate hacker
 if random.random() < attack_prob:
                attack_start = current \
                    + dt.timedelta(hours=random.random())
                source_ip, end_time = self._hack(
                    when=attack_start,
                    user_list=self.users if \
 random.random() < try_all_users_prob \
 else random.sample(
 self.users, 
 random.randint(0, len(self.users))
                    ),
                    vary_ips=vary_ips
                )
                self.hack_log = self.hack_log.append(
                    dict(
                        start=attack_start, end=end_time, 
                        source_ip=source_ip
                    ), ignore_index=True
                )
            # simulate valid users
            hourly_arrivals, interarrival_times = \
                self._valid_user_arrivals(current)
            random_user = random.choice(self.users)
            random_ip = \
                random.choice(self.user_base[random_user])
            for i in range(hourly_arrivals):
 current += \
 dt.timedelta(hours=interarrival_times[i])
 current = self._valid_user_attempts_login(
 current, random_user
 )
```

我们希望将日志保存到 CSV 文件中，所以我们添加了`_save()`方法作为静态方法，以减少两个保存方法代码中的重复。`save_log()`方法将保存登录尝试，`save_hack_log()`方法将保存攻击的记录:

```
    @staticmethod
    def _save(data, filename, sort_column):
        """Sort data by the datetime and save to a CSV file."""
        data.sort_values(sort_column)\
            .to_csv(filename, index=False)
    def save_log(self, filename):
        """Save the login attempts log to a CSV file."""
        self._save(self.log, filename, 'datetime')
    def save_hack_log(self, filename):
        """Save the record of the attacks to a CSV file."""
        self._save(self.hack_log, filename, 'start')
```

注意，这个类中有许多私有方法；这是因为这个类的用户只需要能够创建这个类的一个实例(`__init__()`)、按小时模拟(`simulate()`)并保存输出(`save_log()`和`save_hack_log()`)——所有其他方法都供这个类的对象内部使用。幕后的方法将处理大部分工作。

最后，我们有了`__init__.py`文件，它使这个成为一个包，但是也为我们提供了一个更简单的方法来导入主类:

```
"""Package for simulating login data."""
from .login_attempt_simulator import LoginAttemptSimulator
```

现在我们已经了解了模拟器的工作原理，我们将讨论如何运行模拟来收集登录尝试数据。

## 从命令行模拟

我们不需要编写代码来模拟每次的登录尝试，而是可以将它打包到一个脚本中，我们可以很容易地从命令行运行它。Python 标准库有`argparse`模块([https://docs.python.org/3/library/argparse.html](https://docs.python.org/3/library/argparse.html))，它允许我们为脚本指定参数，这些参数可以从命令行提供。

让我们看看`simulate.py`文件，看看如何做到这一点。我们从进口开始:

```
"""Script for simulating login attempts."""
import argparse
import datetime as dt
import os
import logging
import random
import login_attempt_simulator as sim
```

为了在从命令行使用它时提供状态更新，我们将使用标准库的`logging`模块([https://docs.python.org/3/library/logging.html](https://docs.python.org/3/library/logging.html))来设置日志消息:

```
# Logging configuration
FORMAT = '[%(levelname)s] [ %(name)s ] %(message)s'
logging.basicConfig(level=logging.INFO, format=FORMAT)
logger = logging.getLogger(os.path.basename(__file__))
```

接下来，我们定义一些用于生成文件路径的实用函数，我们将需要在模拟期间读取和写入数据:

```
def get_simulation_file_path(path_provided, directory,
                             default_file):
    """Get filepath, make directory if necessary."""
    if path_provided:
        file = path_provided
    else:
        if not os.path.exists(directory):
            os.mkdir(directory)
        file = os.path.join(directory, default_file)
    return file
def get_user_base_file_path(path_provided, default_file):
    """Get the path for a user_data directory file."""
    return get_simulation_file_path(
        path_provided, 'user_data', default_file
    )
def get_log_file_path(path_provided, default_file):
    """Get the path for a logs directory file."""
    return get_simulation_file_path(
        path_provided, 'logs', default_file
    )
```

该脚本的最大部分定义了可以传递哪些命令行参数——我们将允许用户指定他们是否想要创建新的用户群、设置种子、何时开始模拟、模拟多长时间以及将所有文件保存在哪里。由于我们构建的包，实际的模拟只需要几行代码就可以完成。该部分仅在该模块运行时运行，而不是导入时运行:

```
if __name__ == '__main__':
    # command-line argument parsing
    parser = argparse.ArgumentParser()
 parser.add_argument(
 'days', type=float,
 help='number of days to simulate from start'
 )
 parser.add_argument(
 'start_date', type=str,
 help="datetime to start in the form 'YYYY-MM-DD(...)'"
 )
 parser.add_argument(
 '-m', '--make', action='store_true', 
 help='make user base'
 )
 parser.add_argument(
 '-s', '--seed', type=int, 
 help='set a seed for reproducibility'
 )
 parser.add_argument(
 '-u', '--userbase', 
 help='file to write the user base to'
 )
 parser.add_argument(
 '-i', '--ip', 
 help='file to write user-IP address map to'
 )
 parser.add_argument(
 '-l', '--log', help='file to write the attempt log to'
 )
 parser.add_argument(
 '-hl', '--hacklog', 
 help='file to write the hack log to'
 )
```

小费

放置在`if __name__ == '__main__'`块中的代码只有在该模块作为脚本运行时才会运行。这使得我们可以在不运行模拟的情况下导入模块中定义的功能。

在定义了参数之后，我们需要解析它们以便使用它们:

```
    args = parser.parse_args()
```

一旦我们解析了命令行参数，我们就检查是否需要生成用户基础或读入它:

```
    user_ip_mapping_file = \
        get_user_base_file_path(args.ip, 'user_ips.json')
    if args.make:
        logger.warning(
            'Creating new user base, mapping IP addresses.'
        )
        user_base_file = get_user_base_file_path(
            args.userbase, 'user_base.txt'
        )
        # seed the creation of user base
        random.seed(args.seed)
        # create usernames and write to file
        sim.utils.make_user_base(user_base_file)
        # create 1 or more IP addresses per user, save mapping 
        valid_users = sim.utils.get_valid_users(user_base_file)
        sim.utils.save_user_ips(
            sim.utils.assign_ip_addresses(valid_users), 
            user_ip_mapping_file
        )
```

之后，我们从命令行参数解析开始日期，并通过将命令行参数的持续时间加到开始日期来确定结束日期:

```
    try:
        start = \
            dt.datetime(*map(int, args.start_date.split('-')))
    except TypeError:
        logger.error('Start date must be in "YYYY-MM-DD" form')
        raise
    except ValueError:
        logger.warning(
            f'Could not interpret {args.start_date}, '
            'using January 1, 2020 at 12AM as start instead'
        )
        start = dt.datetime(2020, 1, 1)
    end = start + dt.timedelta(days=args.days)
```

小费

查看前面代码片段中的`try...except`块。我们有一个单一的`try`条款和多个`except`条款。我们可以通过声明哪个异常类型属于给定的`except`子句来指定如何处理代码执行期间发生的特定错误(称为**异常**)。在这种情况下，我们让`logger`对象为用户打印一条更有帮助的消息，然后通过简单地编写`raise`来重新引发同一个异常(因为我们不打算处理它)。这就结束了程序，用户可以用有效的输入再试一次。尝试触发这个异常，看看这有多有用。不过，要记住的一点是顺序很重要——在拥有一个通用的`except`子句之前，一定要处理特定的异常；否则，特定于每个异常类型的代码将永远不会触发。另外，注意使用`except`而不提供特定的异常将会捕获所有的异常，甚至是不应该被捕获的异常。

最后，我们运行实际的模拟，并将结果写入指定的文件(或默认路径)。我们将给定时间内的攻击概率设置为 10% ( `attack_prob`)，黑客尝试猜测所有用户名的概率为 20% ( `try_all_users_prob`)，并让黑客使用相同的 IP 地址进行所有尝试(`vary_ips`):

```
    try:
        logger.info(f'Simulating {args.days} days...')
        simulator = sim.LoginAttemptSimulator(
            user_ip_mapping_file, start, end, seed=args.seed
        )
        simulator.simulate(
            attack_prob=0.1, try_all_users_prob=0.2, 
            vary_ips=False
        )
        # save logs
        logger.info('Saving logs')
        simulator.save_hack_log(
            get_log_file_path(args.hacklog, 'attacks.csv')
        )
        simulator.save_log(
            get_log_file_path(args.log, 'log.csv')
        )
        logger.info('All done!')
    except:
        logger.error('Oops! Something went wrong...')
        raise
```

小费

注意，在整个脚本中，我们使用了`logger`对象将有用的消息打印到屏幕上；这将有助于这个脚本的用户知道这个过程进行到什么程度。这些消息有不同的严重级别(我们在这里使用`INFO`、`WARNING`和`ERROR`，允许它们被放置用于调试(`DEBUG`级别)，并且一旦代码进入生产就留在那里，因为打印的最低级别可以提高到`INFO`，所以没有`DEBUG`消息被打印。这远远超出了简单的`print()`语句，因为我们不必担心在进入生产时删除它们，或者在开发继续时添加回这些消息。

现在让我们看看如何运行这个脚本。我们知道`simulate.py`可以在命令行上运行，但是怎么才能看到需要传递什么参数呢？简单—我们将帮助标志(`-h`或`--help`)添加到呼叫中:

```
(book_env) $ python3 simulate.py -h
usage: simulate.py [-h] [-m] [-s SEED] [-u USERBASE] [-i IP] 
                   [-l LOG] [-hl HACKLOG]
                   days start_date
positional arguments:
  days                  number of days to simulate from start
  start_date            datetime to start in the form 
                        'YYYY-MM-DD' or 'YYYY-MM-DD-HH'
optional arguments:
  -h, --help            show this help message and exit
  -m, --make            make user base
  -s SEED, --seed SEED  set a seed for reproducibility
  -u USERBASE, --userbase USERBASE
                        file to write the user base to
  -i IP, --ip IP        file to write the user-IP address 
                        map to
  -l LOG, --log LOG     file to write the attempt log to
  -hl HACKLOG, --hacklog HACKLOG
                        file to write the hack log to
```

重要说明

注意，当我们用`argparse`添加其他参数时，我们没有指定`help`参数；它是由`argparse`自动创建的。

一旦我们知道我们可以传递哪些参数，并且决定了我们想要提供哪些参数，我们就可以运行模拟了。让我们模拟 30 天，从 2018 年 11 月 1 日上午 12 点开始，同时让脚本创建所需的用户群和 IP 地址映射:

```
(book_env) $ python3 simulate.py -ms 0 30 '2018-11-01'
[WARNING] [ simulate.py ] Creating new user base and mapping IP addresses to them.
[INFO] [ simulate.py ] Simulating 30.0 days...
[INFO] [ simulate.py ] Saving logs
[INFO] [ simulate.py ] All done!
```

小费

因为我们设置了一个种子(`-s 0`)，所以这个模拟的输出是可再现的。简单地移除种子或改变它以获得不同的结果。

Python 模块也可以作为脚本运行。与导入模块相反，当我们将一个模块作为脚本运行时，`if __name__ == '__main__'`下的任何代码也将被运行，这意味着我们不总是需要编写单独的脚本。我们构建的大多数模块只定义了函数和类，所以将它们作为脚本运行不会有任何作用；然而，我们在 [*第 1 章*](B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015)*数据分析简介*中用`venv`创建虚拟环境的方式就是一个例子。因此，前面的代码块相当于以下命令:

```
# leave off the .py
(book_env) $ python3 -m simulate -ms 0 30 "2018-11-01"
```

现在我们有了模拟数据，让我们开始分析。

# 探索性数据分析

在这个场景中，我们拥有访问标记数据(`logs/attacks.csv`)的优势，并将使用它来研究如何区分合法用户和攻击者。但是，这是我们往往没有的奢侈品，尤其是一旦离开研究阶段，进入应用阶段。在 [*第 11 章*](B16834_11_Final_SK_ePub.xhtml#_idTextAnchor237) 、*机器学习异常检测*中，我们将重温这一场景，但开始时没有更多挑战性的标记数据。像往常一样，我们从导入和读取数据开始:

```
>>> %matplotlib inline
>>> import matplotlib.pyplot as plt
>>> import numpy as np
>>> import pandas as pd
>>> import seaborn as sns
>>> log = pd.read_csv(
...     'logs/log.csv', index_col='datetime', parse_dates=True
... )
```

登录尝试数据帧(`log`)在`datetime`列中包含每次尝试的日期和时间，它来自的 IP 地址(`source_ip`)，使用的用户名(`username`)，尝试是否成功(`success`，如果不成功则失败的原因(`failure_reason`):

![Figure 8.3 – Sample of the login attempt data
](image/Figure_8.3_B16834.jpg)

图 8.3–登录尝试数据示例

在处理这些数据时，我们需要考虑正常活动和黑客活动是什么样的。这两个群体之间的任何巨大差异都有可能被用来识别黑客。我们希望合法用户有很高的成功率，最常见的失败原因是密码不正确。我们预计用户会从几个不同的 IP 地址登录(电话、家用电脑、工作电脑和他们可能拥有的任何其他设备)，并且人们可能会共享设备。在不了解这个 web 应用的性质的情况下，我们无法对全天多次登录是否正常说什么。我们也不知道这些数据在哪个时区，所以我们无法对登录时间做出任何推断。潜在地，我们可以看看这些 IP 地址来自哪个国家，但是有屏蔽 IP 地址的方法，所以我们不会走这条路。鉴于我们现有的数据，这给我们留下了几个可行的选择:

*   调查任何尝试和失败的峰值(整体和每个 IP 地址)。
*   检查失败原因是用户名不正确的情况。
*   看看每个 IP 地址的失败率。
*   找到试图用许多不同的用户名登录的 IP 地址。

另一件要注意的事情是，我们希望尽早标记异常行为。等待一个月来标记一些东西是不太有价值的(随着时间的推移，价值会迅速下降)，所以我们需要找到一种方法来更快地标记；比如说，使用每小时一次的频率。由于我们处于研究阶段，我们有一些标记的数据要处理:

```
>>> attacks = pd.read_csv(
...     'logs/attacks.csv',
...     converters={
...         'start': np.datetime64, 
...         'end': np.datetime64
...     }
... ) # make start and end columns datetimes but not the index
```

这个数据就是对 web 应用(`attacks`)的攻击记录。它包含攻击开始的日期和时间(`start`)、攻击结束的日期和时间(`end`)以及与攻击相关的 IP 地址(`source_ip`):

![Figure 8.4 – Sample of the labeled data
](image/Figure_8.4_B16834.jpg)

图 8.4–标签数据样本

使用`shape`属性，我们可以看到来自合法和恶意用户的 72 次攻击和 12，836 次登录尝试，使用`nunique()`，我们看到 22%的 IP 地址与攻击有关:

```
>>> attacks.shape, log.shape
((72, 3), (12836, 4))
>>> attacks.source_ip.nunique() / log.source_ip.nunique()
0.22018348623853212
```

重要说明

通常情况下，知道攻击何时发生并不是一件小事——它们可能会持续很长时间而不被检测到，即使如此，将攻击者的行为与普通用户的行为隔离开来也不是一件容易的事情。

我们的数据非常干净(毕竟，我们设计它就是为了这个目的)，所以让我们看看是否可以通过执行一些**探索性数据分析** ( **EDA** )来找到任何有趣的东西。首先，让我们看看每小时有多少次尝试:

```
>>> log.assign(attempts=1).attempts.resample('1H').sum()\
...     .plot(figsize=(15, 5), title='hourly attempts')\
...     .set(xlabel='datetime', ylabel='attempts')
```

几个小时有非常大的峰值，这可能是攻击发生的时间。使用该图，我们可以报告具有高水平登录尝试活动的时间，但除此之外没有其他信息:

![Figure 8.5 – Hourly login attempts
](image/Figure_8.5_B16834.jpg)

图 8.5–每小时登录尝试次数

另一个有趣的探索途径是查看每个 IP 地址有多少次尝试。我们可以通过运行以下命令来实现这一点:

```
>>> log.source_ip.value_counts().describe()
count    327.000000
mean      39.253823
std       69.279330
min        1.000000
25%        5.000000
50%       10.000000
75%       22.500000
max      257.000000
Name: source_ip, dtype: float64
```

这个数据显然有一些异常值，这使得每个 IP 地址的尝试次数非常高。让我们创建一些图来更好地评估这一点:

```
>>> fig, axes = plt.subplots(1, 2, figsize=(15, 5))
>>> log.source_ip.value_counts()\
...     .plot(kind='box', ax=axes[0]).set_ylabel('attempts')
>>> log.source_ip.value_counts()\
...     .plot(kind='hist', bins=50, ax=axes[1])\
...     .set_xlabel('attempts')
>>> fig.suptitle('Attempts per IP Address')
```

每个 IP 地址的尝试分布是有效用户和攻击者分布的总和。直方图表明这种分布是双峰的，但我们无法通过查看图表来确定是否所有尝试次数高的 IP 地址都是黑客:

![Figure 8.6 – Distribution of login attempts per IP address
](image/Figure_8.6_B16834.jpg)

图 8.6–每个 IP 地址的登录尝试分布

由于我们可以访问每个攻击的细节，我们可以检查直方图的右边部分是否是黑客的分布。他们的 IP 地址占按尝试次数排名的顶级 IP 地址的 88.9%:

```
>>> num_hackers = attacks.source_ip.nunique()
>>> log.source_ip.value_counts().index[:num_hackers]\
...     .isin(attacks.source_ip).sum() / num_hackers
0.8888888888888888
```

我们可以简单地在这里停下来，标记每月尝试次数最多的 IP 地址列表中的任何 IP 地址，但我们最有可能需要一个更强大的解决方案，因为黑客每次都可以简单地更改他们的 IP 地址，从而避免被检测到。理想情况下，我们还能够检测到攻击，而无需等待整整一个月的数据。不幸的是，查看每个 IP 地址每小时进行的尝试并不能给我们提供太多信息，尽管:

```
>>> log.assign(attempts=1).groupby('source_ip').attempts\
...     .resample('1H').sum().unstack().mean()\
...     .plot(
...         figsize=(15, 5), 
...         title='average hourly attempts per IP address'
...     ).set_ylabel('average hourly attempts per IP address')
```

记得从 [*第一章*](B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015) 、*数据分析导论*中得知，均值对于异常值是不稳健的。如果攻击者进行多次尝试，他们将提高每个 IP 地址每小时的平均尝试次数。我们可以在这个线图中看到几个大的峰值，但请注意，其中许多峰值只有两到三个。我们真的可以期望只有一个用户从给定的 IP 地址访问 web 应用程序吗？这可能不是一个现实的假设:

![Figure 8.7 – Average hourly login attempts per IP address
](image/Figure_8.7_B16834.jpg)

图 8.7–每个 IP 地址每小时平均登录尝试次数

那么，如果我们不能依靠 IP 地址(毕竟，黑客可能足够聪明，可以将攻击分散到许多不同的地址)，我们还能尝试什么呢？也许黑客们成功登录有更多的困难:

```
>>> log[log.source_ip.isin(attacks.source_ip)]\
...     .success.value_counts(normalize=True)
False    0.831801
True     0.168199
Name: success, dtype: float64
```

黑客成功的几率只有 17%,但是合法用户成功的几率有多大呢？这些信息对于确定网站正常行为的基线非常重要。正如我们所料，有效用户的成功率要高得多:

```
>>> log[~log.source_ip.isin(attacks.source_ip)]\
...     .success.value_counts(normalize=True)
True     0.873957
False    0.126043
Name: success, dtype: float64
```

由于日志附带了登录尝试失败的原因，我们可以使用交叉表来查看黑客和合法的用户为什么无法成功登录。这里的任何差异都可能有助于我们区分这两组:

```
>>> pd.crosstab(
...     index=pd.Series(
...         log.source_ip.isin(attacks.source_ip),
...         name='is_hacker'
...     ), columns=log.failure_reason
... )
```

合法用户有时会错误地输入他们的密码或用户名，但是黑客在获得正确的用户名和密码方面有更多的问题:

![Figure 8.8 – Reason for failed login attempts
](image/Figure_8.8_B16834.jpg)

图 8.8–登录尝试失败的原因

合法用户不会在他们的凭证上犯很多错误，所以如果黑客对很多用户做了很多尝试，我们可以标记它。为了证实这一点，我们可以看看每个用户每小时的平均尝试次数:

```
>>> log.assign(attempts=1).groupby('username').attempts\
...     .resample('1H').sum().unstack().mean()\
...     .plot(figsize=(15, 5),
...           title='average hourly attempts per user')\
...     .set_ylabel('average hourly attempts per user')
```

在大多数情况下，每个用户名每小时尝试不到一次。也不能保证这个指标中的峰值是攻击的迹象。或许该网站正在进行闪购；在这种情况下，我们可能会看到由有效用户引起的该指标的峰值:

![Figure 8.9 – Average hourly login attempts per username
](image/Figure_8.9_B16834.jpg)

图 8.9–每个用户名每小时的平均登录尝试次数

根据我们的发现，错误率似乎是检测攻击最有效的指标，因此我们将研究错误率高的 IP 地址。为此，我们可以创建一个数据透视表来计算一些有用的指标:

```
>>> pivot = log.pivot_table(
...     values='success', index=log.source_ip, 
...     columns=log.failure_reason.fillna('success'), 
...     aggfunc='count', fill_value=0
... )
>>> pivot.insert(0, 'attempts', pivot.sum(axis=1))
>>> pivot = pivot.sort_values('attempts', ascending=False)\
...     .assign(
...         success_rate=lambda x: x.success / x.attempts,
...         error_rate=lambda x: 1 - x.success_rate
...     )
>>> pivot.head()
```

小费

`insert()`方法允许我们在当前数据帧的特定位置插入新创建的`attempts`列。我们通过对`axis=1`求和，将`attempts`列创建为错误和成功的总和(我们用`success`填充`failure_reason`列中的`NaN`值，以在此进行计数)。

这将产生以下按次尝试排序的数据透视表(从最多到最少):

![Figure 8.10 – Metrics per IP address
](image/Figure_8.10_B16834.jpg)

图 8.10–每个 IP 地址的指标

我们知道某些 IP 地址正在进行多次尝试，因此有必要了解每个 IP 地址有多少用户名正在尝试登录；我们希望合法用户只从几个 IP 地址登录，而不要和其他人分享他们的 IP 地址。这可以通过 group by 和聚合来确定:

```
>>> log.groupby('source_ip').agg(dict(username='nunique'))\
...     .username.value_counts().describe()
count     53.000000
mean       6.169811
std       34.562505
min        1.000000
25%        1.000000
50%        1.000000
75%        2.000000
max      253.000000
Name: username, dtype: float64
```

这显然是一个隔离邪恶用户的好策略。大多数 IP 地址由两个或更少的用户使用，但最多为 253 个。虽然这一标准可以帮助我们识别一些攻击者，但如果黑客足够聪明，在整个攻击过程中改变他们的 IP 地址，这一标准将无济于事。

在我们继续讨论异常检测方法之前，让我们看看我们是否能够直观地识别黑客。让我们为每个 IP 地址的成功和尝试创建一个散点图:

```
>>> pivot.plot(
...     kind='scatter', x='attempts', y='success', alpha=0.25,
...     title='successes vs. attempts by IP address' 
... )
```

似乎有几个不同的集群。在图的左下角，我们看到点形成一条线，成功与尝试之间存在一对一的关系。该图的右上部分包含一个不太密集的集群，具有大量尝试和中等成功。由于我们使用了`alpha`参数来控制透明度，我们可以看到似乎连接两个集群的点的轨迹并不密集。即使没有坐标轴刻度，我们也可以预测左下方的集群是普通用户，右上方的集群是黑客(因为我们认为普通用户比黑客多，而普通用户的成功率更高)。然而，中间的点更难判断:

![Figure 8.11 – Scatter plot of successes versus attempts by IP address
](image/Figure_8.11_B16834.jpg)

图 8.11–按 IP 地址划分的成功与尝试的散点图

在不做任何假设的情况下，我们可以绘制一条边界线，将中间点与其最近的簇组合在一起:

```
>>> ax = pivot.plot(
...     kind='scatter', x='attempts', y='success', alpha=0.25, 
...     title='successes vs. attempts by IP address'
... )
>>> plt.axvline(
...     125, label='sample boundary',
...     color='red', linestyle='--'
... )
>>> plt.legend(loc='lower right')
```

当然，当缺乏标记数据时，很难评估这个决策边界的有效性:

![Figure 8.12 – Visualizing a decision boundary
](image/Figure_8.12_B16834.jpg)

图 8.12–可视化决策边界

幸运的是，我们有黑客使用的 IP 地址的数据，因为我们得到了标记的数据来进行我们的研究，所以我们可以使用`seaborn`来实际查看分离:

```
>>> fig, axes = plt.subplots(1, 2, figsize=(15, 5))
>>> for ax in axes:
...     sns.scatterplot(
...         y=pivot.success, x=pivot.attempts, 
...         hue=pivot.assign(
...             is_hacker=\
...                 lambda x: x.index.isin(attacks.source_ip)
...         ).is_hacker,
...         ax=ax, alpha=0.5
...     ) 
...     for spine in ['top', 'right']: # make less boxy
...         ax.spines[spine].set_visible(False)
>>> axes[1].set_xscale('log')
>>> plt.suptitle('successes vs. attempts by IP address')
```

我们关于有两个不同星团的直觉是完全正确的。然而，中间区域更难确定。左边蓝色(较暗)的点看起来确实是沿着一条向上的线，而左边橙色(较亮)的点是沿着一条到橙色星团的线。相反，通过绘制尝试日志，我们在橙色中间点和蓝色点之间获得了更多的分离:

![Figure 8.13 – Using labeled data to check our intuition
](image/Figure_8.13_B16834.jpg)

图 8.13-使用标记数据检查我们的直觉

请记住，我们还可以使用一个方框图来检查可能的异常值，这些异常值将显示为点。让我们看看每个 IP 地址的成功和尝试是什么样的:

```
>>> pivot[['attempts', 'success']].plot(
...     kind='box', subplots=True, figsize=(10, 3),
...     title='stats per IP address'
... )
```

标记为异常值的点与我们制作的散点图右上角的点一致:

![Figure 8.14 – Checking for outliers
](image/Figure_8.14_B16834.jpg)

图 8.14–检查异常值

现在我们对数据有了很好的理解，我们准备学习如何实现一些简单的异常检测策略。

# 实施基于规则的异常检测

是时候抓住那些黑客了。在前一节的 EDA 之后，我们有了一个关于如何做这件事的想法。在实践中，这要困难得多，因为它涉及更多的维度，但我们在这里简化了它。**我们希望找到尝试次数过多且成功率低的 IP 地址，以及那些试图使用比我们认为正常的更独特的用户名登录的 IP 地址(异常情况)**。为此，我们将采用基于阈值的规则作为异常检测的第一步；然后，在 [*第 11 章*](B16834_11_Final_SK_ePub.xhtml#_idTextAnchor237) 、*机器学习异常检测*中，我们将在重温这个场景时探索一些机器学习技术。

因为我们对标记可疑的 IP 地址感兴趣，所以我们将安排数据，以便每个 IP 地址都有每小时的聚合数据(如果在那个小时有活动):

```
>>> hourly_ip_logs = log.assign(
...     failures=lambda x: np.invert(x.success)
... ).groupby('source_ip').resample('1H').agg({
...     'username': 'nunique', 'success': 'sum', 
...     'failures': 'sum'
... }).assign(
...     attempts=lambda x: x.success + x.failures,
...     success_rate=lambda x: x.success / x.attempts,
...     failure_rate=lambda x: 1 - x.success_rate
... ).dropna().reset_index()
```

小费

`np.invert()`函数是翻转布尔值的简单方法。它沿着一个类似数字阵列的结构从`True`转到`False`，从`False`转到`True`。

聚合数据如下所示:

![Figure 8.15 – Hourly aggregated data per IP address
](image/Figure_8.15_B16834.jpg)

图 8.15–每个 IP 地址每小时的聚合数据

基于规则的异常检测的最简单形式包括计算阈值并检查数据是否超出阈值。这可能意味着值低于某个下限阈值，或者值超过某个上限阈值。因为我们正在查看登录尝试，所以我们对大于正常值的值感兴趣。因此，我们将计算上限的阈值，并将其与我们的数据进行比较。

## 百分比差异

假设我们对网站上正常的登录尝试活动(不包括黑客)有一个概念，我们可以标记出偏离这个值一定百分比的值。为了计算这个基线，我们可以随机抽取几个 IP 地址，每小时替换一次，然后计算他们尝试登录的平均次数。我们正在引导，因为我们没有太多的数据(大约 50 个独特的 IP 地址，从每个 24 小时挑选)。

为此，我们可以编写一个函数，该函数接收我们刚刚创建的聚合数据帧，以及要计算的每列数据的统计名称，以用作阈值的起点:

```
>>> def get_baselines(hourly_ip_logs, func, *args, **kwargs):
...     """
...     Calculate hourly bootstrapped statistic per column.
...
...     Parameters:
...         - hourly_ip_logs: Data to sample from.
...         - func: Statistic to calculate.
...         - args: Additional positional arguments for `func`
...         - kwargs: Additional keyword arguments for `func`
...
...     Returns: 
...         `DataFrame` of hourly bootstrapped statistics
...     """
...     if isinstance(func, str):
...         func = getattr(pd.DataFrame, func)
...
...     return hourly_ip_logs.assign(
...         hour=lambda x: x.datetime.dt.hour
...     ).groupby('hour').apply(
...         lambda x: x\
...             .sample(10, random_state=0, replace=True)\
...             .pipe(func, *args, **kwargs, numeric_only=True)
...     )
```

重要说明

在前面的代码片段中，`random_state`与`sample()`一起使用是为了再现性；然而，在实践中，我们可能不希望总是选择相同的行。

注意，如果我们在按照我们想要采样的列分组之后，在`apply()`中使用`sample()`，我们可以为所有组(这里是小时)获得相同大小的样本。这意味着我们选择 10 行，每列每小时替换一次。这里我们必须按小时采样，因为如果我们做简单的随机采样，很可能我们没有每小时的统计数据。让我们使用`get_baselines()`通过平均值来计算列基线:

```
>>> averages = get_baselines(hourly_ip_logs, 'mean')
>>> averages.shape
(24, 7)
```

小费

相反，如果我们想要执行分层随机抽样，我们可以用`x.shape[0] * pct`替换`get_baselines()`函数中的`10`，其中`pct`是我们想要从每组中抽样的百分比。

每一列都有随机选择的 10 个 IP 地址每小时的平均值，用于评估正常行为。然而，这种技术不能保证我们不会将任何黑客活动混入我们的基线计算中。例如，让我们看看故障率基线值最高的六个小时:

```
>>> averages.nlargest(6, 'failure_rate')
```

我们可能会发现很难用这个基线标记在时间 **19** 、 **23** 或 **14** 的任何活动，因为失败率和尝试的唯一用户名都很高:

![Figure 8.16 – Hourly baselines using the mean
](image/Figure_8.16_B16834.jpg)

图 8.16–使用平均值的每小时基线

为了解决这个问题，我们可以通过将 top *x* %排除在基线计算之外来精简我们的汇总统计数据。让我们从每个小时中删除大于第 95 个百分点的值。首先，我们将编写一个函数来修剪给定时间内数据超过给定分位数的行:

```
>>> def trim(x, quantile):
...     """
...     Remove rows with entries for the username, attempts, 
...     or failure_rate columns above a given quantile.
...     """
...     mask = (
...         (x.username <= x.username.quantile(quantile)) &
...         (x.attempts <= x.attempts.quantile(quantile)) &
...         (x.failure_rate
...          <= x.failure_rate.quantile(quantile))
...     )
...     return x[mask]
```

接下来，我们将按小时对 IP 地址数据进行分组，并应用我们的微调功能。由于我们将使用我们的引导函数，我们需要清理一些由这个操作产生的额外的列，所以我们删除`hour`列，重置索引，然后删除分组列和旧的索引:

```
>>> trimmed_hourly_logs = hourly_ip_logs\
...     .assign(hour=lambda x: x.datetime.dt.hour)\
...     .groupby('hour').apply(lambda x: trim(x, 0.95))\
...     .drop(columns='hour').reset_index().iloc[:,2:]
```

现在，我们可以使用`get_baselines()`函数获取基线，使用平均值和修剪后的数据:

```
>>> averages = get_baselines(trimmed_hourly_logs, 'mean')
>>> averages.iloc[[19, 23, 3, 11, 14, 16]]
```

修整后的基线现在与在第 **19** 、 **23** 和 **14** 小时的*图 8.16* 完全不同:

![Figure 8.17 – Trimmed hourly baselines using the mean
](image/Figure_8.17_B16834.jpg)

图 8.17–使用平均值修整每小时基线

现在我们已经有了基线，让我们编写一个函数来计算基线的阈值和每列的百分比差，返回被标记为黑客的 IP 地址:

```
>>> def pct_change_threshold(hourly_ip_logs, baselines,
...                          pcts=None):
...     """
...     Return flagged IP addresses based on thresholds.
...
...     Parameters:
...         - hourly_ip_logs: Aggregated data per IP address.
...         - baselines: Hourly baselines per column in data.
...         - pcts: Dictionary of custom percentages per column 
...           for calculating upper bound thresholds
...           (baseline * pct). If not provided, pct will be 1
...
...     Returns: `Series` containing the IP addresses flagged.
...     """
...     pcts = {} if not pcts else pcts
...
...     return hourly_ip_logs.assign(
...         hour=lambda x: x.datetime.dt.hour
...     ).join(
...         baselines, on='hour', rsuffix='_baseline'
...     ).assign(
...         too_many_users=lambda x: x.username_baseline \
...             * pcts.get('username', 1) <= x.username,
...         too_many_attempts=lambda x: x.attempts_baseline \
...             * pcts.get('attempts', 1) <= x.attempts,
... high_failure_rate=lambda x: \
... x.failure_rate_baseline \
... * pcts.get('failure_rate', 1) <= x.failure_rate
...     ).query(
...         'too_many_users and too_many_attempts '
...         'and high_failure_rate'
...     ).source_ip.drop_duplicates()
```

`pct_change_threshold()`函数使用一系列链式操作来给我们标记的 IP 地址:

1.  首先，它将基线加入到`hour`列上的每小时 IP 地址日志中。由于所有基线列都与每小时的 IP 地址日志同名，并且我们不想加入它们，所以我们在它们的名称后面加上了`'_baseline'`。
2.  之后，我们需要检查是否超过阈值的所有数据都在同一个数据帧中。我们用`assign()`做三个新的布尔列，表示我们的每一个条件(用户太多，尝试太多，失败率高)是否都被违反了。
3.  然后，我们链接一个对`query()`方法的调用，这让我们可以轻松地选择所有布尔列都是`True`的行(注意，我们不需要显式地说`<column> == True`)。
4.  最后，我们确保只返回 IP 地址，并丢弃任何重复的地址，以防同一个 IP 地址被标记多个小时。

为了使用这个函数，我们需要从每个基线中选择一个百分比差。默认情况下，这将是 100%的基线，因为这是平均值，将标记太多的 IP 地址。取而代之的是，让我们获得其值比每个标准的基线高 25%的 IP 地址:

```
>>> pct_from_mean_ips = pct_change_threshold(
...     hourly_ip_logs, averages, 
...     {key: 1.25 for key in [
...         'username', 'attempts', 'failure_rate'
...     ]}
... )
```

小费

我们使用的百分比在一个字典中，关键字是它们对应的列，值是百分比本身。如果函数的调用者不提供这些，我们就使用默认值 100%，因为我们使用`get()`从字典中选择。

这些规则标记了 73 个 IP 地址:

```
>>> pct_from_mean_ips.nunique()
73
```

重要说明

实际上，我们可能不会在用于计算基线的条目上运行这个规则，因为它们的行为会影响基线的定义。

## 图克栅栏

正如我们在 [*第一章*](B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015) 、*数据分析导论*中所讨论的，均值对于异常值是不稳健的。如果我们觉得有很多异常值影响我们的基线，我们可以回到百分比差异并尝试使用中位数或使用 **Tukey fence** 。记住前面章节中的 Tukey 围栏从第一个和第三个四分位数以及**四分位数间范围** ( **IQR** )获得其边界。由于我们只关心超过上限，这解决了平均值的问题，假设异常值占我们数据的 25%以下。我们可以使用以下公式来计算上限:

![](image/Formula_08_005.jpg)

我们的`get_baselines()`函数仍然会帮助我们，但是我们需要做一些额外的处理。我们将编写一个函数，它将计算 Tukey fence 的上限，并让我们测试乘数(`k`)的各种值。请注意，我们还有选项，在这里使用 Tukey 围栏的百分比:

```
>>> def tukey_fence_test(trimmed_data, logs, k, pct=None):
...     """
...     See which IP addresses get flagged with a Tukey fence 
...     with multiplier k and optional percent differences.
...  
...     Parameters: 
...         - trimmed_data: Data for calculating the baselines
...         - logs: The data to test
...         - k: The multiplier for the IQR
...         - pct: Dictionary of percentages per column for use 
...                with `pct_change_threshold()`
...
...     Returns: 
...         `pandas.Series` of flagged IP addresses
...     """
...     q3 = get_baselines(trimmed_data, 'quantile', .75)\
...         .drop(columns=['hour'])
...
...     q1 = get_baselines(trimmed_data, 'quantile', .25)\
...         .drop(columns=['hour'])
...
...     iqr = q3 - q1
...     upper_bound = (q3 + k * iqr).reset_index()
...
...     return pct_change_threshold(logs, upper_bound, pct)
```

让我们使用`tukey_fence_test()`函数，使用一个`3`的 IQR 乘数来获取超过 Tukey fence 上限的 IP 地址:

```
>>> tukey_fence_ips = tukey_fence_test(
...     trimmed_hourly_logs, hourly_ip_logs, k=3
... )
```

使用这种方法，我们标记了 83 个 IP 地址:

```
>>> tukey_fence_ips.nunique()
83
```

重要说明

我们在这里使用了乘数 3。然而，根据应用的不同，为了减少限制，我们可能会使用 1.5。在现实中，我们可以使用任何数字；找到最好的可能需要一些尝试和错误。

## Z 分数

请记住，从 [*第 1 章*](B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015) 、*数据分析简介*中，我们还可以计算 Z 分数和标志 IP 地址相对于平均值的给定数量的标准偏差。我们之前写的`pct_change_threshold()`函数不会帮助我们，因为我们不仅仅是与基线比较。相反，我们需要从所有值中减去平均值的基线，然后除以标准偏差的基线，因此我们必须重新设计我们的方法。

让我们编写一个新函数`z_score_test()`，使用高于平均值的任意数量的标准偏差作为截止值来执行我们的 Z 得分测试。首先，我们将使用`get_baselines()`函数计算带有修整数据的每小时基线标准偏差。然后，我们将标准偏差和平均值连接在一起，加上后缀。这允许我们为这个任务修改`pct_change_threshold()`的逻辑:

```
>>> def z_score_test(trimmed_data, logs, cutoff):
...     """
...     See which IP addresses get flagged with a Z-score
...     greater than or equal to a cutoff value.
...
...     Parameters: 
...         - trimmed_data: Data for calculating the baselines
...         - logs: The data to test
...         - cutoff: Flag row when z_score >= cutoff
...
...     Returns: 
...         `pandas.Series` of flagged IP addresses
...     """
...     std_dev = get_baselines(trimmed_data, 'std')\
...         .drop(columns=['hour'])
...     averages = get_baselines(trimmed_data, 'mean')\
...         .drop(columns=['hour'])
...
...     return logs.assign(hour=lambda x: x.datetime.dt.hour)\
...         .join(std_dev.join(
...             averages, lsuffix='_std', rsuffix='_mean'
...         ), on='hour')\
...         .assign(
...             too_many_users=lambda x: (
...                 x.username - x.username_mean
...             )/x.username_std >= cutoff,
...             too_many_attempts=lambda x: (
...                 x.attempts - x.attempts_mean
...             )/x.attempts_std >= cutoff,
...             high_failure_rate=lambda x: (
...                 x.failure_rate - x.failure_rate_mean
...             )/x.failure_rate_std >= cutoff
...         ).query(
...             'too_many_users and too_many_attempts '
...             'and high_failure_rate'
...         ).source_ip.drop_duplicates()
```

让我们称我们的函数为均值的三个或更多标准差的截止值:

```
>>> z_score_ips = \
...     z_score_test(trimmed_hourly_logs, hourly_ip_logs, 3)
```

通过这种方法，我们标记了 62 个 IP 地址:

```
>>> z_score_ips.nunique()
62
```

重要说明

实际上，Z 分数的临界值也是我们想要调整的一个参数。

## 评估表现

因此，我们现在有了每组规则的一系列 IP 地址，但是我们想知道每种方法做得有多好(假设我们可以实际检查)。在这种情况下，我们有攻击者的 IP 地址用于我们的研究，所以我们可以看到每种方法有多少是正确的——这在实践中并不那么微不足道；相反，我们可以标记我们在过去发现的恶意行为，并在未来寻找类似的行为。

这是一个有两个类的分类问题；我们希望将每个 IP 地址分类为合法用户或恶意用户。这给我们留下了四种可能的结果，我们可以使用**混淆矩阵**来可视化:

![Figure 8.18 – The confusion matrix
](image/Figure_8.18_B16834.jpg)

图 8.18–混淆矩阵

在本应用中，这些结果的含义如下:

*   **真阳性(TP)** :我们的方法将它标记为恶意，它确实是。
*   **真阴性(TN)** :我们的方法没有标记它，也没有恶意。
*   **假阳性(FP)** :我们的方法标记了它，但它不是恶意的。
*   **假阴性(FN)** :我们的方法没有标记出来，但是有恶意。

真阳性和真阴性意味着我们的方法做得很好，但假阳性和假阴性是可能需要改进的地方(记住，这永远不会是完美的)。现在，让我们编写一个函数来帮助确定每个方法的位置:

```
>>> def evaluate(alerted_ips, attack_ips, log_ips):
...     """
...     Calculate true positives (TP), false positives (FP),
...     true negatives (TN), and false negatives (FN) for 
...     IP addresses flagged as suspicious.
...
...     Parameters:
...         - alerted_ips: `Series` of flagged IP addresses
...         - attack_ips: `Series` of attacker IP addresses
...         - log_ips: `Series` of all IP addresses seen
...
...     Returns:
...         Tuple of the form (TP, FP, TN, FN)
...     """
...     tp = alerted_ips.isin(attack_ips).sum()
...     tn = np.invert(np.isin(
...         log_ips[~log_ips.isin(alerted_ips)].unique(),
...         attack_ips
...     )).sum()
...     fp = np.invert(alerted_ips.isin(attack_ips)).sum()
...     fn = np.invert(attack_ips.isin(alerted_ips)).sum()
...     return tp, fp, tn, fn
```

在我们开始计算指标之前，让我们创建一个分部函数，这样我们就不必一直传入一系列攻击者 IP 地址(`attacks.source_ip`)和日志中的 IP 地址(`pivot.index`)。请记住，分部函数允许我们固定某些参数的值，并在以后调用该函数:

```
>>> from functools import partial
>>> scores = partial(
...     evaluate, attack_ips=attacks.source_ip,
...     log_ips=pivot.index
... )
```

现在，让我们用它来计算一些衡量我们表现的指标。一个常见的指标是**假阳性率** ( **FPR** )，它告诉我们**假警报率**。它是通过计算假阳性与实际阴性的之比得出的:

![](image/Formula_08_001.jpg)

**错误发现率** ( **FDR** )，它告诉我们不正确的阳性百分比，这是看待错误警报的另一种方式:

![](image/Formula_08_002.jpg)

让我们看看 FPR 和罗斯福是什么，我们从均值方法的百分比差异:

```
>>> tp, fp, tn, fn = scores(pct_from_mean_ips)
>>> fp / (fp + tn), fp / (fp + tp)
(0.00392156862745098, 0.0136986301369863)
```

另一个感兴趣的指标是**假阴性率** ( **FNR** )，它告诉我们未能检测到的东西(即**漏检率**)。它是通过假阴性与实际阳性的比率计算出来的:

![](image/Formula_08_003.jpg)

查看假阴性的另一种方式是**假遗漏率** ( **代表**)，它告诉我们我们错误标记为阴性的病例的百分比:

![](image/Formula_08_004.jpg)

我们与均值方法的百分比差异没有假阴性，因此 FNR 和 FOR 都为零:

```
>>> fn / (fn + tp), fn / (fn + tn)
(0.0, 0.0)
```

这里有一个典型的权衡——我们是想要抓住尽可能多的黑客，并冒着标记有效用户的风险(通过关注 FNR/FOR ),还是想要避免给我们的有效用户带来不便，并冒着遗漏黑客活动的风险(通过最小化 FPR/FDR )?这些问题很难回答，并且将取决于领域，因为假阳性的成本不一定等于(或者甚至在规模上接近)假阴性的成本。

小费

我们将在第九章 、*Python 机器学习入门*中讨论可用于评估我们表现的其他指标。

现在让我们编写一个函数来处理所有这些计算:

```
>>> def classification_stats(tp, fp, tn, fn):
...     """Calculate metrics"""
...     return {
...         'FPR': fp / (fp + tn), 'FDR': fp / (fp + tp),
...         'FNR': fn / (fn + tp), 'FOR': fn / (fn + tn)
...     }
```

我们现在可以使用来自`evaluate()`函数的结果来计算我们的指标。对于与平均值的百分比差,我们得到以下输出:

```
>>> classification_stats(tp, fp, tn, fn)
{'FPR': 0.00392156862745098, 'FDR': 0.0136986301369863,
 'FNR': 0.0, 'FOR': 0.0}
```

看起来我们的三项标准做得很好。如果我们在计算基线时担心黑客 IP 地址的选择，但不想进行调整，我们可以使用中间值而不是平均值:

```
>>> medians = get_baselines(hourly_ip_logs, 'median')
>>> pct_from_median_ips = pct_change_threshold(
...     hourly_ip_logs, medians, 
...     {key: 1.25 for key in
...      ['username', 'attempts', 'failure_rate']}
... )
```

使用中间值，我们可以获得与平均值相似的性能。然而，在这种情况下，我们不需要事先调整数据。这是因为中位数对于异常值是稳健的，这意味着在给定的一个小时内选择单个黑客 IP 地址不会影响该小时的基线，因为它会影响平均值:

```
>>> tp, fp, tn, fn = scores(pct_from_median_ips)
>>> classification_stats(tp, fp, tn, fn)
{'FPR': 0.00784313725490196, 'FDR': 0.02702702702702703,
 'FNR': 0.0, 'FOR': 0.0}
```

为了比较所讨论的每一种方法，我们可以使用字典理解来用性能指标填充`DataFrame`对象:

```
>>> pd.DataFrame({
...     method: classification_stats(*scores(ips))
...     for method, ips in {
...         'means': pct_from_mean_ips,
...         'medians': pct_from_median_ips,
...         'Tukey fence': tukey_fence_ips,
...         'Z-scores': z_score_ips
...     }.items()
... })
```

小费

`scores()`函数返回一个`(tp, fp, tn, fn)`的元组，但是`classification_stats()`函数需要四个参数。然而，由于`scores()`返回它们的顺序与`classification_stats()`期望的顺序相同，我们可以使用`*`来解包元组，并将值作为四个位置参数发送。

平均值会受到异常值的影响，但一旦我们对数据进行了修整，它就成为了一种可行的方法。我们不需要修整数据来处理中位数；中位数的有用性取决于包含少于 50%异常值的数据。Tukey fence 通过使用第三个四分位数并假设少于 25%的数据点是异常值，进一步发展了这一点。Z-score 方法也受到异常值的影响，因为它使用平均值；然而，通过调整数据，我们能够以适度的三个截止值实现良好的性能:

![Figure 8.19 – Comparing performance
](image/Figure_8.19_B16834.jpg)

图 8.19–性能比较

最终，我们在实践中使用哪种方法将取决于假阳性和假阴性的代价——是在没有问题时发出警报更糟糕，还是在有问题时保持沉默更糟糕？在这种情况下，我们宁可减少假阴性，因为我们不想错过任何东西。

重要说明

异常检测的另一个常见用例是工业环境中的质量或过程控制，例如监控工厂设备性能和输出。过程控制使用基于阈值和基于模式的规则来确定系统是否失控。这些可以用于确定底层数据的分布何时改变，这可能是后来问题的前兆。**西电规则**和**尼尔森规则**是常见的。两个的参考资料可以在本章末尾的*进一步阅读*部分找到。

# 总结

在我们的第二章应用程序中，我们学习了如何在 Python 中模拟事件，并获得了额外的编写包的机会。我们还看到了如何编写可以从命令行运行的 Python 脚本，我们用它来运行登录尝试数据的模拟。然后，我们对模拟数据进行了一些 EDA，看看我们是否能找出让黑客活动容易被发现的方法。

这让我们关注每小时尝试对每个 IP 地址进行身份验证的不同用户名的数量，以及尝试次数和失败率。使用这些指标，我们能够创建一个散点图，它似乎显示了两组不同的点，以及连接这两组的一些其他点；很自然，这些代表了合法用户和邪恶用户，其中一些黑客不像其他人那样明显。

最后，我们开始创建规则，标记黑客可疑活动的 IP 地址。首先，我们使用`pandas`将我们的数据重塑为每个 IP 地址每小时的总量。然后，我们编写函数来修整大于第 95 个百分位数的值，并计算每小时给定统计数据的基线，我们使用这些基线来创建我们的规则，这些规则基于平均值和中值的百分比差异，超过 Tukey 围栏的上限，并使用 Z 分数。我们看到，建立良好的规则取决于仔细调整我们的参数:平均值和中值的差异百分比、Tukey 围栏的乘数以及 Z 值的阈值。为了确定哪个规则执行得最好，我们使用了漏检率、误漏率、误发现率和误报警率。

在接下来的两章中，我们将使用`scikit-learn`介绍 Python 中的机器学习，在 [*第 11 章*](B16834_11_Final_SK_ePub.xhtml#_idTextAnchor237) ，*机器学习异常检测*中，我们将再次讨论使用机器学习进行异常检测的场景。

# 练习

完成以下练习，练习本章中涵盖的概念:

1.  将 2018 年 12 月的模拟运行到新的日志文件中，无需再次创建用户基础。确保运行`python3 simulate.py -h`来查看命令行参数。将种子设置为`27`。该数据将用于剩余的练习。
2.  使用练习 *1* 中模拟的数据，找出唯一用户名、尝试、成功和失败的数量，以及每个 IP 地址的成功/失败率。
3.  创建两个支线剧情，左边是失败与尝试的对比，右边是失败率与不同用户名的对比。为结果图绘制决策边界。确保根据是否是黑客 IP 地址来标记每个数据点。
4.  如果失败和尝试次数都是各自中值的五倍，或者如果不同用户名的数量是中值的五倍，则使用与中值的百分比差异来建立基于规则的标准，以标记 IP 地址。确保使用一个小时的窗口。记住使用`get_baselines()`函数来计算基线所需的指标。
5.  使用本章中的`evaluate()`和`classification_stats()`函数计算指标，评估这些规则的执行情况。

# 延伸阅读

查看以下资源，了解本章所涵盖主题的更多信息:

*   *自举方法的温柔介绍*:[https://machine learning mastery . com/A-Gentle-Introduction-to-the-Bootstrap-Method/](https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/)
*   *自举方法介绍*:[https://towards data science . com/An-Introduction-to-the-Bootstrap-Method-58 BCB 51 B4 d 60](https://towardsdatascience.com/an-introduction-to-the-bootstrap-method-58bcb51b4d60)
*   *加盐哈希:更好的密码存储方式*:[https://auth 0 . com/blog/Adding-Salt-to-Hashing-A-Better-Way-to-Store-Passwords/](https://auth0.com/blog/adding-salt-to-hashing-a-better-way-to-store-passwords/)
*   *蛮力攻击*:【https://en.wikipedia.org/wiki/Brute-force_attack】T2
*   *分类精度不够:可以使用更多的表现衡量指标*:[https://machine learning mastery . com/Classification-Accuracy-Is-Not-success-More-Performance-Measures-You-Can-Use/](https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/)
*   *字典攻击*:【https://en.wikipedia.org/wiki/Dictionary_attack】T2
*   *尼尔森规则*:https://en.wikipedia.org/wiki/Nelson_rules[规则](https://en.wikipedia.org/wiki/Nelson_rules)
*   *离线密码破解:攻击和最佳防御*:[https://www . alpine security . com/blog/Offline-Password-Cracking-The-Attack-and-The-Best-Defense-against-it](https://www.alpinesecurity.com/blog/offline-password-cracking-the-attack-and-the-best-defense-against-it)
*   *泊松点过程*:【https://en.wikipedia.org/wiki/Poisson_point_process 
*   *精度和召回*:【https://en.wikipedia.org/wiki/Precision_and_recall 
*   *Python 中的概率分布*:[https://www . data camp . com/community/tutorials/Probability-Distributions-Python](https://www.datacamp.com/community/tutorials/probability-distributions-python)
*   *彩虹表:你的密码最糟糕的噩梦*:[https://www . lifewire . com/Rainbow-Tables-Your-passwords-Worst-nightman-2487288](https://www.lifewire.com/rainbow-tables-your-passwords-worst-nightmare-2487288)
*   *RFC 1597(专用互联网的地址分配)*:【http://www.faqs.org/rfcs/rfc1597.html 
*   *采样技术*:[https://towards data science . com/Sampling-Techniques-a4e 34111d 808](https://towardsdatascience.com/sampling-techniques-a4e34111d808)
*   *修整估计量*:【https://en.wikipedia.org/wiki/Trimmed_estimator】T2
*   *西电规则*:【https://en.wikipedia.org/wiki/Western_Electric_rules 