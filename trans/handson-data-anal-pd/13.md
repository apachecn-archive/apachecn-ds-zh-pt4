

# 九、Python 中的机器学习入门

本章将向我们展示机器学习的术语以及机器学习可以用来解决的常见任务。之后，我们将学习如何准备我们的数据用于机器学习模型。我们已经讨论过数据清理，但只是为了人类消费——机器学习模型需要不同的**预处理**(清理)技术。这里有相当多的细微差别，所以我们将花时间来讨论这个主题，并讨论我们如何使用`scikit-learn`来构建预处理管道以简化这个过程，因为我们的模型将只与它们被训练的数据一样好。

接下来，我们将介绍如何使用`scikit-learn`来构建模型并评估其性能。Scikit-learn 有一个非常用户友好的 API，所以一旦我们知道如何构建一个模型，我们就可以构建任意数量的模型。我们不会探究模型背后的任何数学原理；这方面有整本书，本章的目的是作为这个主题的介绍。在本章结束时，我们将能够确定我们要解决的是什么类型的问题和一些可以帮助我们的算法，以及如何实现它们。

本章将涵盖以下主题:

*   机器学习前景概述
*   使用在前面章节中学到的技能进行探索性数据分析
*   预处理用于机器学习模型的数据
*   聚类有助于理解未标记的数据
*   学习何时回归是合适的，以及如何用 scikit-learn 实现它
*   了解分类任务并学习如何使用逻辑回归

# 章节材料

在本章中，我们将使用三个数据集。前两个来自 P. Cortez、A. Cerdeira、F. Almeida、T. Matos 和 J. Reis 捐赠给 UCI 机器学习数据库([http://archive.ics.uci.edu/ml/index.php](http://archive.ics.uci.edu/ml/index.php))的葡萄酒质量数据，其中包含各种葡萄酒样品的化学性质信息，以及葡萄酒专家小组盲品的质量评级。这些文件可以在 GitHub 资源库([https://GitHub . com/stef molin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/tree/master/ch _ 09](https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/tree/master/ch_09))的本章文件夹内的`data/`文件夹中找到，分别作为红葡萄酒和白葡萄酒的`winequality-red.csv`和`winequality-white.csv`。

我们的第三个数据集是使用开放的系外行星目录数据库收集的，该数据库可以在[https://github . com/OpenExoplanetCatalogue/Open _ exo planet _ Catalogue/](https://github.com/OpenExoplanetCatalogue/open_exoplanet_catalogue/)找到。这个数据库提供**可扩展标记语言** ( **XML** )格式的数据，类似于 HTML。GitHub 上的`planet_data_collection.ipynb`笔记本包含了用于将这些信息解析成我们将在本章中使用的 CSV 文件的代码；虽然我们不会明确地讨论这个问题，但我鼓励您看一看它。数据文件也可以在`data/`文件夹中找到。本章我们将使用`planets.csv`；但是，其他层次结构的解析数据是为了练习和进一步探索而提供的。它们是`binaries.csv`、`stars.csv`和`systems.csv`，分别包含双星数据(恒星或双星组成两个一组)、单颗恒星数据和行星系统数据。

我们将使用`red_wine.ipynb`笔记本来预测红酒的质量，`wine.ipynb`笔记本根据红酒或白酒的化学性质对其进行分类，而`planets_ml.ipynb`笔记本将构建一个回归模型来预测行星的年长度，并执行聚类以找到相似的行星群。我们将使用`preprocessing.ipynb`笔记本进行预处理部分。

回到 [*第一章*](B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015) ，*数据分析简介*，当我们设置我们的环境时，我们从 GitHub 安装了一个名为`ml_utils`的包。这个包包含了我们将在机器学习的三章中用到的实用函数和类。与上两章不同，我们不会讨论如何制作这个包；不过，感兴趣的人可以在 https://github.com/stefmolin/ml-utils/tree/2nd_edition 浏览代码，并按照第七章[](B16834_07_Final_SK_ePub.xhtml#_idTextAnchor146)*、*金融分析-比特币和股票市场*的说明，以可编辑模式安装。*

 *以下是数据源的参考链接:

*   *开放系外行星目录数据库*，可在[https://github . com/openexoplanetocatalogue/Open _ exo planet _ Catalogue/# data-structure](https://github.com/OpenExoplanetCatalogue/open_exoplanet_catalogue/#data-structure)获得。
*   p .科尔特斯、a .塞尔代拉、f .阿尔梅达、t .马托斯和 j .雷伊斯。通过物理化学特性的数据挖掘建立葡萄酒偏好模型。在决策支持系统中，Elsevier，47(4):547-553，2009。可在 http://archive.ics.uci.edu/ml/datasets/Wine+Quality[在线购买](http://archive.ics.uci.edu/ml/datasets/Wine+Quality)。
*   *Dua d .和 Karra Taniskidou e .(2017 年)。http://archive.ics.uci.edu/ml/index.php 机器学习库[**]。加州欧文:加州大学信息与计算机科学学院。*

# 机器学习前景概述

**机器学习**是**人工智能** ( **AI** )的子集，由此算法可以学习从输入数据中预测值，而无需明确地被教导规则。这些算法在学习时依靠统计数据进行推断；然后他们利用他们所学到的知识进行预测。

申请贷款，使用搜索引擎，用语音命令发送机器人吸尘器来清洁特定的房间——机器学习随处可见。这是因为它可以用于许多目的，例如，Alexa、Siri 或谷歌助手等人工智能助手的语音识别，通过探索周围环境绘制平面图，确定谁将拖欠贷款，计算出哪些搜索结果是相关的，甚至绘画([https://www . bored panda . com/computer-deep-learning-algorithm-painting-masters/](https://www.boredpanda.com/computer-deep-learning-algorithm-painting-masters/))。

机器学习模型可以适应输入随时间的变化，并在每次不需要人类的情况下做出决策时提供巨大帮助。考虑在信用卡上申请贷款或增加信用额度；银行或信用卡公司将依靠机器学习算法从申请人的信用评分和历史记录中查找信息，以确定申请人是否应该被批准。最有可能的是，如果模型预测他或她有很大的机会可以获得贷款或新的信贷限额，他们只会在那一刻批准申请人。在模型不能如此确定的情况下，他们可以把它交给人类来做最后的决定。这减少了员工必须筛选的申请数量，同时也为那些非临界情况提供了更快的答案(该过程几乎是即时的)。

这里需要强调的一点是，根据法律，用于贷款审批等任务的模型必须是可解释的。需要有一种方式向申请人解释他们被拒绝的原因——有时，技术以外的原因会影响和限制我们使用的方法或数据。

## 机器学习的类型

机器学习通常分为三类:无监督学习、有监督学习和强化学习。当我们没有标签数据告诉我们我们的模型应该为每个数据点说什么时，我们使用**无监督学习**。在许多情况下，收集标记数据成本很高或者根本不可行，因此将使用无监督学习。请注意，优化这些模型的性能更加困难，因为我们不知道它们的表现如何。如果我们可以访问标签，我们可以使用**监督学习**；这使得我们更容易评估我们的模型并寻求改进它们，因为我们可以计算它们与真实标签相比的性能指标。

小费

由于无监督学习会在没有正确答案的情况下寻找数据的意义，因此它可用于在分析过程中或在进行监督学习之前了解更多的数据。

**强化学习**关注对环境反馈的反应；这是用于游戏中的机器人、AI 之类的东西。这已经超出了本书的范围，但是在*延伸阅读*部分可以找到更多信息。

请注意，并非所有的机器学习方法都完全符合上述类别。一个的例子是**深度学习**，它旨在使用**神经网络**等方法来学习数据表示。深度学习方法通常被视为黑盒，这阻止了它们在某些需要可解释模型的领域中的使用；然而，它们被用于诸如语音识别和图像分类的任务。深度学习也超出了本书的范围，但意识到它也是机器学习是很好的。

重要说明

可解释的机器学习是一个活跃的研究领域。查看*进一步阅读*部分的参考资料，了解更多信息。

## 常见任务

最常见的机器学习任务是聚类、分类和回归。在**聚类**中，我们期待将数据分配到组中，目标是组被很好地定义，这意味着组的成员紧密地在一起，并且组与其他组分离。聚类可以在无监督的情况下使用，以尝试更好地理解数据，或者在有监督的情况下尝试预测数据属于哪个聚类(本质上是分类)。请注意，聚类可以用于以无监督的方式进行预测；然而，我们将需要破译每个集群意味着什么。从聚类中获得的标签甚至可以用作监督学习者的输入，以模拟观察如何映射到每个组；这叫做**半监督学习**。

**分类**，正如我们在前一章中讨论的，看起来是给数据分配一个类别标签，比如*良性*或者*恶意*。这听起来像是将它分配给一个集群，然而，我们并不担心分配给*良性*的值有多相似，只是将它们标记为*良性*。因为我们被分配到一个类或类别，这个类的模型被用来预测一个离散的标签。**另一方面，回归**用于预测数值，如房价或图书销量；它模拟变量之间关系的强度和大小。两者都可以作为无监督或有监督的学习来执行；然而，监督模型更有可能表现得更好。

## Python 中的机器学习

现在我们知道了什么是机器学习，我们需要知道我们如何建立自己的模型。Python 提供了很多构建机器学习模型的包；我们应该了解的一些库包括:

*   `scikit-learn`:易于使用(和学习)，它的特点是用 Python 为机器学习提供一致的 API(【https://scikit-learn.org/stable/index.html】T2)
*   `statsmodels`:统计建模库，也提供统计测试(【https://www.statsmodels.org/stable/index.html】T2)
*   `tensorflow`:谷歌开发的机器学习库，具有更快的计算速度(【https://www.tensorflow.org/】T2
*   `keras`:运行深度学习的高层 API，来自 tensor flow(【https://keras.io/】)等库
*   `pytorch`: A deep learning library developed by Facebook ([https://pytorch.org](https://pytorch.org))

    小费

    这些库大多使用 NumPy 和 SciPy，后者是一个基于 NumPy 构建的库，用于统计、数学和工程目的。SciPy 可用于处理线性代数、插值、积分和聚类算法等。关于 SciPy 的更多信息可以在[https://docs . SciPy . org/doc/SciPy/reference/tutorial/general . html](https://docs.scipy.org/doc/scipy/reference/tutorial/general.html)找到。

在本书中，我们将使用`scikit-learn`作为其用户友好的 API。在`scikit-learn`中，我们的基类是一个**估计器**(不要在统计术语中与模型混淆)，它能够通过其`fit()`方法从数据中学习。我们使用**转换器**通过他们的`transform()`方法准备我们的数据——将数据转换成某种**预测器**(监督或无监督学习的类)可以通过他们的`predict()`方法使用的东西。**模型**类能够使用`score()`方法计算它们的性能。知道了这四种方法，我们可以很容易地构建`scikit-learn`提供的任何机器学习模型。关于这种设计模式的更多信息可以在[https://scikit-learn.org/stable/developers/develop.html](https://scikit-learn.org/stable/developers/develop.html)找到。

# 探索性数据分析

正如我们在本书中学到的，我们的第一步应该是参与一些**探索性的数据分析** ( **EDA** )来熟悉我们的数据。为了简洁起见，这一节将包括每个笔记本中可用的 EDA 的子集——请务必查看各个笔记本的完整版本。

小费

虽然我们将使用`pandas`代码来执行我们的 EDA，但请务必查看`pandas-profiling`包(【https://github.com/pandas-profiling/pandas-profiling】)可用于通过交互式 HTML 报告对数据快速执行一些初始 EDA。

让我们从我们的导入开始，这在我们将在本章中使用的所有笔记本中都是相同的:

```
>>> %matplotlib inline
>>> import matplotlib.pyplot as plt
>>> import numpy as np
>>> import pandas as pd
>>> import seaborn as sns
```

在进入行星之前，我们将从葡萄酒质量数据开始我们的 EDA。

## 红酒质量数据

让我们阅读红酒数据中的，并使用我们在本书中学到的技术做一些 EDA:

```
>>> red_wine = pd.read_csv('data/winequality-red.csv')
```

我们有红酒 11 种不同化学性质的数据，还有一栏显示了参与盲品测试的葡萄酒专家的质量分数。我们可以通过观察化学性质来预测质量分数:

![Figure 9.1 – Red wine dataset
](image/Figure_9.1_B16834.jpg)

图 9.1-红酒数据集

让我们看看`quality`列的分布情况:

```
>>> def plot_quality_scores(df, kind):
...     ax = df.quality.value_counts().sort_index().plot.barh(
...         title=f'{kind.title()} Wine Quality Scores',
...         figsize=(12, 3)
...     ) 
...     ax.axes.invert_yaxis()
...     for bar in ax.patches:
...         ax.text(
...             bar.get_width(),
...             bar.get_y() + bar.get_height()/2,
...             f'{bar.get_width()/df.shape[0]:.1%}',
...             verticalalignment='center'
...         )
...     plt.xlabel('count of wines')
...     plt.ylabel('quality score')
...  
...     for spine in ['top', 'right']:
...         ax.spines[spine].set_visible(False)
... 
...     return ax
>>> plot_quality_scores(red_wine, 'red')
```

数据集上的信息说`quality`从 0(糟糕)到 10(优秀)不等；然而，我们只有该范围中间的值。这个数据集的一个有趣的任务可能是看看我们是否能预测高质量的红酒(质量分数为 7 或更高):

![Figure 9.2 – Distribution of red wine quality scores
](image/Figure_9.2_B16834.jpg)

图 9.2-红酒质量分数的分布

我们所有的数据都是数值，所以我们不必担心处理文本值；我们也没有任何缺失的值:

```
>>> red_wine.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1599 entries, 0 to 1598
Data columns (total 12 columns):
 #   Column                Non-Null Count  Dtype  
---  ------                --------------  -----  
 0   fixed acidity         1599 non-null   float64
 1   volatile acidity      1599 non-null   float64
 2   citric acid           1599 non-null   float64
 3   residual sugar        1599 non-null   float64
 4   chlorides             1599 non-null   float64
 5   free sulfur dioxide   1599 non-null   float64
 6   total sulfur dioxide  1599 non-null   float64
 7   density               1599 non-null   float64
 8   pH                    1599 non-null   float64
 9   sulphates             1599 non-null   float64
 10  alcohol               1599 non-null   float64
 11  quality               1599 non-null   int64  
dtypes: float64(11), int64(1)
memory usage: 150.0 KB
```

我们可以使用`describe()`来了解各个列的每个的规模:

```
>>> red_wine.describe()
```

结果表明，如果我们的模型对任何事物使用距离度量，我们肯定必须进行一些缩放，因为我们的列不都在相同的范围内:

![Figure 9.3 – Summary statistics for the red wine dataset
](image/Figure_9.3_B16834.jpg)

图 9.3-红酒数据集的汇总统计数据

最后，让我们使用`pd.cut()`来分类我们的高品质红酒(大约占数据的 14%)以备后用:

```
>>> red_wine['high_quality'] = pd.cut(
...     red_wine.quality, bins=[0, 6, 10], labels=[0, 1]
... )
>>> red_wine.high_quality.value_counts(normalize=True)
0    0.86429
1    0.13571
Name: high_quality, dtype: float64
```

重要说明

为了简洁起见，我们在这里停止了 EDA 然而，在尝试任何建模之前，我们应该确保充分探索我们的数据并咨询领域专家。要特别注意的一件事是变量和我们试图预测的东西(在这种情况下是高质量的红酒)之间的相关性。具有强相关性的变量可能是包含在模型中的好特征。然而，请注意，相关性并不意味着因果关系。我们已经学习了一些使用可视化来寻找相关性的方法:我们在 [*第 5 章*](B16834_05_Final_SK_ePub.xhtml#_idTextAnchor106) 、*使用 Pandas 和 Matplotlib* 可视化数据中讨论的散点图，以及来自 [*第 6 章*](B16834_06_Final_SK_ePub.xhtml#_idTextAnchor125) 、*使用 Seaborn 和定制技术绘制的热图和对图*。一对图包含在`red_wine.ipynb`笔记本中。

## 白葡萄酒和红葡萄酒的化学性质数据

现在，我们一起来看看红、白葡萄酒的数据。由于数据来自单独的文件，我们需要读入两个并将它们连接成一个数据帧。白酒文件实际上是用分号(`;`)分隔的，所以我们必须向`pd.read_csv()`提供`sep`参数:

```
>>> red_wine = pd.read_csv('data/winequality-red.csv')
>>> white_wine = \
...     pd.read_csv('data/winequality-white.csv', sep=';')
```

我们也可以看看白葡萄酒的质量分数，就像我们对红葡萄酒所做的那样，我们会发现白葡萄酒总体上被评为更高。这可能会让我们质疑评委是否更喜欢白葡萄酒而不是红葡萄酒，从而在他们的评分中产生偏见。事实上，所使用的评级系统似乎相当主观:

![Figure 9.4 – Distribution of white wine quality scores 
](image/Figure_9.4_B16834.jpg)

图 9.4-白葡萄酒质量分数的分布

这两个数据帧有相同的列，所以我们可以将它们组合起来，无需进一步的工作。在这里，我们使用`pd.concat()`将白葡萄酒数据堆叠在红葡萄酒数据之上，在此之前添加一列来标识每个观察值属于哪种葡萄酒类型:

```
>>> wine = pd.concat([
...     white_wine.assign(kind='white'),
...     red_wine.assign(kind='red')
... ])
>>> wine.sample(5, random_state=10)
```

正如我们对红酒数据集所做的那样，我们可以运行`info()`来检查我们是否需要执行类型转换，或者我们是否丢失了任何数据；谢天谢地，我们这里也不需要。我们合并的葡萄酒数据集如下所示:

![Figure 9.5 – Combined wine dataset
](image/Figure_9.5_B16834.jpg)

图 9.5-组合葡萄酒数据集

使用`value_counts()`，我们可以看到数据中白葡萄酒比红葡萄酒多得多:

```
>>> wine.kind.value_counts()
white    4898
red      1599
Name: kind, dtype: int64
```

最后，让我们用`seaborn`来检查按葡萄酒类型划分的每种化学性质的方框图。这可以帮助我们识别**特征**(模型输入)，这将有助于我们构建模型来区分红葡萄酒和白葡萄酒:

```
>>> import math
>>> chemical_properties = [col for col in wine.columns
...                        if col not in ['quality', 'kind']]
>>> melted = \
...     wine.drop(columns='quality').melt(id_vars=['kind'])
>>> fig, axes = plt.subplots(
...     math.ceil(len(chemical_properties) / 4), 4, 
...     figsize=(15, 10)
... )
>>> axes = axes.flatten()
>>> for prop, ax in zip(chemical_properties, axes):
...     sns.boxplot(
...         data=melted[melted.variable.isin([prop])], 
...         x='variable', y='value', hue='kind', ax=ax
...     ).set_xlabel('')
>>> for ax in axes[len(chemical_properties):]:
...     ax.remove() # remove the extra subplots
>>> plt.suptitle(
...     'Comparing Chemical Properties of Red and White Wines'
... )
>>> plt.tight_layout()
```

给定以下结果，我们可能会在构建模型时使用固定酸度、挥发性酸度、总二氧化硫和硫酸盐，因为它们在红葡萄酒和白葡萄酒中的分布似乎不同:

![Figure 9.6 – Comparing red and white wine on a chemical level
](image/Figure_9.6_B16834.jpg)

图 9.6-在化学水平上比较红葡萄酒和白葡萄酒

小费

比较变量在不同类中的分布有助于为我们的模型选择特性。如果我们看到一个变量的分布在不同的类之间非常不同，那么这个变量包含在我们的模型中可能非常有用。在继续建模之前，我们必须对数据进行深入探索。一定要使用我们在 [*第 5 章*](B16834_05_Final_SK_ePub.xhtml#_idTextAnchor106) 、*用 Pandas 和 Matplotlib* 可视化数据、 [*第 6 章*](B16834_06_Final_SK_ePub.xhtml#_idTextAnchor125) 、*用 Seaborn 和定制技术*绘图中提到的可视化，因为它们将证明对这个过程是非常宝贵的。

我们将在第十章 、*的[、第十章*中，当我们检查我们的模型做出的不正确预测时，回到这个可视化上来。现在，让我们看看我们将使用的另一个数据集。*](B16834_10_Final_SK_ePub.xhtml#_idTextAnchor217)*

## 行星和系外行星数据

一颗**系外行星**简单来说就是，一颗围绕太阳系外的一颗恒星运行的行星，所以从现在开始我们将把这两颗行星统称为**行星**。现在让我们读取我们的行星数据:

```
>>> planets = pd.read_csv('data/planets.csv')
```

我们可以利用这些数据完成一些有趣的任务，根据它们的轨道找到相似行星的集群，并尝试预测轨道周期(行星上的一年有多长)，以地球日为单位:

![Figure 9.7 – Planets dataset
](image/Figure_9.7_B16834.jpg)

图 9.7–行星数据集

我们可以构建一个关联矩阵热图来帮助找到最佳功能:

```
>>> fig = plt.figure(figsize=(7, 7))
>>> sns.heatmap(
...     planets.drop(columns='discoveryyear').corr(), 
...     center=0, vmin=-1, vmax=1, square=True, annot=True,
...     cbar_kws={'shrink': 0.8}
... )
```

热图向我们展示了行星轨道的半长轴与其周期的长度高度正相关，这使得 T2 有意义，因为半长轴(沿着偏心率的 T3)有助于定义行星围绕其恒星运行的路径:

![Figure 9.8 – Correlations between features in the planets dataset
](image/Figure_9.8_B16834.jpg)

图 9.8-行星数据集中要素之间的相关性

为了预测`period`，我们可能想看看`semimajoraxis`、`mass`和`eccentricity`。轨道偏心率量化了轨道与正圆的差异程度:

![Figure 9.9 – Understanding eccentricity
](image/Figure_9.9_B16834.jpg)

图 9.9-了解偏心率

让我们来看看的形状我们的轨道是:

```
>>> planets.eccentricity.min(), planets.eccentricity.max()
(0.0, 0.956) # circular and elliptical eccentricities
>>> planets.eccentricity.hist()
>>> plt.xlabel('eccentricity')
>>> plt.ylabel('frequency')
>>> plt.title('Orbit Eccentricities')
```

看起来几乎所有的东西都是椭圆，这是我们所期望的，因为这些是行星:

![Figure 9.10 – Distribution of orbit eccentricities
](image/Figure_9.10_B16834.jpg)

图 9.10–轨道偏心率的分布

椭圆是一个拉长的圆，有两个轴:*长轴*和*短轴*分别代表最长和最短的。半长轴是长轴的一半。与圆相比，轴类似于直径，穿过整个形状，而半轴类似于半径，是直径的一半。下面是在行星围绕一颗正好位于其椭圆轨道中心的恒星运行的情况下(由于其他物体的引力，实际上，这颗恒星可以在轨道路径内的任何地方)的情况:

![Figure 9.11 – Understanding the semi-major axis
](image/Figure_9.11_B16834.jpg)

图 9.11-理解半长轴

既然我们理解了这些列的意思，让我们再做一些 EDA。这些数据不像我们的葡萄酒数据那样清晰——当我们伸出手去触摸它时，测量一切肯定会容易得多。我们只有有一小部分行星的`eccentricity`、`semimajoraxis`或`mass`数据，尽管知道大部分`period`值:

```
>>> planets[[
...     'period', 'eccentricity', 'semimajoraxis', 'mass'
... ]].info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 4094 entries, 0 to 4093
Data columns (total 4 columns):
 #   Column         Non-Null Count  Dtype  
---  ------         --------------  -----  
 0   period         3930 non-null   float64
 1   eccentricity   1388 non-null   float64
 2   semimajoraxis  1704 non-null   float64
 3   mass           1659 non-null   float64
dtypes: float64(4)
memory usage: 128.1 KB
```

如果我们要删除这些列中任何一列为空的数据，我们将剩下大约 30%的数据:

```
>>> planets[[
...     'period', 'eccentricity', 'semimajoraxis', 'mass'
... ]].dropna().shape
(1222, 4)
```

如果我们只是简单地寻找一种方法来预测一年的长度(当我们有这些可用的值时)以了解更多关于它们之间的关系，我们就不必担心丢弃丢失的数据。在这里进行估算对我们的模型来说可能更糟。至少所有的东西都被正确地编码为十进制(`float64`)；然而，让我们检查一下我们是否需要做一些缩放(如果我们的模型对数量级的差异敏感，这是有益的):

```
>>> planets[[
...     'period', 'eccentricity', 'semimajoraxis', 'mass'
... ]].describe()
```

这向表明，根据我们的模型，我们肯定会进行一些缩放，因为`period`列中的值比其他列中的值大得多:

![Figure 9.12 – Summary statistics for the planets dataset
](image/Figure_9.12_B16834.jpg)

图 9.12–行星数据集的汇总统计数据

我们也可以看一些散点图。注意，行星所属的组有一个`list`列，如`Solar System`或`Controversial`。我们可能想看看周期(和离恒星的距离)是否会对此产生影响:

```
>>> sns.scatterplot(
...     x=planets.semimajoraxis, y=planets.period, 
...     hue=planets.list, alpha=0.5
... )
>>> plt.title('period vs. semimajoraxis')
>>> plt.legend(title='') 
```

有争议的行星似乎遍布各处,具有更大的半长轴和周期。也许它们是有争议的，因为它们离它们的恒星非常远:

![Figure 9.13 – Planet period versus semi-major axis
](image/Figure_9.13_B16834.jpg)

图 9.13–行星周期与半长轴

不幸的是，我们可以看到,`period`的比例使其很难阅读，所以我们可以尝试在 *y* 轴上进行对数变换，以在左下方更密集的部分获得更多的分离。这次我们只指出太阳系中的行星:

```
>>> fig, ax = plt.subplots(1, 1, figsize=(10, 10))
>>> in_solar_system = (planets.list == 'Solar System')\
...     .rename('in solar system?')
>>> sns.scatterplot(
...     x=planets.semimajoraxis, y=planets.period, 
...     hue=in_solar_system, ax=ax
... )
>>> ax.set_yscale('log')
>>> solar_system = planets[planets.list == 'Solar System']
>>> for planet in solar_system.name:
...     data = solar_system.query(f'name == "{planet}"')
...     ax.annotate(
...         planet, 
...         (data.semimajoraxis, data.period), 
...         (7 + data.semimajoraxis, data.period),
...         arrowprops=dict(arrowstyle='->')
...     )
>>> ax.set_title('log(orbital period) vs. semi-major axis')
```

那里肯定有很多行星藏在地图左下角的 T2 里。我们现在可以看到许多年短于水星 88 个地球日的行星:

![Figure 9.14 – Our solar system compared to exoplanets
](image/Figure_9.14_B16834.jpg)

图 9.14–我们的太阳系与系外行星的比较

既然我们已经对将要处理的数据有了一种感觉，那么让我们学习如何准备在机器学习模型中使用它。

# 预处理数据

在本节中，我们将在`preprocessing.ipynb`笔记本中工作，然后将返回到我们用于 EDA 的笔记本。我们将从我们的导入开始，并读入数据:

```
>>> import numpy as np
>>> import pandas as pd
>>> planets = pd.read_csv('data/planets.csv')
>>> red_wine = pd.read_csv('data/winequality-red.csv')
>>> wine = pd.concat([
...     pd.read_csv(
...         'data/winequality-white.csv', sep=';'
...     ).assign(kind='white'), 
...     red_wine.assign(kind='red')
... ])
```

机器学习模型遵循垃圾进，垃圾出的原则。我们必须确保我们**训练**我们的模型(让他们学习)尽可能好的数据版本。这意味着什么将取决于我们选择的模式。例如，如果我们的特征在非常不同的尺度上，使用距离度量来计算相似性的模型很容易被混淆。除非我们正在处理一个**自然语言处理** ( **NLP** )问题来尝试理解单词的意思，否则我们的模型将对文本值毫无用处——或者更糟，无法解释文本值。数据缺失或无效也会导致问题；我们将不得不决定是放弃它们还是估算它们。在将数据交给模型学习之前，我们对数据进行的所有调整统称为预处理。

## 训练和测试集

到目前为止，机器学习听起来非常棒——我们可以建立一个模型，学习如何为我们执行任务。因此，我们应该给它所有我们拥有的数据，以便它很好地学习，对吗？可惜没那么简单。如果我们给模型我们所有的数据，我们冒着**过度拟合**它的风险，这意味着它将不能很好地推广到新的数据点，因为它适合样本而不是总体。另一方面，如果我们不给它足够的数据，它就会**欠拟合**，无法捕捉数据中的潜在信息。

小费

当一个模型符合数据中的随机性时，就说符合数据中的**噪声**。

另一件要考虑的事情是，如果我们使用所有的数据来训练模型，我们如何评估它的性能？如果我们在用于训练的数据上测试它，我们将高估它有多好，因为我们的模型在训练数据上总是表现得更好。由于这些原因，将我们的数据分成**训练集**和**测试集**是很重要的。为此，我们可以调整数据帧，选择顶部的 *x* %的行进行训练，剩下的进行测试:

```
shuffled = \
    planets.reindex(np.random.permutation(planets.index))
train_end_index = int(np.ceil(shuffled.shape[0] * .75))
training = shuffled.iloc[:train_end_index,]
testing = shuffled.iloc[train_end_index:,]
```

这是可行的，但是每次都要写很多东西。谢天谢地，`scikit-learn`在`model_selection`模块中为我们提供了`train_test_split()`函数，这是一个更健壮、更易用的解决方案。它要求我们事先将输入数据(`X`)和输出数据(`y`)分开。这里，我们将挑选 75%的数据用于训练集(`X_train`、`y_train`)，25%的数据用于测试集(`X_test`、`y_test`)。我们将设置一个种子(`random_state=0`)，以便分割是可再现的:

```
>>> from sklearn.model_selection import train_test_split
>>> X = planets[['eccentricity', 'semimajoraxis', 'mass']]
>>> y = planets.period
>>> X_train, X_test, y_train, y_test = train_test_split(
...     X, y, test_size=0.25, random_state=0
... )
```

虽然没有具体的标准来确定测试集的大小，但经验法则通常是数据的 10%到 30%。然而，如果我们没有太多的数据，我们将转向 10%的测试集，以确保我们有足够的数据来学习。相反，如果我们有大量的数据，我们可能会走向 30%测试，因为，我们不仅不想过度拟合，而且我们想给我们的模型大量的数据来证明它的价值。请注意，这个经验法则有一个很大的警告:我们使用的训练数据量的回报是递减的。如果我们有一吨的数据，我们很可能将少于 70%的数据用于训练，因为我们的计算成本可能会因微小的改进和过度拟合风险的增加而显著上升。

重要说明

当构建需要调整的模型时，我们将数据分成训练集、验证集和测试集。我们将在第十章 、*中介绍验证集，做出更好的预测-优化模型*。

现在让我们来看看我们的训练和测试集的大小。因为我们使用了三个特征(`eccentricity`、`semimajoraxis`和`mass`)，所以`X_train`和`X_test`有三列。`y_train`和`y_test`组将各为一列。用于训练的`X`和`y`数据中的观察值数量将相等，测试集的情况也是如此:

```
>>> X.shape, y.shape # original data
((4094, 3), (4094,))
>>> X_train.shape, y_train.shape # training data
((3070, 3), (3070,))
>>> X_test.shape, y_test.shape # testing data
((1024, 3), (1024,))
```

`X_train`和`X_test`作为数据帧返回给我们，因为这是我们传递它们的格式。如果我们直接处理 NumPy 中的数据，我们将获得 NumPy 数组或`ndarrays`。我们将在*预处理数据*部分的其他示例中使用这些数据，所以让我们看看`X_train`数据帧的前五行。现在不要担心`NaN`的价值；我们将在*输入*部分讨论处理它们的不同方式:

```
>>> X_train.head()
      eccentricity  semimajoraxis  mass
1390           NaN            NaN   NaN
2837           NaN            NaN   NaN
3619           NaN         0.0701   NaN
1867           NaN            NaN   NaN
1869           NaN            NaN   NaN
```

`y_train`和`y_test`都是序列，因为这是我们传递给`train_test_split()`函数的内容。如果我们传入了一个 NumPy 数组，这就是我们应该得到的结果。`y_train`和`y_test`中的行必须分别与`X_train`和`X_test`中的行对齐。让我们通过查看`y_train`的前五行来确认这一点:

```
>>> y_train.head()
1390     1.434742
2837    51.079263
3619     7.171000
1867    51.111024
1869    62.869161
Name: period, dtype: float64
```

事实上，一切都符合预期。注意，对于我们的葡萄酒模型，我们需要使用分层的抽样，这也可以通过将`stratify`参数中的值传递给来用`train_test_split()`完成。我们将在*分类*部分看到这一点。现在，让我们继续进行其余的预处理。

## 缩放和居中数据

我们已经看到，我们的数据框架有不同比例的列；如果我们想要使用任何计算距离度量的模型(比如 k-means，我们将在本章中讨论，或者**k-nearest neighbors**(**k-NN**，我们将在 [*第 10 章*](B16834_10_Final_SK_ePub.xhtml#_idTextAnchor217) 、*做出更好的预测-优化模型*中简要讨论)，我们将需要缩放这些。正如我们在 [*第 1 章*](B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015) 、*数据分析简介*中所讨论的，我们有相当多的选择来这样做。Scikit-learn 在`preprocessing`模块中提供了用于标准化(通过计算 Z 分数进行缩放)和最小-最大缩放(将数据标准化到范围[0，1])等的选项。

重要说明

我们应该检查我们正在构建的模型的需求，看看数据是否需要缩放。

对于标准缩放，我们使用`StandardScaler`类。`fit_transform()`方法结合了`fit()`和`transform()`，前者计算居中和缩放所需的平均值和标准偏差，后者将转换应用于数据。注意，当实例化一个`StandardScaler`对象时，我们可以通过将`False`分别传递给`with_mean`或`with_std`来选择不减去平均值或不除以标准偏差。两者默认都是`True`:

```
>>> from sklearn.preprocessing import StandardScaler
>>> standardized = StandardScaler().fit_transform(X_train)
# examine some of the non-NaN values
>>> standardized[~np.isnan(standardized)][:30]
array([-5.43618156e-02,  1.43278593e+00,  1.95196592e+00,
        4.51498477e-03, -1.96265630e-01,  7.79591646e-02, 
        ...,
       -2.25664815e-02,  9.91013258e-01, -7.48808523e-01,
       -4.99260165e-02, -8.59044215e-01, -5.49264158e-02])
```

经过这种转换后，数据以**科学记数法**表示。字符`e`后的信息告诉我们小数点移到了哪里。对于一个`+`符号，我们将小数点向右移动指定的位数；我们向左移动，看到一个`-`的标志。所以，`1.00e+00`相当于`1`，`2.89e-02`相当于`0.0289`，`2.89e+02`相当于`289`。转换后的行星数据大多在-3 和 3 之间，因为现在一切都是 Z 值。

其他定标器可以使用相同的语法。让我们使用`MinMaxScaler`类将行星数据转换到范围[0，1]:

```
>>> from sklearn.preprocessing import MinMaxScaler
>>> normalized = MinMaxScaler().fit_transform(X_train)
# examine some of the non-NaN values
>>> normalized[~np.isnan(normalized)][:30]
array([2.28055906e-05, 1.24474091e-01, 5.33472803e-01,
       1.71374569e-03, 1.83543340e-02, 1.77824268e-01, 
       ...,
       9.35966714e-04, 9.56961137e-02, 2.09205021e-02, 
       1.50201619e-04, 0.00000000e+00, 6.59028789e-06])
```

小费

另一个选项是`RobustScaler`类，它使用中位数和 IQR 来实现对异常值的稳健缩放。笔记本里有这样的例子。更多的预处理类可以在[https://scikit-learn . org/stable/modules/classes . html # module-sk learn . preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)找到。

## 编码数据

到目前为止，我们讨论的所有定标器都处理了数字数据的预处理，但是我们如何处理分类数据呢？我们需要将类别编码成整数值。这里有几个选项，取决于类别所代表的内容。如果我们的类别是二进制的(如`0` / `1`、`True` / `False`或`yes` / `no`)，那么我们将**将这些编码为两个选项的单个列，其中`0`是一个选项，`1`是另一个选项。我们可以用`np.where()`函数轻松做到这一点。让我们将葡萄酒数据的`kind`字段编码为红色的`1`和白色的`0`:**

```
>>> np.where(wine.kind == 'red', 1, 0)
array([0, 0, 0, ..., 1, 1, 1])
```

这实际上是一个告诉我们葡萄酒是否是红色的列。请记住，当我们创建`wine`数据帧时，我们将红葡萄酒连接到白葡萄酒的底部，因此`np.where()`将为顶行返回 0，为底行返回 1，就像我们在前面的结果中看到的一样。

小费

我们也可以使用`scikit-learn`中的`LabelBinarizer`类对`kind`域进行编码。请注意，如果我们的数据实际上是连续的，但我们想将其视为二进制分类值，我们可以使用`Binarizer`类并提供阈值或`pd.cut()` / `pd.qcut()`。笔记本上有这些例子。

如果我们的类别是有序的，我们可能想要在那些列上使用**顺序编码**；这将保持类别的顺序。例如，如果我们想将红酒分为低、中、高质量，我们可以分别编码为`0`、`1`和`2`。这样做的好处是，我们可以使用回归技术来预测质量，或者我们可以将此作为模型中的一个特征来预测其他东西；该模型将能够利用高质量比中质量好的事实，中质量比低质量好。我们可以用`LabelEncoder`类来实现这一点。请注意，标签将根据字母顺序创建，因此按字母顺序排列的第一个类别将是`0`:

```
>>> from sklearn.preprocessing import LabelEncoder
>>> pd.Series(LabelEncoder().fit_transform(pd.cut(
...     red_wine.quality, 
...     bins=[-1, 3, 6, 10], 
...     labels=['0-3 (low)', '4-6 (med)', '7-10 (high)']
... ))).value_counts()
1    1372
2     217
0      10
dtype: int64
```

重要说明

Scikit-learn 提供了`OrdinalEncoder`类，但是我们的数据格式不正确——它需要 2D 数据(比如一个`DataFrame`或`ndarray`对象),而不是我们在这里使用的 1D `Series`对象。我们仍然需要事先确保类别的顺序是正确的。

但是，请注意，序号编码可能会产生潜在的数据问题。在我们的例子中，如果高质量的葡萄酒现在是`2`，中等质量的葡萄酒是`1`，那么模型可能会解释为`2 * med = high`。这就隐含地在我们可能不同意的质量水平之间建立了一种联系。

或者，更安全的方法是执行**一键编码**来创建两个新列— `is_low`和`is_med`，这仅需要`0`或`1`。利用这两个，我们自动知道酒的质量是否高(当`is_low` = `is_med` = `0`)。这些被称为**虚拟变量**或**指示变量**；它们用数字表示用于机器学习的组成员。如果指标或虚拟指标的值为`1`，则该行是该组的成员；在我们的葡萄酒质量类别示例中，如果`is_low`是`1`，那么该行是低质量组的成员。这可以通过`pd.get_dummies()`函数和`drop_first`参数来实现，这将删除多余的列。

让我们使用一键编码对行星数据中的`list`列进行编码，因为类别没有固有的顺序。在进行任何转换之前，让我们看一下数据中的列表:

```
>>> planets.list.value_counts()
Confirmed planets                    3972
Controversial                          97
Retracted planet candidate             11
Solar System                            9
Kepler Objects of Interest              4
Planets in binary systems, S-type       1
Name: list, dtype: int64
```

如果我们想在模型中包含行星列表，我们可以使用`pd.get_dummies()`函数创建虚拟变量:

```
>>> pd.get_dummies(planets.list).head()
```

这将我们的单个序列变成了下面的数据帧，其中虚拟变量是按照它们在数据中出现的顺序创建的:

![Figure 9.15 – One-hot encoding
](image/Figure_9.15_B16834.jpg)

图 9.15–一键编码

如前所述，其中一列是冗余的，因为剩余列中的值可用于确定冗余列的值。一些模型可能受到这些列之间的高度相关性(称为**多重共线性**)的显著影响，因此我们应该通过传入`drop_first`参数来移除一个冗余列:

```
>>> pd.get_dummies(planets.list, drop_first=True).head()
```

注意，先前结果的第一列已经被删除，但是我们仍然可以确定除了最后一行之外的所有行都在`Confirmed Planets`列表中:

![Figure 9.16 – Dropping redundant columns after one-hot encoding
](image/Figure_9.16_B16834.jpg)

图 9.16–在一次热编码后删除冗余列

注意，我们可以通过在行星列表中使用`LabelBinarizer`类及其`fit_transform()`方法来获得类似的结果。这不会丢弃一个多余的特征，所以我们再次拥有属于已确认行星列表的第一个特征，这可以在下面的结果中以粗体显示:

```
>>> from sklearn.preprocessing import LabelBinarizer
>>> LabelBinarizer().fit_transform(planets.list)
array([[1, 0, 0, 0, 0, 0],
       [1, 0, 0, 0, 0, 0], 
       [1, 0, 0, 0, 0, 0],
       ..., 
       [1, 0, 0, 0, 0, 0],
       [1, 0, 0, 0, 0, 0],
       [1, 0, 0, 0, 0, 0]])
```

重要说明

Scikit-learn 提供了`OneHotEncoder`类，但是我们的数据格式不正确——它期望数据以 2D 数组的形式出现，而我们的系列只是 1D。我们将在*附加变压器*部分看到如何使用的示例。

## 输入

我们已经知道我们的行星数据中有一些缺失值，所以让我们讨论一下`scikit-learn`提供的处理它们的几个选项，这些选项可以在`impute`模块中找到:用一个值进行输入(使用常数或汇总统计)，基于类似观察的进行输入，并指出缺失了什么。

回到*探索性数据分析*部分，我们对计划建模的行星数据运行`dropna()`。假设我们不想摆脱它，而是想尝试将其归咎于。我们数据的最后几行有一些`semimajoraxis`的缺失值:

```
>>> planets[['semimajoraxis', 'mass', 'eccentricity']].tail()
      semimajoraxis    mass  eccentricity
4089        0.08150  1.9000         0.000
4090        0.04421  0.7090         0.038
4091            NaN  0.3334         0.310
4092            NaN  0.4000         0.270
4093            NaN  0.4200         0.160
```

我们可以使用`SimpleImputer`类来估算一个值，这个值默认为平均值:

```
>>> from sklearn.impute import SimpleImputer
>>> SimpleImputer().fit_transform(
...     planets[['semimajoraxis', 'mass', 'eccentricity']]
... )
array([[ 1.29      , 19.4       ,  0.231     ],
       [ 1.54      , 11.2       ,  0.08      ],
       [ 0.83      ,  4.8       ,  0\.        ],
       ...,
       [ 5.83796389,  0.3334    ,  0.31      ],
       [ 5.83796389,  0.4       ,  0.27      ],
       [ 5.83796389,  0.42      ,  0.16      ]])
```

均值在这里似乎不是一个好的策略，因为我们所知道的行星可能有一些共同点，当然像行星是什么系统的一部分和它的轨道可以是一些缺失数据点的良好指标。我们可以选择为`strategy`参数提供平均值以外的方法；目前可以是`median`、`most_frequent`或`constant`(用`fill_value`指定数值)。这些都不适合我们。然而，`scikit-learn`也提供了`KNNImputer`类，用于基于类似的观察输入缺失值。默认情况下，它使用五个最近的邻居并运行 k-NN，我们将在第 10 章 、*中讨论这一点，做出更好的预测-优化模型*，使用没有遗漏的特性:

```
>>> from sklearn.impute import KNNImputer
>>> KNNImputer().fit_transform(
...     planets[['semimajoraxis', 'mass', 'eccentricity']]
... )
array([[ 1.29    , 19.4     ,  0.231   ],
       [ 1.54    , 11.2     ,  0.08    ],
       [ 0.83    ,  4.8     ,  0\.      ],
       ...,
       [ 0.404726,  0.3334  ,  0.31    ],
       [ 0.85486 ,  0.4     ,  0.27    ],
       [ 0.15324 ,  0.42    ,  0.16    ]])
```

请注意，底部三行中的每一行现在都有一个唯一的半长轴估算值。这是因为质量和偏心率被用来寻找相似的行星来估算半长轴。虽然这肯定比使用`SimpleImputer`类获得行星数据要好，但估算可能是危险的。

在某些情况下，我们可能更感兴趣的是记录缺失数据的位置，并将其作为模型中的一个特征，而不是对数据进行输入。这可以通过`MissingIndicator`类来实现:

```
>>> from sklearn.impute import MissingIndicator
>>> MissingIndicator().fit_transform(
...     planets[['semimajoraxis', 'mass', 'eccentricity']]
... )
array([[False, False, False],
       [False, False, False],
       [False, False, False],
       ...,
       [ True, False, False],
       [ True, False, False],
       [ True, False, False]])
```

当我们把注意力转向我们将讨论的最后一组预处理程序时，请注意它们都有一个`fit_transform()`方法，以及`fit()`和`transform()`方法。这个 API 设计决策使得如何使用新类变得非常容易，这也是`scikit-learn`如此容易学习和使用的原因之一——它非常一致。

## 附加变压器

如果我们想运行一个数学运算，比如求平方根或对数，而不是对数据进行缩放或编码，会怎么样？`preprocessing`模块对此也有一些类。虽然有几个执行特定转换的类，比如`QuantileTransformer`类，但是我们将把注意力集中在`FunctionTransformer`类上，它允许我们提供一个任意的函数来使用:

```
>>> from sklearn.preprocessing import FunctionTransformer
>>> FunctionTransformer(
...     np.abs, validate=True
... ).fit_transform(X_train.dropna())
array([[0.51   , 4.94   , 1.45   ],
       [0.17   , 0.64   , 0.85   ],
       [0.08   , 0.03727, 1.192  ],
       ...,
       [0.295  , 4.46   , 1.8    ],
       [0.34   , 0.0652 , 0.0087 ],
       [0.3    , 1.26   , 0.5    ]])
```

这里，我们取了每个数字的绝对值。记下`validate=True`参数；`FunctionTransformer`类知道`scikit-learn`模型不接受`NaN`值、无穷大值或缺失值，所以如果我们取回这些值，它将抛出一个错误。为此，我们也在这里运行`dropna()`。

请注意，对于缩放、编码、输入和转换数据，我们传递的所有内容都被转换了。如果我们有不同数据类型的特性，我们可以在一次调用中使用`ColumnTransformer`类将转换映射到一列(或一组列):

```
>>> from sklearn.compose import ColumnTransformer 
>>> from sklearn.impute import KNNImputer
>>> from sklearn.preprocessing import (
...     MinMaxScaler, StandardScaler
... )
>>> ColumnTransformer([
...     ('impute', KNNImputer(), [0]),
...     ('standard_scale', StandardScaler(), [1]),
...     ('min_max', MinMaxScaler(), [2])
... ]).fit_transform(X_train)[10:15] 
array([[ 0.17      , -0.04747176,  0.0107594 ],
       [ 0.08      , -0.05475873,  0.01508851],
       [ 0.15585591,         nan,  0.13924042],
       [ 0.15585591,         nan,         nan],
       [ 0\.        , -0.05475111,  0.00478471]])
```

还有一个`make_column_transformer()`函数，它将为我们命名变形金刚。让我们创建一个将分类数据和数值数据区别对待的`ColumnTransformer`对象:

```
>>> from sklearn.compose import make_column_transformer
>>> from sklearn.preprocessing import (
...     OneHotEncoder, StandardScaler
... )
>>> categorical = [
...     col for col in planets.columns
...     if col in [
...         'list', 'name', 'description', 
...         'discoverymethod', 'lastupdate'
...     ]
... ]
>>> numeric = [
...     col for col in planets.columns
...     if col not in categorical
... ]
>>> make_column_transformer(
...     (StandardScaler(), numeric),
...     (OneHotEncoder(sparse=False), categorical)
... ).fit_transform(planets.dropna())
array([[ 3.09267587, -0.2351423 , -0.40487424, ...,  
         0\.        ,  0\.        ],
       [ 1.432445  , -0.24215395, -0.28360905, ...,  
         0\.        ,  0\.        ],
       [ 0.13665505, -0.24208849, -0.62800218, ...,  
         0\.        ,  0\.        ],
       ...,
       [-0.83289954, -0.76197788, -0.84918988, ...,  
         1\.        ,  0\.        ],
       [ 0.25813535,  0.38683239, -0.92873984, ...,  
         0\.        ,  0\.        ],
       [-0.26827931, -0.21657671, -0.70076129, ...,  
         0\.        ,  1\.        ]])
```

小费

我们在实例化我们的`OneHotEncoder`对象时传递`sparse=False`，以便我们可以看到我们的结果。实际上，我们不需要这样做，因为`scikit-learn`模型知道如何处理 NumPy 稀疏矩阵。

## 构建数据管道

看起来预处理我们的数据需要很多步骤，它们需要以正确的顺序应用于训练和测试数据——非常繁琐。令人欣慰的是，`scikit-learn`提供了创建流水线的能力，以简化预处理，并确保训练集和测试集被同等对待。这可以防止出现问题，例如，使用所有数据计算平均值以便将其标准化，然后将其分成训练集和测试集，这将创建一个看起来比实际表现更好的模型。

重要说明

当来自训练集之外的信息(例如使用完整的数据集来计算标准化的平均值)用于训练模型时，它被称为**数据泄漏**。

在我们构建第一个模型之前，我们正在学习管道，因为它们确保模型构建正确。管道可以包含所有预处理步骤和模型本身。制作管道非常简单，只需定义步骤并命名即可:

```
>>> from sklearn.pipeline import Pipeline
>>> from sklearn.preprocessing import StandardScaler
>>> from sklearn.linear_model import LinearRegression
>>> Pipeline([
...     ('scale', StandardScaler()), ('lr', LinearRegression())
... ])
Pipeline(steps=[('scale', StandardScaler()), 
                ('lr', LinearRegression())])
```

我们不局限于在模型中使用管道——它们也可以在其他`scikit-learn`对象中使用，例如，`ColumnTransformer`对象。这使得我们可以首先在半长轴数据(索引`0`处的列)上使用 k-NN 输入，然后标准化结果。然后，我们可以将其作为管道的一部分，这为我们构建模型提供了极大的灵活性:

```
>>> from sklearn.compose import ColumnTransformer 
>>> from sklearn.impute import KNNImputer
>>> from sklearn.pipeline import Pipeline
>>> from sklearn.preprocessing import (
...     MinMaxScaler, StandardScaler
... )
>>> ColumnTransformer([
... ('impute', Pipeline([
... ('impute', KNNImputer()),
... ('scale', StandardScaler())
... ]), [0]),
...     ('standard_scale', StandardScaler(), [1]),
...     ('min_max', MinMaxScaler(), [2])
... ]).fit_transform(X_train)[10:15]
array([[ 0.13531604, -0.04747176,  0.0107594 ],
       [-0.7257111 , -0.05475873,  0.01508851],
       [ 0\.        ,         nan,  0.13924042],
       [ 0\.        ,         nan,         nan],
       [-1.49106856, -0.05475111,  0.00478471]])
```

就像使用`ColumnTransformer`类一样，我们有一个函数可以为制作管道，而不必命名步骤。让我们制作另一个管道，但这次我们将使用`make_pipeline()`函数:

```
>>> from sklearn.pipeline import make_pipeline
>>> make_pipeline(StandardScaler(), LinearRegression())
Pipeline(steps=[('standardscaler', StandardScaler()),
                ('linearregression', LinearRegression())])
```

请注意，这些步骤已经被自动命名为小写版本的类名。正如我们将在下一章中看到的，命名步骤将使通过名称优化模型参数变得更加容易。`scikit-learn` API 的一致性也将允许我们使用这个管道来拟合我们的模型，并使用相同的对象进行预测，这将在下一节中看到。

# 聚类

我们使用聚类将我们的数据点分成相似点的组。每个组中的点比其他组中的点更像他们的同伴组成员。聚类通常用于推荐系统(想想网飞是如何根据其他看过类似节目的人在看什么来推荐什么)和市场细分等任务。

例如，假设我们在一家在线零售商工作，想要对我们的网站用户进行细分，以进行更有针对性的营销工作；我们可以收集在网站上花费的时间、页面访问量、浏览的产品、购买的产品等数据。然后，我们可以有一个无监督的聚类算法来寻找具有相似行为的用户组；如果我们分成三组，我们可以根据每组的行为给它们贴上标签:

![Figure 9.17 – Clustering website users into three groups
](image/Figure_9.17_B16834.jpg)

图 9.17-将网站用户分为三组

由于我们可以使用聚类进行无监督学习，我们将需要解释所创建的组，然后尝试为每个组导出一个有意义的名称。如果我们的聚类算法识别了前面散点图中的三个聚类，我们可能能够进行以下行为观察:

*   **常客(0 组)**:购买很多，看很多产品。
*   **偶尔顾客(第 1 组)**:有过一些购买行为，但少于最频繁顾客。
*   **浏览器(第二组)**:访问了网站，但还没买东西。

一旦确定了这些群体，营销团队就可以针对这些群体中的每一个群体进行不同的营销；很明显，常客会为底线做更多的事情，但是如果他们已经买了很多，也许营销预算可以更好地用于增加临时客户的购买量或将浏览器转化为临时客户。

重要说明

决定要创建的组的数量显然会影响以后如何解释这些组，这意味着这不是一个微不足道的决定。我们至少应该将我们的数据可视化，并在尝试猜测要将数据分成多少组之前获得一些领域知识。

或者，如果我们知道用于训练目的的一些数据的组标签，可以以监督的方式使用聚类。假设我们收集了关于登录活动的数据，就像在 [*第 8 章*](B16834_08_Final_SK_ePub.xhtml#_idTextAnchor172) ，*基于规则的异常检测*中一样，但是我们有一些攻击者活动的例子；我们可以收集所有活动的数据点，然后使用聚类算法将其分配给有效用户组或攻击者组。因为我们有了标签，我们可以调整我们的输入变量和/或我们使用的聚类算法，以最好地将这些组与它们的真实组对齐。

## k 均值

由`scikit-learn`提供的聚类算法可以在[https://scikit-learn . org/stable/modules/classes . html # module-sk learn . cluster](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.cluster)的`cluster`模块文档中找到。我们来看一下 **k-means** ，它使用与组的**质心**的距离(中心点)迭代分配点给最近的组，使 *k* 组。由于该模型使用距离计算，我们必须事先了解比例对我们结果的影响；然后我们可以决定缩放哪些列(如果有的话)。

重要说明

有许多方法可以测量空间中两点之间的距离。通常，欧几里德距离或直线距离是默认的；然而，另一个常见的是曼哈顿距离，它可以被认为是城市街区距离。

当我们使用周期的对数标度绘制出所有行星的周期与半长轴的关系时，我们看到行星沿着一条弧线很好的分离。我们将使用 k-means 来寻找沿着该弧具有相似轨道的行星群。

### 根据轨道特征对行星进行分组

正如我们在*预处理数据*部分所讨论的，我们可以构建一个管道来扩展，然后对我们的数据建模。在这里，我们的模型将是一个由八个星团组成的`KMeans`物体(代表我们太阳系中行星的数量——抱歉，是冥王星)。由于 k-means 算法随机选择它的起始质心，除非我们指定种子，否则可能得到不同的聚类结果。因此，我们也提供`random_state=0`用于再现性:

```
>>> from sklearn.cluster import KMeans
>>> from sklearn.pipeline import Pipeline
>>> from sklearn.preprocessing import StandardScaler
>>> kmeans_pipeline = Pipeline([
...     ('scale', StandardScaler()), 
...     ('kmeans', KMeans(8, random_state=0))
... ])
```

一旦我们有了我们的管道，我们就把它放在所有的数据上，因为我们不试图预测任何东西(在这种情况下)——我们只想找到相似的行星:

```
>>> kmeans_data = planets[['semimajoraxis', 'period']].dropna()
>>> kmeans_pipeline.fit(kmeans_data)
Pipeline(steps=[('scale', StandardScaler()),
                ('kmeans', KMeans(random_state=0))])
```

一旦模型适合我们的数据，我们可以使用`predict()`方法来获得每个点的聚类标签(在我们之前使用的相同数据上)。让我们来看看 k-means 确定的聚类:

```
>>> fig, ax = plt.subplots(1, 1, figsize=(7, 7))
>>> sns.scatterplot(
...     x=kmeans_data.semimajoraxis, 
...     y=kmeans_data.period, 
...     hue=kmeans_pipeline.predict(kmeans_data),
...     ax=ax, palette='Accent'
... )
>>> ax.set_yscale('log')
>>> solar_system = planets[planets.list == 'Solar System']
>>> for planet in solar_system.name:
...     data = solar_system.query(f'name == "{planet}"')
...     ax.annotate(
...         planet, 
...         (data.semimajoraxis, data.period), 
...         (7 + data.semimajoraxis, data.period),
...         arrowprops=dict(arrowstyle='->')
...     )
>>> ax.get_legend().remove()
>>> ax.set_title('KMeans Clusters')
```

水星和金星落在同一个星团里，地球和火星也是。Jupyter、土星和天王星分别属于不同的星团，而海王星和冥王星共享一个星团:

![Figure 9.18 – Eight clusters of planets identified by k-means
](image/Figure_9.18_B16834.jpg)

图 9.18–通过 k 均值识别的八个行星簇

我们在这里随意挑选了八个星团，因为这是我们太阳系中行星的数量。理想情况下，我们应该对真正的分组有一些领域知识，或者需要选择一个特定的数字。例如，假设我们想让婚礼宾客坐在五张桌子上，这样他们都能和睦相处，那么我们的 *k* 就是 5；如果我们可以在用户群上运行三次营销活动，我们就有了 3 个 *k* 。如果我们对数据中的组数没有直觉，经验法则是尝试我们的观察值的平方根，但这可能会产生难以管理的群集数量。所以，如果在我们的数据上创建很多 k-means 模型不需要太长时间，我们可以用肘点法。

### 确定 k 的肘点法

**肘点法**包括创建具有多个 *k* 值的多个模型，并绘制每个模型的**惯性** ( **类内平方和**)与类数量的关系。我们希望最小化从点到聚类中心的平方距离的总和，同时不创建太多的聚类。

`ml_utils.elbow_point`模块包含了我们的`elbow_point()`函数，这里复制了它:

```
import matplotlib.pyplot as plt
def elbow_point(data, pipeline, kmeans_step_name='kmeans',    
                k_range=range(1, 11), ax=None):
    """
    Plot the elbow point to find an appropriate k for
    k-means clustering.
    Parameters:
        - data: The features to use
        - pipeline: The scikit-learn pipeline with `KMeans`
        - kmeans_step_name: Name of `KMeans` step in pipeline
        - k_range: The values of `k` to try
        - ax: Matplotlib `Axes` to plot on.
    Returns: 
        A matplotlib `Axes` object
    """
    scores = []
    for k in k_range:
        pipeline.named_steps[kmeans_step_name].n_clusters = k
        pipeline.fit(data)
        # score is -1*inertia so we multiply by -1 for inertia
        scores.append(pipeline.score(data) * -1)
    if not ax:
        fig, ax = plt.subplots()
    ax.plot(k_range, scores, 'bo-')
    ax.set_xlabel('k')
    ax.set_ylabel('inertias')
    ax.set_title('Elbow Point Plot')
    return ax
```

让我们用肘点法为 *k* 找到一个合适的值:

```
>>> from ml_utils.elbow_point import elbow_point
>>> ax = elbow_point(
...     kmeans_data, 
...     Pipeline([
...         ('scale', StandardScaler()), 
...         ('kmeans', KMeans(random_state=0))
...     ])
... )
>>> ax.annotate(
...     'possible appropriate values for k', xy=(2, 900), 
...     xytext=(2.5, 1500), arrowprops=dict(arrowstyle='->')
... )
>>> ax.annotate(
...     '', xy=(3, 3480), xytext=(4.4, 1450), 
...     arrowprops=dict(arrowstyle='->')
... )
```

我们看到收益递减的点是一个合适的 *k* ，这里可能是 2 或 3 左右:

![Figure 9.19 – Interpreting an elbow point plot
](image/Figure_9.19_B16834.jpg)

图 9.19–解释肘点图

如果我们只创建两个星团，我们将这些行星分为一组，其中大部分行星(橙色)和第二组，其中只有一小部分在右上角(蓝色)，它们很可能是离群值:

![Figure 9.20 – Two clusters of planets identified by k-means
](image/Figure_9.20_B16834.jpg)

图 9.20–通过 k 均值识别的两个行星群

请注意虽然这可能是一个适当的集群数量，但它并没有告诉我们之前尝试的那么多。如果我们想知道与我们太阳系中的每一颗行星相似的行星，我们会想要使用更大的 *k* 。

### 解释质心并可视化聚类空间

由于我们在聚类之前对数据进行了标准化，我们可以查看**质心**或聚类中心，以查看成员最接近的 Z 得分。质心的位置将是聚类中点的每个维度的平均值。我们可以用模型的`cluster_centers_`属性来获取它。蓝色星团的质心位于(18.9，20.9)，呈(半长轴，周期)格式；请记住，这些是 Z 分数，因此它们与其他数据相差甚远。另一方面，橙色群集的中心位于(-0.035，-0.038)。

让我们构建一个可视化，用缩放的输入数据和聚类距离空间(其中点表示为到其聚类质心的距离)向我们显示质心的位置。首先，我们将在一个较大的地块内为一个较小的地块设置布局:

```
>>> fig = plt.figure(figsize=(8, 6))
>>> outside = fig.add_axes([0.1, 0.1, 0.9, 0.9])
>>> inside = fig.add_axes([0.6, 0.2, 0.35, 0.35])
```

接下来，我们获取输入数据的缩放版本以及这些数据点和它们所属的群集的质心之间的距离。我们可以使用`transform()`和`fit_transform()` ( `fit()`后跟`transform()`)方法将输入数据转换到聚类距离空间。我们返回 NumPy `ndarrays`,其中外部数组中的每个值代表一个点的坐标:

```
>>> scaled = kmeans_pipeline_2.named_steps['scale']\ 
...     .fit_transform(kmeans_data) 
>>> cluster_distances = kmeans_pipeline_2\
...     .fit_transform(kmeans_data)
```

因为我们知道外部数组中的每个数组都将半长轴作为第一个条目，将周期作为第二个条目，所以我们使用`[:,0]`选择所有的半长轴值，使用`[:,1]`选择所有的周期值。这些将是我们散点图的 *x* 和 *y* 。请注意，我们实际上不需要调用`predict()`来获取数据的聚类标签，因为我们需要我们训练模型的数据的标签；这意味着我们可以使用`KMeans`对象的`labels_`属性:

```
>>> for ax, data, title, axes_labels in zip(
...     [outside, inside], [scaled, cluster_distances], 
...     ['Visualizing Clusters', 'Cluster Distance Space'], 
...     ['standardized', 'distance to centroid']
... ):
...     sns.scatterplot(
...         x=data[:,0], y=data[:,1], ax=ax, alpha=0.75, s=100,
...         hue=kmeans_pipeline_2.named_steps['kmeans'].labels_
...     )
... 
...     ax.get_legend().remove()
...     ax.set_title(title)
...     ax.set_xlabel(f'semimajoraxis ({axes_labels})')
...     ax.set_ylabel(f'period ({axes_labels})')
...     ax.set_ylim(-1, None)
```

最后，我们在外部图上标注质心的位置，它显示了缩放的数据:

```
>>> cluster_centers = kmeans_pipeline_2\
...     .named_steps['kmeans'].cluster_centers_
>>> for color, centroid in zip(
...     ['blue', 'orange'], cluster_centers
... ):
...     outside.plot(*centroid, color=color, marker='x')
...     outside.annotate(
...         f'{color} center', xy=centroid, 
...         xytext=centroid + [0, 5], 
...         arrowprops=dict(arrowstyle='->')
...     )
```

在生成的图中，我们可以很容易地看到三个蓝点与其他蓝点非常不同，它们是第二个集群的唯一成员:

![Figure 9.21 – Visualizing the planets in the cluster distance space
](image/Figure_9.21_B16834.jpg)

图 9.21–可视化星团距离空间中的行星

到目前为止，我们一直在使用`transform()`或者组合的方法，比如`fit_predict()`或者`fit_transform()`，但是并不是所有的型号都会支持这些方法。我们将在*回归*和*分类*部分看到一个稍微不同的工作流程。一般来说，根据它们的用途，大多数`scikit-learn`对象将支持以下内容:

![Figure 9.22 – General reference for the scikit-learn model API
](image/Figure_9.22_B16834.jpg)

图 9.22–sci kit-learn 模型 API 的一般参考

现在我们已经建立了一些模型，我们为下一步做好了准备:量化它们的性能。`scikit-learn`中的`metrics`模块包含各种度量标准，用于评估跨聚类、回归和分类任务的模型性能；API 在[https://sci kit-learn . org/stable/modules/classes . html # module-sk learn . metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)列出了函数。接下来我们讨论一下如何评估一个无监督聚类模型。

## 评估聚类结果

评估我们的聚类结果的最重要的标准是它们对我们开始做的事情有用；我们使用肘点法来为 *k* 选择一个合适的值，但是这对我们来说没有八个集群的原始模型有用。也就是说，当想要量化表现时，我们需要选择与我们执行的学习类型相匹配的指标。

当我们知道数据的真正聚类时，我们可以检查我们的聚类模型是否将这些点放在一个聚类中，就像它们在真正的聚类中一样。我们的模型给出的聚类标签可能与真实的不同——重要的是同一真实聚类中的点也在预测聚类中。一个这样的指标是**福尔克斯-马洛指数**，我们将在本章末尾的练习中看到。

对于行星数据，我们执行了无监督聚类，因为我们没有每个数据点的标签，因此，我们无法衡量我们在这些方面做得有多好。这意味着我们必须使用度量来评估聚类本身的各个方面，例如它们相距多远，以及一个聚类中的点在一起有多近。我们可以比较多个指标，以获得更全面的性能评估。

一种这样的方法被称为**轮廓系数**，它有助于量化聚类分离。它是通过从给定聚类中的点与最近的不同聚类( *b* )之间的距离的平均值中减去聚类中每两个点之间的距离的平均值( *a* )并除以两者中的最大值来计算的:

![](image/Formula_09_001.jpg)

此度量返回[-1，1]范围内的值，其中-1 是最差的(错误分配聚类)，1 是最好的；接近 0 的值表示重叠的簇。该数字越大，聚类的定义就越清晰(分离程度越高):

```
>>> from sklearn.metrics import silhouette_score
>>> silhouette_score(
...     kmeans_data, kmeans_pipeline.predict(kmeans_data)
... )
0.7579771626036678
```

我们可以用来评估我们的聚类结果的另一个分数是**类内距离**(类中各点之间的距离)与**类间距离**(不同类中各点之间的距离)的比值，称为 **Davies-Bouldin 分数**。值越接近零表示集群之间的分区越好:

```
>>> from sklearn.metrics import davies_bouldin_score
>>> davies_bouldin_score(
...     kmeans_data, kmeans_pipeline.predict(kmeans_data)
... )
0.4632311032231894 
```

我们将在这里讨论的非监督聚类的最后一个指标是**卡林斯基和哈拉巴斯分数**，或**方差比标准**，它是一个聚类内的离差与聚类间的离差之比。较高的值表示更好定义的(更分离的)聚类:

```
>>> from sklearn.metrics import calinski_harabasz_score
>>> calinski_harabasz_score(
...     kmeans_data, kmeans_pipeline.predict(kmeans_data)
... )
21207.276781867335
```

有关`scikit-learn`提供的集群评估指标(包括监督集群)以及何时使用它们的完整列表，请查看其指南的*集群性能评估*部分，网址为[https://sci kit-learn . org/stable/modules/Clustering . html # Clustering-evaluation](https://scikit-learn.org/stable/modules/clustering.html#clustering-evaluation)。

# 回归

有了行星数据集，我们想预测一年的长度，这是一个数值，所以我们将转向回归。正如本章开始时提到的，回归是一种对我们想要预测的自变量(我们的`X`数据)——通常称为**回归变量**——和因变量(我们的`y`数据)之间的关系的强度和大小进行建模的技术。

## 线性回归

Scikit-learn 提供了许多可以处理回归任务的算法，从决策树到线性回归，根据不同的算法类分布在各个模块中。然而，通常情况下，最好的起点是线性回归，可以在`linear_model`模块中找到。在**简单线性回归**中，我们将数据拟合成以下形式的直线:

![](image/Formula_09_002.jpg)

这里，ε(*ε*)是误差项，β(*β*)是系数。

重要说明

我们从我们的模型中获得的系数是那些最小化**成本函数**，或者观测值( *y* )和用模型预测的值( *ŷ* ，发音为 *y-hat* )之间的误差的系数。我们的模型给出了这些系数的估计值，我们将它们记为![](image/Formula_09_004.png)(读作 *beta-hat* )。

然而，如果我们想要模拟额外的关系，我们需要使用**多元线性回归**，它包含多个回归变量:

![](image/Formula_09_005.jpg)

`scikit-learn`中的线性回归使用**普通最小二乘法** ( **OLS** )，产生最小化误差平方和的系数(测量为 *y* 和 *ŷ* 之间的距离)。系数可以使用封闭形式的解决方案找到，或者使用优化方法估计，例如**梯度下降**，其使用负梯度(用偏导数计算的最陡上升方向)来确定接下来尝试哪个系数(更多信息，参见*进一步阅读*部分中的链接)。我们将在第十一章[](B16834_11_Final_SK_ePub.xhtml#_idTextAnchor237)**中使用梯度下降进行机器学习异常检测*。*

 *重要说明

线性回归对数据做了一些假设，在选择使用这种技术时，我们必须记住这些假设。它假设残差是正态分布和同方差的，并且没有多重共线性(回归变量之间的高度相关性)。

现在我们对线性回归的工作原理有了一点了解，让我们建立一个模型来预测行星的轨道周期。

### 预测行星上一年的长度

在我们可以构建我们的模型之前，我们必须将用于预测的列(`semimajoraxis`、`mass`和`eccentricity`)与将被预测的列(`period`)隔离开来:

```
>>> data = planets[
...     ['semimajoraxis', 'period', 'mass', 'eccentricity']
... ].dropna()
>>> X = data[['semimajoraxis', 'mass', 'eccentricity']]
>>> y = data.period
```

这是一项受监督的任务。我们希望能够使用行星的半长轴、质量和轨道偏心率来预测行星上一年的长度，并且我们有数据中大多数行星的周期长度。让我们为测试数据创建一个 75/25 的训练分割，以便我们可以评估该模型预测年长度的效果:

```
>>> from sklearn.model_selection import train_test_split
>>> X_train, X_test, y_train, y_test = train_test_split(
...     X, y, test_size=0.25, random_state=0
... )
```

一旦我们将数据分成训练集和测试集，我们就可以创建和拟合模型:

```
>>> from sklearn.linear_model import LinearRegression
>>> lm = LinearRegression().fit(X_train, y_train)
```

该拟合模型可用于检查估计的系数，也可用于预测给定的一组自变量的因变量的值。我们将在接下来的两节中讨论这两种用例。

### 解释线性回归方程

从线性回归模型导出的方程给出了量化变量之间关系的系数。如果我们处理不止一个回归变量，在试图解释这些系数时必须小心。在多重共线性的情况下，我们无法解释它们，因为我们无法保持所有其他回归变量不变来检查单个回归变量的影响。

幸运的是，我们用于行星数据的回归变量是不相关的，正如我们在*探索性数据分析*部分(*图 9.8* )中制作的相关矩阵热图所示。因此，让我们从拟合的线性模型对象中获得截距和系数:

```
# get intercept
>>> lm.intercept_
-622.9909910671811 
# get coefficients
>>> [(col, coef) for col, coef in 
...  zip(X_train.columns, lm.coef_)]
[('semimajoraxis', 1880.4365990440929),
 ('mass', -90.18675916509196),
 ('eccentricity', -3201.078059333091)] 
```

这为我们的行星年长度线性回归模型产生了以下方程:

![](image/Formula_09_006.jpg)

为了更完整地解释这一点，我们需要理解一切事物的单位:

*   `period`(一年的长度):地球日
*   `semimajoraxis` : **天文单位** ( **奥斯**)
*   `mass`:Jupyter质量(行星质量除以Jupyter质量)
*   `eccentricity`: N/A

    小费

    一个天文单位是地球到太阳的平均距离，相当于 149，597，870，700 米。

这个特定模型中的截距没有任何意义:如果这颗行星的半长轴为零，没有质量，并且是正圆偏心率，那么它的一年将是-623 个地球日长。一颗行星必须有一个非负的非零周期，半长轴和质量，所以这显然没有意义。然而，我们可以解释其他的系数。等式表明，保持质量和偏心率不变，在半长轴距离上增加一个额外的天文单位，一年的长度就会增加 1880 个地球日。保持半长轴和偏心率不变，每增加一个Jupyter质量，一年的长度就会减少 90.2 个地球日。

从一个完美的圆形轨道(`eccentricity=0`)进入一个近乎抛物线的逃逸轨道(`eccentricity=1`)将使一年的长度减少 3201 个地球日；请注意，这是这一项的近似值，因为按照抛物线逃逸轨道，行星将永远不会返回，因此，这个方程没有意义。事实上，如果我们试图将这个方程用于大于或等于 1 的偏心率，我们将进行外推，因为我们在训练数据中没有这样的值。这是外推不起作用的一个明显例子。等式告诉我们，偏心率越大，一年越短，但一旦我们达到偏心率 1 或更高，行星就再也不会回来(它们已经到达逃逸轨道)，所以一年是无限的。

训练数据中的所有偏心率值都在范围[0，1]内，因此我们进行插值(使用训练范围内的数据预测周期值)。这意味着只要我们要预测的行星的偏心率也在[0，1]范围内，我们就可以用这个模型来进行预测。

### 做预测

既然我们对每个回归变量的影响有了概念，让我们使用我们的模型来预测测试集中行星的年长度:

```
>>> preds = lm.predict(X_test)
```

让我们通过绘制实际值和预测值来想象我们做得有多好:

```
>>> fig, axes = plt.subplots(1, 1, figsize=(5, 3))
>>> axes.plot(
...     X_test.semimajoraxis, y_test, 'ob',
...     label='actuals', alpha=0.5
... )
>>> axes.plot(
...     X_test.semimajoraxis, preds, 'or', 
...     label='predictions', alpha=0.5
... )
>>> axes.set(xlabel='semimajoraxis', ylabel='period')
>>> axes.legend()
>>> axes.set_title('Linear Regression Results')
```

预测的值似乎非常接近实际值，并且遵循类似的模式:

![Figure 9.23 – Predictions versus actual values
](image/Figure_9.23_B16834.jpg)

图 9.23–预测值与实际值的对比

小费

试着只用`semimajoraxis`回归器运行这个回归。一些数据的整形将是必要的，但这将显示当我们添加`eccentricity`和`mass`时，性能有多好。在实践中，我们经常不得不构建模型的许多版本，以找到我们满意的版本。

我们可以检查它们的相关性，看看我们的模型跟踪真实关系的效果如何:

```
>>> np.corrcoef(y_test, preds)[0][1]
0.9692104355988059
```

我们的预测与实际值呈非常强的正相关(相关系数为 0.97)。请注意，相关系数将告诉我们，我们的模型是否与实际数据一起移动；然而，它不会告诉我们是否偏离了星等。为此，我们将使用下一节讨论的指标。

## 评估回归结果

在评估回归模型时，我们感兴趣的是我们的模型能够捕获多少数据的方差，以及预测有多准确。我们可以结合使用指标和视觉效果来评估这些方面的模型。

### 分析残差

每当我们用线性回归处理时，我们应该可视化我们的**残差**，或者实际值和模型预测之间的差异；正如我们在 [*第七章*](B16834_07_Final_SK_ePub.xhtml#_idTextAnchor146) 、*金融分析——比特币和股票市场*中所了解到的，它们应当以零和同方差(自始至终类似的方差)为中心。我们可以使用核密度估计来评估残差是否以零为中心，并使用散点图来查看它们是否是同伦的。

让我们看看`ml_utils.regression`中的效用函数，它将创建这些用于检查残差的子图:

```
import matplotlib.pyplot as plt
import numpy as np
def plot_residuals(y_test, preds):
    """
    Plot residuals to evaluate regression.
    Parameters:
        - y_test: The true values for y
        - preds: The predicted values for y
    Returns:
        Subplots of residual scatter plot and residual KDE
    """
    residuals = y_test – preds
    fig, axes = plt.subplots(1, 2, figsize=(15, 3))
    axes[0].scatter(np.arange(residuals.shape[0]), residuals)
    axes[0].set(xlabel='Observation', ylabel='Residual')
    residuals.plot(kind='kde', ax=axes[1])
    axes[1].set_xlabel('Residual')
    plt.suptitle('Residuals')
    return axes
```

现在，让我们看看这个线性回归的残差:

```
>>> from ml_utils.regression import plot_residuals
>>> plot_residuals(y_test, preds)
```

看起来好像我们的预测没有模式(左边支线剧情)，这很好；然而，它们并不完全以零为中心，并且分布具有负偏斜(右侧子图)。当预测年份比实际年份长时，会出现这些负残差:

![Figure 9.24 – Examining the residuals
](image/Figure_9.24_B16834.jpg)

图 9.24–检验残差

小费

如果我们在残差中找到模式，我们的数据就不是线性的，可视化残差有可能帮助我们计划下一步行动。这可能意味着采用数据的多项式回归或对数变换等策略。

### 韵律学

除了检查残差的，我们应该计算指标来评估我们的回归模型。也许最常见的是 **R** **2** (读作 *R 平方*)，或者**决定系数**，它量化了我们可以从自变量预测的因变量的方差比例。它的计算方法是从 1:1 减去残差平方和与总平方和之比。

![](image/Formula_09_007.jpg)

小费

适马(*∑*)代表总和。 *y* 值的平均值表示为 *ȳ* (读作 *y-bar* )。预测用 *ŷ* 表示(读作 *y 帽*)。

该值将在范围[0，1]内，其中值越高越好。`scikit-learn`中的`LinearRegression`类的对象使用 R2 作为它们的评分方法。因此，我们可以简单地用`score()`法为我们计算一下:

```
>>> lm.score(X_test, y_test)
0.9209013475842684 
```

我们还可以从`metrics`模块中获取 R2:

```
>>> from sklearn.metrics import r2_score
>>> r2_score(y_test, preds)
0.9209013475842684 
```

这款车型有非常好的 R2；然而，请记住，有许多因素会影响周期，例如恒星和其他行星，它们会对所讨论的行星施加引力。尽管有这种抽象，我们的简化做得很好，因为行星的轨道周期在很大程度上是由必须经过的距离决定的，我们通过使用半长轴数据来说明这一点。

然而，R2 有一个问题；我们可以不断添加回归变量，这将使我们的模型越来越复杂，同时增加 R2。我们需要一个惩罚模型复杂性的度量。为此，我们对 R 2 进行了**调整，只有当添加的回归变量对模型的改善程度超出预期时，R**2 才会增加:

![](image/Formula_09_008.jpg)

不幸的是，`scikit-learn`不提供这个度量；但是，落实到我们自己身上是非常容易的。`ml_utils.regression`模块包含为我们计算调整后的 R2 的函数。让我们来看看:

```
from sklearn.metrics import r2_score
def adjusted_r2(model, X, y):
    """
    Calculate the adjusted R^2.
    Parameters:
        - model: Estimator object with a `predict()` method
        - X: The values to use for prediction.
        - y: The true values for scoring.
    Returns: 
        The adjusted R^2 score.
    """
    r2 = r2_score(y, model.predict(X))
    n_obs, n_regressors = X.shape
    adj_r2 = \
        1 - (1 - r2) * (n_obs - 1)/(n_obs - n_regressors - 1)
    return adj_r2
```

调整后的 R2 将永远低于 R2。通过使用`adjusted_r2()`函数，我们可以看到调整后的 R2 略低于 R2 值:

```
>>> from ml_utils.regression import adjusted_r2
>>> adjusted_r2(lm, X_test, y_test)
0.9201155993814631 
```

不幸的是，R2(和调整后的 R2)值并没有告诉我们任何关于预测误差或的信息，甚至我们是否正确地指定了我们的模型。回想一下我们在 [*第一章*](B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015)*数据分析导论*中讨论安斯康贝四重奏的时候。这四个不同的数据集具有相同的汇总统计数据。当用线性回归线拟合时，它们也具有相同的 R2(0.67)，尽管它们中的一些没有表明线性关系:

![Figure 9.25 – R2 can be misleading
](image/Figure_9.25_B16834.jpg)

图 9.25-R2 可能会产生误导

由`scikit-learn`提供的另一个指标是**解释的方差得分**，它告诉我们由我们的模型解释的方差的百分比。我们希望这个值尽可能接近 1:

![](image/Formula_09_009.jpg)

我们可以看到我们的模型解释了 92%的方差:

```
>>> from sklearn.metrics import explained_variance_score
>>> explained_variance_score(y_test, preds)
0.9220144218429371 
```

当评估我们的回归模型时，我们不局限于看方差；我们也可以看看误差本身的大小。我们将在本节中讨论的其余指标都会产生与我们用于预测的测量单位相同的误差(此处为地球日)，因此我们可以理解误差大小的含义。

**平均绝对误差** ( **梅**)告诉我们我们的模型在任一方向上产生的平均误差。值的范围从 0 到∞(无穷大)，值越小越好:

![](image/Formula_09_010.jpg)

通过使用`scikit-learn`函数，我们可以看到我们的 MAE 是 1369 个地球日:

```
>>> from sklearn.metrics import mean_absolute_error
>>> mean_absolute_error(y_test, preds)
1369.441817073533 
```

**均方根误差** ( **RMSE** )允许对糟糕的预测进行进一步的惩罚:

![](image/Formula_09_011.jpg)

Scikit-learn 为**均方误差** ( **MSE** )提供了一个函数，它是前面的等式在平方根里面的部分；因此，我们只需计算结果的平方根。当不希望出现较大误差时，我们会使用这一指标:

```
>>> from sklearn.metrics import mean_squared_error
>>> np.sqrt(mean_squared_error(y_test, preds))
3248.499961928374 
```

所有这些基于平均值的测量的替代方法是**中值绝对误差**，它是残差的中值。这可以用在我们的残差中有几个异常值，并且我们想要更准确地描述大部分误差的情况下。请注意，这比我们的数据的 MAE 要小:

```
>>> from sklearn.metrics import median_absolute_error
>>> median_absolute_error(y_test, preds)
759.8613358335442 
```

还有一个`mean_squared_log_error()`函数，只能用于非负值。一些预测是负面的，这阻止了我们使用这个。当半长轴非常小(小于 1)时，会出现负面预测，因为这是回归方程中唯一具有正系数的部分。如果半长轴不够大，不足以平衡方程的其余部分，那么预测将是负的，因此必然是不正确的。关于`scikit-learn`提供的回归指标的完整列表，请查看[https://sci kit-learn . org/stable/modules/classes . html # regression-metrics](https://scikit-learn.org/stable/modules/classes.html#regression-metrics)。

# 分类

分类的目标是确定如何使用一组离散的标签来标记数据。这听起来可能类似于监督聚类；然而，在这种情况下，我们不关心组成员在空间上有多近。相反，我们关心的是用正确的类别标签对它们进行分类。还记得在 [*第八章*](B16834_08_Final_SK_ePub.xhtml#_idTextAnchor172)*基于规则的异常检测*中，我们把 IP 地址分类为有效用户还是攻击者吗？我们并不关心 IP 地址簇的定义有多好——我们只想找到攻击者。

正如回归一样，`scikit-learn`为分类任务提供了许多算法。这些分布在各个模块中，但是对于分类任务，通常会在最后称之为*分类器*，而对于回归任务，则称之为*回归器*。一些常用的方法有逻辑回归、**支持向量机** ( **SVMs** )、k-NN、决策树、随机森林；在这里，我们将讨论逻辑回归。

## 逻辑回归

逻辑回归是一种使用线性回归来解决分类任务的方法。但是，它使用逻辑 sigmoid 函数返回范围[0，1]内可映射到分类标签的概率:

![Figure 9.26 – The logistic sigmoid function
](image/Figure_9.26_B16834.jpg)

图 9.26–逻辑 sigmoid 函数

让我们使用逻辑回归将红酒分为高质量或低质量，并根据其化学性质将红酒分为红葡萄酒或白葡萄酒。我们可以像对待上一节中的线性回归一样对待逻辑回归，使用`scikit-learn`中的`linear_model`模块。就像线性回归问题一样，我们将使用监督方法进行，因此我们必须将数据分成测试集和训练集。

小费

虽然本节中讨论的例子都是二元分类问题(两个类)，`scikit-learn`也提供了对多类问题的支持。构建多类模型的过程与二进制模型几乎相同，但是可能需要传递一个额外的参数来让模型知道有两个以上的类。在本章末尾的练习中，你将有机会建立一个多类分类模型。

### 预测红酒质量

我们在这一章的开始就已经做了`high_quality`专栏，但是请记住优质红酒的数量有很大的不平衡。因此，当我们分割数据时，我们将按照分层随机样本的列进行分层，以确保训练集和测试集都保留数据中高质量和低质量葡萄酒的比例(大约 14%是高质量的):

```
>>> from sklearn.model_selection import train_test_split
>>> red_y = red_wine.pop('high_quality')
>>> red_X = red_wine.drop(columns='quality')
>>> r_X_train, r_X_test, \
... r_y_train, r_y_test = train_test_split(
...     red_X, red_y, test_size=0.1, random_state=0,
...     stratify=red_y
... )
```

让我们建立一个管道，首先将我们所有的数据标准化，然后建立一个逻辑回归。我们将为可再现性提供种子(`random_state=0`)并让`class_weight='balanced'`让`scikit-learn`计算类的权重，因为我们有一个不平衡:

```
>>> from sklearn.preprocessing import StandardScaler
>>> from sklearn.pipeline import Pipeline
>>> from sklearn.linear_model import LogisticRegression
>>> red_quality_lr = Pipeline([
...     ('scale', StandardScaler()), 
...     ('lr', LogisticRegression(
...         class_weight='balanced', random_state=0
... ))
... ])
```

类别权重决定了对于每个类别的错误预测，模型将受到多少惩罚。通过选择平衡权重，对较小类的错误预测将具有更大的权重，其中权重将与数据中该类的频率成反比。这些权重用于正则化，我们将在 [*第 10 章*](B16834_10_Final_SK_ePub.xhtml#_idTextAnchor217) 、*做出更好的预测-优化模型*中详细讨论。

一旦我们有了自己的管道，我们就可以用`fit()`方法来拟合数据:

```
>>> red_quality_lr.fit(r_X_train, r_y_train)
Pipeline(steps=[('scale', StandardScaler()),
                ('lr', LogisticRegression(
                     class_weight='balanced',
                     random_state=0))])
```

最后，我们可以使用我们对训练数据的模型拟合来预测测试数据的红酒质量:

```
>>> quality_preds = red_quality_lr.predict(r_X_test)
```

小费

Scikit-learn 使模型之间的切换变得容易，因为我们可以指望它们有相同的方法，比如`score()`、`fit()`和`predict()`。在某些情况下，我们也可以用`predict_proba()`来表示概率，或者用`decision_function()`来代替`predict()`用模型导出的方程来评估一个点。

在我们继续评估这个模型的性能之前，让我们使用完整的葡萄酒数据集建立另一个分类模型。

### 根据化学性质确定葡萄酒的类型

我们想知道是否有可能仅仅根据它们的化学特性来区分红葡萄酒和白葡萄酒。为了测试这一点，我们将建立第二个逻辑回归模型，它将预测葡萄酒是红还是白。首先，让我们将数据分成测试集和训练集:

```
>>> from sklearn.model_selection import train_test_split 
>>> wine_y = np.where(wine.kind == 'red', 1, 0)
>>> wine_X = wine.drop(columns=['quality', 'kind'])
>>> w_X_train, w_X_test, \
... w_y_train, w_y_test = train_test_split(
...     wine_X, wine_y, test_size=0.25, 
...     random_state=0, stratify=wine_y
... )
```

我们将再次在管道中使用逻辑回归:

```
>>> from sklearn.linear_model import LogisticRegression
>>> from sklearn.pipeline import Pipeline
>>> from sklearn.preprocessing import StandardScaler
>>> white_or_red = Pipeline([
...     ('scale', StandardScaler()), 
...     ('lr', LogisticRegression(random_state=0))
... ]).fit(w_X_train, w_y_train)
```

最后，我们将保存我们对测试集中每个观察结果是哪种酒的预测:

```
>>> kind_preds = white_or_red.predict(w_X_test)
```

现在我们已经使用各自的测试集对两个逻辑回归模型进行了预测，我们准备评估它们的性能。

## 评估分类结果

我们通过查看模型对数据中每个类别的预测程度来评估分类模型的性能。**正班**就是我们感兴趣的班；所有其他班级都被认为是**的负面班级**。在我们的红酒分类中，正级是高品质，而负级是低品质。尽管我们的问题只是一个二元分类问题，但本节讨论的度量标准可以扩展到多类分类问题。

### 混淆矩阵

正如我们在 [*第 8 章*](B16834_08_Final_SK_ePub.xhtml#_idTextAnchor172) 、*基于规则的异常检测*中所讨论的，可以通过使用**混淆矩阵**将预测标签与实际标签进行比较来评估分类问题:

![Figure 9.27 – Evaluating classification results with a confusion matrix
](image/Figure_9.27_B16834.jpg)

图 9.27-用混淆矩阵评估分类结果

根据预测值与实际值的匹配程度，每个预测值可以是四种结果之一:

*   **真阳性(TP)** :正确预测为阳性类别
*   **假阳性(FP)** :错误地预测为阳性类别
*   **真阴性(TN)** :正确预测不是阳性类
*   **False Negative (FN)**: Incorrectly predicted to not be the positive class

    重要说明

    假阳性又称为**I 型错误**，假阴性为**II 型错误**。给定某个分类器，减少其中一个的努力会导致另一个的增加。

Scikit-learn 提供了`confusion_matrix()`函数，我们可以将它与来自`seaborn`的`heatmap()`函数配对来可视化我们的混淆矩阵。在`ml_utils.classification`模块中，`confusion_matrix_visual()`函数为我们处理这个问题:

```
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.metrics import confusion_matrix
def confusion_matrix_visual(y_true, y_pred, class_labels, 
                            normalize=False, flip=False, 
                            ax=None, title=None, **kwargs):
    """
    Create a confusion matrix heatmap
    Parameters:
        - y_test: The true values for y
        - preds: The predicted values for y
        - class_labels: What to label the classes.
        - normalize: Whether to plot the values as percentages.
        - flip: Whether to flip the confusion matrix. This is 
          helpful to get TP in the top left corner and TN in 
          the bottom right when dealing with binary 
          classification with labels True and False.
        - ax: The matplotlib `Axes` object to plot on.
        - title: The title for the confusion matrix
        - kwargs: Additional keyword arguments to pass down.
    Returns: A matplotlib `Axes` object.
    """
    mat = confusion_matrix(y_true, y_pred)
    if normalize:
        fmt, mat = '.2%', mat / mat.sum()
    else:
        fmt = 'd'
    if flip:
        class_labels = class_labels[::-1]
        mat = np.flip(mat)
    axes = sns.heatmap(
        mat.T, square=True, annot=True, fmt=fmt,
        cbar=True, cmap=plt.cm.Blues, ax=ax, **kwargs
    )
    axes.set(xlabel='Actual', ylabel='Model Prediction')
    tick_marks = np.arange(len(class_labels)) + 0.5
    axes.set_xticks(tick_marks)
    axes.set_xticklabels(class_labels)
    axes.set_yticks(tick_marks)
    axes.set_yticklabels(class_labels, rotation=0)
    axes.set_title(title or 'Confusion Matrix')
    return axes
```

让我们调用我们的混淆矩阵可视化函数，看看我们对每个分类模型做了什么。首先，我们将看看该模型如何识别高品质的红酒:

```
>>> from ml_utils.classification import confusion_matrix_visual
>>> confusion_matrix_visual(
...     r_y_test, quality_preds, ['low', 'high']
... )
```

使用混淆矩阵，我们可以看到模型很难始终如一地找到高品质的红酒(底部一行):

![Figure 9.28 – Results for the red wine quality model
](image/Figure_9.28_B16834.jpg)

图 9.28-红酒质量模型的结果

现在，让我们看看`white_or_red`模型对葡萄酒类型的预测有多准确:

```
>>> from ml_utils.classification import confusion_matrix_visual
>>> confusion_matrix_visual(
...     w_y_test, kind_preds, ['white', 'red']
... )
```

看起来这个模型更加容易，几乎没有错误的预测:

`

![Figure 9.29 – Results for the white or red wine model
](image/Figure_9.29_B16834.jpg)

图 9.29-白葡萄酒或红葡萄酒模型的结果

现在我们已经了解了混淆矩阵的组成，我们可以用它来计算额外的性能指标。

### 分类指标

使用混淆矩阵中的值，我们可以计算度量来帮助评估分类器的性能。最佳度量将取决于我们构建模型的目标以及我们的类是否平衡。本节中的公式源自我们从混淆矩阵中获得的数据，其中 *TP* 是真阳性的数量， *TN* 是真阴性的数量，以此类推。

#### 准确度和误差率

当我们的类大小大致相等时，我们可以使用**精度**，这将给出正确分类值的百分比:

![](image/Formula_09_012.jpg)

`sklearn.metrics`中的`accuracy_score()`函数将根据公式计算精度；然而，我们模型的`score()`方法也会给我们准确性(并非总是如此，我们将在第 10 章 、*中的 [*网格搜索中看到，做出更好的预测-优化模型*):](B16834_10_Final_SK_ePub.xhtml#_idTextAnchor217)*

```
>>> red_quality_lr.score(r_X_test, r_y_test)
0.775
```

由于准确度是我们正确分类的百分比(我们的**成功率**，因此我们的**错误率**(我们出错的百分比)可以计算如下:

![](image/Formula_09_013.jpg)

我们的准确度分数告诉我们，我们有 77.5%的红葡萄酒根据它们的质量被正确分类。相反，`zero_one_loss()`函数给出了被错误分类的值的百分比，对于红酒质量模型是 22.5%:

```
>>> from sklearn.metrics import zero_one_loss
>>> zero_one_loss(r_y_test, quality_preds)
0.22499999999999998
```

请注意，虽然这两者都很容易计算和理解，但它们需要一个阈值。默认情况下，这是 50%，但是当使用`scikit-learn`中的`predict_proba()`方法预测类时，我们可以使用任何我们希望的概率作为截止值。此外，在类别不平衡的情况下，准确性和错误率可能会产生误导。

#### 精确度和召回率

当我们有一个**等级不平衡**时，准确性可能成为衡量我们表现的一个不可靠的指标。例如，如果我们在两个类 A 和 B 之间有 99/1 的分割，其中罕见事件 B 是我们的正面类，我们可以通过只说所有东西都属于 A 类来构建一个 99%准确的模型。这个问题源于这样一个事实，即真正的负面将非常大，并且在分子中(除了分母之外)，它们将使结果看起来比它们更好。显然，如果一个模型对识别 B 类没有任何作用，我们就不应该构建它；因此，我们需要不同的标准来阻止这种行为。对于这一点，我们使用精度和召回，而不是准确性。**精度**是真阳性与所有标记为阳性的比率:

![](image/Formula_09_014.jpg)

**回忆**给我们**真实阳性率** ( **TPR** )，即真实阳性与实际阳性的比率:

![](image/Formula_09_015.jpg)

在类别 A 和类别 B 之间 99/1 划分的情况下，将所有事物分类为 A 的模型对于阳性类别 B 的召回率为 0%(精度将是未定义的-0/0)。精度和召回率提供了一种更好的方法来评估模型在类别不平衡时的性能。他们会正确地告诉我们，这个模型对我们的用例没有什么价值。

Scikit-learn 提供了`classification_report()`函数，它将为我们计算精度和召回。除了计算每个类标签的这些指标之外，它还计算**宏**平均值(类之间的未加权平均值)和**加权平均值**(类之间的平均值，按每个类中的观察数量加权)。 **support** 列使用带标签的数据指示属于每个类的观察计数。

分类报告表明，我们的模型在寻找低质量的红酒方面做得很好，但是对于高质量的红酒就不那么好了:

```
>>> from sklearn.metrics import classification_report
>>> print(classification_report(r_y_test, quality_preds))
              precision    recall  f1-score   support
           0       0.95      0.78      0.86       138
           1       0.35      0.73      0.47        22
    accuracy                           0.78       160
   macro avg       0.65      0.75      0.66       160
weighted avg       0.86      0.78      0.80       160
```

鉴于质量分数非常主观，与化学性质没有必然联系，这个简单模型表现不佳也就不足为奇了。另一方面，红葡萄酒和白葡萄酒的化学性质是不同的，因此这些信息对`white_or_red`模型更有用。正如我们所想象的，基于`white_or_red`模型的混淆矩阵，指标是好的:

```
>>> from sklearn.metrics import classification_report
>>> print(classification_report(w_y_test, kind_preds))
              precision    recall  f1-score   support
           0       0.99      1.00      0.99      1225
           1       0.99      0.98      0.98       400
    accuracy                           0.99      1625
   macro avg       0.99      0.99      0.99      1625
weighted avg       0.99      0.99      0.99      1625
```

就像精度一样，精度和召回率都很容易计算和理解，但是需要阈值。此外，精确度和召回率各只考虑混淆矩阵的一半:

![Figure 9.30 – Confusion matrix coverage for precision and recall
](image/Figure_9.30_B16834.jpg)

图 9.30-精确度和召回率的混淆矩阵覆盖范围

典型地，在最大化召回率和最大化精确度之间有一个权衡，我们必须决定哪个对我们更重要。这种偏好可以用 F 值来量化。

#### f 分数

分类报告还包括 **F** 1 **分数**，这有助于我们使用两者的**调和平均值**来平衡精度和召回:

![](image/Formula_09_016.jpg)

重要说明

调和平均值是算术平均值的倒数，与利率一起使用可以得到更准确的平均值(与利率的算术平均值相比)。精确度和召回率都是在[0，1]范围内的比例，我们可以把它当作比率。

**F** β **分数**，读作*F-β*，是 F 分数更通用的表述。通过改变β，我们可以更重视精确度(β在 0 和 1 之间)或召回率(β大于 1)，其中β是召回率比精确度高多少倍:

![](image/Formula_09_017.jpg)

一些常用的β值如下:

*   **F** 0.5 **分数**:精确度是回忆的两倍
*   **F** 1 **得分**:调和平均值(同等重要)
*   **F** 2 **分数**:回忆比精度重要两倍

F 分数也很容易计算，并且依赖于阈值。然而，它没有考虑真正的负面因素，并且由于精确度和召回率之间的权衡，很难优化。请注意，当处理大的类别不平衡时，我们通常更关心正确预测积极的类别，这意味着我们可能对真正的消极因素不太感兴趣，因此使用忽略它们的指标不一定是问题。

小费

精确度、召回率、F1 分数和 Fβ分数的函数可在`sklearn.metrics`模块中找到。

#### 敏感性和特异性

沿着精度和召回权衡的路线，我们有另一对度量标准可以用来说明我们在分类问题上努力实现的微妙平衡:敏感性和特异性。

**灵敏度**是我们之前看到的真阳性率，或回忆。然而，**特异性**是**真阴性率**，或者真阴性率与本应被归类为阴性的所有事物的比例:

![](image/Formula_09_021.jpg)

请注意，特异性和敏感性一起考虑整个混淆矩阵:

![Figure 9.31 – Confusion matrix coverage for sensitivity and specificity
](image/Figure_9.31_B16834.jpg)

图 9.31–灵敏度和特异性的混淆矩阵覆盖率

我们希望最大限度地提高敏感性和特异性；然而，我们可以通过减少我们将某些东西归类为阳性类别的次数来轻松地最大化特异性，这将降低灵敏度。Scikit-learn 不提供特异性作为衡量标准——更喜欢精度和召回率——但是，我们可以通过编写函数或使用来自`scikit-learn`的`make_scorer()`函数来轻松地创建自己的标准。我们在这里讨论它们是因为它们构成了敏感性-特异性图或 ROC 曲线的基础，这是下一节的主题。

### 受试者工作特征曲线

除了使用度量来评估分类问题，我们可以求助于可视化。通过绘制真阳性率(*灵敏度*)对假阳性率( *1 -特异性*)的曲线，我们得到**受试者工作特性** ( **ROC** ) **曲线**。这条曲线让我们可以看到真阳性率和假阳性率之间的权衡。当使用`scikit-learn`中的`predict_proba()`方法预测概率类时，我们可以确定一个我们愿意接受的假阳性率，并使用它来找到用作截止值的阈值。假设我们发现阈值为 60%—我们将要求`predict_proba()`返回一个大于或等于 0.6 的值来预测正类(`predict()`使用 0.5 作为截止值)。

来自`scikit-learn`的`roc_curve()`函数使用由模型确定的属于给定类别的的观察值的概率，计算阈值从 0 到 100%的假阳性率和真阳性率。然后我们可以对此进行绘图，目标是最大化曲线 ( **AUC** )下的**面积，该面积在范围[0，1]内；低于 0.5 的值比猜的差，好的分数在 0.8 以上。注意，当提到 ROC 曲线下的面积时，AUC 也可以写成 **AUROC** 。AUROC 总结了模型在不同阈值上的表现。**

以下是良好 ROC 曲线的示例。虚线是随机猜测的(没有预测值),用作基线；任何低于这个数字的都被认为比猜测更糟糕。我们想靠近左上角:

![Figure 9.32 – Comparing ROC curves
](image/Figure_9.32_B16834.jpg)

图 9.32–比较 ROC 曲线

`ml_utils.classification`模块包含一个绘制 ROC 曲线的函数。让我们来看看:

```
import matplotlib.pyplot as plt
from sklearn.metrics import auc, roc_curve
def plot_roc(y_test, preds, ax=None):
    """
    Plot ROC curve to evaluate classification.
    Parameters:
        - y_test: The true values for y
        - preds: The predicted values for y as probabilities
        - ax: The `Axes` object to plot on
    Returns: 
        A matplotlib `Axes` object.
    """
    if not ax:
        fig, ax = plt.subplots(1, 1)
    fpr, tpr, thresholds = roc_curve(y_test, preds)
    ax.plot(
        [0, 1], [0, 1], color='navy', lw=2, 
        linestyle='--', label='baseline'
    )
    ax.plot(fpr, tpr, color='red', lw=2, label='model')
    ax.legend(loc='lower right')
    ax.set_title('ROC curve')
    ax.set_xlabel('False Positive Rate (FPR)')
    ax.set_ylabel('True Positive Rate (TPR)')
    ax.annotate(
        f'AUC: {auc(fpr, tpr):.2}', xy=(0.5, 0),
        horizontalalignment='center'
    )
    return ax
```

可以想象，我们的`white_or_red`模型会有非常好的 ROC 曲线。让我们通过调用`plot_roc()`函数来看看是什么样子的。因为我们需要传递属于正类的每个条目的概率，所以我们需要使用`predict_proba()`方法来代替`predict()`。这给了我们每个观察值属于每个类的概率。

这里，对于`w_X_test`中的每一行，我们都有一个`[P(white), P(red)]`的 NumPy 数组。因此，我们使用切片来为 ROC 曲线选择葡萄酒是红色的概率(`[:,1]`):

```
>>> from ml_utils.classification import plot_roc
>>> plot_roc(
...     w_y_test, white_or_red.predict_proba(w_X_test)[:,1]
... )
```

正如我们所料，`white_or_red`模型的 ROC 曲线非常好，AUC 接近 1:

![Figure 9.33 – ROC curve for the white or red wine model
](image/Figure_9.33_B16834.jpg)

图 9.33–白葡萄酒或红葡萄酒模型的 ROC 曲线

考虑到我们已经看过的其他指标，我们不认为红酒质量预测模型会有很大的 ROC 曲线。让我们调用我们的函数来看看红酒质量模型的 ROC 曲线是什么样的:

```
>>> from ml_utils.classification import plot_roc
>>> plot_roc(
...     r_y_test, red_quality_lr.predict_proba(r_X_test)[:,1]
... )
```

这条 ROC 曲线不如之前的好，正如预期的那样:

![Figure 9.34 – ROC curve for the red wine quality model
](image/Figure_9.34_B16834.jpg)

图 9.34–红酒质量模型的 ROC 曲线

我们的 AUROC 是 0.85；然而，请注意，AUROC 在类不平衡的情况下提供了乐观的估计(因为它考虑了真正的负值)。出于这个原因，我们也应该看看精确-召回曲线。

### 精确回忆曲线

当面对类别不平衡时，我们使用**精确召回曲线**而不是 ROC 曲线。这条曲线显示了不同概率阈值下的精确度和召回率。基线是数据百分比处的水平线，表示属于阳性类别。我们希望我们的曲线高于这条线，精确召回曲线下的**区域**(**)大于这个百分比(越高越好)。**

 **`ml_utils.classification`模块包含用于绘制精度召回曲线和提供 AUPR 的`plot_pr_curve()`函数；

```
import matplotlib.pyplot as plt
from sklearn.metrics import (
    auc, average_precision_score, precision_recall_curve
)
def plot_pr_curve(y_test, preds, positive_class=1, ax=None):
    """
    Plot precision-recall curve to evaluate classification.
    Parameters:
        - y_test: The true values for y
        - preds: The predicted values for y as probabilities
        - positive_class: Label for positive class in the data
        - ax: The matplotlib `Axes` object to plot on
    Returns: A matplotlib `Axes` object.
    """
    precision, recall, thresholds = \
        precision_recall_curve(y_test, preds)
    if not ax:
        fig, ax = plt.subplots()
    ax.axhline(
        sum(y_test == positive_class) / len(y_test), 
        color='navy', lw=2, linestyle='--', label='baseline'
    )
    ax.plot(
 recall, precision, color='red', lw=2, label='model'
 )
    ax.legend()
    ax.set_title(
        'Precision-recall curve\n'
        f"""AP: {average_precision_score(
            y_test, preds, pos_label=positive_class
        ):.2} | """
        f'AUC: {auc(recall, precision):.2}'
    )
    ax.set(xlabel='Recall', ylabel='Precision')
    ax.set_xlim(-0.05, 1.05)
    ax.set_ylim(-0.05, 1.05)
    return ax
```

由于`scikit-learn`中 AUC 计算的实现使用了插值，因此它可能会给出一个乐观的结果，因此我们的函数还会计算**平均精度** ( **AP** )，它将精度-召回曲线总结为在不同阈值下获得的精度分数( *P* n)的加权平均值。权重是从一个阈值和下一个阈值之间的召回变化( *R* n)中得出的。值介于 0 和 1 之间，值越高越好:

![](image/Formula_09_022.jpg)

让我们来看看红酒质量模型的精确召回曲线:

```
>>> from ml_utils.classification import plot_pr_curve
>>> plot_pr_curve(
...     r_y_test, red_quality_lr.predict_proba(r_X_test)[:,1]
... )
```

这仍然表明我们的模型优于随机猜测的基线；然而，我们在这里得到的性能读数似乎更符合我们在分类报告中看到的黯淡性能。我们还可以看到，当召回率从 0.2 上升到 0.4 时，模型的精确度会降低很多。这里，精确度和召回率之间的权衡是显而易见的，我们可能会选择优化一个:

![Figure 9.35 – Precision-recall curve for the red wine quality model
](image/Figure_9.35_B16834.jpg)

图 9.35-红酒质量模型的精确召回曲线

由于我们在高质量和低质量的红酒之间存在等级不平衡(不到 14%是高质量的)，我们必须做出选择，我们是优化精度还是召回。我们的选择取决于我们在葡萄酒行业为谁工作。如果我们以生产高质量的葡萄酒而闻名，并且我们正在选择将哪些葡萄酒提供给评论家进行评论，我们希望确保我们选择了最好的葡萄酒，并且宁愿错过好的葡萄酒(假阴性)，而不是用模型归类为高质量的低质量葡萄酒来玷污我们的名字(假阳性)。然而，如果我们试图从销售葡萄酒中获得最大利润，我们不会想以与低质量葡萄酒相同的价格出售这样一种高质量的葡萄酒(假阴性)，所以我们宁愿对一些低质量的葡萄酒定价过高(假阳性)。

请注意，我们可以很容易地将每样东西归类为低质量，以永远不会让人失望，或者归类为高质量，以最大化我们的销售利润；然而，这并不太实际。很明显，我们需要在误报和漏报之间找到一个可接受的平衡。要做到这一点，我们需要量化这两个极端之间的权衡，即什么对我们更重要。然后，我们可以使用精度-召回曲线来找到满足我们的精度和召回目标的阈值。在第十一章[](B16834_11_Final_SK_ePub.xhtml#_idTextAnchor237)*，*机器学习异常检测*中，我们将通过一个例子来说明这一点。*

 *现在让我们来看看白葡萄酒或红葡萄酒分类器的精确召回曲线:

```
>>> from ml_utils.classification import plot_pr_curve
>>> plot_pr_curve(
...     w_y_test, white_or_red.predict_proba(w_X_test)[:,1]
... )
```

注意这条曲线在右上角。有了这个模型，我们可以实现高精度和高召回率:

![Figure 9.36 – Precision-recall curve for the white or red wine model
](image/Figure_9.36_B16834.jpg)

图 9.36-白葡萄酒或红葡萄酒模型的精确召回曲线

正如我们在红酒质量模型中看到的，AUPR 很好地处理了阶级不平衡。然而，它不能跨数据集进行比较，计算成本高，并且难以优化。请注意，这只是我们可以用来评估分类问题的度量的子集。`scikit-learn`提供的所有分类指标都可以在[https://sci kit-learn . org/stable/modules/classes . html # classification-metrics](https://scikit-learn.org/stable/modules/classes.html#classification-metrics)找到。

# 总结

本章介绍了 Python 中的机器学习。我们讨论了常用于描述学习类型和任务的术语。然后，我们使用我们在本书中学到的技能来练习 EDA，以感受葡萄酒和行星数据集。这给了我们一些关于我们想要建立什么样的模型的想法。在试图建立模型之前，对数据的彻底探索是必不可少的。

接下来，我们学习了如何准备用于机器学习模型的数据，以及在建模之前将数据分成训练集和测试集的重要性。为了有效地准备我们的数据，我们在`scikit-learn`中使用管道来打包从预处理到模型的所有东西。

我们使用无监督的 k-means 根据行星的半长轴和周期对它们进行聚类；我们还讨论了如何使用肘点法为 *k* 找到一个好的值。然后，我们继续进行监督学习，并使用半长轴、轨道偏心率和质量建立了一个线性回归模型来预测行星的周期。我们学习了如何解释模型系数以及如何评估模型的预测。最后，我们转向分类，以识别高品质的红葡萄酒(存在等级不平衡)，并根据化学性质区分红葡萄酒和白葡萄酒。使用精确度、召回率、F1 分数、混淆矩阵、ROC 曲线和精确度-召回率曲线，我们讨论了如何评估分类模型。

重要的是要记住，机器学习模型对底层数据做出假设，虽然这不是关于机器学习数学的一章，但我们应该确保我们明白违反这些假设会有后果。在实践中，当寻求构建模型时，我们对统计和领域级专业知识有一个坚实的理解是至关重要的。我们看到有许多评估模型的指标。每个指标都有它的优点和缺点，根据问题的不同，有些比其他的好；我们必须注意为手头的任务选择合适的度量标准。

在下一章中，我们将学习如何调整我们的模型来提高它们的性能，所以在继续之前，请务必完成练习来练习本章的内容。

# 练习

通过以下练习，在`scikit-learn`中练习构建和评估机器学习模型:

1.  Build a clustering model to distinguish between red and white wine by their chemical properties:

    a)合并红葡萄酒和白葡萄酒数据集(分别为`data/winequality-red.csv`和`data/winequality-white.csv`)，并为葡萄酒的种类(红葡萄酒或白葡萄酒)添加一列。

    b)执行一些初始 EDA。

    c)构建并安装一个管道，该管道对数据进行缩放，然后使用 k-means 聚类来生成两个聚类。确保不要使用`quality`栏。

    d)使用 Fowlkes-Mallows 指数(`sklearn.metrics`中的`fowlkes_mallows_score()`函数)来评估 k-means 区分红葡萄酒和白葡萄酒的能力。

    e)找到每个聚类的中心。

2.  Predict star temperature:

    a)使用`data/stars.csv`文件，执行一些初始 EDA，然后构建所有数字列的线性回归模型，以预测恒星的温度。

    b)在 75%的初始数据上训练模型。

    c)计算模型的 R2 和 RMSE。

    d)找出每个回归变量的系数和线性回归方程的截距。

    e)使用来自`ml_utils.regression`模块的`plot_residuals()`函数可视化残差。

3.  Classify planets that have shorter years than Earth:

    a)使用`data/planets.csv`文件，以`eccentricity`、`semimajoraxis`和`mass`列为回归变量建立逻辑回归模型。你需要为 *y* (比地球短的一年)创建一个新的列。

    b)找出准确度分数。

    c)使用`scikit-learn`中的`classification_report()`函数查看每个类别的精确度、召回率和 F1 分数。

    d)使用来自`ml_utils.classification`模块的`plot_roc()`功能，绘制 ROC 曲线。

    e)使用来自`ml_utils.classification`模块的`confusion_matrix_visual()`函数创建混淆矩阵。

4.  Multiclass classification of white wine quality:

    a)使用`data/winequality-white.csv`文件，对白葡萄酒数据进行一些初始 EDA。一定要看看有多少葡萄酒有一个给定的质量分数。

    b)建立管道以标准化数据并拟合多类逻辑回归模型。将`multi_class='multinomial'`和`max_iter=1000`传递给`LogisticRegression`构造函数。

    c)查看您的型号的分类报告。

    d)使用来自`ml_utils.classification`模块的`confusion_matrix_visual()`函数创建混淆矩阵。这将适用于多类分类问题。

    e)扩展`plot_roc()`函数，使其适用于多个类别标签。为此，您需要为每个类标签(这里是质量分数)创建一条 ROC 曲线，其中真阳性表示正确预测质量分数，假阳性表示预测任何其他质量分数。注意`ml_utils`有一个函数可以实现这个功能，但是请尝试构建自己的实现。

    f)按照与第 *e)* 部分类似的方法，扩展`plot_pr_curve()`功能，使其适用于多个类别标签。然而，给每个职业一个自己的支线剧情。注意`ml_utils`有一个函数可以实现这个功能，但是请尝试构建自己的实现。

5.  We have seen how easy the `scikit-learn` API is to navigate, making it a cinch to change which algorithm we are using for our model. Rebuild the red wine quality model that we created in this chapter using an SVM instead of logistic regression. We haven't discussed this model, but you should still be able to use it in `scikit-learn`. Check out the link in the *Further reading* section to learn more about the algorithm. Some guidance for this exercise is as follows:

    a)你需要使用来自`scikit-learn`的`SVC`(支持向量分类器)类，它可以在[https://sci kit-learn . org/stable/modules/generated/sk learn . SVM . SVC . html](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)找到。

    b)使用`C=5`作为`SVC`构造函数的参数。

    c)将`probability=True`传递给`SVC`构造函数，以便能够使用`predict_proba()`方法。

    d)首先使用`StandardScaler`类构建管道，然后使用`SVC`类。

    e)请务必查看模型的分类报告、精确度-召回曲线和混淆矩阵。

# 延伸阅读

请查阅以下资源，了解本章所涵盖主题的更多信息:

*   *深度强化学习入门指南*:【https://pathmind.com/wiki/deep-reinforcement-learning 
*   *梯度下降和线性回归介绍*:[https://spin . atomic object . com/2014/06/24/Gradient-Descent-Linear-Regression/](https://spin.atomicobject.com/2014/06/24/gradient-descent-linear-regression/)
*   *多元线性回归的假设*:[https://www . statistics solutions . com/Assumptions-of-Multiple-Linear-Regression/](https://www.statisticssolutions.com/assumptions-of-multiple-linear-regression/)
*   *聚类*:【https://scikit-learn.org/stable/modules/clustering.html 
*   *广义线性模型*:【https://scikit-learn.org/stable/modules/linear_model.html 
*   *可解释机器学习指南——破除深度学习黑盒神话的技术*:[https://towards data science . com/Guide-to-Interpretable-Machine-Learning-d 40 e 8 a 64 b 6 cf](https://towardsdatascience.com/guide-to-interpretable-machine-learning-d40e8a64b6cf)
*   *深度:k-Means*:[https://jakevdp . github . io/python datascience handbook/05.11-k-Means . html](https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html)
*   *可解释的机器学习——让黑盒模型变得可解释的指南*:【https://christophm.github.io/interpretable-ml-book/】T2
*   *可解释的机器学习——从任何机器学习模型中提取人类可理解的见解*:[https://towardsdatascience . com/Interpretable-Machine-Learning-1 dec 0 f 2e 3 e 6 b](https://towardsdatascience.com/interpretable-machine-learning-1dec0f2f3e6b)
*   梅和 RMSE——哪个指标更好？:[https://medium . com/human-in-a-machine-world/Mae-and-RMSE-metric-is-better-e 60 AC 3 bde 13d](https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d)
*   *模型评估:量化预测质量*:[https://sci kit-learn . org/stable/modules/Model _ evaluation . html](https://scikit-learn.org/stable/modules/model_evaluation.html)
*   *预处理数据*:【https://scikit-learn.org/stable/modules/preprocessing.html 
*   *sci kit-学习常用术语和 API 元素的词汇表*:【https://scikit-learn.org/stable/glossary.html#glossary 
*   *Scikit-learn 用户指南*:【https://scikit-learn.org/stable/user_guide.html 
*   *眼见论* [*第六章*](B16834_06_Final_SK_ePub.xhtml#_idTextAnchor125) *:回归分析*:[https://seening-Theory . brown . edu/index . html # second page/Chapter 6](https://seeing-theory.brown.edu/index.html#secondPage/chapter6)
*   *强化学习简易入门指南&其实施*:[https://www . analyticsvidhya . com/blog/2017/01/introduction-to-Reinforcement-Learning-implementation/](https://www.analyticsvidhya.com/blog/2017/01/introduction-to-reinforcement-learning-implementation/)
*   *支持向量机-机器学习算法介绍*:[https://towardsdatascience . com/Support-Vector-Machine-Introduction-to-Machine-Learning-Algorithms-934 a 444 FCA 47](https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47)
*   *数据科学家需要知道的 5 种聚类算法*:[https://towards Data science . com/The-5-Clustering-Algorithms-Data-Scientists-Need-to-Know-a36d 136 ef 68](https://towardsdatascience.com/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68)*****