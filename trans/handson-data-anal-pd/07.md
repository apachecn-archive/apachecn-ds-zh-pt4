<title>B16834_05_Final_SK_ePub</title> <link href="css/style-JRserifv3.css" rel="stylesheet" type="text/css">

# *第五章*:用 Pandas 和 Matplotlib 可视化数据

到目前为止，我们一直严格使用表格格式的数据。然而，人类的大脑擅长挑选视觉模式；因此，我们自然的下一步是学习如何可视化我们的数据。可视化使我们更容易发现数据中的异常，并向他人解释我们的发现。然而，我们不应该将数据可视化专门保留给那些我们向其展示结论的人，因为可视化对于帮助我们在探索性数据分析中更快、更完整地理解数据至关重要。

有许多类型的可视化超越了我们过去可能看到的。在本章中，我们将介绍最常见的绘图类型，如折线图、直方图、散点图和条形图，以及基于这些的其他几种绘图类型。我们不会讨论饼状图——它们因难以正确阅读而臭名昭著，有更好的方法来表达我们的观点。

Python 有许多用于创建可视化的库，但是用于数据分析(和其他目的)的主要库是`matplotlib`。起初，`matplotlib`库可能有点难学，但是谢天谢地，`pandas`有自己的包装器来包装一些`matplotlib`功能，允许我们创建许多不同类型的可视化，而不需要用`matplotlib`写一行(或者至少很少)。对于没有内置到`pandas`或`matplotlib`中的更复杂的情节类型，我们有`seaborn`库，我们将在下一章讨论。有了这三者，我们应该能够创造出大多数(如果不是全部)我们想要的可视化效果。动画和互动情节超出了本书的范围，但是你可以查看*延伸阅读*部分以获得更多信息。

在本章中，我们将讨论以下主题:

*   matplotlib 简介
*   和熊猫一起策划
*   熊猫.绘图模块

# 章节材料

本章的材料可以在 GitHub 上找到，网址是[https://GitHub . com/stef molin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/tree/master/ch _ 05](https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/tree/master/ch_05)。我们将使用三个数据集，所有这些数据集都可以在`data/`目录中找到。在`fb_stock_prices_2018.csv`文件中，我们有 2018 年 1 月至 12 月脸书股票的每日开盘价、最高价、最低价和收盘价，以及交易量。这是使用`stock_analysis`包获得的，我们将在 [*第 7 章*](B16834_07_Final_SK_ePub.xhtml#_idTextAnchor146) 、*金融分析——比特币和股票市场*中构建这个包。股市周末休市，所以我们只有交易日的数据。

`earthquakes.csv`文件包含从 2018 年 9 月 18 日到 2018 年 10 月 13 日从**美国地质调查局**(**USGS**)API([https://earthquake.usgs.gov/fdsnws/event/1/](https://earthquake.usgs.gov/fdsnws/event/1/))收集的地震数据。对于每一次地震，我们都有震级的值(`mag`列)、测量的震级(`magType`列)、发生的时间(`time`列)和地点(`place`列)，以及地震发生的州或国家的`parsed_place`列(我们在第 2 章 、*使用熊猫数据帧*中添加了此列)。其他不必要的列已被删除。

在`covid19_cases.csv`文件中，我们导出了由**欧洲疾病预防控制中心** ( **ECDC** )提供的*全球各国新冠肺炎每日新报告病例数*数据集，该数据集可在[https://www . ecdc . Europa . eu/en/publications-data/download-data-geographical-distribution-新冠肺炎-cases-worldwide](https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide) 上找到。为了脚本或自动收集这些数据，ECDC 通过[https://open data . ecdc . Europa . eu/covid 19/casedistribution/CSV](https://opendata.ecdc.europa.eu/covid19/casedistribution/csv)提供当天的 CSV 文件。我们将使用的快照是在 2020 年 9 月 19 日收集的，包含 2019 年 12 月 31 日至 2020 年 9 月 18 日每个国家的新新冠肺炎病例数，以及 2020 年 9 月 19 日的部分数据。在本章中，我们将了解从 2020 年 1 月 18 日到 2020 年 9 月 18 日的 8 个月时间跨度。

在本章中，我们将学习三本笔记本。它们按照使用的顺序编号，本章的每个主要部分都有一个编号。我们将从介绍`1-introducing_matplotlib.ipynb`笔记本中的`matplotlib`开始讨论 Python 中的绘图。然后，我们将学习如何使用`2-plotting_with_pandas.ipynb`笔记本中的`pandas`创建可视化效果。最后，我们将探索`pandas`在`3-pandas_plotting_module.ipynb`笔记本中提供的一些额外的绘图选项。在笔记本之间切换时，系统会提示您。

# matplotlib 简介

`pandas`和`seaborn`中的绘图功能是由`matplotlib`提供的:这两个包都为`matplotlib`中的底层功能提供了包装器。因此，我们有许多可视化选项，只需编写最少的代码；然而，这是有代价的:我们所能创造的灵活性降低了。

我们可能会发现`pandas`或`seaborn`的实现并不完全符合我们的需求，事实上，在用它们创建情节后，可能无法覆盖特定的设置，这意味着我们将不得不用`matplotlib`做一些跑腿的工作。此外，可视化最终外观的许多调整将由`matplotlib`命令处理，我们将在下一章讨论。因此，了解一下`matplotlib`是如何运作的将会对我们大有裨益。

## 基础知识

这个包相当大，因为它包含了相当多的功能。对我们来说幸运的是，对于我们的大多数绘图任务，我们所需要的就是`pyplot`模块，它为提供了一个类似 MATLAB 的绘图框架。有时，我们需要为其他任务导入额外的模块，例如动画、改变样式或改变默认参数；我们将在下一章看到一些这样的例子。

我们不会导入整个`matplotlib`包，我们将只导入使用点(`.`)符号的`pyplot`模块；这减少了我们为了访问我们需要的东西而需要的打字量，并且我们不会用不需要的代码占用更多的内存空间。注意`pyplot`习惯上被称为`plt`:

```
import matplotlib.pyplot as plt
```

在我们看我们的第一个图之前，让我们看看如何实际查看它们。Matplotlib 将使用绘图命令创建我们的可视化；然而，我们不会看到可视化，直到我们要求看到它。这是以这种方式完成的，这样我们就可以用额外的代码不断地调整可视化，直到我们准备好完成它。除非我们保存对我们的情节的引用，一旦它被显示，我们将不得不重新创建它来改变一些东西。这是因为对最后一个情节的引用将被销毁以释放内存中的资源。

Matplotlib 使用`plt.show()`函数来显示可视化。它必须在我们创建的每个可视化之后被调用。当使用 Python shell 时，它还会阻止额外的代码被执行，直到窗口被关闭，因为它是一个阻塞函数。在 Jupyter 笔记本中，我们可以简单地使用一次`%matplotlib inline` **魔法命令**(一个特殊的 IPython 命令，前面有一个`%`符号)，当执行带有我们可视化代码的单元格时，我们的可视化将自动显示。魔术命令(或简称为 *magics* )作为 Jupyter 笔记本电脑单元中的常规代码运行。如果到目前为止，你还不热衷于使用 Jupyter 笔记本，现在就想开始使用，你可以参考第 1 章 、*数据分析介绍*。

重要说明

魔法将剧情的静态图像嵌入到我们的笔记本中。另一个常见的选择是`%matplotlib notebook`魔法。它通过允许调整大小和缩放等操作为绘图提供了小级别的交互性，但请注意，如果您使用 JupyterLab，这需要一些额外的设置，并且可能会导致一些令人困惑的错误，这取决于笔记本中运行的代码。查看本文了解更多:[https://medium . com/@ 1522933668924/using-matplotlib-in-jupyter-notebooks-comparising-methods-and-some-tips-python-c 38 e 85 b 40 ba 1](mailto:https://medium.com/@1522933668924/using-matplotlib-in-jupyter-notebooks-comparing-methods-and-some-tips-python-c38e85b40ba1)。

让我们在`1-introducing_matplotlib.ipynb`笔记本中创建第一个图表，使用本章存储库中`fb_stock_prices_2018.csv`文件中的脸书股票价格数据。首先，我们需要导入`pyplot`和`pandas`(在这个例子中，我们将使用`plt.show()`，所以我们不需要在这里运行魔法):

```
>>> import matplotlib.pyplot as plt
>>> import pandas as pd
```

接下来，我们读入 CSV 文件，并将索引指定为`date`列，因为我们从前面的章节中知道了数据的样子:

```
>>> fb = pd.read_csv(
...     'data/fb_stock_prices_2018.csv', 
...     index_col='date',
...     parse_dates=True
... )
```

为了了解脸书的股票如何随着时间的推移而演变，我们可以创建一个每日开盘价的折线图。对于这个任务，我们将使用`plt.plot()`函数，分别提供在 *x* 轴和 *y* 轴上使用的数据。然后我们将调用`plt.show()`来显示它:

```
>>> plt.plot(fb.index, fb.open)
>>> plt.show()
```

结果是如下的情节:

![Figure 5.1 – Our first plot with matplotlib
](image/Figure_5.1_B16834.jpg)

图 5.1–我们使用 matplotlib 的第一个图

如果我们想要呈现这个可视化，我们将不得不返回并添加我们的轴标签、绘图标题、图例(如果适用)，并可能固定 *y* 轴范围；这将在下一章讨论格式化和定制绘图外观时涉及。至少熊猫和`seaborn`会帮我们解决一些问题。

在本书的剩余部分，我们将使用`%matplotlib inline`魔法命令(记住，这需要在 Jupyter 笔记本中使用才能工作)，所以我们不会在绘图代码后调用`plt.show()`。下面的代码给出了与前面的块相同的输出:

```
>>> %matplotlib inline
>>> import matplotlib.pyplot as plt
>>> import pandas as pd
>>> fb = pd.read_csv(
...     'data/fb_stock_prices_2018.csv', 
...     index_col='date',
...     parse_dates=True
... )
>>> plt.plot(fb.index, fb.open)
```

重要说明

如果你使用的是 Jupyter 笔记本，请务必运行`%matplotlib inline` magic 命令。这确保了本章剩余部分中的绘图代码自动显示输出。

我们还可以使用`plt.plot()`函数来生成散点图，前提是我们为该图指定一个格式字符串作为第三个参数。格式字符串的形式为`'[marker][linestyle][color]'`；例如，`'--k'`为黑色虚线。由于我们不想要散点图的线条，我们省略了`linestyle`组件。我们可以用`'or'`格式的字符串做一个红圈散点图；这里，`o`表示圆形，`r`表示红色。下面的代码生成了一个高价与低价的散点图。注意，我们可以在`data`参数中传递 dataframe，然后使用列的字符串名称，而不是将序列作为`x`和`y`传递:

```
>>> plt.plot('high', 'low', 'or', data=fb.head(20))
```

除非有几天的大幅波动，我们预计这些点会形成一条线，因为最高价和最低价不会相差太远。这在很大程度上是正确的，但是要小心自动生成的比例——x 轴*和 y 轴*并不完全一致:**

![Figure 5.2 – Making a scatter plot with matplotlib
](image/Figure_5.2_B16834.jpg)

图 5.2–使用 matplotlib 制作散点图

注意在指定格式字符串时有一些灵活性。例如，`'[color][marker][linestyle]'`形式的格式字符串将会工作，除非它是不明确的。下表显示了如何为各种绘图样式制定格式字符串的一些示例；完整的选项列表可以在[https://matplotlib . org/API/_ as _ gen/matplotlib . py plot . plot . html](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html)的文档中的**注释**部分找到:

![Figure 5.3 – Styling shortcuts for matplotlib
](image/Figure_5.3_B16834.jpg)

图 5.3–matplotlib 的样式快捷方式

格式字符串是一种一次指定多个选项的便捷方式，好消息是，正如我们将在*用 pandas* 绘图一节中看到的，它也可以与`pandas`中的`plot()`方法一起工作。但是，如果我们想分别指定每个选项，我们可以使用`color`、`linestyle`和`marker`参数；查看我们可以作为关键字参数传递给文档中的`plt.plot()`的值— `pandas`也会为我们将这些值传递给`matplotlib`。

小费

作为为每个被绘制的变量定义样式的替代方法，可以考虑尝试`matplotlib`团队的`cycler`来指定哪些组合`matplotlib`应该在[https://matplotlib.org/gallery/color/color_cycler.html](https://matplotlib.org/gallery/color/color_cycler.html)之间循环。我们将在 [*第 7 章*](B16834_07_Final_SK_ePub.xhtml#_idTextAnchor146) 、*金融分析——比特币和股票市场*中看到这样的例子。

为了用`matplotlib`创建直方图，我们改用`hist()`函数。让我们在`earthquakes.csv`文件中制作一个地震震级的直方图，使用那些用`ml`震级类型测量的:

```
>>> quakes = pd.read_csv('data/earthquakes.csv')
>>> plt.hist(quakes.query('magType == "ml"').mag)
```

由此产生的直方图让我们了解了使用`ml`测量技术可以预测的地震震级范围:

![Figure 5.4 – Making a histogram with matplotlib
](image/Figure_5.4_B16834.jpg)

图 5.4–使用 matplotlib 制作直方图

正如我们可能已经猜到的，数量级往往很小，并且分布似乎有点正常。然而，关于直方图需要注意的是，仓的大小很重要。在有些情况下，我们可以改变数据被分成的仓的数量，并且改变直方图指示的分布。例如，如果我们使用不同数量的箱为该数据制作两个直方图，分布看起来会有所不同:

```
>>> x = quakes.query('magType == "ml"').mag
>>> fig, axes = plt.subplots(1, 2, figsize=(10, 3))
>>> for ax, bins in zip(axes, [7, 35]):
...     ax.hist(x, bins=bins)
...     ax.set_title(f'bins param: {bins}')
```

请注意，分布如何在左侧子图中显示为单峰，而在右侧子图中显示为双峰:

![Figure 5.5 – Different bin sizes can drastically change a histogram
](image/Figure_5.5_B16834.jpg)

图 5.5–不同的箱尺寸会显著改变直方图

小费

可以在[https://en . Wikipedia . org/wiki/Histogram # Number _ of _ bins _ and _ width](https://en.wikipedia.org/wiki/Histogram#Number_of_bins_and_width)找到一些选择箱数的通用经验法则。然而，请注意，在某些情况下，蜂群图可能比直方图更容易解释；这可以用`seaborn`创建，正如我们将在 [*第 6 章*](B16834_06_Final_SK_ePub.xhtml#_idTextAnchor125)*中看到的用 Seaborn 和定制技术*绘图。

在这个例子中，有几个额外的事情需要注意，我们将在下一节的绘图组件中解决:

*   我们可以制作支线剧情。
*   `pyplot`中的绘图函数也可以作为`matplotlib`对象的方法，比如`Figure`和`Axes`对象。

关于基本用法的最后一件事我们会发现很方便的是将绘图保存为图像——我们不应该局限于只显示 Python 中的图形。我们可以通过传入保存图像的路径，用`plt.savefig()`函数保存最后一个图形；比如`plt.savefig('my_plot.png')`。注意，如果在保存之前调用了`plt.show()`，文件将会是空的，因为在调用`plt.show()`之后，对最后一个情节的引用将会消失(`matplotlib`关闭`Figure`对象以释放内存中的资源)。使用`%matplotlib inline`魔法命令，我们可以在同一个单元格中查看和保存我们的图像。

## 绘图组件

在前面使用`plt.plot()`的例子中，我们不需要创建一个`Figure`对象——`matplotlib`会在后台为我们创建它。然而，正如我们在创建*图 5.5* 时看到的，任何超出基本情节的东西都需要更多的跑腿工作，包括我们自己创建一个`Figure`对象。`Figure`类是`matplotlib`可视化的顶级。它包含`Axes`对象，这些对象本身包含额外的绘图对象，如直线和刻度。在支线剧情的情况下，`Figure`对象包含具有附加功能的`Axes`对象。

我们使用`plt.figure()`函数来创建`Figure`对象；这些将有零个`Axes`对象，直到添加一个情节:

```
>>> fig = plt.figure()
<Figure size 432x288 with 0 Axes>
```

函数`plt.subplots()`为指定排列的支线剧情创建一个带有`Axes`对象的`Figure`对象。如果我们向`plt.subplots()`请求一行一列，将返回一个带有一个`Axes`对象的`Figure`对象。这在编写基于输入生成子情节布局的函数时很有用，因为我们不需要担心需要一个特例来处理单个子情节。这里，我们将指定一行两列的排列；这将返回一个`(Figure, Axes)`元组，我们可以对其进行解包:

```
>>> fig, axes = plt.subplots(1, 2)
```

当使用`%matplotlib inline` magic 命令时，我们将看到创建的图形:

![Figure 5.6 – Creating subplots
](image/Figure_5.6_B16834.jpg)

图 5.6–创建支线剧情

使用`plt.subplots()`的替代方法是在运行`plt.figure()`后得到的`Figure`对象上使用`add_axes()`方法。`add_axes()`方法采用`[left, bottom, width, height]`形式的列表作为图形尺寸的比例，表示该子情节在图形中应该占据的面积:

```
>>> fig = plt.figure(figsize=(3, 3))
>>> outside = fig.add_axes([0.1, 0.1, 0.9, 0.9])
>>> inside = fig.add_axes([0.7, 0.7, 0.25, 0.25])
```

这允许在地块内创建地块:

![Figure 5.7 – Plot with an inset plot using matplotlib
](image/Figure_5.7_B16834.jpg)

图 5.7–使用 matplotlib 绘制插图

如果我们的目标是保持所有的情节分开，但不是大小相等，我们可以在`Figure`对象上使用`add_gridspec()`方法来创建支线剧情的网格。然后，我们可以运行`add_subplot()`，从网格中传递给定支线剧情应该占据的区域:

```
>>> fig = plt.figure(figsize=(8, 8))
>>> gs = fig.add_gridspec(3, 3)
>>> top_left = fig.add_subplot(gs[0, 0])
>>> mid_left = fig.add_subplot(gs[1, 0])
>>> top_right = fig.add_subplot(gs[:2, 1:])
>>> bottom = fig.add_subplot(gs[2,:])
```

这导致了以下布局:

![Figure 5.8 – Building custom plot layouts with matplotlib
](image/Figure_5.8_B16834.jpg)

图 5.8–使用 matplotlib 构建自定义绘图布局

在上一节中，我们讨论了如何使用`plt.savefig()`保存可视化效果，但是我们也可以对`Figure`对象使用`savefig()`方法:

```
>>> fig.savefig('empty.png')
```

记住这一点非常有用，因为使用`plt.<func>()`，我们只能访问最后一个`Figure`对象；然而，如果我们保存对我们的`Figure`对象的引用，我们可以使用它们中的任何一个，不管它们是什么时候创建的。此外，这预示了一个重要的概念，你会在本章中注意到:`Figure`和`Axes`对象拥有与它们的`pyplot`函数相似或相同名称的方法。

虽然引用我们创建的所有`Figure`对象很方便，但是当我们使用完这些对象时，最好关闭它们，这样我们就不会浪费任何资源。这可以通过`plt.close()`功能完成。如果我们不传入任何东西，它将关闭最后一个`Figure`对象；然而，我们可以传入一个特定的`Figure`对象来只关闭那个对象，或者传入`'all'`来关闭所有已经打开的`Figure`对象:

```
>>> plt.close('all')
```

直接舒适地使用`Figure`和`Axes`对象很重要，因为这样可以对结果可视化进行更精细的控制。这将在下一章中变得明显。

## 附加选项

我们的一些可视化看起来有点挤。为了解决这个问题，我们可以在对`plt.figure()`或`plt.subplots()`的调用中为中的`figsize`传递一个值。我们用一个以英寸为单位的`(width, height)`元组来指定尺寸。我们将在`pandas`中看到的`plot()`方法也接受`figsize`参数，所以请记住这一点:

```
>>> fig = plt.figure(figsize=(10, 4))
<Figure size 720x288 with 0 Axes>
>>> fig, axes = plt.subplots(1, 2, figsize=(10, 4))
```

请注意，这些支线剧情比图 5.6 中*的支线剧情更加方形，因为我们没有指定`figsize`:*

![Figure 5.9 – Specifying plot size
](image/Figure_5.9_B16834.jpg)

图 5.9–指定地块大小

为我们的图逐个指定`figsize`参数并不太坏。然而，如果我们发现我们把所有的东西都调整到同样的大小，有一个更好的选择。Matplotlib 将其默认值保存在`rcParams`中，它的作用就像一个字典，这意味着我们可以轻松地覆盖我们希望的会话，并在我们重新启动 Python 会话时恢复默认值。由于这本字典中有许多选项(在写作时超过 300 个)，让我们随机选择其中几个，以了解哪些是可用的:

```
>>> import random
>>> import matplotlib as mpl
>>> rcparams_list = list(mpl.rcParams.keys())
>>> random.seed(20) # make this repeatable
>>> random.shuffle(rcparams_list)
>>> sorted(rcparams_list[:20])
['axes.axisbelow',
 'axes.formatter.limits',
 'boxplot.vertical',
 'contour.corner_mask',
 'date.autoformatter.month',
 'legend.labelspacing',
 'lines.dashed_pattern',
 'lines.dotted_pattern',
 'lines.scale_dashes',
 'lines.solid_capstyle',
 'lines.solid_joinstyle',
 'mathtext.tt',
 'patch.linewidth',
 'pdf.fonttype',
 'savefig.jpeg_quality',
 'svg.fonttype',
 'text.latex.preview',
 'toolbar',
 'ytick.labelright',
 'ytick.minor.size'] 
```

正如你所看到的，这里有许多我们可以修改的选项。让我们检查一下`figsize`的当前默认值是多少:

```
>>> mpl.rcParams['figure.figsize']
[6.0, 4.0]
```

要在当前会话中更改它，只需将其设置为一个新值:

```
>>> mpl.rcParams['figure.figsize'] = (300, 10)
>>> mpl.rcParams['figure.figsize']
[300.0, 10.0]
```

在我们继续之前，让我们使用`mpl.rcdefaults()`功能恢复默认设置。`figsize`的默认值实际上与我们之前的不同；这是因为`%matplotlib inline`在第一次运行时为一些与绘图相关的参数设置了不同的值([https://github . com/ipython/ipykernel/blob/master/ipykernel/pylab/config . py # L42-L56](https://github.com/ipython/ipykernel/blob/master/ipykernel/pylab/config.py#L42-L56)):

```
>>> mpl.rcdefaults()
>>> mpl.rcParams['figure.figsize']
[6.8, 4.8]
```

注意，如果我们知道它的组(`figure`，在这种情况下)和参数名(`figsize`，我们也可以使用`plt.rc()`函数来更新一个特定的设置。正如我们之前所做的，我们可以使用`plt.rcdefaults()`来重置默认值:

```
# change `figsize` default to (20, 20)
>>> plt.rc('figure', figsize=(20, 20)) 
>>> plt.rcdefaults() # reset the default
```

小费

如果我们发现自己每次启动 Python 时都做了相同的更改，我们应该考虑读入我们的配置，而不是每次都更新默认值。更多信息请参考`mpl.rc_file()`功能。

# 与熊猫密谋

`Series`和`DataFrame`对象都有一个`plot()`方法，允许我们创建几个不同的情节，并控制它们格式的某些方面，如支线剧情布局、图形大小、标题，以及是否跨支线剧情共享一个轴。这使得绘制我们的数据更加方便，因为创建可展示的绘图的大部分工作都是通过一个方法调用来完成的。在幕后，`pandas`正在给`matplotlib`打几个电话，制作我们的剧情。`plot()`方法最常用的一些参数如下:

![Figure 5.10 – Frequently used pandas plotting arguments
](image/Figure_5.10_B16834.jpg)

图 5.10-常用的熊猫绘图参数

正如我们在讨论`matplotlib`时看到的，来自`pandas`的`plot()`方法允许我们使用`kind`参数来指定我们想要的绘图类型，而不是为每种绘图类型使用单独的函数。情节的选择将决定需要哪些其他参数。我们可以使用由`plot()`方法返回的`Axes`对象来进一步修改我们的情节。

让我们在`2-plotting_with_pandas.ipynb`笔记本中探索一下这一功能。在开始之前，我们需要处理本部分的导入，并读入我们将使用的数据(脸书股票价格、地震和新冠肺炎案例):

```
>>> %matplotlib inline
>>> import matplotlib.pyplot as plt
>>> import numpy as np
>>> import pandas as pd
>>> fb = pd.read_csv(
...     'data/fb_stock_prices_2018.csv', 
...     index_col='date',
...     parse_dates=True
... )
>>> quakes = pd.read_csv('data/earthquakes.csv')
>>> covid = pd.read_csv('data/covid19_cases.csv').assign(
...     date=lambda x: \
...         pd.to_datetime(x.dateRep, format='%d/%m/%Y')
... ).set_index('date').replace(
...     'United_States_of_America', 'USA'
... ).sort_index()['2020-01-18':'2020-09-18']
```

在接下来的几节中，我们将讨论如何为特定的分析目标生成适当的可视化，例如显示随时间的演变或数据中变量之间的关系。请注意，只要有可能，这些情节都已经被设计好了，这样它们就可以在本书中被解释成黑白的。

## 随时间演变

当处理时间序列数据时(比如存储在`fb`变量中的脸书股票数据)，我们经常想要显示数据是如何随着时间的推移而变化的。为此，我们使用了线图，在某些情况下，还使用了条形图(在*计数和频率*章节中有所介绍)。在线图的情况下，我们简单地提供`kind='line'`到`plot()`，指示哪些列将是`x`和`y`。注意，我们实际上不需要为`x`提供列，因为默认情况下`pandas`将使用索引(这也使得生成`Series`对象的线图成为可能)。此外，请注意，我们可以向`style`参数提供一个格式字符串，就像我们对`matplotlib`图所做的那样:

```
>>> fb.plot(
...     kind='line', y='open', figsize=(10, 5), style='-b',
...     legend=False, title='Evolution of Facebook Open Price'
... )
```

这给了我们一个类似于我们用`matplotlib`得到的情节；但是，在这个单一的方法调用中，我们只为这个图指定了图形大小，关闭了图例，并为它指定了一个标题:

![Figure 5.11 – Our first plot with pandas
](image/Figure_5.11_B16834.jpg)

图 5.11-我们的第一个熊猫地块

与`matplotlib`一样，我们不必使用样式格式字符串——相反，我们可以单独传递每个组件及其相关的关键字。例如，下面的代码给出了与上一个代码相同的结果:

```
fb.plot(
    kind='line', y='open', figsize=(10, 5),
 color='blue', linestyle='solid',
    legend=False, title='Evolution of Facebook Open Price'
)
```

我们不局限于用`plot()`方法一次绘制一行；我们还可以传入一个列列表来分别绘制和样式化它们。注意，我们实际上不需要指定`kind='line'`，因为这是默认值:

```
>>> fb.first('1W').plot(
...     y=['open', 'high', 'low', 'close'], 
...     style=['o-b', '--r', ':k', '.-g'],
...     title='Facebook OHLC Prices during '
...           '1st Week of Trading 2018'
... ).autoscale() # add space between data and axes
```

这导致出现在下面的图中，其中每条线都有不同的样式:

![Figure 5.12 – Plotting multiple columns
](image/Figure_5.12_B16834.jpg)

图 5.12–绘制多列

此外，我们可以轻松地让`pandas`在同一个调用中绘制所有列。`x`和`y`参数可以采用单个列名或列名列表；如果我们什么都不提供，`pandas`会使用所有的。注意，当`kind='line'`时，列必须作为`y`参数传递；然而，其他绘图类型也支持将列列表传递给`x`。在这种情况下，要求支线剧情可能会有帮助，而不是让所有的线都在同一个情节上。让我们将脸书数据中的所有列可视化为线图:

```
>>> fb.plot(
...     kind='line', subplots=True, layout=(3, 2),
...     figsize=(15, 10), title='Facebook Stock 2018'
... )
```

使用的`layout`参数，我们告诉`pandas`如何安排我们的支线剧情(三行两列):

![Figure 5.13 – Creating subplots with pandas
](image/Figure_5.13_B16834.jpg)

图 5.13-创建熊猫支线剧情

注意，支线剧情自动共享*x*-轴，因为它们共享一个索引。因为`volume`时间序列在不同的刻度上，所以 *y* 轴不共享。我们可以通过将带有布尔值的`sharex`或`sharey`参数传递给`plot()`来改变某些绘图类型中的这种行为。默认情况下会呈现图例，因此，对于每个子情节，我们在图例中有一个单独的项目来指示它包含哪些数据。在这种情况下，我们没有提供带有`title`参数的支线剧情标题列表，因为传说就是为了这个目的；然而，我们为整个情节的标题传递了一个单独的字符串。总而言之，在处理支线剧情的时候，我们有两种选择:

*   传递一个字符串作为整个图形的标题。
*   传递一个字符串列表作为每个子情节的标题。

有时候，我们想让制作一些支线剧情，每一个里面都有一些变量来做比较。这可以通过首先用`plt.subplots()`创建子情节，然后将`Axes`对象提供给`ax`参数来实现。为了说明这一点，让我们看看中国、西班牙、意大利、美国、巴西和印度每天新增的新冠肺炎病例。这是长格式数据，所以我们必须首先透视它，以便日期(我们在读取 CSV 文件时将其设置为索引)在数据透视表的索引中，国家(`countriesAndTerritories`)在列中。由于这些值有很大的波动，我们将使用第 4 章 、*汇总熊猫数据帧*中介绍的`rolling()`方法绘制新病例的 7 天移动平均值:

```
>>> new_cases_rolling_average = covid.pivot_table(
...     index=covid.index,
...     columns='countriesAndTerritories',
...     values='cases'
... ).rolling(7).mean()
```

我们不会为每个国家创建一个单独的图(这使得比较更加困难)或者将它们都绘制在一起(这使得很难看到较小的值)，我们将在同一子图中绘制具有相似病例数的国家。我们还将使用不同的线条样式来区分黑白线条:

```
>>> fig, axes = plt.subplots(1, 3, figsize=(15, 5))
>>> new_cases_rolling_average[['China']]\
...     .plot(ax=axes[0], style='-.c')
>>> new_cases_rolling_average[['Italy', 'Spain']].plot(
...     ax=axes[1], style=['-', '--'],
...     title='7-day rolling average of new '
...           'COVID-19 cases\n(source: ECDC)'
... )
>>> new_cases_rolling_average[['Brazil', 'India', 'USA']]\ 
...     .plot(ax=axes[2], style=['--', ':', '-'])
```

通过直接使用`matplotlib`为每个子情节生成`Axes`对象，我们在最终布局中获得了更多的灵活性:

![Figure 5.14 – Controlling which data gets plotted in each of the subplots
](image/Figure_5.14_B16834.jpg)

图 5.14–控制每个子图中绘制的数据

在前面的情节中，我们能够比较每日新新冠肺炎病例水平相似的国家，但由于规模的原因，我们无法在同一子情节中比较所有国家。解决这个问题的一个方法是使用**面积图**，这使我们能够直观地显示新新冠肺炎病例的整体 7 天滚动平均值，同时，每个国家对总数的贡献是多少。为了便于阅读，我们将意大利和西班牙归为一组，并为美国、巴西和印度之外的国家创建另一个类别:

```
>>> cols = [
...     col for col in new_cases_rolling_average.columns 
...     if col not in [
...         'USA', 'Brazil', 'India', 'Italy & Spain'
...     ]
... ]
>>> new_cases_rolling_average.assign(
...     **{'Italy & Spain': lambda x: x.Italy + x.Spain}
... ).sort_index(axis=1).assign(
...     Other=lambda x: x[cols].sum(axis=1)
... ).drop(columns=cols).plot(
...     kind='area', figsize=(15, 5), 
...     title='7-day rolling average of new '
...           'COVID-19 cases\n(source: ECDC)'
... )
```

对于那些黑白观看结果图的人来说，巴西是底层，印度在上面，以此类推。绘图区域的总高度是总体值，给定阴影区域的高度是该国家的值。这向我们表明，超过一半的每日新增病例发生在巴西、印度、意大利、西班牙和美国:

![Figure 5.15 – Creating an area plot
](image/Figure_5.15_B16834.jpg)

图 5.15–创建面积图

另一种可视化随时间演变的方法是查看随时间的累积总和。让我们绘制中国、西班牙、意大利、美国、巴西和印度的新冠肺炎病例的累计数量，再次使用`ax`参数来创建支线剧情。为了计算一段时间内累积的总和，我们按照位置(`countriesAndTerritories`)和日期(这是我们的索引)进行分组，因此我们使用`pd.Grouper()`；这一次，我们将使用`groupby()`和`unstack()`将我们的数据转换为绘图的宽格式:

```
>>> fig, axes = plt.subplots(1, 3, figsize=(15, 3))
>>> cumulative_covid_cases = covid.groupby(
...     ['countriesAndTerritories', pd.Grouper(freq='1D')]
... ).cases.sum().unstack(0).apply('cumsum')
>>> cumulative_covid_cases[['China']]\
...     .plot(ax=axes[0], style='-.c')
>>> cumulative_covid_cases[['Italy', 'Spain']].plot(
...     ax=axes[1], style=['-', '--'], 
...     title='Cumulative COVID-19 Cases\n(source: ECDC)'
... )
>>> cumulative_covid_cases[['Brazil', 'India', 'USA']]\ 
...     .plot(ax=axes[2], style=['--', ':', '-'])
```

查看累积的新冠肺炎病例可以发现，尽管中国和意大利似乎已经控制住了新冠肺炎病例，但西班牙、美国、巴西和印度仍在苦苦挣扎:

![Figure 5.16 – Plotting the cumulative sum over time
](image/Figure_5.16_B16834.jpg)

图 5.16–绘制一段时间内的累积和

重要说明

在本节中，我们多次使用虚线和虚线，以确保生成的图可以用黑色和白色解释；但是，请注意，当以彩色显示这些图时，接受默认颜色和线条样式就足够了。通常，不同的线条样式表示数据类型的不同，例如，我们可以用实线表示随时间的变化，用虚线表示滚动平均值。

## 变量之间的关系

当我们想要可视化变量之间的关系时，我们通常从散点图开始，散点图向我们显示在`x`变量的不同值处`y`变量的值。这使得我们很容易发现相关性和可能的非线性关系。在前一章中，当我们查看脸书股票数据时，我们看到高交易量的日子似乎与股价的大幅下跌相关联。我们可以用散点图来形象化这种关系:

```
>>> fb.assign(
...     max_abs_change=fb.high - fb.low
... ).plot(
...     kind='scatter', x='volume', y='max_abs_change',
...     title='Facebook Daily High - Low vs. Volume Traded'
... )
```

看似有关系，但似乎不是线性的:

![Figure 5.17 – Making scatter plots with pandas
](image/Figure_5.17_B16834.jpg)

图 5.17–制作熊猫散点图

让我们试着取体积的对数。为此，我们有几个选择:

*   使用`np.log()`创建一个作为卷日志的新列。
*   通过将`logx=True`传递给`plot()`方法或调用`plt.xscale('log')`，使用 *x* 轴的对数刻度。

在这种情况下，最有意义的是简单地改变我们显示数据的方式，因为我们不打算使用新的列:

```
>>> fb.assign(
...     max_abs_change=fb.high - fb.low
... ).plot(
...     kind='scatter', x='volume', y='max_abs_change',
...     title='Facebook Daily High - '
...           'Low vs. log(Volume Traded)',
...     logx=True
... )
```

在修改了 *x* 轴刻度后，我们得到如下散点图:

![Figure 5.18 – Applying a logarithmic scale to the x-axis
](image/Figure_5.18_B16834.jpg)

图 5.18–对 *x* 轴应用对数标度

小费

`pandas`中的`plot()`方法有三个对数刻度参数:`logx` / `logy`用于单轴调整，`loglog`用于将两者都设置为对数刻度。

散点图的一个问题是，很难辨别给定区域内的点的集中程度，因为它们只是一个点一个点地绘制。我们可以使用`alpha`参数来控制点的透明度；该参数从`0`到`1`取值，其中`0`完全透明，`1`完全不透明。默认情况下，它们是不透明的(值为`1`)；但是，如果我们使它们更加透明，我们应该能够看到一些重叠部分:

```
>>> fb.assign(
...     max_abs_change=fb.high - fb.low
... ).plot(
...     kind='scatter', x='volume', y='max_abs_change',
...     title='Facebook Daily High - '
...           'Low vs. log(Volume Traded)', 
...     logx=True, alpha=0.25
... )
```

我们现在可以开始在图的左下区域确定点的密度，但这仍然相对困难:

![Figure 5.19 – Modifying transparency to visualize overlap
](image/Figure_5.19_B16834.jpg)

图 5.19–修改透明度以可视化重叠

谢天谢地，我们还有另外一种情节类型可以使用:`hexbin`。**hex bin**通过将图形划分为六边形网格，并根据每个 bin 中的点的集中程度对其进行着色，从而形成二维直方图。让我们将这些数据视为六边形:

```
>>> fb.assign(
...     log_volume=np.log(fb.volume),
...     max_abs_change=fb.high - fb.low
... ).plot(
...     kind='hexbin', 
...     x='log_volume', 
...     y='max_abs_change', 
...     title='Facebook Daily High - '
...           'Low vs. log(Volume Traded)', 
...     colormap='gray_r', 
...     gridsize=20,
...     sharex=False # bug fix to keep the x-axis label
... )
```

在侧的颜色条指示颜色和该框中的点数之间的关系。我们选择的色彩映射表(`gray_r`)对高密度的箱进行较暗(向黑色)的着色，对低密度的箱进行较亮(向白色)的着色。通过传入`gridsize=20`，我们指定应该在 *x* 轴上使用 20 个六边形，然后让`pandas`决定沿着 *y* 轴使用多少个六边形，这样它们在形状上是近似规则的；然而，我们可以传递一个元组来双向选择数字。`gridsize`的较大值将使箱子更难看到，而较小的值将导致箱子更满，在图上占据更多空间——我们必须取得平衡:

![Figure 5.20 – Plotting hexbins with pandas
](image/Figure_5.20_B16834.jpg)

图 5.20–绘制熊猫的六角图

最后，如果我们只是想可视化变量之间的相关性，我们可以绘制一个相关矩阵。一个**相关矩阵**描述了相关性的大小和方向(正或负)。让我们来看看我们一直在处理的脸书数据的相关矩阵。为此，我们可以使用`pandas`和来自`matplotlib`的`plt.matshow()`或`plt.imshow()`函数的组合。由于有许多代码需要在同一个单元中运行，我们将在这个代码块之后立即讨论每个部分的用途:

```
>>> fig, ax = plt.subplots(figsize=(20, 10))
# calculate the correlation matrix
>>> fb_corr = fb.assign(
...     log_volume=np.log(fb.volume),
...     max_abs_change=fb.high - fb.low
... ).corr()
# create the heatmap and colorbar
>>> im = ax.matshow(fb_corr, cmap='seismic')
>>> im.set_clim(-1, 1)
>>> fig.colorbar(im)
# label the ticks with the column names
>>> labels = [col.lower() for col in fb_corr.columns]
>>> ax.set_xticks(ax.get_xticks()[1:-1])
>>> ax.set_xtickabels(labels, rotation=45)
>>> ax.set_yticks(ax.get_yticks()[1:-1])
>>> ax.set_yticklabels(labels)
# include the value of the correlation coefficient in the boxes
>>> for (i, j), coef in np.ndenumerate(fb_corr):
...     ax.text(
...         i, j, fr'$\rho$ = {coef:.2f}', 
...         ha='center', va='center', 
...         color='white', fontsize=14
...     )
```

一个**热图**让我们很容易地可视化相关系数，假设我们选择一个发散的色图——当我们在 [*第 6 章*](B16834_06_Final_SK_ePub.xhtml#_idTextAnchor125) 、*用 Seaborn 绘图和定制技术*中讨论定制绘图时，我们将讨论不同类型的色图。本质上，对于这个图，我们希望相关系数大于零的为红色，相关系数小于零的为蓝色；接近零的相关系数将没有颜色，更强的相关性将是它们各自颜色的更暗阴影。这可以通过选择`seismic`色图，然后将色标的界限设置为[-1，1]来实现，因为相关系数具有这些界限:

```
im = ax.matshow(fb_corr, cmap='seismic')
im.set_clim(-1, 1) # set the bounds of the color scale
fig.colorbar(im) # add the colorbar to the figure
```

为了能够阅读生成的热图，我们需要用数据中变量的名称标记行和列:

```
labels = [col.lower() for col in fb_corr.columns]
ax.set_xticks(ax.get_xticks()[1:-1]) # to handle matplotlib bug
ax.set_xticklabels(labels, rotation=45)
ax.set_yticks(ax.get_yticks()[1:-1]) # to handle matplotlib bug
ax.set_yticklabels(labels)
```

虽然色标将使我们容易区分弱相关性和强相关性，但用实际的相关系数来注释热图通常是有帮助的。这可以通过在包含绘图的`Axes`对象上使用`text()`方法来实现。对于该图，我们放置了白色居中对齐的文本，表示每个变量组合的皮尔逊相关系数的值:

```
# iterate over the matrix 
for (i, j), coef in np.ndenumerate(fb_corr): 
    ax.text(
        i, j, 
        fr'$\rho$ = {coef:.2f}', # raw (r), format (f) string
        ha='center', va='center', 
        color='white', fontsize=14
    )
```

这将生成一个带注释的热图，显示脸书数据集中变量之间的相关性:

![Figure 5.21 – Visualizing correlations as a heatmap
](image/Figure_5.21_B16834.jpg)

图 5.21–将相关性可视化为热图

在*图 5.21* 中，我们可以很容易地看到 OHLC 时间序列之间，以及交易量和变化的最大绝对值之间的强正相关性。然而，这些群体之间存在微弱的负相关。再者，我们可以看到，取体积的对数，确实会把与`max_abs_change`的相关系数从 0.64 提高到 0.73。当我们在下一章讨论`seaborn`时，我们将学习一种更简单的生成热图的方法，并更详细地讨论注释。

## 分布

通常，我们希望可视化数据的分布，以了解它呈现出什么样的值。根据我们拥有的数据类型，我们可以选择使用直方图、**核密度估计值** ( **KDEs** )、箱线图或**经验累积分布函数** ( **ECDFs** )。当处理离散数据时，直方图是一个很好的起点。让我们来看一下脸书股票的日交易量柱状图:

```
>>> fb.volume.plot(
...     kind='hist', 
...     title='Histogram of Daily Volume Traded '
...           'in Facebook Stock'
... )
>>> plt.xlabel('Volume traded') # label x-axis (see ch 6)
```

这是真实世界数据的一个很好的例子，它肯定不是正态分布的。交易量是右偏的，右边有一条长尾巴。回想一下，在 [*第 4 章*](B16834_04_Final_SK_ePub.xhtml#_idTextAnchor082) 、*汇总熊猫数据框架*中，当我们讨论宁滨并查看低、中、高交易量时，几乎所有数据都落在低位，这与我们在该柱状图中看到的一致:

![Figure 5.22 – Creating a histogram with pandas
](image/Figure_5.22_B16834.jpg)

图 5.22–创建熊猫直方图

小费

与来自`matplotlib`的`plt.hist()`函数一样，我们可以用`bins`参数为容器数量提供一个自定义值。然而，我们必须小心不要歪曲分布。

我们还可以在同一个图上创建多个直方图，通过使用`ax`参数为每个图指定相同的`Axes`对象来比较分布。在这种情况下，我们必须使用`alpha`参数来查看任何重叠。鉴于我们有许多不同的地震测量技术(`magType`栏)，我们可能有兴趣比较它们产生的不同震级范围:

```
>>> fig, axes = plt.subplots(figsize=(8, 5))
>>> for magtype in quakes.magType.unique():
...     data = quakes.query(f'magType == "{magtype}"').mag
...     if not data.empty:
...         data.plot(
...             kind='hist', 
...             ax=axes, 
...             alpha=0.4, 
...             label=magtype, 
...             legend=True, 
...             title='Comparing histograms '
...                   'of earthquake magnitude by magType'
...         )
>>> plt.xlabel('magnitude') # label x-axis (discussed in ch 6)
```

这向我们展示了`ml`是最常见的`magType`，其次是`md`，它们产生了相似的星等范围；然而，第三常见的`mb`会产生更高的幅度:

![Figure 5.23 – Plotting overlapping histograms with pandas
](image/Figure_5.23_B16834.jpg)

图 5.23–用熊猫绘制重叠直方图

当处理连续数据(比如股票价格)时，我们可以使用 KDEs。让我们来看看脸书股票每日高价的 KDE。注意，我们可以通过`kind='kde'`或`kind='density'`:

```
>>> fb.high.plot(
...     kind='kde', 
...     title='KDE of Daily High Price for Facebook Stock'
... )
>>> plt.xlabel('Price ($)') # label x-axis (discussed in ch 6)
```

得到的密度曲线有些向左倾斜:

![Figure 5.24 – Visualizing the KDE with pandas
](image/Figure_5.24_B16834.jpg)

图 5.24–可视化熊猫 KDE

我们可能还想将叠加在直方图顶部的 KDE 可视化。Pandas 允许我们传递想要绘制的`Axes`对象，并在创建可视化后返回一个对象，这使得它变得不在话下:

```
>>> ax = fb.high.plot(kind='hist', density=True, alpha=0.5)
>>> fb.high.plot(
...     ax=ax, kind='kde', color='blue', 
...     title='Distribution of Facebook Stock\'s '
...           'Daily High Price in 2018'
... )
>>> plt.xlabel('Price ($)') # label x-axis (discussed in ch 6)
```

注意，当我们生成直方图时，我们必须传递`density=True`，以确保直方图的 *y* 轴和 KDE 在同一刻度上。否则，KDE 会小到看不见。然后直方图在 y 轴上绘制出密度，这样我们可以更好地理解 KDE 是如何形成的。我们还增加了直方图的透明度，这样我们就可以看到顶部的 KDE 线。注意，如果我们移除 KDE 调用的`color='blue'`部分，我们不需要改变直方图调用中`alpha`的值，因为 KDE 和直方图将是不同的颜色；我们用蓝色绘制它们，因为它们代表相同的数据:

![Figure 5.25 – Combining a KDE and a histogram with pandas
](image/Figure_5.25_B16834.jpg)

图 5.25-结合熊猫的 KDE 和直方图

KDE 向我们展示了一个估计的**概率密度函数** ( **PDF** ，它告诉我们概率是如何分布在数据值上的。但是，在某些情况下，我们更感兴趣的是得到小于或等于(或大于或等于)某个值的概率，这可以用**累积分布函数** ( **CDF** )来看。

重要说明

使用 CDF， *x* 变量的值沿着 *x* 轴，而获得给定 *x* 的累积概率最多沿着 *y* 轴。这个累积概率在 0 到 1 之间，写成 *P(X ≤ x)* ，其中小写( *x* )是比较的值，大写( *X* )是随机变量， *X* 。更多信息请访问[https://www . ITL . NIST . gov/div 898/handbook/EDA/section 3/EDA 362 . htm](https://www.itl.nist.gov/div898/handbook/eda/section3/eda362.htm)。

使用`statsmodels`包，我们可以估计 CDF，给我们**经验累积分布函数** ( **ECDF** )。让我们用这个来理解用`ml`震级类型测量的地震的震级分布:

```
>>> from statsmodels.distributions.empirical_distribution \
...     import ECDF
>>> ecdf = ECDF(quakes.query('magType == "ml"').mag)
>>> plt.plot(ecdf.x, ecdf.y)
# axis labels (we will cover this in chapter 6)
>>> plt.xlabel('mag') # add x-axis label 
>>> plt.ylabel('cumulative probability') # add y-axis label
# add title (we will cover this in chapter 6)
>>> plt.title('ECDF of earthquake magnitude with magType ml')
```

这产生了下面的 ECDF:

![Figure 5.26 – Visualizing the ECDF
](image/Figure_5.26_B16834.jpg)

图 5.26–可视化 ECDF

这对于我们进行 EDA 时更好地理解数据非常有用。然而，如果我们选择这样做，我们必须小心我们如何解释这一点以及我们如何向他人解释这一点。在这里，我们可以看到，如果这种分布确实代表了总体，那么对于使用该测量技术测量的地震，地震的`ml`震级小于或等于 **3** 的概率为 **98%** :

![Figure 5.27 – Interpreting the ECDF
](image/Figure_5.27_B16834.jpg)

图 5.27–解读 ECDF

最后，我们可以使用箱线图来可视化潜在的异常值和使用四分位数的分布。作为一个例子，让我们想象一下整个数据集中脸书股票的 OHLC 价格:

```
>>> fb.iloc[:,:4].plot(
...     kind='box', 
...     title='Facebook OHLC Prices Box Plot'
... )
>>> plt.ylabel('price ($)') # label x-axis (discussed in ch 6)
```

请注意，我们确实丢失了一些在其他图中获得的信息。我们不再知道点在整个分布中的密度；对于方框图，我们将重点放在 5 个数字的汇总上:

![Figure 5.28 – Creating box plots with pandas
](image/Figure_5.28_B16834.jpg)

图 5.28–用熊猫创建方框图

小费

我们可以通过传入`notch=True`来创建一个缺口盒图。该凹口标志着中位数周围 95%的置信区间，这在比较组间差异时很有帮助。笔记本里有个例子。

我们可以在调用`groupby()`之后也调用`boxplot()`方法。让我们看看当我们根据交易量计算箱线图时，它们是如何变化的:

```
>>> fb.assign(
...     volume_bin=\
...         pd.cut(fb.volume, 3, labels=['low', 'med', 'high']) 
... ).groupby('volume_bin').boxplot(
...     column=['open', 'high', 'low', 'close'], 
...     layout=(1, 3), figsize=(12, 3)
... )
>>> plt.suptitle(
...     'Facebook OHLC Box Plots by Volume Traded', y=1.1
... )
```

请记住从 [*第 4 章*](B16834_04_Final_SK_ePub.xhtml#_idTextAnchor082) 、*汇总熊猫数据框架、*可知，大部分时间都处于低交易量时段，因此我们预计会看到更多的变化，因为随着时间的推移，股票数据看起来是这样的:

![Figure 5.29 – Box plots per group with pandas
](image/Figure_5.29_B16834.jpg)

图 5.29–每组熊猫的盒状图

我们还可以使用这种技术来查看地震震级的分布，并将其与美国地质调查局网站上的预期范围进行比较([https://www . USGS . gov/natural-hazards/seismic-hazards/science/magnitude-types](https://www.usgs.gov/natural-hazards/earthquake-hazards/science/magnitude-types)):

```
>>> quakes[['mag', 'magType']]\
...     .groupby('magType')\
...     .boxplot(figsize=(15, 8), subplots=False)
# formatting (covered in chapter 6)
>>> plt.title('Earthquake Magnitude Box Plots by magType')
>>> plt.ylabel('magnitude')
```

美国地质调查局网站提到了某些测量技术无法使用的情况，以及每种测量技术的权威震级范围(当超出该范围时，使用其他技术)。在这里，我们可以看到，这些技术综合起来覆盖了很宽的幅度范围，但没有一种技术能覆盖所有方面:

![Figure 5.30 – Box plots per group in a single plot
](image/Figure_5.30_B16834.jpg)

图 5.30-单个地块中每组的箱线图

重要说明

虽然直方图、KDEs、ECDFs 和箱线图都是查看数据分布的方式，但我们看到每种可视化都向我们展示了数据的不同方面。在得出任何结论之前，从多个角度对数据进行可视化是很重要的。

## 计数和频率

当处理分类数据时，我们可以创建条形图来显示数据的计数或特定值的频率。条可以是垂直的(`kind='bar'`)或水平的(`kind='barh'`)。当我们有许多类别或者类别有一定的顺序时(例如，随时间的演变)，垂直条形图非常有用。水平条形图便于比较每个类别的大小，同时为长类别名称留出足够的空白空间(无需旋转它们)。

我们可以使用一个水平条形图来查看`quakes`数据框架中的哪些地方发生了最多的地震。首先，我们在`parsed_place`序列上调用`value_counts()`方法，取地震前 15 位。接下来，我们颠倒顺序，使列表中最小的在顶部，这将把最高的排序到我们将要制作的条形图的顶部。请注意，我们可以将排序顺序反转为`value_counts()`的一个参数，但是由于我们仍然需要获取前 15 名，所以我们在一个`iloc`调用中完成了这两个操作:

```
>>> quakes.parsed_place.value_counts().iloc[14::-1,].plot(
...     kind='barh', figsize=(10, 5), 
...     title='Top 15 Places for Earthquakes '
...           '(September 18, 2018 - October 13, 2018)'
... )
>>> plt.xlabel('earthquakes') # label x-axis (see ch 6)
```

记住，切片记法是`[start:stop:step]`，这种情况下，由于步长为负，所以顺序反过来；我们从索引`14`(第 15 个条目)开始，每次都更接近索引`0`。通过`kind='barh'`，我们得到一个水平条形图，显示该数据集中的大多数地震发生在阿拉斯加。也许在如此短的时间内看到如此多的地震令人惊讶，但许多地震的震级都很小，人们甚至感觉不到它们:

![Figure 5.31 – Plotting horizontal bars with pandas
](image/Figure_5.31_B16834.jpg)

图 5.31–用熊猫绘制水平条

我们的数据还包含地震是否伴随海啸的信息。让我们使用`groupby()`制作一个柱状图，显示在我们的数据中的时间段内遭受海啸袭击的前 10 个地方:

```
>>> quakes.groupby(
...     'parsed_place'
... ).tsunami.sum().sort_values().iloc[-10:,].plot(
...     kind='barh', figsize=(10, 5), 
...     title='Top 10 Places for Tsunamis '
...           '(September 18, 2018 - October 13, 2018)'
... )
>>> plt.xlabel('tsunamis') # label x-axis (discussed in ch 6)
```

请注意，这一次我们使用了`iloc[-10:,]`，它从第 10 个最大值开始(因为`sort_values()`默认按升序排序)到最大值，我们得到了前 10 名。在这里，我们可以看到，在这段时间里，印度尼西亚的海啸比其他地方多得多:

![Figure 5.32 – Plotting the result of a group by calculation
](image/Figure_5.32_B16834.jpg)

图 5.32–通过计算绘制一组结果

看到这样的东西后，我们可能会进一步了解印度尼西亚每天发生的海啸数量。我们可以通过使用`kind='bar'`将这种随时间的演变可视化为一个线形图或一个垂直条形图。这里，我们将使用条来避免插值点:

```
>>> indonesia_quakes = quakes.query(
...     'parsed_place == "Indonesia"'
... ).assign(
...     time=lambda x: pd.to_datetime(x.time, unit='ms'),
...     earthquake=1
... ).set_index('time').resample('1D').sum()
# format the datetimes in the index for the x-axis
>>> indonesia_quakes.index = \
...     indonesia_quakes.index.strftime('%b\n%d')
>>> indonesia_quakes.plot(
...     y=['earthquake', 'tsunami'], kind='bar', rot=0, 
...     figsize=(15, 3), label=['earthquakes', 'tsunamis'], 
...     title='Earthquakes and Tsunamis in Indonesia '
...           '(September 18, 2018 - October 13, 2018)'
... )
# label the axes (discussed in chapter 6)
>>> plt.xlabel('date')
>>> plt.ylabel('count')
```

2018 年 9 月 28 日，我们可以看到印度尼西亚的地震和海啸都出现了峰值；这一天发生了 7.5 级地震，引发了毁灭性的海啸:

![Figure 5.33 – Comparing counts over time
](image/Figure_5.33_B16834.jpg)

图 5.33–比较一段时间内的计数

我们还可以通过使用`groupby()`和`unstack()`从单个列的值中创建分组条形图。这使得我们可以为列中的每个不同值生成条形。让我们用这个策略来看看伴随地震的海啸发生的频率，以百分比表示。我们可以使用`apply()`方法来处理这个问题，正如我们在第 4 章、*聚合熊猫数据帧*和`axis=1`中所学的那样(逐行应用)。为了便于说明，我们来看看伴随海啸的地震比例最高的七个地方:

```
>>> quakes.groupby(['parsed_place', 'tsunami']).mag.count()\
...     .unstack().apply(lambda x: x / x.sum(), axis=1)\
...     .rename(columns={0: 'no', 1: 'yes'})\
...     .sort_values('yes', ascending=False)[7::-1]\
...     .plot.barh(
...         title='Frequency of a tsunami accompanying '
...               'an earthquake'
...     )
# move legend to the right of the plot; label axes
>>> plt.legend(title='tsunami?', bbox_to_anchor=(1, 0.65))
>>> plt.xlabel('percentage of earthquakes')
>>> plt.ylabel('')
```

在此期间，圣诞岛发生了一次地震，但伴随着海啸。另一方面，巴布亚新几内亚大约 40%的地震都伴随着海啸:

![Figure 5.34 – Bar plot with a group by
](image/Figure_5.34_B16834.jpg)

图 5.34–带有分组依据的条形图

小费

保存前面的图时，长类别名称可能会被截断；如果是这种情况，请在保存之前尝试运行`plt.tight_layout()`。

现在，让我们用竖条来看看哪些测量地震震级的方法是最普遍使用的`kind='bar'`:

```
>>> quakes.magType.value_counts().plot(
...     kind='bar', rot=0,
...     title='Earthquakes Recorded per magType'
... )
# label the axes (discussed in ch 6)
>>> plt.xlabel('magType')
>>> plt.ylabel('earthquakes')
```

看来`ml`是目前最常用的测量地震震级的方法。这是有意义的，因为根据美国地质调查局解释我们正在使用的数据集`magType`字段的页面([https://www . USGS . gov/natural-hazards/seismic-hazards/science/magnitude-types](https://www.usgs.gov/natural-hazards/earthquake-hazards/science/magnitude-types))，这是 1935 年 Richter 和 Gutenberg 为当地地震定义的*原始震级关系:*

![Figure 5.35 – Comparing category counts
](image/Figure_5.35_B16834.jpg)

图 5.35–比较类别计数

假设我们想让看到给定震级的地震有多少次，并通过`magType`来区分它们。这向我们展示了单一情节中的几件事:

*   哪些震级在`magType`中出现频率最高。
*   每个`magType`产生的相对震级范围。
*   最常见的数值为`magType`。

为此，我们可以制作一个堆积条形图。首先，我们将所有幅度向下舍入到最接近的整数。这意味着所有地震都将被标记为小数点前的震级部分(例如，5.5 被标记为 5，就像 5.7、5.2 和 5.0 一样)。接下来，我们需要创建一个数据透视表，其中包含索引中的量值和列中的量值类型；我们将计算地震次数的值:

```
>>> pivot = quakes.assign(
...     mag_bin=lambda x: np.floor(x.mag)
... ).pivot_table(
...     index='mag_bin', 
...     columns='magType', 
...     values='mag', 
...     aggfunc='count'
... )
```

一旦我们有了数据透视表，我们就可以通过在绘图时传入`stacked=True`来创建一个堆积条形图:

```
>>> pivot.plot.bar(
...     stacked=True,
...     rot=0, 
...     title='Earthquakes by integer magnitude and magType'
... )
>>> plt.ylabel('earthquakes') # label axes (discussed in ch 6)
```

这导致了下面图中的,该图显示了大多数地震是用`ml`震级类型测量的，并且震级低于四级:

![Figure 5.36 – Stacked bar plot
](image/Figure_5.36_B16834.jpg)

图 5.36–堆积条形图

与`ml`相比，其他的条柱都相形见绌，这使得我们很难看出哪种震级类型赋予地震更高的震级。为了解决这个问题，我们可以制作一个标准化的堆积条形图。我们不会显示每个震级和`magType`组合的地震计数，而是显示给定震级的地震使用每个`magType`的百分比:

```
>>> normalized_pivot = \
...     pivot.fillna(0).apply(lambda x: x / x.sum(), axis=1)
... 
>>> ax = normalized_pivot.plot.bar(
...     stacked=True, rot=0, figsize=(10, 5),
...     title='Percentage of earthquakes by integer magnitude '
...           'for each magType'
... )
>>> ax.legend(bbox_to_anchor=(1, 0.8)) # move legend
>>> plt.ylabel('percentage') # label axes (discussed in ch 6)
```

现在，我们可以很容易地看到`mww`产生了更高的量级，而`ml`似乎分布在光谱的低端:

![Figure 5.37 – Normalized stacked bar plot
](image/Figure_5.37_B16834.jpg)

图 5.37–标准化堆积条形图

注意，我们也可以通过调用`groupby()`和`unstack()`方法来使用这种策略。让我们重新审视伴随地震绘图的海啸频率，但我们将堆叠它们，而不是使用分组柱状图:

```
>>> quakes.groupby(['parsed_place', 'tsunami']).mag.count()\
...     .unstack().apply(lambda x: x / x.sum(), axis=1)\
...     .rename(columns={0: 'no', 1: 'yes'})\
...     .sort_values('yes', ascending=False)[7::-1]\
...     .plot.barh(
...         title='Frequency of a tsunami accompanying '
...               'an earthquake',
...         stacked=True
...     )
# move legend to the right of the plot
>>> plt.legend(title='tsunami?', bbox_to_anchor=(1, 0.65))
# label the axes (discussed in chapter 6)
>>> plt.xlabel('percentage of earthquakes')
>>> plt.ylabel('')
```

这个堆积条形图让我们很容易比较不同地方的海啸频率:

![Figure 5.38 – Normalized stacked bar plot with a group by
](image/Figure_5.38_B16834.jpg)

图 5.38–带有分组依据的标准化堆积条形图

分类数据限制了我们可以使用的图表类型，但是有一些替代柱状图的方法。我们将在下一章的*利用 seaborn 进行高级绘图*一节中看到它们；现在，让我们来看看`pandas.plotting`模块。

# 熊猫.标图模块

在*用熊猫*绘制的部分，我们涵盖了`pandas`为提供了更容易实现的标准地块。然而，`pandas`也有一个模块(被恰当地命名为`plotting`)有特殊的绘图，我们可以在我们的数据上使用。请注意，由于它们是如何合成并返回给我们的，因此它们的定制选项可能会更加有限。

对于这一部分，我们将在`3-pandas_plotting_module.ipynb`笔记本中工作。像往常一样，我们将从导入和读取数据开始；我们将只使用脸书的数据:

```
>>> %matplotlib inline
>>> import matplotlib.pyplot as plt
>>> import numpy as np
>>> import pandas as pd
>>> fb = pd.read_csv(
...     'data/fb_stock_prices_2018.csv', 
...     index_col='date', 
...     parse_dates=True
... )
```

现在，让我们浏览一下`pandas.plotting`模块中的一些可用图，并了解我们如何在 EDA 中利用结果可视化。

## 散布矩阵

在本章的前面，我们讨论了使用散点图来显示变量之间的关系。通常，我们希望看到数据中变量的每个组合，这可能执行起来很繁琐。`pandas.plotting`模块包含了`scatter_matrix()`函数，这使得这变得更加容易。让我们使用来查看脸书股票价格数据中各列组合的散点图:

```
>>> from pandas.plotting import scatter_matrix
>>> scatter_matrix(fb, figsize=(10, 10))
```

这导致了下面的绘图矩阵，它通常用于机器学习，以查看哪些变量在建立模型时可能有用。我们很容易发现，开盘价、最高价、最低价和收盘价之间有很强的正相关性:

![Figure 5.39 – Pandas scatter matrix
](image/Figure_5.39_B16834.jpg)

图 5.39-熊猫散点图

默认情况下，在对角线上，即列与自身成对的地方，我们得到它的直方图。或者，我们可以通过传入`diagonal='kde'`来请求 KDE:

```
>>> scatter_matrix(fb, figsize=(10, 10), diagonal='kde')
```

这产生了一个散点图矩阵，其 kde 沿着对角线，而不是直方图:

![Figure 5.40 – Scatter matrix with KDEs
](image/Figure_5.40_B16834.jpg)

图 5.40–带 KDEs 的散点图

虽然散点图使我们很容易检查变量之间的关系，但有时，我们对**自相关**感兴趣，这意味着时间序列与其自身的滞后版本相关。一种形象化的方法是用滞后图。

## 滞后图

我们可以使用**滞后图**来检查给定时间的值与该时间之前某个周期的值之间的关系；也就是说，对于 1 个周期的滞后，我们创建一个`data[:-1]`(除最后一个条目之外的所有条目)和`data[1:]`(从第二个条目到最后一个条目)的散点图。

如果我们的数据是随机的，这个图将没有模式。让我们用 NumPy 生成的一些随机数据对此进行测试:

```
>>> from pandas.plotting import lag_plot
>>> np.random.seed(0) # make this repeatable
>>> lag_plot(pd.Series(np.random.random(size=200)))
```

随机数据点不表示任何模式，只是随机噪声:

![Figure 5.41 – Lag plot of random noise
](image/Figure_5.41_B16834.jpg)

图 5.41–随机噪声的滞后图

根据我们的股票数据，我们知道某一天的价格是由前一天发生的事情决定的；因此，我们期望在滞后图上看到一个模式。让我们用脸书股票的收盘价来检验我们的直觉是否正确:

```
>>> lag_plot(fb.close)
```

正如所料，这会导致线性模式:

![Figure 5.42 – Lag plot of Facebook stock prices
](image/Figure_5.42_B16834.jpg)

图 5.42-脸书股票价格的滞后曲线图

我们还可以指定用于延迟的周期数。默认的延迟是 1，但是我们可以用参数`lag`来改变它。例如，我们可以将每个值与前一周的`lag=5`值进行比较(记住，股票数据只包含工作日的数据，因为市场在周末关闭):

```
>>> lag_plot(fb.close, lag=5)
```

这仍然会产生很强的相关性，但是，与*图 5.42* 相比，它显然看起来更弱:

![Figure 5.43 – Customizing the number of periods for the lag plot
](image/Figure_5.43_B16834.jpg)

图 5.43–自定义滞后图的周期数

虽然滞后图有助于我们可视化自相关，但它们并没有显示我们的数据包含多少个自相关周期。为此，我们可以使用自相关图。

## 自相关图

Pandas 为我们提供了一种额外的方法，让我们通过`autocorrelation_plot()`函数来寻找数据中的自相关性，该函数通过滞后的数量来显示自相关性。随机数据将接近零的自相关。

正如我们在讨论滞后图时所做的那样，让我们先来看看用 NumPy 生成的随机数据是什么样的:

```
>>> from pandas.plotting import autocorrelation_plot
>>> np.random.seed(0) # make this repeatable
>>> autocorrelation_plot(pd.Series(np.random.random(size=200)))
```

事实上，自相关接近于零，并且该线在置信带内(99%是虚线；95%是固体):

![Figure 5.44 – Autocorrelation plot of random data
](image/Figure_5.44_B16834.jpg)

图 5.44–随机数据的自相关图

让我们探索一下脸书股票收盘价格的自相关图是什么样子的，因为滞后图显示了几个自相关期:

```
>>> autocorrelation_plot(fb.close)
```

这里，我们可以看到，在成为噪声之前，许多滞后期都存在自相关:

![Figure 5.45 – Autocorrelation plot of Facebook stock prices
](image/Figure_5.45_B16834.jpg)

图 5.45-脸书股票价格的自相关图

小费

回想一下 [*第一章*](B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015) 、*数据分析介绍*，ARIMA 模型中的一个分量是自回归分量。自相关图可用于帮助确定要使用的时滞数量。我们将在 [*第七章*](B16834_07_Final_SK_ePub.xhtml#_idTextAnchor146) 、*金融分析——比特币和股票市场*中建立一个 ARIMA 模型。

## 自举图

pandas还提供绘图功能，通过 **bootstrapping** 评估普通汇总统计的不确定性。该函数将从有问题的变量(分别为`samples`和`size`参数)中抽取指定数量的给定大小的随机样本(替换)，并计算汇总统计数据。然后，它将返回结果的可视化。

让我们看看交易量数据汇总统计的不确定性是什么样的:

```
>>> from pandas.plotting import bootstrap_plot
>>> fig = bootstrap_plot(
...     fb.volume, fig=plt.figure(figsize=(10, 6))
... )
```

这导致了下面的子图，我们可以用它来评估平均值、中间值和中间值(范围的中点)的不确定性:

![Figure 5.46 – Pandas bootstrap plot
](image/Figure_5.46_B16834.jpg)

图 5.46-熊猫引导图

这是`pandas.plotting`模块中几个函数的示例。如需完整列表，请查看[https://pandas . pydata . org/pandas-docs/stable/reference/plotting . html](https://pandas.pydata.org/pandas-docs/stable/reference/plotting.html)。

# 总结

现在我们已经完成了这一章，我们已经准备好使用`pandas`和`matplotlib`在 Python 中快速创建各种可视化。我们现在了解了`matplotlib`如何运作的基本原理和一个情节的主要组成部分。此外，我们讨论了各种绘图类型以及使用它们的情况—数据可视化的一个重要组成部分是选择合适的绘图。请务必查看*附录*中的*选择合适的可视化*部分，以备将来参考。

请注意，可视化的最佳实践不仅适用于绘图类型，也适用于绘图的格式，我们将在下一章讨论。除此之外，我们将在此基础上讨论使用`seaborn`的附加图以及如何使用`matplotlib`定制我们的图。在继续之前，请务必完成本章末尾的练习，以练习绘图，因为我们将基于本章的材料。

# 练习

利用你在本书中到目前为止所学的知识，创建以下可视化效果。使用本章`data/`目录中的数据:

1.  使用`pandas`绘制脸书收盘价的 20 天滚动最小值。
2.  创建脸书股票价格从开盘到收盘变化的直方图和 KDE。
3.  使用地震数据，为印度尼西亚使用的每个`magType`的震级创建箱线图。
4.  对脸书的周最高价和周最低价之间的差异做一个线图。这应该是一行。
5.  Plot the 14-day moving average of the daily change in new COVID-19 cases in Brazil, China, India, Italy, Spain, and the USA:

    a)首先，使用第四章 、*汇总熊猫数据帧*中*处理时间序列数据*部分介绍的`diff()`方法，计算新病例的日变化。然后，用`rolling()`计算 14 日均线。

    b)制作三个支线剧情:一个给中国；一个给西班牙和意大利；一个针对巴西、印度和美国。

6.  Using `matplotlib` and `pandas`, create two subplots side-by-side showing the effect that after-hours trading has had on Facebook's stock prices:

    a)第一个子图将包含当天的开盘价和前一天的收盘价之间的每日差价的折线图(请务必查看第 4 章[](B16834_04_Final_SK_ePub.xhtml#_idTextAnchor082)*、*聚合熊猫数据帧*的*使用时间序列数据*部分，以获得一种简单的方法)。*

    *b)第二个子图将是一个柱状图，使用`resample()`显示每月的净效果。*

    *c)奖金#1:根据股价是上涨(绿色)还是下跌(红色)来给条形标上颜色。*

    *d)奖金#2:修改条形图的*x*-轴，以显示月份的三个字母缩写。*

 *# 延伸阅读

有关本章中讨论的概念的更多信息，请查看以下资源:

*   *Bootstrapping(统计)*:[https://en . Wikipedia . org/wiki/Bootstrapping _(统计)](https://en.wikipedia.org/wiki/Bootstrapping_(statistics))
*   *数据可视化-最佳实践和基础*:[https://www . top tal . com/designers/Data-Visualization/Data-Visualization-最佳实践](https://www.toptal.com/designers/data-visualization/data-visualization-best-practices)
*   *如何用 Python 创建动画图形(用 matplotlib)*:[https://towardsdatascience . com/How-to-Create-Animated-Graphs-in-Python-bb 619 cc 2 dec 1](https://towardsdatascience.com/how-to-create-animated-graphs-in-python-bb619cc2dec1)
*   *用 JavaScript (D3.js)交互剧情*:【https://d3js.org/ 
*   *Python 中的动画介绍(带 plotly)*:【https://plot.ly/python/animations/ 
*   *IPython:内置魔法命令*:[https://IPython . readthe docs . io/en/stable/interactive/magics . html](https://ipython.readthedocs.io/en/stable/interactive/magics.html)
*   *完整性的重要性:情节参数如何影响解释*:[https://www . t4g . com/insights/Plot-Parameters-Influence-Interpretation/](https://www.t4g.com/insights/plot-parameters-influence-interpretation/)
*   *5 个用于创建互动情节的 Python 库*:【https://mode.com/blog/python-interactive-plot-libraries/ *