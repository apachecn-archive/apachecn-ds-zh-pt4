<title>Chapter 10. How to Tell If Your Toaster Is Learning – Machine Learning Essentials</title>   <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 第十章。如何判断你的烤面包机是否在学习——机器学习基础

机器学习已经成为近十年的热门话题。似乎每次我们听到下一个最伟大的创业公司或打开新闻，我们都会听到一些关于机器学习技术的革命性进展，以及它将如何改变我们的生活方式。

这一章重点介绍机器学习作为数据科学的一个实用部分。我们将在本章中讨论以下主题:

*   定义不同类型的机器学习，以及每种类型的示例
*   回归、分类等领域
*   什么是机器学习，它如何用于数据科学
*   机器学习和统计建模之间的区别，以及机器学习是后者的一个更广泛的类别

我们的目标是利用统计学、概率和算法思维来理解和应用基本的机器学习技能到实际行业，比如市场营销。示例包括预测餐馆评论的星级、预测疾病的存在、垃圾邮件检测等等。这一章更侧重于机器学习作为一个整体和单一的统计模型。随后的章节将涉及更多的模型，其中一些更为复杂。

我们还将把我们的注意力转向度量，度量告诉我们我们的模型有多有效。我们将使用度量标准来总结结果，并使用机器学习进行预测。

# 什么是机器学习？

没有什么是机器学习的具体定义，继续下去是没有意义的。好吧，让我们先回顾一下。在第一章、*如何听起来像数据科学家*中，我们将机器学习定义为赋予计算机从数据中学习的能力，而无需程序员给出明确的*规则*。这个定义仍然适用。机器学习涉及从数据中确定某些模式(信号)的能力，即使数据中存在固有错误(噪声)。

机器学习模型能够在没有人类明确帮助的情况下从数据中学习。这就是机器学习模型和*经典算法*的主要区别。经典算法被告知如何在复杂系统中找到最佳答案，然后算法搜索这些最佳解决方案，并且通常比人工作得更快更有效。然而，这里的瓶颈是人类必须首先想出*最佳解决方案*。在机器学习中，模型不会被告知最佳解决方案，相反，模型会被给出几个问题的例子，并被告知，*找出最佳解决方案*。

机器学习只是数据科学家工具带中的另一个工具。它与统计检验(卡方检验或 t 检验)处于同一水平，或者使用基本概率/统计来估计总体参数。机器学习通常被认为是数据科学家唯一知道如何做的事情，这根本不是事实。真正的数据科学家能够识别机器学习何时适用，更重要的是，何时不适用。

机器学习是一个关联和关系的游戏。现有的大多数机器学习算法都与发现和/或利用数据集(通常表示为 Pandas 数据帧中的列)之间的关系有关。一旦机器学习算法可以确定某些相关性，该模型就可以使用这些关系来预测未来的观察结果，或者概括数据以揭示有趣的模式。

也许解释机器学习的一个很好的方法是提供一个问题的例子，并结合两种可能的解决方案:一种使用机器学习算法，另一种使用非机器学习算法。

**示例–面部识别**

这个问题被很好地记录了下来。给定一张脸的图片，它属于谁的脸？然而，我认为，在此之前，还有一个更重要的问题必须提出。假设您希望实现一个家庭安全系统，它可以识别谁正在进入您的房子。最有可能的是，在白天，你的房子大部分时间都是空的，只有当照片中有一个人时，面部识别才能发挥作用。这正是我提议我们尝试解决的问题——给定一张照片，照片里有一张脸吗？

针对这个问题，我提出以下两种解决方案:

*   非机器学习算法将*定义*一张脸具有圆形结构、两只眼睛、头发、鼻子等等。该算法然后在照片中寻找这些*硬编码的*特征，并返回它是否能够找到这些特征中的任何一个。
*   机器学习算法的工作方式会有所不同。该模型将仅被给定几张被如此标记的人脸和非人脸的照片。从这些样本(称为训练集)中，它会找出自己对人脸的定义。

该解决方案的机器学习版本从未被告知什么是脸，它只是给出了几个例子，一些有脸，一些没有。然后由机器学习模型来找出两者之间的差异。一旦它找出两者之间的差异，它就利用这些信息来获取一张照片，并*预测*新照片中是否有人脸。例如，为了训练模型，我们将给它以下三幅图像:

![What is machine learning?](graphics/B05260_10_1.jpg)

然后，该模型将计算出标记为**人脸**的图片和标记为**无人脸**的图片之间的差异，并能够使用该差异在未来的照片中找到人脸。

<title>Machine learning isn't perfect</title>   <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 机器学习并不完美

机器学习有许多警告。许多特定于正在实现的不同模型，但有一些假设对于任何机器学习模型都是通用的，如下所示:

*   The data used is, for the most part, is preprocessed and cleaned using the methods outlined in the earlier chapters.

    几乎没有机器学习模型会容忍带有缺失值或分类值的脏数据。使用虚拟变量和填充/丢弃技术来处理这些差异。

*   已清理数据集的每一行都代表我们试图建模的环境的单个观察。
*   If our goal is to find relationships between variables, then there is an assumption that there is some kind of relationship between these variables.

    这个假设特别重要。许多机器学习模型非常重视这一假设。这些模型不能够传达可能不存在关系。

*   Machine learning models are generally considered semiautomatic, which means that intelligent decisions by humans are still needed.

    这台机器很聪明，但是很难把事情联系起来。大多数模型的输出是一系列试图量化模型表现的数字和指标。这取决于一个人如何正确看待这些指标，并将结果传达给观众

*   Most machine learning models are sensitive to noisy data.

    这意味着当你包含没有意义的数据时，模型会变得混乱。例如，如果您试图查找世界各地的经济数据之间的关系，而您的列之一是首都的小狗收养率，则该信息很可能不相关，并将混淆模型。

这些假设在处理机器学习的时候会反复出现。它们都太重要了，常常被数据科学家新手忽略。

<title>How does machine learning work?</title>   <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 机器学习是如何工作的？

每种类型的机器学习和每个单独的模型都以非常不同的方式工作，利用了数学和数据科学的不同部分。但是，一般来说，机器学习的工作方式是接收数据，查找数据中的关系，然后将模型学习到的内容作为输出，如下图所示:

![How does machine learning work?](graphics/B05260_10_2.jpg)

机器学习模型综述

当我们探索不同类型的机器学习模型时，我们将看到它们如何以不同的方式操作数据，并为不同的应用程序提供不同的输出。

<title>Types of machine learning</title>   <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 机器学习的类型

有许多方法可以细分机器学习并深入研究。在第一章、*如何听起来像数据科学家*中，我提到了统计和概率模型。这些模型利用了我们在前面章节中看到的统计和概率，以便找到数据之间的关系并做出预测。在本章中，我们将实现这两种类型的模型。在接下来的章节中，我们将会看到统计/概率这一僵化的数学世界之外的机器学习。人们可以通过不同的特征来分割机器学习模型，包括:

*   他们使用的数据类型/有机结构(树/图/神经网络)
*   他们最相关的数学领域(统计/概率)
*   训练所需的计算水平(深度学习)

出于教育的目的，我将提供我自己对机器学习模型的分类。机器学习的顶级分支有以下三个子集:

*   监督学习
*   无监督学习
*   强化学习

## 监督学习

简而言之，监督学习寻找数据集的特征和目标变量之间的关联。例如，监督学习模型可能会试图找到一个人的健康特征(心率、肥胖水平等)与该人心脏病发作风险(目标变量)之间的关联。

这些关联允许监督模型基于过去的例子进行预测。当人们听到“机器学习”这个词时，这通常是他们想到的第一件事，但它绝不包含机器学习的领域。监督机器学习模型通常被称为 **预测分析模型**，因其基于过去预测未来的能力而得名。

监督机器学习需要某种类型的数据，称为 **标记数据**。这意味着，我们必须通过给出标有正确答案的历史例子来教授我们的模型。回想一下面部识别的例子。这是一个监督学习模型，因为我们正在训练我们的模型，之前的图片被标记为*人脸*或*非人脸*，然后要求模型*预测*新图片中是否有人脸。

具体来说，监督学习使用部分数据来预测另一部分。首先，我们必须将数据分成两部分，如下所示:

*   The predictors, which are the columns that will be used to make our prediction.

    这些有时被称为特征、输入、变量和独立变量。

*   The response, which is the column that we wish to predict.

    这有时被称为结果、标签、目标和因变量。

监督学习试图找到预测者和响应之间的关系，以便做出预测。这个想法是，在未来，一个数据观察将会出现，我们将只知道预测。然后，模型将不得不使用预测值来准确预测响应值。

**示例–心脏病发作预测**

假设我们希望预测某人是否会在一年内心脏病发作。为了预测这一点，我们知道了那个人的胆固醇、血压、身高、吸烟习惯，或许还有更多。根据这些数据，我们必须确定心脏病发作的可能性。假设，为了做出这个预测，我们查看以前的病人和他们的病史。由于这些是以前的病人，我们不仅知道他们的预测指标(胆固醇、血压等等)，而且还知道他们是否真的有心脏病发作(因为已经发生了！).

这是一个有监督的机器学习问题，因为我们:

*   对某人进行预测
*   使用历史训练数据发现医学变量和心脏病发作之间的关系![Supervised learning](graphics/B05260_10_3.jpg)

    监督模型概述

这里的希望是，一个病人明天走进来，我们的模型将能够根据她/他的情况来识别病人是否有心脏病发作的风险(就像医生会做的那样！).

随着模型看到越来越多的标签数据，它会自我调整，以匹配给我们的正确标签。我们可以使用不同的指标(在本章后面解释)来准确地指出我们的监督机器学习模型做得有多好，以及它如何更好地自我调整。

有监督的机器学习的最大缺点之一是，我们需要这些标记的数据，这些数据可能很难获得。假设我们希望预测心脏病发作，我们可能需要成千上万的患者以及他们填写的所有医疗信息和每个人多年的随访记录，这可能是一场噩梦。

简而言之，监督模型使用历史标记数据来预测未来。监督学习的一些可能应用包括:

*   股票价格预测
*   天气预测
*   犯罪预测

请注意前面的每个例子是如何使用单词**预测**的，这可以看出我是如何强调监督学习对未来做出预测的能力的。然而，预测并不是故事的终点。

以下是监督模型如何使用标记数据来*拟合*自己并准备自己进行预测的可视化:

![Supervised learning](graphics/B05260_10_4.jpg)

注意监督模型是如何从一堆训练数据中学习的，然后，当它准备好了，它会查看看不见的案例并输出预测。

### 不仅仅是关于预测

监督学习利用预测者和响应之间的关系来进行预测，但有时，仅仅知道存在某种关系就足够了。假设我们正在使用监督机器学习模型来预测客户是否会购买给定的商品。一个可能的数据集可能如下所示:

| 

人员 ID

 | 

年龄

 | 

性别

 | 

就业？

 | 

购买了产品？

 |
| --- | --- | --- | --- | --- |
| one | Sixty-three | F | 普通 | Y |
| Two | Twenty-four | M | Y | 普通 |

请注意，在这种情况下，我们的预测因素是年龄、性别和职业，而我们的反应是购买产品？这是因为我们想看看，如果给定某人的年龄、性别和就业状况，他们是否会购买该产品。

假设一个模型是根据这些数据训练出来的，可以对某人是否会买东西做出准确的预测。这本身就很令人兴奋，但还有更令人兴奋的事情。我们能够做出准确预测的事实意味着这些变量之间存在联系，这意味着要知道某人是否会购买你的产品，你只需要知道他们的年龄、性别和就业状况！这可能与之前的市场研究相矛盾，之前的市场研究表明，要做出这样的预测，必须对潜在客户有更多的了解。

这说明了监督机器学习的能力*能够理解哪些预测因素影响反应以及如何影响*。例如，女性是否更有可能购买该产品，哪个年龄组更容易拒绝该产品，是否有年龄和性别的组合比任何一个单独的列都更好的预测？随着某人年龄的增长，他们购买该产品的机会是上升、下降还是保持不变？

也有可能所有的列都不是必需的。机器学习的可能输出可能表明，只有某些列是进行预测所必需的，而其他列只是噪声(它们与响应不相关，因此混淆了模型)。

### 监督学习的类型

一般来说，有两种类型的监督学习模型:**回归**和**分类**。两者的区别很简单，在于响应变量。

#### 回归

回归模型试图预测一个连续的反应。这意味着响应可以取一个无限值的范围。考虑下面的例子:

*   美元金额

    *   工资
    *   预算

*   温度
*   时间

    *   一般以秒或分钟记录

#### 分类

**分类**试图预测分类反应，这意味着反应只有有限数量的选择。例子包括以下给出的例子:

*   癌症等级(1、2、3、4、5)
*   是非题，比如下面的例子:

    *   “这个人一年内会不会心脏病发作？”
    *   “你会得到这份工作吗？”

*   给定一张脸的照片，这张脸是谁的？(面部识别)
*   预测某人出生年份:

    *   注意有很多可能的答案(超过 100 个)但还是有限多了

**示例–回归**

下图显示了三个分类变量(年龄、出生年份和教育水平)与个人工资之间的关系:

![Classification](graphics/B05260_10_5.jpg)

来源:[https://lag unita . Stanford . edu/c4x/humanitisescience/StatLearning/asset/introduction . pdf](https://lagunita.stanford.edu/c4x/HumanitiesScience/StatLearning/asset/introduction.pdf)

注意，即使每个预测值都是分类的，这个例子也是回归的，因为 *y* 轴，我们的因变量，我们的响应，是连续的。

我们之前的心脏病例子是分类，因为答案是*这个人会在一年内心脏病发作吗？*，它只有两种可能的答案:*是*或者*否*。

### 旁观者眼中的数据

有时，决定是否应该使用分类或回归可能很棘手。考虑到我们对外面的天气感兴趣。我们可以问这样一个问题，外面有多热？，在这种情况下你的答案是在一个连续的尺度上，一些可能的答案是 60.7 度，或者 98 度。然而，作为一个练习，去问 10 个人外面的温度是多少。我向你保证，有人(如果不是大多数人)不会在某种程度上回答，但会说出他们的答案，说一些像 60 年代的*。*

*我们可能希望将这个问题视为一个分类问题，其中响应变量不再是精确的度数，而是在一个桶中。理论上只有有限数量的桶，这使得模型可能更好地了解 60 年代和 70 年代之间的差异。*

## *无监督学习*

*第二种类型的机器学习不处理预测，但有一个更加开放的目标。无监督学习接受一组预测器，并利用预测器之间的关系来完成任务，例如:*

*   *Reducing the dimension of the data by condensing variables together.

    文件压缩就是一个例子。压缩的工作原理是利用数据中的模式，并以较小的格式表示数据。* 
*   *找到行为相似的观察组并将它们分组在一起。*

*这个列表中的第一个元素叫做**降维** ，第二个叫做 **聚类**。这两者都是无监督学习的例子，因为它们不试图发现预测器和特定响应之间的关系，因此不用于进行任何类型的预测。取而代之的是，无监督模型被用来寻找以前未知的数据的组织和表示。*

*![Unsupervised learning](graphics/B05260_10_6.jpg)*

*前面的屏幕截图展示了一个聚类分析。该模型将认识到每个独特颜色的观察值聚类与另一个相似，但与其他聚类不同。*

*无监督学习的一大优势是不需要标记数据，这意味着更容易获得符合无监督学习模型的数据。当然，这样做的一个缺点是，我们失去了所有的预测能力，因为响应变量包含了做出预测的信息，没有它，我们的模型将无法做出任何类型的预测。*

*一个很大的缺点是很难看到我们做得有多好。在回归或分类问题中，我们可以通过将模型的答案与实际答案进行比较，轻松判断模型的预测效果。例如，如果我们的监督模型预测下雨，而外面是晴天，那么这个模型就是不正确的。如果我们的监督模型预测价格将上涨 1 美元，它将上涨 99 美分，我们的模型非常接近！在监督建模中，这个概念是外来的，因为我们没有答案来比较我们的模型。无监督的模型仅仅是暗示差异和相似性，这就需要人类的解释。*

*![Unsupervised learning](graphics/B05260_10_7.jpg)

无监督模型综述* 

*简而言之，无监督模型的主要目标是发现数据观测值之间的相似性和差异。我们将在后面的章节中深入讨论无监督模型。*

### *强化学习*

*在强化学习中，算法到达*在环境中选择*一个动作，然后因为选择这个动作而得到奖励(正面或负面)。然后，算法会自我调整并修改其策略，以完成某个目标，通常是为了获得更多奖励。*

*这种类型的机器学习在人工智能辅助的游戏中非常受欢迎，因为*代理人*(人工智能)被允许探索虚拟世界并收集奖励和学习最佳导航技术。这种模式在机器人领域也很流行，尤其是在包括汽车在内的自动机械领域:*

*![Reinforcement learning](graphics/B05260_10_8.jpg)

无人驾驶汽车读取传感器输入，采取相应行动，然后因采取某种行动而获得奖励。汽车然后调整它的行为以收集更多的奖励。

图片来源:[https://www.quora.com/How-do-Googles-self-driving-cars-work](https://www.quora.com/How-do-Googles-self-driving-cars-work)* 

*可以认为，强化类似于监督学习，因为代理人正在从其过去的行动中学习，以便在未来采取更好的行动；然而，主要的区别在于报酬。奖励不必以任何方式与“正确”或“不正确”的决策挂钩。奖励只是鼓励(或阻止)不同的行为。*

*强化学习是三种类型的机器学习中探索最少的，因此在本文中没有详细探讨。本章的其余部分将集中在监督和非监督学习。*

### *机器学习类型概述*

*在三种类型的机器学习中——有监督的、无监督的和强化学习——我们可以把机器学习的世界想象成这样:*

*![Overview of the types of machine learning](graphics/B05260_10_9.jpg)*

*三种类型的机器学习各有其优点和缺点，如下所示:*

*   ***Supervised machine learning**: This exploits relationships between predictors and response variables to make predictions of future data observations.

    优点:

    *   它可以预测未来
    *   它可以量化预测和反应变量之间的关系
    *   它可以向我们展示变量之间是如何相互影响的，以及影响有多大

    缺点:

    *   它需要标记的数据(这可能很难获得)* 
*   ***Unsupervised machine learning**: This finds similarities and differences between data points.

    优点:

    *   它可以找到人类永远不会注意到的行为相似的数据点组
    *   It can be a preprocessing step for supervised learning

        想象一下对一堆数据点进行聚类，然后使用这些聚类作为响应！

    *   它可以使用更容易找到的未标记数据

    缺点:

    *   它的预测能力为零
    *   很难确定我们是否在正确的轨道上
    *   它更依赖于人类的解释* 
*   ***Reinforcement learning**: This is reward-based learning that encourages agents to take particular actions in their environments.

    优点:

    *   非常复杂的奖励系统创造了非常复杂的人工智能系统
    *   它可以在几乎任何环境中学习，包括我们自己的地球

    缺点:

    *   The agent is erratic at first and makes many terrible choices before realizing that these choices have negative rewards

        例如，一辆汽车可能会撞上一堵墙，直到环境对它产生负面影响，它才知道这是不对的

    *   在代理完全避免决策之前，可能需要一段时间
    *   代理人可能会谨慎行事，只选择一个动作，并且因为害怕被惩罚而“太害怕”而不敢尝试其他动作* 

*<title>How does statistical modeling fit into all of this?</title>   <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 统计建模如何适应这一切？

到目前为止，我一直使用机器学习这个术语，但是你可能会问统计建模在所有这些中是如何发挥作用的。

这在数据科学领域仍然是一个有争议的话题。我认为统计建模是机器学习模型的另一个术语，它严重依赖于使用从概率和统计中借来的数学规则来创建数据变量之间的关系(通常在预测意义上)。

本章的剩余部分将主要集中在一个统计/概率模型——线性回归。

<title>Linear regression</title>   <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 线性回归

终于！我们将探索我们第一个真正的机器学习模型。线性回归是回归的一种形式，这意味着它是一个机器学习模型，试图找到预测因素和响应变量之间的关系，而响应变量是，你猜对了，连续的！这个概念等同于制作最适合的的*线。*

在线性回归的情况下，我们将试图找到预测值和响应变量之间的线性关系。形式上，我们希望求解以下格式的公式:

![Linear regression](graphics/B05260_010_f1.jpg)

*   y 是我们的响应变量
*   *x[I]是我们的第 I 个变量( *i ^第列或 *i ^第列预测值)***
*   *B[0]是拦截*
*   *B[I]是 xi 项的系数*

在深入之前，我们先来看一些数据。该数据集是公开可用的，并试图预测某一天自行车共享计划所需的自行车数量:

```
# read the data and set the datetime as the index
# taken from Kaggle: https://www.kaggle.com/c/bike-sharing-demand/data
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
url = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/bikeshare.csv'
bikes = pd.read_csv(url)

bikes.head()
```

![Linear regression](graphics/B05260_10_10.jpg)

我们可以看到每一行代表自行车使用的一个小时。在这种情况下，我们感兴趣的是预测`count`，它表示在那一小时内租赁的自行车总数。

![Linear regression](graphics/B05260_10_11.jpg)

例如，让我们看看温度(`temp`列)和计数之间的散点图，如下所示:

```
bikes.plot(kind='scatter', x='temp', y='count', alpha=0.2)
```

现在，让我们使用一个名为`seaborn`的模块，给自己画一条最佳拟合线，如下所示:

```
import seaborn as sns #using seaborn to get a line of best fit
sns.lmplot(x='temp', y='count', data=bikes, aspect=1.5, scatter_kws={'alpha':0.2})
```

![Linear regression](graphics/B05260_10_12.jpg)

图中的这条线试图让形象化并量化`temp`和`count`之间的关系。为了进行预测，我们只需找到一个给定的温度，然后看看这条线在哪里可以预测计数。例如，如果温度是 20 摄氏度(请注意)，那么我们的生产线将预测大约 200 辆自行车将被租赁。如果气温在 40 度以上，那么就需要 400 多辆自行车！

看来随着`temp`上升，我们的`count`也上升。让我们看看量化变量之间线性关系的相关值是否也符合这个概念:

```
bikes[['count', 'temp']].corr()
# 0.3944
```

这两个变量之间存在(弱)正相关关系！现在，让我们回到线性回归的形式:

![Linear regression](graphics/B05260_010_f1.jpg)

我们的模型将试图在前面图形中的所有点之间画一条完美的线，但是当然，我们可以清楚地看到这些点之间没有完美的线！然后，模型将找到可能的最适合的*线*。怎么会？我们可以在数据点之间画无限多条线，但是什么是最好的线呢？

请考虑下图:

![Linear regression](graphics/B05260_10_13.jpg)

在我们的模型中，我们被给定了 *x* 和 *y* ，模型*学习*β系数，也被称为 **模型系数**:

*   黑点是 *x* 和 *y* 的观测值。
*   蓝线是我们最适合的线。
*   点和线之间的红线称为残差；它们是观察值和直线之间的距离。他们知道这条线有多错。

每个数据点都有一个残差，即到最佳拟合线的距离。**残差平方和** 是每个残差平方的总和。最佳拟合线具有最小的残差平方和。让我们用 Python 来构建这一行，好吗？

```
# create X and y
feature_cols = ['temp'] # a lsit of the predictors
X = bikes[feature_cols] # subsetting our data to only the predictors
y = bikes['count'] # our response variable
```

请注意我们是如何创建一个`X`和一个`y`变量的。这些代表了我们的预测和反应变量。

然后，我们将导入我们的机器学习模块`scikit learn`，如下所示:

```
# import scikit-learn, our machine learning module
from sklearn.linear_model import LinearRegression
```

最后，我们将使我们的模型适合预测值和响应变量，如下所示:

```
linreg = LinearRegression() #instantiate a new model
linreg.fit(X, y) #fit the model to our data

# print the coefficients
print linreg.intercept_
print linreg.coef_
6.04621295962  # our Beta_0
[ 9.17054048]     # our beta parameters
```

解释为:

*   *B[0] (6.04)* is the value of `y` when `X = 0`.

    这是对气温为 0 摄氏度时自行车出租量的估计。

    所以，在 0 度，预测有六辆自行车在用(天冷！).

有时，解释截距可能毫无意义，因为可能没有零的概念。回想一下数据的层次。不是所有的层次都有这种观念。温度存在于一个固有概念的水平上*没有自行车*；所以，我们是安全的。但是在未来要小心，要经常问自己，没有这些东西有意义吗:

*   *B [1] (9.17)* 是我们的温度系数。

    *   就是 y 的变化除以 *x 的变化 [1]* 。
    *   表示 *x* 和 *y* 如何一起移动。
    *   1 摄氏度的变化，与约 9 辆自行车租赁量的增加相关。
    *   这个系数的符号很重要。如果是负的，这将意味着气温上升与租金下降有关。

![Linear regression](graphics/B05260_10_14.jpg)

考虑线性回归中β系数的前述表示:

重要的是要重申，这些都是相关性的陈述，而不是因果关系的陈述。我们无法说明租金上涨是否是由气温变化引起的，只是似乎有一起运动。

使用 scikit-learn 进行预测很容易！

```
linreg.predict(20)
# 189.4570
```

这意味着，如果气温是 20 度，190 辆自行车可能会被租走。

## 添加更多预测值

向模型中添加更多的预测值就像在 scikit 中告诉线性回归模型一样简单——了解它们！

在此之前，我们应该查看提供给我们的数据字典，以便更好地理解这些预测因素:

*   1 =春天，2 =夏天，3 =秋天，4 =冬天
*   `holiday`:这一天是否被认为是假日
*   当天是周末还是假日
*   `weather` :

    1.  `Clear`，`Few clouds`，`Partly cloudy`
    2.  `Mist + Cloudy`，`Mist + Broken clouds`，`Mist + Few clouds`，`Mist`
    3.  `Light Snow`，`Light Rain + Thunderstorm + Scattered clouds`，`Light Rain + Scattered clouds`
    4.  `Heavy Rain`+`Ice Pallets`+`Thunderstorm`+`Mist`，`Snow + Fog`

*   `temp`:摄氏温度
*   感觉像摄氏温度
*   `humidity`:相对湿度
*   `windspeed`:风速
*   `casual`:发起次非注册用户租赁的次数
*   `registered`:注册用户发起租用的次数
*   `count`:总租金数

现在让我们实际创建我们的线性回归模型。与之前一样，我们将首先创建一个包含我们希望查看的要素的列表，创建我们的要素和我们的响应数据集(X 和 y ),然后拟合我们的线性回归。拟合回归模型后，我们将查看模型的系数，以了解我们的特征如何与我们的反应相互作用:

```
# create a list of features
feature_cols = ['temp', 'season', 'weather', 'humidity']
# create X and y
X = bikes[feature_cols]
y = bikes['count']

# instantiate and fit
linreg = LinearRegression()
linreg.fit(X, y)

# pair the feature names with the coefficients
zip(feature_cols, linreg.coef_)
```

这给了我们:

```
[('temp', 7.8648249924774403),
 ('season', 22.538757532466754),
 ('weather', 6.6703020359238048),
 ('humidity', -3.1188733823964974)]
```

含义:

*   在所有其他预测因素保持不变的情况下，气温每升高 1 单位，租赁量就会增加 7.86 辆自行车
*   在所有其他预测因素保持不变的情况下，当季每增加 1 个单位，租赁量就会增加 22.5 辆自行车
*   在所有其他预测因素不变的情况下，天气每增加 1 个单位，自行车租赁量就会增加 6.67 辆
*   在所有其他预测因素不变的情况下，湿度每增加 1 个单位，租赁量就会减少 3.12 辆自行车

这很有意思。请注意，随着`weather`上升(意味着天气越来越接近阴天)，自行车需求也在上升，季节变量增加也是如此(意味着我们正在接近冬天)。这完全不是我所期待的！

让我们来看看每个预测值和响应之间的散点图，如图所示:

```
feature_cols = ['temp', 'season', 'weather', 'humidity']
# multiple scatter plots
sns.pairplot(bikes, x_vars=feature_cols, y_vars='count', kind='reg')
```

![Adding more predictors](graphics/B05260_10_15.jpg)

注意天气线是如何向下发展的，这与上一个线性模型的建议相反。现在，我们不得不担心这些预测器中哪些是真正帮助我们做出预测的，哪些只是噪音。为此，我们需要一些更高级的指标。

## 回归指标

使用回归机器学习模型时有三个主要指标。它们如下:

*   平均绝对误差
*   均方差
*   均方根误差

每个指标都试图通过比较一系列预测和一系列正确答案来描述和量化回归模型的有效性。提到的每个指标都与其他指标略有不同，讲述了不同的故事。

![Regression metrics](graphics/B05260_10_16.jpg)

其中:

*   *n* 是观察次数
*   *y[I]是实际值*
*   ![Regression metrics](graphics/B05260_010_f4.jpg)是预测值

让我们来看看 Python 中的:

```
# example true and predicted response values
true = [9, 6, 7, 6]
pred = [8, 7, 7, 12]
# note that each value in the last represents a single prediction for a model
# So we are comparing four predictions to four actual answers

# calculate these metrics by hand!
from sklearn import metrics
import numpy as np
print 'MAE:', metrics.mean_absolute_error(true, pred)
print 'MSE:', metrics.mean_squared_error(true, pred)
print 'RMSE:', np.sqrt(metrics.mean_squared_error(true, pred))

MAE: 2.0 
MSE: 9.5 
RMSE: 3.08220700148
```

这些数字细分如下:

*   **MAE** 可能是最容易理解的，因为它只是平均误差。平均而言，它表明了模型的错误程度。
*   MSE 比 MAE 更有效，因为 MSE 惩罚更大的错误，这在现实世界中更有用。
*   RMSE 甚至比 MSE 更受欢迎，因为它的可解释性更强。

RMSE 通常是回归的首选指标，但无论你选择哪一个，它们都是损失函数，因此是需要最小化的。让我们使用 RMSE 来确定哪些列是有益的，哪些是有害的。

让我们从只使用温度开始。请注意，我们的过程如下:

1.  创建我们的`X`和`y`变量。
2.  拟合线性回归模型。
3.  使用模型根据`X`制作预测列表。
4.  计算预测值和实际值之间的 RMSE。

让我们看一下代码:

```
from sklearn import metrics
# import metrics from scikit learn

feature_cols = ['temp']
# create X and y
X = bikes[feature_cols]
linreg = LinearRegression()
linreg.fit(X, y)
y_pred = linreg.predict(X)
np.sqrt(metrics.mean_squared_error(y, y_pred)) # RMSE
# Can be interpreted loosely as an average error
#166.45
```

现在，让我们用温度和湿度来试试，如图所示:

```
feature_cols = ['temp', 'humidity']
# create X and y
X = bikes[feature_cols]
linreg = LinearRegression()
linreg.fit(X, y)
y_pred = linreg.predict(X)
np.sqrt(metrics.mean_squared_error(y, y_pred)) # RMSE
# 157.79
```

变好了！！让我们尝试使用更多的预测器，如图所示:

```
feature_cols = ['temp', 'humidity', 'season', 'holiday', 'workingday', 'windspeed', 'atemp']
# create X and y
X = bikes[feature_cols]
linreg = LinearRegression()
linreg.fit(X, y)
y_pred = linreg.predict(X)
np.sqrt(metrics.mean_squared_error(y, y_pred)) # RMSE
# 155.75
```

甚至更好！乍一看，这似乎是一个重大的胜利，但实际上这里有一个隐患。注意，我们正在训练这条线以适应`X`和`y`，然后，要求它再次预测`X`！这实际上是机器学习中的一个巨大错误，因为它会导致 **过拟合**，这意味着我们的模型仅仅是*记忆*数据并将其反馈给我们。

想象一下，你是一名学生，你走进第一天的课堂，老师说这门课期末考试很难。为了让你做好准备，她给你一次又一次的练习测试。期末考试的日子到了，你震惊地发现考试的每道题都和模拟考试中的一模一样！幸运的是，你做了这么多遍，你记住了答案，考试得了 100 分。

差不多同样的事情也适用于这里。通过对相同的数据进行拟合和预测，模型正在记忆数据并变得更好。解决这种过度拟合问题的一个很好的方法是使用训练/测试方法来拟合机器学习模型，其工作方式如下所示:

![Regression metrics](graphics/B05260_10_17.jpg)

基本上，我们将采取以下步骤:

1.  将数据集分成两部分:训练集和测试集。
2.  在训练集上拟合我们的模型，然后在测试集上测试它。就像在学校一样，老师会根据一套笔记来教，然后用不同的(但相似的)问题来测试我们。
3.  一旦我们的模型足够好(基于我们的度量)，我们就将模型的注意力转向整个数据集。
4.  我们的模型等待着任何人都未曾见过的新数据。

这里的目标是最小化我们的模型的样本外误差，即我们的模型在它以前从未见过的数据上的误差。这很重要，因为监督模型的主要思想(通常)是预测看不见的测试用例。如果我们的模型不能从我们的训练数据中进行归纳，并使用它来预测看不见的情况，那么我们的模型就不是很好。

上图概述了一种简单的方法，可以确保我们的模型能够有效地获取训练数据，并使用它来预测模型本身从未见过的数据点。当然，作为数据科学家，我们知道测试集也有答案，但模型不知道这一点。

所有这些听起来可能很复杂，但幸运的是，scikit-learn 有一个内置的方法来实现这一点，如下所示:

```
from sklearn.cross_validation import train_test_split
# function that splits data into training and testing sets

feature_cols = ['temp']
X = bikes[feature_cols]
y = bikes['count']
# setting our overall data X, and y
# Note that in this example, we are attempting to find an association between the temperature of the day and the number of bike rentals.

X_train, X_test, y_train, y_test = train_test_split(X, y) # split the data into training and testing sets
# X_train and y_train will be used to train the model
# X_test and y_test will be used to test the model
# Remember that all four of these variables are just subsets of the overall X and y.

linreg = LinearRegression()
# instantiate the model

linreg.fit(X_train, y_train)
# fit the model to our training set

y_pred = linreg.predict(X_test)
# predict our testing set

np.sqrt(metrics.mean_squared_error(y_test, y_pred)) # RMSE
# Calculate our metric: 166.91
```

我们将在[第 12 章](ch12.html "Chapter 12. Beyond the Essentials")、*中花更多时间讨论这种训练/测试分割背后的推理，并研究一种更有帮助的方法，但我们必须完成这项额外工作的主要原因是，我们不想落入一个陷阱，在这个陷阱中，我们的模型只是将我们的数据集回流给我们，而无法处理看不见的数据点。*

换句话说，我们的训练测试分割确保了我们看到的指标是对样本性能的更真实的估计。

现在，让我们用更多的预测值再试一次，如下所示:

```
feature_cols = ['temp', 'workingday']
X = bikes[feature_cols]
y = bikes['count']

X_train, X_test, y_train, y_test = train_test_split(X, y)
# Pick a new random training and test set

linreg = LinearRegression()
linreg.fit(X_train, y_train)
y_pred = linreg.predict(X_test)
# fit and predict

np.sqrt(metrics.mean_squared_error(y_test, y_pred))
# 166.95
```

现在我们的模型实际上变得更糟了！这意味着`workingday`可能不能很好地预测我们的反应，自行车租赁计数。

现在，所有这些都很好，但是我们的模型在预测方面做得有多好呢？我们有大约 167 辆自行车的均方根误差，但是那是好的吗？发现这一点的一个方法是评估 **空模型**。

监督机器学习中的零模型代表着有效地一遍又一遍地猜测预期的结果，并看看你做得如何。例如，在回归分析中，如果我们只猜测每小时自行车租赁的平均数量，那么这个模型会做得怎么样呢？

首先，让我们得到平均每小时的自行车租金，如图所示:

```
average_bike_rental = bikes['count'].mean()
average_bike_rental
# 191.57
```

这意味着，总体而言，在这个数据集中，无论天气、时间、星期几、湿度和其他因素如何，平均每小时外出的自行车数量约为 192 辆。

我们来做一个*假*预测单，其中每一个单项猜测都是 191.57。让我们每隔一个小时进行一次猜测，如下所示:

```
num_rows = bikes.shape[0]
num_rows
# 10886
All 10,886 of them.
null_model_predictions = [average_bike_rental]*num_rows
null_model_predictions
[191.57413191254824,
 191.57413191254824,
 191.57413191254824,
 191.57413191254824,
…
 191.57413191254824,
 191.57413191254824,
 191.57413191254824,
 191.57413191254824]
```

所以，现在我们有 10，886 个值，它们都是平均每小时自行车租赁数。现在，让我们看看，如果我们的模型只是猜测平均每小时自行车租赁次数的期望值，那么均方根误差是多少:

```
np.sqrt(metrics.mean_squared_error(y, null_model_predictions))
181.13613
```

简单地猜测，看起来我们的均方根误差是 181 辆自行车。所以，即使有一两个特征，我们也能打败它！击败零模型是机器学习中的一种基线。如果你想一想，如果你的机器学习甚至不如只是猜测，为什么还要努力呢？

我们已经在线性回归上花费了大量时间，但我现在想花一些时间来看看我们的下一个机器学习模型，它实际上，在某种程度上，是线性回归的表亲。它们基于非常相似的想法，但有一个主要区别-虽然线性回归是一种回归模型，只能用于预测连续数字，但我们的下一个机器学习模型将是一个分类模型，这意味着它将尝试在特征和分类响应之间建立联系。

<title>Logistic regression</title>   <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 逻辑回归

我们的第一个分类模型是称为逻辑回归。我已经能听到你脑子里的疑问了:什么是 makes 是 logistic，如果你声称这是一个分类算法，为什么叫回归？一切都会好的，我的朋友。

逻辑回归是线性回归模型的推广，适用于分类问题。在线性回归中，我们使用一组定量特征变量来预测连续响应变量。在逻辑回归中，我们使用一组定量特征变量来预测类别成员的概率。然后，这些概率可以映射到类别标签，从而预测每个观察的类别。

执行线性回归时，我们使用以下函数来制作最佳拟合线:

*y =*![Logistic regression](graphics/chp10.jpg)*[0]+*![Logistic regression](graphics/chp10.jpg)*[1]x*

这里， *y* 是我们的响应变量(我们希望预测的东西)，我们的 Beta 代表我们的模型参数， *x* 代表我们的输入变量(在这种情况下是一个变量，但正如我们所看到的，它可以接受更多的变量)。

简而言之，让我们假设分类问题中的一个响应选项是类别 1。

执行逻辑回归时，我们使用以下形式:

![Logistic regression](graphics/B05260_010_f5.jpg)

给定 x，y = 1 的概率

这里，![Logistic regression](graphics/B05260_010_f6.jpg)表示给定我们的数据 *x* ，我们的响应变量属于第 1 类的条件概率。现在，你可能想知道右边这个函数的怪物到底是什么，变量 *e* 从何而来？嗯，这个怪物被称为逻辑函数，它实际上是很棒的。而那个变量， *e* ，根本不是变量。让我们倒退一点。

变量 *e* 是一个特殊的数字，就像![Logistic regression](graphics/B05260_010_f6.jpg)一样。它大约是 2.718，被称为**欧拉数**。它经常用在带有*自然* 生长和衰退的建模环境中。例如，科学家使用 e 来模拟细菌和水牛的种群增长。欧拉数用于模拟化学物质的放射性衰变，也用于计算连续复利！今天，我们将把 e 用于一个非常特殊的目的，用于机器学习。

为什么不能像这样直接对数据点属于某一类的概率做线性回归呢？

![Logistic regression](graphics/B05260_010_f7.jpg)

出于几个原因，我们不能这样做，但我要指出一个很大的原因。线性回归，因为它试图涉及一个连续的响应变量，假设我们的 y 是连续的。在我们的例子中，y 代表事件发生的概率。尽管我们的概率实际上是一个连续的范围，但也仅仅是 0 到 1 之间的范围。一条线将外推超过 0 和 1，并且*能够*预测-4 或 1，542 的概率！我们不能这样。我们的图表必须像真实概率一样，整齐地绑定在 y 轴上的 0 和 1 之间。

另一个原因更哲学一点。使用线性回归，我们正在做一个严肃的假设。我们这里的大假设是，概率和我们的特征之间存在线性关系。一般来说，如果我们考虑一个事件的概率，我们倾向于考虑代表它们的平滑曲线，而不是一条单一的乏味的线。所以，我们需要一些更合适的东西。为此，让我们回顾一下基本概率。

<title>Probability, odds, and log odds</title>   <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 概率、赔率和对数赔率

我们熟悉概率的基本概念,因为事件发生的概率可以简单地建模为事件发生的方式数除以所有可能的结果。例如，如果在走进商店的 *3，000* 人中， *1，000* 人确实买了东西，那么我们可以说一个人购买一件商品的概率如下所示:

![Probability, odds, and log odds](graphics/B05260_010_f8.jpg)

不过，我们还有一个相关的概念，叫做**。某个结果发生的几率是该结果发生的方式数除以所有其他可能的结果，而不是所有可能的结果。在同一个例子中，一个人买东西的概率如下:**

**![Probability, odds, and log odds](graphics/B05260_010_f9.jpg)**

**这意味着每转化一个客户，你将*而不是*转化两个客户。这些概念如此相关，甚至有一个公式可以从一个概念转换到另一个概念。我们有:**

**![Probability, odds, and log odds](graphics/B05260_010_f10.jpg)**

**让我们用我们的例子来验证一下，如图所示:**

**![Probability, odds, and log odds](graphics/B05260_010_f11.jpg)**

**核实过了。**

**让我们使用 Python 制作一个概率和相关赔率的表格，如下所示:**

```
# create a table of probability versus odds
table = pd.DataFrame({'probability':[0.1, 0.2, 0.25, 0.5, 0.6, 0.8, 0.9]})
table['odds'] = table.probability/(1 - table.probability)
table
```

**![Probability, odds, and log odds](graphics/B05260_10_18.jpg)**

**因此，我们看到随着我们的概率增加，我们的机会也增加，但是速度更快！事实上，当一个事件发生的概率接近 1 时，我们的几率将会变得无穷大。早些时候，我们说我们不能简单地回归概率，因为我们的线会突然变成正负无穷大，预测不正确的概率，但如果我们回归到赔率呢？好吧，几率会变到正无穷大，但是唉，它们只会在底部接近 0，但永远不会低于 0。因此，我们不能简单地回归到概率或赔率。看起来我们已经跌到了谷底！**

**然而，等待，自然数和对数来拯救！按如下方式考虑对数:**

**![Probability, odds, and log odds](graphics/B05260_010_f13.jpg)**

**基本上，对数和指数是一回事。我们只是太习惯于用第一种方式来写指数，以至于忘记了还有另一种方式来写它们。再举个例子怎么样？如果我们取一个数的对数，我们会问这样一个问题，*嘿，我们需要给这个数加上什么指数才能使它成为给定的数？***

**请注意，`np.log`自动计算所有以 e 为基数的对数，这就是我们想要的:**

```
np.log(10) # == 2.3025
# meaning that e ^ 2.302 == 10

# to prove that
2.71828**2.3025850929940459 # == 9.9999
# e ^ log(10) == 10
```

**让我们继续将赔率的对数或 log-odds 添加到我们的表中，如下所示:**

```
# add log-odds to the table
table['logodds'] = np.log(table.odds)
table
```

**![Probability, odds, and log odds](graphics/B05260_10_19.jpg)**

**所以，现在每一行都有单个事件发生的概率，该事件发生的几率，以及该事件发生的几率对数。让我们继续前进，确保我们的数字上升。让我们选择一个概率`.25`，如图所示:**

```
prob = .25

odds = prob / (1 - prob)
odds
# 0.33333333

logodds = np.log(odds)
logodds
# -1.09861228
```

**核实过了。等等，看！我们的 `logodds`变量似乎下降到零以下，事实上，`logodds`既不在上方有界，也不在下方有界，这意味着它是线性回归的响应变量的一个很好的候选变量。事实上，这是我们的逻辑回归故事真正开始的地方。**

## **逻辑回归的数学**

**简而言之，逻辑回归是我们的特征 *X* 和我们属于某一类的数据的对数概率之间的线性回归，为了一般化，我们将称之为*真值*。**

**如果 *p* 表示数据点属于特定类别的概率，那么逻辑回归可以写成如下:**

**![The math of logistic regression](graphics/B05260_010_f15.jpg)**

**如果我们重新排列我们的变量并为 *p* 求解，我们将得到逻辑函数，它呈现一个 *S* 形状，其中 y 以`[0,1]`为界:**

**![The math of logistic regression](graphics/B05260_010_f16.jpg)****![The math of logistic regression](graphics/B05260_10_20.jpg)**

**上图显示了逻辑函数将我们的连续输入`x`映射到平滑概率曲线的能力，该曲线从左侧开始，接近概率 0，随着我们增加`x`，我们属于某个类别的概率自然增加*，并平滑地上升到概率 1。换句话说:***

*   ***逻辑回归给出了特定类别为真的概率的输出***
*   ***这些概率可以转换成类别预测***

***逻辑函数有一些很好的属性，如下所示:***

***它呈 S 形***

*   ***输出受限于 0 和 1，这是一种概率***

***为了解释逻辑函数的输出，我们必须理解概率和赔率之间的区别。一个事件的概率是由该事件的概率与其补数的比值给出的，如下所示:***

***![The math of logistic regression](graphics/B05260_010_f17.jpg)***

***在线性回归中，![The math of logistic regression](graphics/B05260_010_f18.jpg)参数代表`x`中单位变化的响应变量的变化。在逻辑回归中，![The math of logistic regression](graphics/B05260_010_f18.jpg)代表`x`中单位变化的对数优势的变化。这意味着![The math of logistic regression](graphics/B05260_010_f19.jpg)给了我们`x`中单位变化几率的变化。***

***假设我们对移动购买行为感兴趣。设`y`为表示购买/未购买的类别标签，设`x`表示该手机是否为 iPhone。***

***同样，假设我们执行逻辑回归，我们得到![The math of logistic regression](graphics/B05260_010_f18.jpg) = 0.693。***

***在这种情况下，赔率是 *np.exp(0.693) = 2* ，这意味着如果手机是 iPhone，购买的可能性是两倍。***

### ***注意***

***我们的例子大多是二元分类，这意味着我们只预测两种结果中的一种，但逻辑回归可以使用一对多的方法来预测我们的分类响应中的多个选项，这意味着它将拟合每个分类响应的概率曲线！***

***回到我们的自行车上来看看 scikit-learn 的逻辑回归在起作用。首先，我将创建一个新的分类响应变量。为了简单起见，我做了一个名为`above_average`的专栏，如果每小时自行车租赁数高于平均值，则为真，否则为假。***

```
*# Make a cateogirical response
bikes['above_average'] = bikes['count'] >= average_bike_rental*
```

***如前所述，我们应该看看我们的零模型。在回归中，我们的零模型总是预测平均反应，但在分类中，我们的零模型总是预测最常见的结果。在这种情况下，我们可以使用熊猫值计数来查看。大约 60%的时间，自行车租赁数量不高于平均水平:***

```
*bikes['above_average'].value_counts(normalize=True)*
```

***现在，让我们实际使用逻辑回归来尝试和预测每小时自行车租赁数量是否会高于平均值，如下所示:***

```
*from sklearn.linear_model import LogisticRegression

feature_cols = ['temp']
# using only temperature

X = bikes[feature_cols]
y = bikes['above_average']
# make our overall X and y variables, this time our y is
# out binary response variable, above_average

X_train, X_test, y_train, y_test = train_test_split(X, y)
# make our train test split

logreg = LogisticRegression()
# instantate our model

logreg.fit(X_train, y_train)
# fit our model to our training set

logreg.score(X_test, y_test)
# score it on our test set to get a better sense of out of sample performance

# 0.65650257*
```

***似乎只使用温度，我们就能击败一直猜测错误的零模型！这是我们使我们的模型尽可能好的第一步。***

***在线性回归和逻辑回归之间，我想说我们已经有了一个很好的机器学习形成的工具带，但我有一个问题——似乎这两种算法都只能接受定量列作为特征，但如果我有一个我认为与我的回答有关联的分类特征呢？***

***<title>Dummy variables</title>   <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 虚拟变量

当我们希望将分类特征转换成定量特征时，使用虚拟变量。记住我们有两种类型的范畴特征:名词性的和序数的。序数特征之间有自然顺序，而名义数据没有。

使用单独的列对定性(标称)数据进行编码被称为制造虚拟变量，其工作原理是将标称列的每个唯一类别转换为其自己的真或假列。

例如，如果我们有一个关于某人大学专业的列，我们希望将该信息插入到线性或逻辑回归中，我们不能，因为他们只接受数字！因此，对于每一行，我们都有新的列来表示单个名义列。在这种情况下，我们有四个独特的专业:计算机科学，工程，商业和文学。我们最后有三个新的专栏(我们省略了计算机科学，因为没有必要)。

![Dummy variables](graphics/B05260_10_21.jpg)

注意，第一行所有列都是 0，这意味着这个人的专业是*不是*工科，*不是*商科，*不是*文学。第二个人在工程一栏只有一个 1，因为这是他们所学的专业。

在我们的 bikes 示例中，让我们定义一个名为`when_is_it`的新列，它将是以下四个选项之一:

*   `Morning`
*   `Afternoon`
*   `Rush_hour`
*   `Off_hours`

要做到这一点，我们的方法是创建一个简单的一天中的小时的新列，使用该列来确定一天中的时间，并探索我们是否认为该列可以帮助我们预测`above_daily`列:

```
bikes['hour'] = bikes['datetime'].apply(lambda x:int(x[11]+x[12]))
# make a column that is just the hour of the day
bikes['hour'].head()
0
1
2
3
```

很好，现在让我们定义一个函数，将这些时间转换成字符串。对于这个例子，让我们将 5 点到 11 点之间的时间定义为上午，11 点到 4 点之间的时间定义为下午，4 点到 6 点为高峰时间，其他时间为下班时间:

```
# this function takes in an integer hour
# and outputs one of our four options
def when_is_it(hour):
    if hour >= 5 and hour < 11:
        return "morning"
    elif hour >= 11 and hour < 16:
        return "afternoon"
    elif hour >= 16 and hour < 18:
        return "rush_hour"
    else:
        return "off_hours"
```

让我们将这个函数应用到新的`hour`列，并创建我们全新的列`when_is_it`:

```
bikes['when_is_it'] = bikes['hour'].apply(when_is_it)
bikes[['when_is_it', 'above_average']].head()
```

![Dummy variables](graphics/B05260_10_22.jpg)

让我们尝试只使用这个新的列来确定每小时自行车租赁数量是否会高于平均值。在此之前，让我们做探索性数据分析的基础，并制作一个图表，看看我们是否可以可视化一天四个时间之间的差异。我们的图表将是一个条形图，一天中的每个时间都有一个条形。每个条形代表一天中这个时间自行车租赁量高于正常水平的次数百分比:

```
bikes.groupby('when_is_it').above_average.mean().plot(kind='bar')
```

![Dummy variables](graphics/B05260_10_23.jpg)

我们可以看到有一个相当大的区别！例如，在非工作时间，自行车租赁量超过平均水平的几率约为 25%，而在高峰时间，超过平均水平的几率超过 80%！好吧，这很令人兴奋，但是让我们使用一些内置的 Pandas 工具来提取虚拟列，如下所示:

```
when_dummies = pd.get_dummies(bikes['when_is_it'], prefix='when__')
when_dummies.head()
```

![Dummy variables](graphics/B05260_10_24.jpg)

```
when_dummies = when_dummies.iloc[:, 1:]
# remove the first column
when_dummies.head()
```

![Dummy variables](graphics/B05260_10_25.jpg)

太好了！现在我们有了一个充满数字的数据框架，可以插入到我们的逻辑回归中:

```
X = when_dummies
# our new X is our dummy variables
y = bikes.above_average

logreg = LogisticRegression()
# instantate our model

logreg.fit(X_train, y_train)
# fit our model to our training set

logreg.score(X_test, y_test)
# score it on our test set to get a better sense of out of sample performance

# 0.685157
```

这比仅仅使用温度更好！如果我们加上温度和湿度会怎么样？因此，现在我们使用温度、湿度和一天中的虚拟时间变量来预测我们的自行车租赁是否会高于平均水平:

```
new_bike = pd.concat([bikes[['temp', 'humidity']], when_dummies], axis=1)
# combine temperature, humidity, and the dummy variables

X = new_bike
# our new X is our dummy variables
y = bikes.above_average

X_train, X_test, y_train, y_test = train_test_split(X, y)

logreg = LogisticRegression()
# instantate our model

logreg.fit(X_train, y_train)
# fit our model to our training set

logreg.score(X_test, y_test)
# score it on our test set to get a better sense of out of sample performance

# 0.7182218
```

哇哦。好吧，趁我们还领先就退出吧。

<title>Summary</title>   <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 总结

在这一章，我们看了机器学习及其不同的子类别。我们探索了有监督的、无监督的和强化学习策略，并研究了每种策略派上用场的情况。

通过研究线性回归，我们能够发现预测因子和连续反应变量之间的关系。通过训练/测试分离，我们能够帮助避免过度拟合我们的机器学习模型，并获得更一般化的预测。我们还能够使用均方根误差等指标来评估我们的模型。

通过将线性回归的概念扩展到逻辑回归，我们能够找到相同预测因子之间的联系，但现在是分类反应。

通过在组合中引入虚拟变量，我们能够向模型中添加分类特征，并进一步提高我们的性能。

在接下来的几章中，我们将更深入地研究更多的机器学习模型，同时，我们将了解新的指标、新的验证技术，更重要的是，将我们的数据科学应用于世界的新方法。****