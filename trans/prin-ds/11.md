

# 十一、预测不会长在树上，是吗？

在这一章中，我们将会看到三种机器学习算法。前两个是监督学习的例子，而最后一个算法是非监督学习的例子。

我们在本章的目标是看到并应用从前面章节学到的概念，以便构建和使用现代学习算法，从而收集见解并对真实数据集进行预测。当我们探索下面的算法时，我们应该永远记住，我们要时刻牢记我们的度量标准。

我们开始吧！

# 朴素贝叶斯分类

让我们开始吧！让我们从朴素贝叶斯分类开始。这个机器学习模型很大程度上依赖于前几章的结果，特别是贝叶斯定理:

![Naïve Bayes classification](graphics/B05260_011_f1.jpg)

让我们更仔细地看看这个公式的具体特征:

*   *P(H)* 是我们观察到数据之前的假设的概率，称为**的先验概率，或者仅仅是**的先验****
*   ***P(H|D)* 是我们要计算的，我们观察到数据后假设的概率，称为 **后验****
*   ***P(D|H)* 是给定假设下数据的概率，称为 **似然****
*   ***P(D)* 是数据在任何假设下的概率，称为 **归一化常数****

**朴素贝叶斯分类是一个分类模型，因此也是一个监督模型。鉴于此，我们需要什么样的数据？**

*   **标记数据**
*   **未标记数据**

**(*在此插入危险音乐*)**

**如果你回答了标签数据，那么你就已经在成为数据科学家的路上了！**

**假设我们有一个数据集，有 *n* 个特征，(`x1`，`x2`，…，`xn`)和一个类标签 *C* 。例如，让我们拿一些涉及垃圾邮件文本分类的数据。我们的数据将由单个文本样本的行和我们的特征和我们的类标签的列组成。我们的特征是包含在文本样本中的单词和短语，我们的类别标签只是`spam`或`not spam`。在这个场景中，我将把类`not spam`替换为更容易说出的单词`ham`:**

```
import pandas as pd
import sklearn
df = pd.read_table('https://raw.githubusercontent.com/sinanuozdemir/sfdat22/master/data/sms.tsv',
                   sep='\t', header=None, names=['label', 'msg'])
df
```

**以下是行列格式的文本数据示例:**

**![Naïve Bayes classification](graphics/B05260_011_f2.jpg)**

**让我们做一些初步的统计，看看我们在处理什么。让我们来看看我们可以处理的垃圾邮件和垃圾邮件的数量差异:**

```
df.label.value_counts().plot(kind="bar")
```

**这为我们提供了一个条形图，如下所示:**

**![Naïve Bayes classification](graphics/B05260_11_2.jpg)**

**所以我们收到的垃圾邮件比垃圾邮件多得多。因为这是一个分类问题，所以知道我们的*空准确率*将会非常有用，空准确率是指如果我们继续猜测最常见的类 *ham* 时，正确预测单个行的概率百分比:**

```
df.label.value_counts() / df.shape[0]

ham     0.865937
spam    0.134063
```

**因此，如果我们盲目猜测，我们会有 87%的正确率，但我们可以做得更好。如果我们有一组类， *C* ，和一个特征*x[I]，那么我们可以使用贝叶斯定理来预测一个单独的行属于类 *C* 的概率，使用下面的公式:***

**![Naïve Bayes classification](graphics/B05260_011_f3.jpg)**

**让我们更详细地看看这个公式:**

*   ***P(C 类| {xi})* :后验概率是给定特征 *{xi}* ，该行属于*C 类*的概率。**
*   ***P({ Xi } | C 类)*:这是假设该行在*C 类*中，我们观察到这些特征的可能性。**
*   ***P(C 类)*:这是先验概率。它是在我们看到任何数据之前，数据点属于*C 类*的概率。**
*   **P({xi}) :这是我们的归一化常数。**

**例如，假设我们有一封包含三个单词的电子邮件:`send cash now.`我们将使用朴素贝叶斯将该电子邮件分类为垃圾邮件或垃圾邮件:**

**![Naïve Bayes classification](graphics/B05260_011_f4.jpg)****![Naïve Bayes classification](graphics/B05260_011_f5.jpg)**

**我们关心的是这两个数字的差异。我们可以使用以下标准对任何单个文本样本进行分类:**

*   **如果`P(spam | send cash now)`大于`P(ham | send cash now)`，那么我们将该文本分类为垃圾邮件**
*   **如果`P(ham | send cash now)`大于`P(spam | send cash now)`，那么我们将把文本标记为火腿**

**因为两个方程在分母上都有 *P(现在送钱)*，所以可以忽略。**

**所以现在我们关心以下问题:**

**![Naïve Bayes classification](graphics/B05260_011_f6.jpg)**

**让我们算出这个等式中的数字:**

*   ***P(垃圾邮件)= 0.134063***
*   ***P(ham) = 0.865937***
*   ***P(立即发送现金|垃圾邮件)***
*   ***P(现送现|火腿)***

**最后两个可能性看起来并不难计算。我们所要做的就是计算包含短语`send money now`的垃圾邮件的数量，并将其除以垃圾邮件的总数:**

```
df.msg = df.msg.apply(lambda x:x.lower())
# make all strings lower case so we can search easier

df[df.msg.str.contains('send cash now')] .shape
(0, 2)
```

**哦不！一个都没有！有字面上的`0`文本与确切的短语`send cash now`。这里隐藏的问题是，这个短语非常具体，我们不能假设我们在世界上有足够的数据来多次看到这个确切的短语。相反，我们可以在贝叶斯定理中做一个*的天真假设*。如果我们假设特征(单词)是条件独立的(意味着没有单词影响另一个单词的存在)，那么我们可以重写公式:**

**![Naïve Bayes classification](graphics/B05260_011_f7.jpg)**

```
spams = df[df.label == 'spam']
for word in ['send', 'cash', 'now']:
    print word, spams[spams.msg.str.contains(word)].shape[0] / float(spams.shape[0])revealing 
```

*   ***P(发送|垃圾邮件)= 0.096***
*   ***P(现金|垃圾邮件)= 0.091***
*   ***P(now|spam) = 0.280***

**这意味着我们可以计算如下:**

**![Naïve Bayes classification](graphics/B05260_011_f8.jpg)**

**对火腿重复同样的过程，我们得到以下结果:**

*   ***P(发送|火腿)= 0.03***
*   ***P(现金|火腿)= 0.003***
*   ***P(现在|火腿)= 0.109***

**![Naïve Bayes classification](graphics/B05260_011_f9.jpg)**

**这些数字都非常低的事实不如垃圾邮件概率远大于 ham 计算的事实重要。如果我们计算 *.00032 / .0000084 = 38.1* ，我们看到垃圾邮件的`send cash now`概率是垃圾邮件的 38 倍。**

**这样做意味着我们可以将`send cash now`归类为垃圾邮件！简单吧？**

**让我们使用 Python 来实现一个朴素贝叶斯分类器，而不必自己做所有这些计算。**

**首先，让我们重温一下 scikit-learn 中的计数矢量器，它为我们将文本转化为数字数据。假设我们将针对三个文档(句子)进行训练:**

```
# simple count vectorizer example
from sklearn.feature_extraction.text import CountVectorizer
# start with a simple example
train_simple = ['call you tonight',
                'Call me a cab',
                'please call me... PLEASE 44!']

# learn the 'vocabulary' of the training data
vect = CountVectorizer()
train_simple_dtm = vect.fit_transform(train_simple)
pd.DataFrame(train_simple_dtm.toarray(), columns=vect.get_feature_names())
```

**![Naïve Bayes classification](graphics/B05260_011_f10.jpg)**

**注意，每行代表三个文档(句子)中的一个，每列代表文档中出现的一个单词，每个单元格包含每个单词在每个文档中出现的次数。**

**然后，我们可以使用计数矢量器来转换新的输入测试文档，以符合我们的训练集(三个句子):**

```
# transform testing data into a document-term matrix (using existing vocabulary, notice don't is missing)
test_simple = ["please don't call me"]
test_simple_dtm = vect.transform(test_simple)
test_simple_dtm.toarray()
pd.DataFrame(test_simple_dtm.toarray(), columns=vect.get_feature_names())
```

**![Naïve Bayes classification](graphics/B05260_011_f11.jpg)**

**请注意，在我们的测试句子中，我们有一个新词，即*不要*。当我们对它进行矢量化时，因为我们之前在训练数据中没有见过这个词，所以矢量化工具会忽略它。这很重要，并激励数据科学家为他们的训练集获取尽可能多的数据。**

**现在，让我们对实际数据这样做:**

```
# split into training and testing sets
from sklearn.cross_validation import train_test_split
X_train, X_test, y_train, y_test = train_test_split(df.msg, df.label, random_state=1)

# instantiate the vectorizer
vect = CountVectorizer()

# learn vocabulary and create document-term matrix in a single step
train_dtm = vect.fit_transform(X_train)
train_dtm

<4179x7456 sparse matrix of type '<type 'numpy.int64'>'
```

**以压缩稀疏行格式存储 55209 个元素。**

**请注意，该格式是一个稀疏矩阵，这意味着该矩阵非常大，并且充满了零，存在一种特殊的格式来处理这样的对象。看一下列数。**

**7456 字！！**

**这意味着在我们的训练集中，有 7456 个独特的单词要查看。我们现在可以转换测试数据，以符合我们的词汇表:**

```
# transform testing data into a document-term matrix
test_dtm = vect.transform(X_test)
test_dtm

<1393x7456 sparse matrix of type '<type 'numpy.int64'>'
```

**具有 17604 个压缩稀疏行格式的存储元素。**

**请注意，我们有相同的确切列数，因为它符合我们的测试集，与之前的词汇表完全相同。不多不少。**

**现在让我们建立一个朴素贝叶斯模型(类似于线性回归过程):**

```
## MODEL BUILDING WITH NAIVE BAYES

# train a Naive Bayes model using train_dtm
from sklearn.naive_bayes import MultinomialNB
# import our model

nb = MultinomialNB()
# instantiate our model

nb.fit(train_dtm, y_train)
# fit it to our training set
```

**现在，变量`nb`保存了我们拟合的模型。模型的训练阶段包括计算似然函数，即给定每个类的每个要素的条件概率:**

```
# make predictions on test data using test_dtm
preds = nb.predict(test_dtm)

preds

array(['ham', 'ham', 'ham', ..., 'ham', 'spam', 'ham'], 
      dtype='|S4')
```

**模型的预测阶段包括在给定观察特征的情况下计算每个类别的后验概率，并选择概率最高的类别。**

**我们将使用 sklearn 内置的准确性和混淆矩阵来查看我们的朴素贝叶斯模型的表现如何:**

```
# compare predictions to true labels
from sklearn import metrics
print metrics.accuracy_score(y_test, preds)
print metrics.confusion_matrix(y_test, preds)

accuracy == 0.988513998564
confusion matrix == 
[[1203    5]
 [  11  174]]
```

**首先，我们的精确度很高！与我们 87%的零准确率相比，99%是一个惊人的进步。**

**现在来看看我们的困惑矩阵。从前面，我们知道每行代表实际值，而列代表预测值，所以左上角的值，1，203，代表我们真正的负数。但是什么是消极和积极呢？我们给模型的是字符串`spam`和`ham`作为我们的类，而不是正负。**

**我们可以使用以下方法:**

```
nb.classes_
array(['ham', 'spam'])
```

**然后我们可以排列指数，这样 1203 指的是真实的`ham`预测，174 指的是真实的`spam`预测。**

**还有五个*虚假垃圾邮件分类*，这意味着五个消息被预测为`spam`，但实际上是`ham`，以及 11 个*虚假垃圾邮件分类*。**

**总之，朴素贝叶斯分类使用贝叶斯定理来拟合类的后验概率，以便将数据点正确标记为属于正确的类。**

**

# 决策树

决策树是可以执行回归或分类的监督模型。

我们来看看 1986-1987 年的一些美国职棒大联盟球员数据。每个点代表联盟中的一个玩家:

*   **年数** ( *x* 轴):在大联盟打球的年数
*   **点击量** ( *y* 轴):玩家上一年的点击量
*   **薪资**(颜色):低薪为蓝色/绿色，高薪为红色/黄色

![Decision trees](graphics/B05260_11_6.jpg)

前面的数据是我们的训练数据。这个想法是建立一个模型，根据**年**和**点击**预测未来球员的工资。决策树旨在对我们的数据进行*分割*，以便分割彼此行为相似但与其他数据点不同的数据点。为了尽可能做出最准确的预测，该树会对这些拆分进行多次处理。让我们来看看为前面的数据构建的树:

![Decision trees](graphics/B05260_11_7.jpg)

从上到下阅读:

*   第一个拆分是**年< 4.5** ，当一个拆分规则为*真*时，你跟随左支。当一个分裂规则为*假*时，你跟随正确的分支。所以对于一个新玩家，如果他们玩了不到 4.5 年，我们就走左支。
*   对于左分支中的球员，平均工资是 166，000 美元，因此您用该值对其进行标记(为了便于计算，工资被除以 1000 并对数转换为 5.11)。
*   对于右分支中的玩家，在**安打< 117.5** 上有进一步的划分，将玩家分为两个以上的薪资区域:403，000 美元(转化为 6.00 美元)和 846，000 美元(转化为 6.74 美元)。

这棵树不仅仅给我们预测；它还暗示了我们数据的更多信息:

*   在联盟的年数似乎是决定薪水的最重要因素，年数越少，薪水越低
*   如果一个球员打球时间不长(< 4.5 年)，他们的击球次数就不是他们薪水的重要因素
*   对于 5 年以上的球员来说，命中率是决定他们薪水的一个重要因素
*   在给出答案之前，我们的树只做了两个决定(两个决定被称为树的深度)

## 计算机如何构建回归树？

现代决策树算法倾向于使用递归二进制分裂方法:

1.  该过程从树的顶部开始。
2.  对于每个要素，它将检查每个可能的分割，并选择要素和分割，以使结果树具有最低的可能均方误差(MSE)。算法会进行分割。
3.  然后，它将检查两个结果区域，并再次进行单次分割(在其中一个区域中)以最小化 MSE。
4.  继续重复步骤 3，直到满足停止标准:

    *   最大树深度(到达一片叶子所需的最大分裂数)
    *   一片叶子中的最小观察数(最终)节点

对于分类树，算法非常相似，最大的不同是我们优化的度量。因为 MSE 只存在于回归问题，所以我们不能用它。然而，分类树优化的不是准确度，而是基尼指数(T0)或熵(T5)。

## 计算机如何拟合分类树？

与回归树类似，分类树是通过优化一个指标(在这种情况下，基尼指数)并选择最佳分割来进行优化而构建的。更正式地说，在每个节点，树将采取以下步骤:

1.  计算数据的纯度。
2.  选择求职者分割。
3.  计算拆分后数据的纯度。
4.  对所有变量重复上述步骤。
5.  选择纯度增加最多的变量。
6.  对每个分割重复上述步骤，直到满足某个止损标准。

假设我们预测了一艘豪华游轮上的死亡概率，给出了人口特征。假设我们从 25 人开始，其中 10 人幸存，15 人死亡:

| 拆分前 | 全部 |
| 幸存 | Ten |
| 死亡 | Fifteen |

在做任何事情之前，我们首先计算基尼指数:

![How does a computer fit a classification tree?](graphics/B05260_011_f12.jpg)

总类别(本例中为存活和死亡):

![How does a computer fit a classification tree?](graphics/B05260_011_f13.jpg)

这意味着数据集的纯度为 *0.48* 。

现在让我们考虑一个潜在的性别差异:我们首先计算每个性别的基尼指数:

![How does a computer fit a classification tree?](graphics/B05260_11_09.jpg)

基尼系数(m) = ![How does a computer fit a classification tree?](graphics/B05260_011_f14.jpg)

基尼(f) = ![How does a computer fit a classification tree?](graphics/B05260_011_f15.jpg)

一旦我们有了每个性别的基尼指数,我们就可以计算按性别划分的总体基尼指数，如下所示:

![How does a computer fit a classification tree?](graphics/B05260_011_f16.jpg)

所以按性别划分的基尼系数是 0.27(T2)。然后，我们针对三种可能的拆分遵循以下程序:

*   性别(男性或女性)
*   船上兄弟姐妹的数量(0 或 1+)
*   等级(第一和第二对第三)

![How does a computer fit a classification tree?](graphics/B05260_11_10.jpg)

在本例中，我们将选择性别进行分割，因为这是最低的基尼指数！

下表简要总结了分类决策树和回归决策树之间的差异:

| 

回归树

 | 

分类树

 |
| --- | --- |
| 预测定量反应 | 预测定性响应 |
| 预测是每片叶子的平均值 | 预测是每片叶子中最常见的标签 |
| 选择分裂以最小化 MSE | 选择分割是为了最小化基尼指数(通常) |

让我们使用 scikit-learn 的内置决策树来构建一个决策树:

```
# read in the data
titanic = pd.read_csv('titanic.csv')

# encode female as 0 and male as 1
titanic['Sex'] = titanic.Sex.map({'female':0, 'male':1})

# fill in the missing values for age with the median age
titanic.Age.fillna(titanic.Age.median(), inplace=True)

# create a DataFrame of dummy variables for Embarked
embarked_dummies = pd.get_dummies(titanic.Embarked, prefix='Embarked')
embarked_dummies.drop(embarked_dummies.columns[0], axis=1, inplace=True)

# concatenate the original DataFrame and the dummy DataFrame
titanic = pd.concat([titanic, embarked_dummies], axis=1)

# define X and y
feature_cols = ['Pclass', 'Sex', 'Age', 'Embarked_Q', 'Embarked_S']
X = titanic[feature_cols]
y = titanic.Survived

X.head()
```

![How does a computer fit a classification tree?](graphics/B05260_011_f17.jpg)

请注意，我们将使用类别、性别、年龄和城市虚拟变量作为我们的特征:

```
# fit a classification tree with max_depth=3 on all data
from sklearn.tree import DecisionTreeClassifier
treeclf = DecisionTreeClassifier(max_depth=3, random_state=1)
treeclf.fit(X, y)
```

我们的树的深度是有限的。这意味着，对于任何数据点，我们的树最多只能提出三个问题，并进行三次拆分。我们可以将我们的树输出为可视化格式，我们将获得以下内容:

![How does a computer fit a classification tree?](graphics/B05260_11_12.jpg)

我们可以注意到一些事情:

*   性别是第一个分裂，这意味着性别是一个人能否在车祸中幸存的最重要的决定因素
*   从未在任何拆分中使用过

对于分类树或回归树，我们还可以利用决策树做一些非常有趣的事情，即我们可以输出一个数字来表示每个特征在数据点预测中的重要性:

```
# compute the feature importances
pd.DataFrame({'feature':feature_cols, 'importance':treeclf.feature_importances_})

```

![How does a computer fit a classification tree?](graphics/B05260_011_f19.jpg)

重要性得分是每个变量的平均基尼指数差，较高的值对应于预测的较高*重要性*。我们可以使用这些信息在将来选择更少的特征。例如，与其他特征相比，这两个变量都非常低，因此我们可以说它们在我们的生死预测中并不重要。



# 无监督学习

鉴于我们在本书的大部分时间都在讨论**监督学习模型**，现在是看一些非监督学习的例子的时候了。

## 何时使用无监督学习

有很多时候无监督学习可能是合适的。一些非常常见的例子包括:

*   当没有明确的*响应*变量时。我们没有明确地试图预测或关联其他变量。
*   从不存在明显结构/模式的数据中提取结构(可能是监督学习问题)。
*   当使用称为特征提取的无监督概念时。特征提取是从现有特征创建新特征的过程。这些新功能甚至可能比原始功能更强大。

第一个往往是数据科学家选择使用无监督学习的最常见原因。当我们处理数据时，这种情况经常出现，我们并没有明确地试图预测任何列，我们只是希望找到相似(和不相似)点组的模式。即使我们明确地试图使用一个监督模型来预测一个响应变量，第二种选择也会起作用。有时，简单的 EDA 可能不会在人类可以想象的几个维度的数据中产生任何清晰的模式，而机器可能会在更高维度中拾取彼此行为相似的数据点。

使用无监督学习的第三个常见原因是从已经存在的特征中提取新特征。这个过程(*亲切地称为特征提取*)可能会产生可用于未来监督模型或可用于演示目的(营销或其他)的特征。



# K-均值聚类

K-means 聚类是我们第一个无监督机器学习模型的例子。记住这意味着我们不是在做预测；相反，我们试图从看似非结构化的数据中提取结构。

聚类是一系列无监督的机器学习模型，试图将数据点分组为具有**质心**的**簇**。

### 注意

**定义:**

聚类:一组行为相似的数据点。

**定义:**

质心:一个星团的*中心*。可以认为是集群中的一个平均点。

前面的定义可能非常模糊，但当缩小到特定领域时，它就变得具体了。例如，行为相似的网上购物者可能购买相似的东西或在相似的商店购物，而相似的软件公司可能以相似的价格制造相似的软件。

这是点群的可视化:

![K-means clustering](graphics/B05260_11_14.jpg)

在前面的图中，我们人类的大脑可以非常容易地看出四个集群之间的差异。即红色聚类在图的左下方，而绿色聚类位于图的右下方。这意味着红色的数据点彼此相似，但是*而不是*与其他聚类中的数据点相似。

我们还可以看到每个星团的质心是每种颜色的正方形。注意，质心是*而不是*一个实际的数据点，而仅仅是一个群集的抽象，并代表群集的中心。

相似性的概念是聚类定义的核心，因此也是聚类分析的核心。一般来说，点之间的相似性越大，聚类越好。在大多数情况下，我们将数据转化为 n 维空间中的点，并使用这些点之间的距离作为相似性的一种形式。聚类的质心通常是每个聚类中每个数据点的每个维度(列)的平均值。例如，红色聚类的质心是对每个红色数据点的每列取平均值的结果。

聚类分析的目的是通过将数据分组来增强我们对数据集的理解。集群化提供了一个从单个数据点的抽象层。目标是提取和增强数据的自然结构。分类程序有很多种。在我们的课程中，我们将关注 K-means 聚类，这是最流行的聚类算法之一。

K-means 是一种迭代方法，它将数据集划分为`k`个簇。它分为四个步骤:

1.  选择`k`初始质心(注意`k`是一个输入)。
2.  对于每个点，将该点分配到最近的质心。
3.  重新计算质心位置。
4.  重复步骤 2-3，直到满足停止标准。

## 说明性示例-数据点

假设我们在二维空间中有以下数据点:

![Illustrative example – data points](graphics/B05260_11_15.jpg)

每个点都是灰色的，以便在应用 K-means 算法之前假定没有预先分组。这里的目标是最终给每个点上色并创建分组(集群)。

![Illustrative example – data points](graphics/B05260_11_16.jpg)

在这里，已经应用了第 1 步。我们(随机)选择了三个质心(红色、蓝色和黄色)。

### 注意

大多数 K-means 算法放置随机的初始质心，但是存在其他预先计算的方法来放置初始质心。目前，随机就可以了。

![Illustrative example – data points](graphics/B05260_11_17.jpg)

步骤 2 的第一部分已经应用。对于每个数据点，我们找到了最相似的质心(最近的)。

![Illustrative example – data points](graphics/B05260_11_18.jpg)

第 2 步的第二部分已经应用于此。我们根据最相似的质心给每个数据点着色。

![Illustrative example – data points](graphics/B05260_11_19.jpg)

这是第三步，也是 K-Means 的症结所在。请注意，我们实际上已经将质心移动到了每个簇的实际中心。对于每种颜色，我们已经计算了平均点，并将该点作为新的质心。例如，假设三个红色数据点具有坐标(`1, 3`)、(`2, 5`)和(`3, 4`)。中心(*红十字*)计算如下:

```
# centroid calculation
import numpy as np
red_point1 = np.array([1, 3])
red_point2 = np.array([2, 5])
red_point3 = np.array([3, 4])

red_center = (red_point1 + red_point2 + red_point3) / 3.

red_center 
# array([ 2.,  4.])
```

也就是说，点(`2, 4`)将会是前面的红十字的坐标。

### 注意

没有一个实际的数据点会移动。他们不能。唯一移动的实体是质心，而不是实际的数据点。

![Illustrative example – data points](graphics/B05260_11_20.jpg)

我们通过重复步骤 2 继续我们的算法。这是第一部分，我们找到每个点最近的中心。请注意一个很大的变化:下图中被圈起来的点以前是一个黄色点，但是现在变成了一个红色的聚类点，因为黄色的聚类更靠近它的黄色成分。

![Illustrative example – data points](graphics/B05260_11_21.jpg)

### Tip

将点想象成太空中具有引力的行星可能会有所帮助。每个质心都受到行星引力的牵引。

![Illustrative example – data points](graphics/B05260_11_22.jpg)

这里又是第二部分步骤 2。我们将每个点分配给最近的簇的颜色。

![Illustrative example – data points](graphics/B05260_11_23.jpg)

这里，我们再次重新计算每个聚类的质心(步骤 3)。请注意，蓝色中心完全没有移动，而黄色和红色中心都移动了。

因为我们已经达到了一个停止标准(如果我们重复步骤 2 和 3，集群不会移动)，我们完成了我们的算法，我们有三个集群！

![Illustrative example – data points](graphics/B05260_11_24.jpg)

K 均值算法的最终结果

## 例证——啤酒！

数据科学够了，啤酒！

好的好的，安静下来。这是一本很长的书，我们去喝杯啤酒吧。说到这个，你知道有很多种啤酒吗？我想知道我们是否可以根据不同的数量特征将啤酒分成不同的类别...我们试试吧！

```
# import the beer dataset
url = '../data/beer.txt'
beer = pd.read_csv(url, sep=' ')
print beer.shape
(20, 5)

beer.head()
```

![Illustrative example – beer!](graphics/B05260_011_f20.jpg)

这里我们有 20 种啤酒，有五栏:名称、卡路里、钠、酒精和价格。在聚类中(就像几乎所有的机器学习模型一样)，我们喜欢量化特征，因此我们将在聚类中忽略啤酒的名称:

```
# define X
X = beer.drop('name', axis=1)
```

现在我们将使用 scikit-learn 执行 K-Means:

```
# K-means with 3 clusters
from sklearn.cluster import KMeans
km = KMeans(n_clusters=3, random_state=1)
km.fit(X)
```

### 注意

`n_clusters`就是我们的`k`。这是我们输入的集群数量。`random_state`一如既往地为教育目的提供可重复的结果。现在使用三个集群是随机的。

我们的 K-means 算法已经在我们的数据点上运行了该算法，并得出三个聚类:

```
# save the cluster labels and sort by cluster
beer['cluster'] = km.labels_
```

我们可以通过使用`groupby`和`mean`语句来查看每个集群的中心:

```
# calculate the mean of each feature for each cluster
beer.groupby('cluster').mean()
```

![Illustrative example – beer!](graphics/B05260_011_f21.jpg)

在人体检查中，我们可以看到，平均而言，第 0 组的卡路里含量、钠含量和酒精含量更高，成本也更高。这些可能被认为是较重的啤酒。第 2 组平均酒精含量很低，卡路里也很少。这些可能是淡啤酒。集群 1 在中间的某个地方。

让我们使用 Python 制作一个图表来更详细地了解这一点:

```
import matplotlib.pyplot as plt
%matplotlib inline

# save the DataFrame of cluster centers
centers = beer.groupby('cluster').mean()
# create a "colors" array for plotting
colors = np.array(['red', 'green', 'blue', 'yellow'])
# scatter plot of calories versus alcohol, colored by cluster (0=red, 1=green, 2=blue)
plt.scatter(beer.calories, beer.alcohol, c=colors[list(beer.cluster)], s=50)

# cluster centers, marked by "+"
plt.scatter(centers.calories, centers.alcohol, linewidths=3, marker='+', s=300, c='black')

# add labels
plt.xlabel('calories')
plt.ylabel('alcohol')
```

### 注意

无监督学习的很大一部分是人工检查。聚类没有问题域的上下文，只能告诉我们它找到的聚类，不能告诉我们这些聚类意味着什么。

![Illustrative example – beer!](graphics/B05260_11_27.jpg)

# 为 K 和聚类验证选择最佳数

K-means 聚类的很大一部分是知道最优的聚类数。如果我们提前知道这个数字，那么即使使用无监督学习的目的也可能落空。因此，我们需要一种方法来评估我们的聚类分析的输出。

这里的问题是，因为我们没有执行任何类型的预测，我们无法衡量该算法在预测中的正确程度。准确性和 RMSE 之类的指标被抛到了九霄云外。

## 剪影系数

**剪影系数**是，在*真实*聚类分配未知的情况下，评估聚类性能的常用度量。

每次观察的轮廓系数计算如下:

![The Silhouette Coefficient](graphics/B05260_011_f22.jpg)

让我们更仔细地看看这个公式的具体特征:

*   *a* :到其簇中所有其他点的平均距离
*   *b* :到下一个最近簇中所有其他点的平均距离

范围从-1(最差)到 1(最好)。通过取所有观察的平均分数来计算出**全局分数** 。通常，轮廓系数 1 是优选的，而分数-1 不是优选的:

```
# calculate Silhouette Coefficient for K=3
from sklearn import metrics
metrics.silhouette_score(X, km.labels_)
0.4578
```

让我们尝试计算 K 的多个值的系数，以找到最佳值:

```
# calculate SC for K=2 through K=19
k_range = range(2, 20)
scores = []
for k in k_range:
    km = KMeans(n_clusters=k, random_state=1)
    km.fit(X_scaled)
    scores.append(metrics.silhouette_score(X, km.labels_))

# plot the results
plt.plot(k_range, scores)
plt.xlabel('Number of clusters')
plt.ylabel('Silhouette Coefficient')
plt.grid(True)
```

![The Silhouette Coefficient](graphics/B05260_11_29.jpg)

所以看起来我们的 最佳啤酒簇数是 4！这意味着我们的 k-means 算法已经确定似乎有四种不同类型的啤酒。

K-means 是一种流行的算法，因为它的计算效率和简单直观的性质。但是，K-means 高度依赖于比例，不适合形状和密度变化很大的数据。通过使用 scikit-learn 的标准标量缩放数据，有多种方法可以解决这个问题:

```
# center and scale the data
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# K-means with 3 clusters on scaled data
km = KMeans(n_clusters=3, random_state=1)
km.fit(X_scaled)
```

轻松点。

现在让我们来看看使用无监督方法的第三个原因，它属于使用无监督方法的第三个选项，即特征提取。



# 特征提取和主成分分析

有时我们有大量的列，但可能没有足够的行来处理大量的列。

这个的一个很好的例子就是我们在朴素贝叶斯例子中看到的`send cash now`例子。我们实际上有 0 个文本实例包含这个短语，所以我们转而求助于一个*的天真的*假设，这个假设允许我们推断两个类别的概率。

我们首先遇到这个问题的原因是因为一种叫做维度诅咒的东西。

“维数灾难”基本上是说，当我们引入和考虑新的特性列时，我们几乎需要指数级的更多行(数据点)来填充我们创建的空白空间。

考虑一个例子，其中我们试图使用一个学习模型，该模型利用具有 4086 段文本的文本语料库上的点之间的距离，并且整个事情已经被`Countvectorized`。让我们假设他们之间的这些文本有 18，884 个单词:

```
X.shape
(4086, 18884)
```

现在让我们做一个实验。我将首先考虑一个单词作为我们文本的唯一维度。然后，我会计算有多少段文本彼此在 1 *单位*内。例如，如果两个句子都包含该单词，它们将相距 0 个单位，同样，如果两个句子都不包含该单词，它们将相距 0 个单位:

```
d = 1
# Let's look for points within 1 unit of one another

X_first_word = X[:,:1]
# Only looking at the first column, but ALL of the rows

from sklearn.neighbors import NearestNeighbors
# this module will calculate for us distances between each point

neigh = NearestNeighbors(n_neighbors=4086)
neigh.fit(X_first_word)
# tell the module to calculate each distance between each point
```

### 注意

请注意，我们需要扫描 16，695，396 (4086*4086)的距离

```
A = neigh.kneighbors_graph(X_first_word, mode='distance').todense()
# This matrix holds all distances (over 16 million of them)

num_points_within_d = (A < d).sum()
# Count the number of pairs of points within 1 unit of distance

num_points_within_d
16258504
```

因此，1620 万对文本在一个单位的距离内。现在让我们用前两个词再试一次:

```
X_first_two_words = X[:,:2]
neigh = NearestNeighbors(n_neighbors=4086)
neigh.fit(X_first_two_words)
A = neigh.kneighbors_graph(X_first_two_words, mode='distance').todense()
num_points_within_d = (A < d).sum()

num_points_within_d
16161970
```

太好了！通过添加这一新列，我们失去了大约 100，000 对在一个单位距离内的点。这是因为我们每增加一个维度，就会在它们之间增加空间。让我们进一步测试，计算前 100 个单词的数量，然后绘制结果:

```
d = 1
# Scan for points within one unit

num_columns = range(1, 100)
# Looking at the first 100 columns
points = []
# We will be collecting the number of points within 1 unit for a graph

neigh = NearestNeighbors(n_neighbors=X.shape[0])
for subset in num_columns:
    X_subset = X[:,:subset]
  # look at the first column, then first two columns, then first three columns, etc
    neigh.fit(X_subset)
    A = neigh.kneighbors_graph(X_subset, mode='distance').todense()
    num_points_within_d = (A < d).sum()
# calculate the number of points within 1 unit
    points.append(num_points_within_d)
```

现在让我们绘制一个单位内的点数与我们所观察的维度数的关系图:

![Feature extraction and principal component analysis](graphics/B05260_11_30.jpg)

我们可以清楚地看到，当我们引入越来越多的列时，一个单元内的点的数量急剧下降。而这只是前 100 列！让我们看看当我们考虑所有 18，000+单词时，一个单元内有多少个点:

```
neigh = NearestNeighbors(n_neighbors=4086)
neigh.fit(X)
A = neigh.kneighbors_graph(X, mode='distance').todense()
num_points_within_d = (A < d).sum()

num_points_within_d
4090
```

到最后，只有 4000 个句子在一个单元内。我们通过考虑新列而增加的所有这些空间，使得我们不得不愉快地保持在彼此范围内的有限数量的点变得更加困难。为了填补这个空白，我们必须增加更多的分数。朋友们，这就是为什么我们应该考虑使用降维。

通过增加更多的数据点(这并不总是可能的)，或者实现降维，可以解决维度的诅咒。降维只是减少数据集中的列数，而不是行数。有两种实现降维的方法:

*   **特性选择**:这是对我们的列特性进行子集化的行为，并且只使用最好的特性
*   **特征提取**:这个是将我们的特征集数学转换到一个新提取的坐标系中的动作

我们熟悉的特征选择过程是说*email brked _ Q 对我的决策树没有帮助；先去掉它，看看它的表现如何*。实际上是当我们(或机器)决定忽略某些列时。

特征提取有点棘手…

在特征提取中，我们通常使用相当复杂的数学公式，以便获得新的*超级列*，它们通常比任何单个原始列更好。

我们这样做的主要模型叫做 **主成分分析** ( **PCA** )。PCA 将提取一定数量的超级列，以便用更少的列来表示我们的原始数据。我们来举一个具体的例子。之前我提到了一些有 4086 行和 18000 多列的文本。这个数据集实际上是一组 Yelp 在线评论:

```
url = '../data/yelp.csv'
yelp = pd.read_csv(url, encoding='unicode-escape')

# create a new DataFrame that only contains the 5-star and 1-star reviews
yelp_best_worst = yelp[(yelp.stars==5) | (yelp.stars==1)]

# define X and y
X = yelp_best_worst.text
y = yelp_best_worst.stars == 5
```

我们的目标是根据一个人在评论中使用的词语来预测他是否给出了 5 星或 1 星的评论。让我们用逻辑回归设置一个基线，看看我们能多好地预测这个二元类别:

```
from sklearn.linear_model import LogisticRegression
lr = LogisticRegression()

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=100)
# Make our training and testing sets

vect = CountVectorizer(stop_words='english')
# Count the number of words but remove stop words like a, an, the, you, etc

X_train_dtm = vect.fit_transform(X_train)
X_test_dtm = vect.transform(X_test)
# transform our text into document term matrices

lr.fit(X_train_dtm, y_train)
# fit to our training set

lr.score(X_test_dtm, y_test)
# score on our testing set
0.91193737
```

因此，通过利用我们语料库中的所有单词，我们的模型似乎有超过 91%的准确率。还不错！

让我们试着只使用最常用的 100 个单词:

```
vect = CountVectorizer(stop_words='english', max_features=100)
# Only use the 100 most used words

X_train_dtm = vect.fit_transform(X_train)
X_test_dtm = vect.transform(X_test)
print X_test_dtm.shape  # (1022, 100)

lr.fit(X_train_dtm, y_train)

lr.score(X_test_dtm, y_test)
0.8816
```

注意我们的训练和测试矩阵有 100 列。这是因为我告诉我们的矢量器只查看前 100 个单词。另请注意，我们的性能受到了影响，现在准确率下降到了 88%。这是有意义的，因为我们忽略了语料库中的 4700 多个单词。

现在让我们采取不同的方法。让我们导入一个 PCA 模块，让它为我们制造 100 个新的超级色谱柱，看看它的性能如何:

```
from sklearn import decomposition
# We will be creating 100 super columns

vect = CountVectorizer(stop_words='english')
# Don't ignore any words
pca  = decomposition.PCA(n_components=100)
# instantate a pca object

X_train_dtm = vect.fit_transform(X_train).todense()
# A dense matrix is required to pass into PCA, does not affect the overall message
X_train_dtm = pca.fit_transform(X_train_dtm)

X_test_dtm = vect.transform(X_test).todense()
X_test_dtm = pca.transform(X_test_dtm)
print X_test_dtm.shape  # (1022, 100)

lr.fit(X_train_dtm, y_train)

lr.score(X_test_dtm, y_test)
.89628
```

不仅我们的矩阵仍然有 100 列，而且这些列在我们的语料库中不再是单词。它们是列的复杂转换，是 100 个新列。还要注意，使用 100 个这样的新列比使用 100 个最热门的单词给我们带来了更好的预测性能！

特征提取是使用数学公式提取全新列的一种很好的方式，通常比预先选择最好的列性能更好。

但是我们如何可视化这些新的超级列呢？我想不出比用图像分析来看一个例子更好的方法了。具体来说，我们来做一个面部识别软件。好吗？好的。让我们从导入 scikit-learn 给我们的一些面孔开始:

```
from sklearn.datasets import fetch_lfw_people

lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)

# introspect the images arrays to find the shapes (for plotting)
n_samples, h, w = lfw_people.images.shape

# for machine learning we use the 2 data directly (as relative pixel
# positions info is ignored by this model)
X = lfw_people.data
y = lfw_people.target
n_features = X.shape[1]

X.shape
(1288, 1850)
```

我们已经收集了 1288 张人脸图像，每张都有 1850 个特征(像素)来识别这个人。例如:

```
plt.imshow(X[0].reshape((h, w)), cmap=plt.cm.gray)
lfw_people.target_names[y[0]]
'Hugo Chavez'
```

![Feature extraction and principal component analysis](graphics/B05260_11_31.jpg)

```
plt.imshow(X[100].reshape((h, w)), cmap=plt.cm.gray)
lfw_people.target_names[y[100]]
'George W Bush'
```

![Feature extraction and principal component analysis](graphics/B05260_11_32.jpg)

太好了。为了对我们正在查看的类型的数据集有所了解，让我们来看几个总体指标:

```
# the label to predict is the id of the person
target_names = lfw_people.target_names
n_classes = target_names.shape[0]

print("Total dataset size:")
print("n_samples: %d" % n_samples)
print("n_features: %d" % n_features)
print("n_classes: %d" % n_classes)

Total dataset size:
n_samples: 1288
n_features: 1850
n_classes: 7
```

所以我们有 1，288 张图片，1，850 个特征，7 个类(人)可供选择。我们的目标是制作一个分类器，它将根据提供给我们的 1850 个像素给人脸指定一个名称。

让我们以此为基础，看看什么都不做的情况下，逻辑回归是如何对我们的数据执行的:

```
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from time import time  # for timing our work

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=1)
# get our training and test set

t0 = time() # get the time now
logreg = LogisticRegression()

logreg.fit(X_train, y_train)

# Predicting people's names on the test set
y_pred = logreg.predict(X_test)

print accuracy_score(y_pred, y_test), "Accuracy"
print (time() - t0), "seconds"

0.810559006211 Accuracy
6.31762504578 seconds
```

所以在 6.3 秒内，我们能够在我们的测试集上获得 81%的准确率。不算太坏…

现在让我们用我们的*超级面孔*来试试这个:

```
# split into a training and testing set
from sklearn.cross_validation import train_test_split

# Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled
# dataset): unsupervised feature extraction / dimensionality reduction
n_components = 75

# Extracting the top %d eigenfaces from %d faces
      % (n_components, X_train.shape[0]))
pca = decomposition.PCA(n_components=n_components, whiten=True).fit(X_train)
# This whiten parameter speeds up the computation of our extracted columns

# Projecting the input data on the eigenfaces orthonormal basis
X_train_pca = pca.transform(X_train)
X_test_pca = pca.transform(X_test)
```

前面的代码从 1，850 个未处理的列中收集了 75 个提取的列。这些是我们的`super faces`。现在，让我们将新提取的列插入到我们的逻辑回归中并进行比较:

```
t0 = time()

# Predicting people's names on the test set WITH PCA
logreg.fit(X_train_pca, y_train)
y_pred = logreg.predict(X_test_pca)

print accuracy_score(y_pred, y_test), "Accuracy"
print (time() - t0), "seconds"

0.82298136646 Accuracy
0.194181919098 seconds
```

哇！不仅整个计算比未经处理的图像快了大约 30 倍，预测性能也变得更好！这向我们表明，在对具有许多列的复杂数据集执行机器学习时，PCA 和特征提取通常可以帮助我们。通过在数据集中搜索这些模式并提取新的特征列，我们可以加快并增强我们的学习算法。

让我们看一件更有趣的事情……我之前提到过，这个例子的目的之一是检查和可视化我们的*本征脸*，就像它们被称为的那样。我们的超级专栏。我不会让人失望的。让我们编写一些代码，向我们展示我们的超级列，就像它们在我们人类看来一样:

```
def plot_gallery(images, titles, n_row=3, n_col=4):
    """Helper function to plot a gallery of portraits"""
    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))
    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)
    for i in range(n_row * n_col):
        plt.subplot(n_row, n_col, i + 1)
        plt.imshow(images[i], cmap=plt.cm.gray)
        plt.title(titles[i], size=12)

# plot the gallery of the most significative eigenfaces
eigenfaces = pca.components_.reshape((n_components, h, w))
eigenface_titles = ["eigenface %d" % i for i in range(eigenfaces.shape[0])]
plot_gallery(eigenfaces, eigenface_titles)

plt.show()
```

![Feature extraction and principal component analysis](graphics/B05260_11_33.jpg)

哇哦。这是一张令人难忘而又美丽的图片，展示了数据认为最重要的面部特征。当我们从左上角(第一个超级列)移到底部时，实际上很容易看出图像想要告诉我们什么。第一个超柱看起来是很一般的脸部结构，有眼有鼻有嘴。几乎是在说“我代表了一张脸所有脸必须具备的基本素质”。我们右边的第二个超级柱似乎在告诉我们图像中的阴影。下一张脸可能会告诉我们肤色在识别这个人的过程中扮演了一个角色，这可能就是为什么第三张脸比前两张脸要暗得多。

使用特征提取无监督学习方法(如 PCA)可以让我们深入了解我们的数据，并向我们揭示数据认为最重要的特征，而不仅仅是我们认为它们是什么。特征提取是一个很好的预处理工具，可以加快我们未来的学习方法，使它们更强大，并让我们更深入地了解数据认为应该如何查看。总结这一节，我们将列出利弊。

使用特征提取的优点:

*   我们的模型变得更快
*   我们的预测性能会变得更好
*   可以让我们深入了解提取的特征(特征脸)

使用特征提取的缺点:

*   我们失去了我们的功能的可解释性，因为它们是新的数学推导的列，而不是我们的旧列
*   我们可能会失去预测性能，因为我们提取的列越少，信息就越少



# 总结

在决策树、朴素贝叶斯分类、特征提取和 K-means 聚类之间，我们已经看到机器学习超越了线性和逻辑回归的简单性，可以解决许多类型的复杂问题。

我们还看到了监督学习和非监督学习的例子，并因此熟悉了许多类型的数据科学相关问题。

在下一章，我们将着眼于更复杂的学习算法，包括人工神经网络和集成技术。我们还将看到并理解数据科学中更复杂的概念，包括偏差-方差权衡，以及过度拟合的概念。**