

# 预测营销参与的可能性

在本章中，我们将扩展从上一章以及我们在第[章第 7](72e8f4ee-7f95-4acc-928d-d33c9fc31bd6.xhtml) 、*中进行的客户分析练习中获得的知识，对客户行为进行探索性分析*。对于成功和更智能的营销策略，我们不能停留在分析客户数据上。借助数据科学和机器学习方面的先进技术，我们现在可以对客户的未来行为进行智能猜测和估计，例如什么类型的客户更有可能参与营销活动，客户可能的购买量，或者哪些客户可能会流失。这些基于历史客户数据的预测或智能猜测可以帮助您提高营销表现，并进一步为不同的目标受众量身定制营销策略。在这一章中，我们将学习如何利用数据科学和机器学习来预测未来的结果，以及如何帮助您未来的营销工作。

在本章中，我们将讨论以下主题:

*   营销中的预测分析
*   评估分类模型
*   预测使用 Python 进行营销的可能性
*   预测与 R 营销接触的可能性



# 营销中的预测分析

**预测分析**是从历史数据中分析和提取信息以识别模式并预测未来结果的过程。许多统计和机器学习模型通常用于查找数据集中的属性或特征与您想要预测的目标变量或行为之间的关系。预测分析可以在许多不同的行业中使用和应用。

例如，它经常用于金融行业的欺诈检测，其中机器学习模型被训练来检测和防止潜在的欺诈交易。医疗保健行业也可以从预测分析中受益，以帮助医生制定决策。此外，市场营销的各个部分也可以受益于预测分析，例如客户获取、客户保持、追加销售和交叉销售等。

在预测分析中，一般来说，有两种类型的问题:

*   **分类问题**:分类问题是一个观察可以属于的一组类别。比如预测一个客户是否会打开营销邮件，就是一个分类问题。只有两种可能的结果——打开营销邮件或者不打开邮件。
*   回归问题:另一方面，回归问题的结果可以是任意范围的实数。比如预测客户终身价值就是一个回归问题。一个客户的终身价值为 0 美元，另一个客户的终身价值为 10，000 美元。这类问题的结果可以是连续值，称为回归问题。

在这一章中，我们将关注营销行业中一个常见的分类问题——预测客户参与的可能性。在接下来的章节中，[第 9 章](9b3d36ba-d690-491c-9a6f-b8c00f59cfb4.xhtml)，*客户终身价值*，我们将解决营销行业中经常出现的回归问题之一。



# 预测分析在营销中的应用

如前所述，在营销中有许多应用和利用预测分析的方法。在本节中，我们将讨论预测分析在营销中的四个常见用例:

*   **参与可能性**:预测分析可以帮助营销人员预测客户参与其营销战略的可能性。例如，如果您的营销经常发生在电子邮件领域，您可以利用预测分析来预测哪些客户很有可能会打开您的营销电子邮件，并为这些高可能性客户定制您的营销策略，以最大限度地提高您的营销效果。再举一个例子，如果你在社交媒体上展示广告，预测分析可以帮助你识别可能点击广告的特定类型的客户。
*   **客户终身价值**:预测分析可以帮助您预测客户的预期终身价值。使用历史交易数据，预测分析可以帮助您识别客户群中的高价值客户。有了这些预测，你和你的公司可以更专注于与那些高价值客户建立健康的关系。我们将在下一章更详细地讨论如何为客户终身价值预测建立预测模型。
*   **推荐合适的产品和内容**:正如我们在[第六章](d3ba7047-2873-4b03-9a44-4c1d55b84178.xhtml)、*推荐合适的产品*中已经讨论过的，我们可以使用数据科学和机器学习来预测哪些客户可能会购买产品或查看内容。使用这些预测，您可以通过为个人客户推荐正确的产品和内容来提高客户转化率。
*   **客户获取和保留**:预测分析也被大量用于客户获取和保留。基于您收集的有关潜在客户或潜在客户的个人资料数据以及现有客户的历史数据，您可以应用预测分析来识别高质量的潜在客户，或根据潜在客户转化为活跃客户的可能性对其进行排名。另一方面，您可以使用客户流失数据和现有客户的历史数据来开发预测模型，以预测哪些客户可能会离开或取消订阅您的产品。我们将在[第 11 章](3d5c7798-6874-40e9-b7e9-6fe39592cc2a.xhtml)、*留住客户*中更详细地讨论应用预测分析留住客户。

除了预测分析在营销中的这四个常见用例之外，还有许多其他方式可以将预测分析用于您的营销策略。你应该在未来的营销策略中创造性地使用预测分析的方法和场合。



# 评估分类模型

在开发预测模型时，知道如何评估这些模型是很重要的。在本节中，我们将讨论五种不同的方法来评估分类模型的性能。可以用来衡量预测性能的第一个指标是**准确性**。准确性就是所有预测中正确预测的百分比，如下式所示:

![](assets/84ed1d1c-4cfa-42b1-bbc9-378337f43d0a.png)

分类问题通常使用的第二个度量是**精度**。精确度被定义为真阳性的数量除以真阳性和假阳性的总数。真阳性是模型正确预测为阳性的情况，而假阳性是模型预测为阳性，但真实标签为阴性的情况。该公式如下所示:

![](assets/ae4af65b-cc35-401a-938e-d5da51b56c4d.png)

除了精度之外，**召回**也常用于评估分类模型的性能。召回被定义为真阳性的数量除以真阳性加上假阴性的数量。假阴性是模型被预测为阴性，但真实标签为阳性的情况。回忆可以被认为是模型检索或发现多少正面案例的度量。该公式如下所示:

![](assets/7aef9390-c65f-4cf2-91f2-2c2f5a1d4a58.png)

我们要讨论的最后两个指标是**接收机工作特性** ( **ROC** )曲线和曲线下的**面积** ( **AUC** )。ROC 曲线显示了真阳性率和假阳性率在不同阈值下的变化。AUC 就是 ROC 曲线下的总面积。AUC 范围从 0 到 1，较高的 AUC 数表明模型性能较好。随机分类器的 AUC 为 0.5，因此任何 AUC 高于 0.5 的分类器都表明该模型的性能优于随机预测。典型的 ROC 曲线如下:

![](assets/8b7e03bd-8eec-49a7-8c05-138ca8798c0a.png)

在下面的编程练习中，我们将使用刚才讨论的这五个指标来评估我们在 Python 和 r 中构建的模型的性能。现在让我们深入构建机器学习模型，以预测营销参与的可能性！



# 预测使用 Python 进行营销的可能性

在这一节中，我们将讨论如何使用 Python 中的机器学习算法来构建预测模型。更具体地说，我们将了解如何使用随机森林算法构建预测模型，以及如何调整随机森林模型和评估模型的性能。我们将主要使用`pandas`、`matplotlib`和`scikit-learn`软件包来分析、可视化和构建预测客户营销参与可能性的机器学习模型。对于那些想在这个练习中使用 R 而不是 Python 的读者，您可以跳到下一节。

在这个练习中，我们将使用 IBM 的一个公开可用的数据集，可以通过以下链接找到:[https://www . IBM . com/communities/analytics/Watson-analytics-blog/marketing-customer-value-analysis/](https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/)。您可以点击这个链接，下载 CSV 格式的数据，名为`WA_Fn UseC_ Marketing Customer Value Analysis.csv`。下载完这些数据后，您可以通过运行以下命令将其加载到 Jupyter 笔记本中:

```
import pandas as pd

df = pd.read_csv('../data/WA_Fn-UseC_-Marketing-Customer-Value-Analysis.csv')
```

`df`数据帧如下所示:

![](assets/63a2f76d-29f3-443a-a327-34ab8b596ffd.png)

您可能已经注意到了，这是我们在上一章进行客户分析时使用的同一数据集。根据我们在前一章中获得的关于该数据集的知识，我们将首先通过对目标变量和其他分类变量进行编码来准备我们的数据，我们将使用这些变量作为我们的机器学习模型的特征。



# 可变编码

为了使用 Python 中的`scikit-learn`包建立机器学习模型，数据集中的所有要素都需要有数值。但是，在数据集中，我们有许多包含非数字值的列。例如，目标变量`Response`，也就是我们将要尝试用机器学习模型预测的变量，是非数字的。它包含两个字符串值— `Yes`和`No`。我们将需要用数值编码这个`Response`目标变量，以便能够建立机器学习模型。再举一个例子，我们可以将列`Gender`用作预测模型的特征之一，它也没有数值。它包含两个字符串值—女性的`F`和男性的`M`。在本节中，我们将讨论如何对这些非数字列进行编码，以便我们可以将它们用作机器学习模型的特征。



# 响应变量编码

我们要做的第一件事是编码响应变量`Response`。我们将用`1` s 对`Yes`值进行编码，用`0` s 对`No`值进行编码。请看下面的代码:

```
df['Engaged'] = df['Response'].apply(lambda x: 1 if x == 'Yes' else 0)
```

从这段代码中可以看出，我们使用了`pandas` `DataFrame`的`apply`函数来对`Response`列应用我们的`lambda`函数，这样它就用`1`对`Yes`值进行编码，用`0`对`No`值进行编码。然后，我们将这些编码值存储在新创建的列`Engaged`中。为了使用这个新创建的列获得总体响应或参与度，您可以使用以下代码:

```
tdf['Engaged'].mean()
```

总体参与率如下:

![](assets/90aabaf8-3052-4f9f-a47f-57daf049fbe0.png)



# 分类变量编码

如果仔细观察数据，以下变量是分类变量:

```
columns_to_encode = [
    'Sales Channel', 'Vehicle Size', 'Vehicle Class', 'Policy', 'Policy Type', 
    'EmploymentStatus', 'Marital Status', 'Education', 'Coverage'
]
```

这些变量有一组可以取的不同值，这些值不一定有相互区分的顺序。

如果你还记得[第四章](a9f09970-4826-46d0-8bfd-5796702c5629.xhtml)、*从约定到转换*，有不止一种方式来编码分类变量。在这一章中，我们将使用的方法是使用`pandas`包中的`get_dummies`函数为每一类单独的分类变量创建虚拟变量。看一下下面的代码:

```
categorical_features = []
for col in columns_to_encode:
   encoded_df = pd.get_dummies(df[col])
    encoded_df.columns = [col.replace(' ', '.') + '.' + x for x in encoded_df.columns]

    categorical_features += list(encoded_df.columns)

    df = pd.concat([df, encoded_df], axis=1)
```

从这个代码片段中可以看出，我们正在遍历在`columns_to_encode`中定义的分类变量的列名列表。然后，对于每一列，我们使用`pandas`包中的`get_dummies`函数来构建虚拟变量。为了使事情更清楚，减少混乱，我们对新创建和编码的`DataFrame` `encoded_df`的列进行了重命名，其中每一列都包含关于原始列名及其所代表的类别的信息。例如，对于`Sale Channel`列，新创建的数据帧`encoded_df`将如下所示:

![](assets/cea74d25-63a1-4b68-b9be-1041261dea91.png)

从这个例子中可以看出，这个新的`DataFrame`的每一列都代表了原始`Sales Channel`列中的每一个类别，并且这些值都是一个热编码的，这意味着如果给定的记录属于给定的类别，那么它就分配一个值`1`，否则就分配一个值`0`。

一旦我们为给定的列创建了虚拟变量，我们就将新创建的列存储到名为`categorical_features`的变量中。最后，我们通过使用`pandas`包的`concat`函数，将这个新创建的`DataFrame`连接到原来的`DataFrame`。concat 函数中的一个参数`axis=1`告诉`pandas`通过列连接两个`DataFrames`。

到目前为止，我们已经成功地编码了除`Gender`之外的所有分类变量。由于我们不需要为`Gender`列创建两个虚拟变量，因为只能有两种性别，所以我们将创建一个包含给定记录的性别信息的变量。看一下下面的代码:

```
df['Is.Female'] = df['Gender'].apply(lambda x: 1 if x == 'F' else 0)

categorical_features.append('Is.Female')
```

从这段代码中可以看出，我们正在创建一个名为`Is.Female`的新列。我们使用`pandas` `DataFrame`的应用函数，用值`1`对所有女性进行编码，用值`0`对所有男性进行编码。



# 构建预测模型

我们几乎准备好开始构建和训练机器学习模型，以预测客户的反应或参与。我们的数据中有一些东西需要清理。看一下下面的代码:

```
all_features = continuous_features + categorical_features
response = 'Engaged'

sample_df = df[all_features + [response]]
sample_df.columns = [x.replace(' ', '.') for x in sample_df.columns]
all_features = [x.replace(' ', '.') for x in all_features]
```

从这段代码中可以看出，我们正在创建一个新的`DataFrame` `sample_df`，它包含所有的特性、`all_features`和响应变量`response`。然后，我们通过用点替换名称中的所有空格来清理列和特性名称。在这些清理之后，DataFrame `sample_df`现在看起来如下:

![](assets/eb370c76-2e57-4457-a963-d7d7e9995c9f.png)

现在我们有了一个可以用来训练和测试我们的机器学习模型的样本集，让我们将这个样本集分成两个子集——一个用于训练模型，另一个用于测试和评估训练好的模型。Python 机器学习包`scikit-learn`，有一个将给定样本集拆分成训练集和测试集的功能。看一下下面的代码:

```
from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(sample_df[all_features], sample_df[response], test_size=0.3)
```

在`scikit-learn`包的`model_selection`模块中，有一个名为`train_test_split`的函数。此函数将样本集以及训练集和测试集大小之间的所需细分作为输入参数，并返回随机拆分的训练集和测试集。从这个代码片段中可以看出，我们使用样本集的`70%`进行训练，剩余的`30%`进行测试。下面显示了样本集的训练集和测试集的细目分类:

![](assets/b4bae11b-4c12-4301-a00b-a4d6616a5795.png)

这里可以看到，`sample_df`中共有`9,134`条记录，`x_train`中共有`6,393`条记录，`x_test`中共有`2,741`条记录，也就是说样本集的大致`70%`进入了训练集，样本集的剩余`30%`进入了测试集。在接下来的部分中，我们将使用这些训练集和测试集来构建和评估模型。



# 随机森林模型

根据我们目前准备的数据，我们将使用随机森林算法建立一个预测模型，预测客户是否会响应或参与营销活动。在 Python 的`scikit-learn`包中，随机森林算法是在`ensemble`模块中实现的，您可以使用以下代码导入随机森林类:

```
from sklearn.ensemble import RandomForestClassifier
```

您可以使用以下代码创建随机森林分类器:

```
rf_model = RandomForestClassifier()
```

但是，对于随机森林模型，您可以调整许多超参数。超参数是在训练机器学习模型之前定义的参数。例如，对于随机森林算法，您可以在随机森林模型中定义想要的树的数量。作为另一个例子，您可以定义森林中每棵树的最大深度，这样您就可以限制森林中每棵树可以生长到多大。

您可以在`scikit-learn`的`RandomForestClassifier`类中定义许多超参数。我们将看看下面几个超参数的例子:

*   这定义了你想要在森林里建造的树的数量。一般来说，树越多，性能越好。但是，随着林中树数量的增加，每增加一棵树的性能提升量会减少。由于林中有更多的树意味着训练额外的树的计算成本更高，所以您应该尝试找到平衡点，当训练额外的树的计算成本超过性能收益时，停止添加树。
*   `max_depth`:该参数定义了单棵树的最大深度。深度越大，你的树可以从训练集中捕获的信息就越多，这意味着较大的树比较小的树更好地学习训练集。然而，树长得越大，就越有可能超过列车组。这意味着经过训练的树在训练集内执行和预测得很好，但是在它以前没有见过的数据集中预测得很差。为了避免过度拟合，我们希望将树的深度限制在一个点上，在这个点上它不会过度拟合到训练集，但是可以足够好地预测结果。
*   `min_samples_split`:定义了分割树节点所需的最小数据点数。例如，如果您将`min_samples_split`定义为`50`，但是该节点只有`40`条记录，那么它将不会进一步分割该节点。另一方面，如果该节点具有多于预定义的最小数量的样本，那么它将把该节点分割成子节点。类似于`max_depth`超参数，这可以帮助你管理树中发生的过度拟合的数量。
*   `max_features`:这定义了分割一个节点要考虑的特征的最大数量。该参数在随机森林模型中创建*随机性*。给定要考虑进行分割的最大数量的要素，随机森林算法随机选择最大数量的要素子集，并决定如何分割树的给定节点。这有助于随机森林模型的每棵树从训练集中学习不同的信息。当这些已经学习了具有稍微不同的特征集的训练集的树被打包或集合在一起时，那么结果森林将在其预测中变得更加准确和健壮。

关于其他超参数更详细的描述和信息，可以参考他们的官方文档，可以在以下链接找到:[https://sci kit-learn . org/stable/modules/generated/sk learn . ensemble . randomforestclassifier . html](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)。



# 训练随机森林模型

使用`scikit-learn`训练随机森林模型很简单。看一下下面的代码:

```
rf_model = RandomForestClassifier(
    n_estimators=200,
    max_depth=5
)

rf_model.fit(X=x_train, y=y_train)
```

使用`scikit-learn`包的`ensemble`模块中的`RandomforestClasifier`类，首先需要用超参数创建一个`RandomforestClasifier`对象。为了便于说明，我们指示模型构建`200`树，其中每棵树只能生长到`5`的深度。然后，您可以使用`fit`函数训练该模型，该函数采用两个参数`X`和`y`，其中`X`用于训练样本，`y`用于训练标签或目标值。

当您运行此代码时，您将看到如下所示的输出:

![](assets/eb29841c-0a3c-423b-8568-410014d5215e.png)

一旦训练或拟合了随机森林模型，模型对象就包含了大量有用的信息。您可以从训练过的`scikit-learn`随机森林模型中提取的一个有用属性是关于森林中每棵树的信息。使用`estimators_`属性，您可以检索构建在森林中的单棵树。看一下下面的输出:

![](assets/08d11a03-fa14-417c-aa6e-c7f2b7750427.png)

正如您在这个输出中看到的，`estimators_`属性返回一个子评估器列表，这些子评估器是决策树。有了这些信息，您可以模拟每个子估计器对每个输入的预测。例如，以下代码显示了如何从森林中的第一个子估计器获得预测:

```
rf_model.estimators_[0].predict(x_test)
```

以下输出显示了前五个子估计器的一些预测:

![](assets/db72f840-2ef0-4e2f-a4c0-8526c150a6c1.png)

从这个输出可以看出，不同的树对测试集的每条记录都有不同的预测。这是因为每棵树都是用随机选择的不同特征子集训练的。让我们快速看一下这些单独的子估计量的预测。第一棵树预测测试集中的`6th`记录是`1`的一个类，其余的是`0`的一个类。另一方面，第二棵树预测测试集的前 10 个记录是一个类别`0`。使用这些信息，您可以看到随机森林模型的最终预测是如何从这些单独的子估计量或树中形成的。

我们可以从经过训练的`RandomForestClassifier`对象中获得的其他有用信息是特征重要性，通过它我们可以了解每个特征对最终预测的重要性或影响。您可以使用以下代码获得每个特性的特性重要性:

```
rf_model.feature_importances_
```

这段代码的输出如下所示:

![](assets/1b9b3774-34bf-4bb3-8431-5be4b5e0c88f.png)

为了将这些功能重要性与相应的功能相关联，可以使用以下代码:

```
feature_importance_df = pd.DataFrame(list(zip(rf_model.feature_importances_, all_features)))
feature_importance_df.columns = ['feature.importance', 'feature']
```

结果如下所示:

![](assets/9482caaa-0e7e-418d-a0fc-eaa2ca7edc89.png)

从这个输出中可以看出，`EmploymentStatus.Retired`特性似乎是做出最终预测的最重要因素，而`Income`、`Total.Claim.Amount`和`Customer.Lifetime.Value`特性紧随其后，成为第二、第三和第四重要的特性。



# 评估分类模型

在本章的前面，我们已经讨论了五种不同的方法来观察分类模型的性能。在本节中，我们将学习如何使用我们刚刚构建的随机森林模型来计算和可视化 Python 中评估分类模型的指标。

我们要看的前三个指标是准确度、精确度和召回率。Python 的`scikit-learn`包实现了这三个指标的函数。您可以使用以下代码行导入这些函数:

```
from sklearn.metrics import accuracy_score, precision_score, recall_score
```

从这段代码片段中可以看到，`scikit-learn`包的`metrics`模块有一个用于计算模型精度的`accuracy_score`函数，一个用于计算精度的`precision_score`函数，以及一个用于召回的`recall_score`函数。

在我们继续评估模型性能之前，我们需要模型预测结果。为了让我们在上一节中构建的随机森林模型对数据集进行预测，我们可以简单地使用模型的`predict`函数。看一下下面的代码:

```
in_sample_preds = rf_model.predict(x_train)
out_sample_preds = rf_model.predict(x_test)
```

根据这些预测结果，我们将评估我们的随机森林模型在训练集和测试集中的表现。下面的代码展示了我们如何使用`scikit-learn`包中的`accuracy_score`、`precision_score`和`recall_score`函数:

```
# accuracy
accuracy_score(actual, predictions)

# precision 
precision_score(actual, predictions)

# recall 
recall_score(actual, predictions)
```

从这段代码中可以看出，`accuracy_score`、`precision_score`和`recall_score`函数都有两个参数——真实标签和预测标签。看一下下面的输出:

![](assets/d6d2fa84-f2c8-4adc-95d2-47d878b3792f.png)

这个输出让我们对我们的模型在预测响应方面的表现有一个简要的了解。对于列车组，整体预测的准确性为`0.8724`，这意味着模型预测在大约`87%`的时间内是正确的。对于测试集，整体预测的准确度为`0.8818`，与训练集内的预测准确度大致相当。还可以看到，样本内和样本外预测的精度分别是`0.9919`和`0.9423`，召回是`0.1311`和`0.1324`。由于随机性和您可能使用的不同超参数，您可能会得到不同的结果。

我们要看的下一组指标是 ROC 曲线和 AUC。`scikit-learn`包中的`metrics`模块具有方便的 ROC 曲线和 AUC 函数。看一下下面的代码行:

```
from sklearn.metrics import roc_curve, auc
```

`scikit-learn`包的度量模块中的`roc_curve`函数计算 ROC，而`auc`函数计算 AUC。为了使用这些函数计算 ROC 和 AUC，我们需要首先从随机森林模型中获得预测概率。以下代码显示了我们如何获得随机森林模型对训练集和测试集的预测概率:

```
in_sample_preds = rf_model.predict_proba(x_train)[:,1]
out_sample_preds = rf_model.predict_proba(x_test)[:,1]
```

从这段代码中可以看出，我们正在使用随机森林模型`rf_model`的`predict_proba`函数。该函数输出给定记录属于每个类的预测概率。因为在我们的例子中只有两个可能的类，`0`表示没有响应，`1`表示有响应，`predict_proba`函数的输出有两列，其中第一列表示否定类的预测概率，这意味着每个记录都没有响应，第二列表示肯定类的预测概率，这意味着每个记录都有响应。因为我们只对回应营销努力的可能性感兴趣，所以我们可以用第二列来表示积极类的预测概率。

有了训练集和测试集的阳性类别的这些预测概率，我们现在可以计算 ROC 曲线和 AUC。让我们首先看看如何在下面的代码中使用`roc_curve`函数计算 ROC 曲线:

```
in_sample_fpr, in_sample_tpr, in_sample_thresholds = roc_curve(y_train, in_sample_preds)
out_sample_fpr, out_sample_tpr, out_sample_thresholds = roc_curve(y_test, out_sample_preds)
```

从这段代码中可以看出，`roc_curve`函数有两个参数——观察到的标签和预测的概率。这个函数返回三个变量，`fpr`、`tpr`和`thresholds`。`fpr`值代表每个给定阈值的假阳性率，而`tpr`值代表每个给定阈值的真阳性率。`thresholds`值代表测量`fpr`和`tpr`的实际阈值。

接下来，利用这些`fpr`和`tpr`值，我们可以使用以下代码计算 AUC:

```
in_sample_roc_auc = auc(in_sample_fpr, in_sample_tpr)
out_sample_roc_auc = auc(out_sample_fpr, out_sample_tpr)

print('In-Sample AUC: %0.4f' % in_sample_roc_auc)
print('Out-Sample AUC: %0.4f' % out_sample_roc_auc)
```

从这段代码中可以看出，`auc`函数有两个参数— `fpr`和`tpr`。使用之前从`roc_curve`函数中计算出的`fpr`和`tpr`值，我们可以很容易地计算出训练集和测试集的 AUC 数。输出如下所示:

![](assets/0bd94f4b-6d28-4250-a692-262db25c71ae.png)

根据随机森林算法中的超参数和随机性，您的 AUC 数字可能与这些示例不同。然而，在我们的例子中，样本内训练集 AUC 是`0.8745`，样本外测试集 AUC 是`0.8425`。如果您看到这两个数字之间有很大的差距，这是过度拟合的迹象，您应该通过调整超参数(如要分割的最大深度和最小样本数)来修剪森林中的树，从而尝试解决这个问题。

我们评估机器学习模型要看的最后一件事是实际的 ROC 曲线。利用`roc_curve`函数的输出，我们可以使用`matplotlib`包绘制实际的 ROC 曲线。看一下下面的代码:

```
plt.figure(figsize=(10,7))

plt.plot(
    out_sample_fpr, out_sample_tpr, color='darkorange', label='Out-Sample ROC curve (area = %0.4f)' % in_sample_roc_auc
)
plt.plot(
    in_sample_fpr, in_sample_tpr, color='navy', label='In-Sample ROC curve (area = %0.4f)' % out_sample_roc_auc
)
plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')
plt.grid()
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('RandomForest Model ROC Curve')
plt.legend(loc="lower right")

plt.show()
```

正如您在这段代码中看到的，我们绘制了三个线图—一个是样本外测试集 ROC 曲线，另一个是样本内训练集 ROC 曲线，最后一个是基准的直线。结果如下所示:

![](assets/0a2dedf6-0a8c-4f20-909b-6d231c502508.png)

从这个图中可以看出，使用 ROC 曲线可以更容易地看到和比较训练集和测试集之间模型的整体性能。样本内 ROC 曲线和样本外 ROC 曲线之间的差距越大，模型对训练集的过度拟合就越严重，并且不能对未预见数据的发现进行概括。

这个 Python 练习的完整代码可以在下面的链接中找到:[https://github . com/Yoon hwang/hands-on-data-science-for-marketing/blob/master/ch . 8/Python/predictingengagement . ipynb](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.8/python/PredictingEngagement.ipynb)



# 预测与 R 营销接触的可能性

在本节中，我们将讨论如何使用 r 中的机器学习算法构建预测模型。更具体地说，我们将学习如何使用随机森林算法构建预测模型，以及如何调整随机森林模型，并评估模型的性能。我们将主要使用`caTools`、`ROCR`和`randomForest`包来评估、可视化和构建预测客户营销参与可能性的机器学习模型。对于那些想在这个练习中使用 Python 而不是 R 的读者，您可以参考上一节。

在这个练习中，我们将使用来自 IBM 的一个公开可用的数据集，该数据集可以通过以下链接找到:[https://www . IBM . com/communities/analytics/Watson-analytics-blog/marketing-customer-value-analysis/](https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/)。您可以点击这个链接，下载 CSV 格式的数据，名为`WA_Fn UseC_ Marketing Customer Value Analysis.csv`。下载完这些数据后，您可以通过运行以下命令将其加载到 RStudio 中:

```
#### 1\. Load Data ####
df <- read.csv(
  file="~/Documents/data-science-for-marketing/ch.8/data/WA_Fn-UseC_-Marketing-Customer-Value-Analysis.csv", 
  header=TRUE
)
```

`df`外观如下:

![](assets/5ae79a64-9bbd-424d-9259-21bdec131954.png)

您可能已经注意到，这与我们在上一章进行客户分析时使用的数据集相同。根据我们在前一章中获得的关于该数据集的知识，我们将首先通过对目标变量和其他分类变量进行编码来准备我们的数据，我们将使用这些变量作为我们的机器学习模型的特征。



# 可变编码

为了在 R 中建立机器学习模型，数据集中的所有特征都需要有数值。然而，在数据集中，我们有许多列有非数字值。例如，目标变量`Response`，也就是我们试图用机器学习模型预测的变量，是非数字的。它包含两个字符串值— `Yes`或`No`。我们将需要用数值对这个`Response`目标变量进行编码，以便能够建立机器学习模型。再举一个例子，我们可以将`Gender`列用作预测模型的特性之一，它也没有数值。它包含两个字符串值—女性的`F`和男性的`M`。在本节中，我们将讨论如何对这些非数字列进行编码，以便在机器学习模型中使用它们作为特征。



# 响应变量编码

我们要做的第一件事是编码响应变量`Response`。我们将用`1` s 对`Yes`值进行编码，用`0` s 对`No`值进行编码。请看下面的代码:

```
## 2.1\. Response Variable: Response
df$Engaged <- as.integer(df$Response) - 1
```

从这段代码中可以看出，我们只是使用`as.integer`函数将`Response`列的值转换为整数值。我们之所以用`1`做减法，是因为它将值编码成`No`的`1`和`Yes`的`2`，而不是我们想要的`No`的`0`和`Yes`的`1`。然后，我们将这些编码值存储在一个新创建的列中，`Engaged`。为了使用这个新创建的列获得总体响应或参与度，您可以使用以下代码:

```
mean(df$Engaged)
```

总体参与率如下:

![](assets/aa44411e-2bd6-4206-938f-11a79d3908ec.png)



# 分类变量编码

如果您仔细观察数据，您会发现以下各列是我们数据集中的分类变量:

```
## 2.2\. Categorical Features

categoricalVars = c(
  'Sales.Channel', 'Vehicle.Size', 'Vehicle.Class', 'Policy', 'Policy.Type',
  'EmploymentStatus', 'Marital.Status', 'Education', 'Coverage', 'Gender'
)
```

这些变量有一组可以取的不同值，这些值不一定有相互区分的顺序。

如果您还记得第四章、*从约定到转换*中的[，我们讨论了如何在 r 中为这类分类变量创建因子变量。在本章中，我们将使用的方法是使用 r 中的`model.matrix`函数为每个分类变量类别创建虚拟变量。请看下面的代码:](a9f09970-4826-46d0-8bfd-5796702c5629.xhtml)

```
encodedDF <- model.matrix(~.-1, df[categoricalVars])
```

从这段代码中可以看出，为 R 中的分类变量创建虚拟变量很简单。您所需要做的就是对 R `DataFrame`的分类变量列应用`model.matrix`函数。如果你仔细观察代码，你会注意到我们在这里使用的`~.-1`公式。如果没有这个公式，`model.matrix`函数将在输出矩阵中创建一个不必要的名为`Intercept`的列。为了避免这个不必要的列，我们可以使用这个代码示例中的公式。新创建的`DataFrame` `encodedDf`的前几列如下所示:

![](assets/b03f57a2-e6e4-43cd-9918-6b10293bf4b2.png)

从这个输出中可以看到，这个新的`DataFrame`的每一列都代表了原始列中的每一个类别。例如，如果销售代理联系了给定的记录或客户，则第一列`Sales.ChannelAgent`用`1`编码，否则用`0`编码。再举一个例子，如果给定的记录或客户有中型汽车，第五列`Vehicle.SizeMedsize`用`1`编码，否则用`0`编码。

既然我们已经成功地用数值对所有分类变量进行了编码，我们需要将连续变量添加到这个新创建的`DataFrame`、`encodedDF`中。看一下下面的代码:

```
## 2.3\. Continuous Features
continuousFeatures <- c(
  'Customer.Lifetime.Value', 'Income', 'Monthly.Premium.Auto',
  'Months.Since.Last.Claim', 'Months.Since.Policy.Inception',
  'Number.of.Open.Complaints', 'Number.of.Policies', 'Total.Claim.Amount'
)

encodedDF <- cbind(encodedDF, df[continuousFeatures])
```

正如您从这段代码中看到的，我们使用了`cbind` R 函数，它按列组合了两个数据帧。我们将之前创建的包含所有编码分类变量的数据框架`encodedDF`与包含连续变量的数据框架相结合。然后，我们将这个组合的`DataFrame`存储回`encodedDF`变量。



# 构建预测模型

我们几乎准备好开始构建和训练机器学习模型，以预测客户的反应或参与。在开始训练随机森林模型之前，我们需要做一件事。我们需要将样本集`encodedDF`变量分成两个子集——一个用于训练模型，另一个用于测试和评估训练好的模型。R 包有一个方便的功能，可以将给定的样本集分成训练集和测试集。如果您的 R 环境中没有安装这个库，您可以使用下面的命令安装它:

```
install.packages('caTools')
```

现在，看一下下面的代码，它说明了如何将样本集分成训练集和测试集:

```
library(caTools)

sample <- sample.split(df$Customer, SplitRatio = .7)

trainX <- as.matrix(subset(encodedDF, sample == TRUE))
trainY <- as.double(as.matrix(subset(df$Engaged, sample == TRUE)))

testX <- as.matrix(subset(encodedDF, sample == FALSE))
testY <- as.double(as.matrix(subset(df$Engaged, sample == FALSE)))
```

让我们仔细看看这段代码。`caTools`包中的`sample.split`函数让我们将数据集分割成我们想要的比例。从这段代码中可以看出，我们将`SplitRatio`定义为`0.7`，这意味着我们将样本集的`70%`作为训练集，将`sample`集的剩余`30%`作为测试集。结果变量 sample 现在有一个布尔值数组，`TRUE`或`FALSE`，其中数组的`70%`是`TRUE`，其余的`30%`是`FALSE`。

有了这些数据，我们可以创建训练集和测试集。从代码中可以看出，我们使用 R 中的`subset`函数来创建训练集和测试集。首先，我们将那些对应于`sample`变量中的`TRUE`值的记录作为训练集。然后，我们将那些索引对应于`sample`变量中`FALSE`值的记录作为测试集。下面显示了样本集的训练集和测试集的细分:

![](assets/9b3580ee-87ad-4281-9f57-cc83a7323b88.png)

这里可以看到，`encodedDF`中共有`9,134`条记录，`trainX`中共有`6,393`条记录，`testX`中共有`2,741`条记录，也就是说样本集的大致`70%`进入了训练集，样本集的剩余`30%`进入了测试集。在接下来的部分中，我们将使用这些训练集和测试集来构建和评估模型。



# 随机森林模型

根据我们目前准备的数据，我们将使用随机森林算法建立一个预测模型，预测客户是否会响应或参与营销活动。我们将使用 R 库。如果您的 R 环境中没有安装这个库，您可以使用下面的命令安装它:

```
install.packages('randomForest')
```

一旦安装了这个包，就可以使用下面的代码来构建一个随机森林模型:

```
library(randomForest)

rfModel <- randomForest(x=trainX, y=factor(trainY))
```

但是，对于随机森林模型，您可以调整许多超参数。超参数是在训练机器学习模型之前定义的参数。例如，对于随机森林算法，您可以在随机森林模型中定义想要的树的数量。作为另一个例子，您可以为林中的每棵树定义最大终端节点数，这样您就可以限制林中每棵树可以增长到多大。

您可以定义和微调许多超参数。我们将看看其中的一些超参数:

*   这定义了你想要在森林里建造的树的数量。一般来说，树越多，性能越好。但是，随着林中树数量的增加，每增加一棵树的性能提升量会减少。由于林中有更多的树意味着训练额外的树的计算成本更高，所以您应该尝试找到平衡点，当训练额外的树的计算成本超过性能收益时，停止添加树。
*   **sampsize** :该参数定义了为训练每棵树而抽取的样本的大小。这在训练随机森林模型时在森林中引入了随机性。样本大小越高，森林的随机性就越小，过度拟合的可能性就越大。这意味着经过训练的树在训练集内执行和预测得很好，但是在它以前没有见过的数据集中预测得很差。减小样本大小有助于避免过度拟合，但是模型的性能通常会随着样本大小的减小而降低。
*   **nodesize** :该参数定义了终端节点的最小大小，即每个终端节点至少需要多少个样本。这个数字越大，树就越小。随着该数值的增加，可以缓解过度拟合问题，但会影响模型性能。
*   **maxnodes** :该参数定义了森林中每棵树可以拥有的最大终端节点数。如果你不设置这个数字，这个算法将使树增长到最大。这可能导致列车组过拟合。减少终端节点的最大数量可以帮助您克服过度拟合问题。

关于其他超参数更详细的描述和信息，可以参考官方文档，可以在以下链接找到:[https://www . rdocumentation . org/packages/random forest/versions/4.6-14/topics/random forest](https://www.rdocumentation.org/packages/randomForest/versions/4.6-14/topics/randomForest)。



# 训练随机森林模型

使用`randomForest`包训练一个随机森林模型很简单。看一下下面的代码:

```
rfModel <- randomForest(x=trainX, y=factor(trainY), ntree=200, maxnodes=24)
```

使用`randomForest`包中的`randomForest`函数，可以很容易地训练出一个随机的森林模型。您只需要向函数提供训练集。出于说明的目的，我们指示模型构建`200`树，其中每棵树只能生长到`24`终端节点。

当您运行这段代码时，您的模型对象将如下所示:

![](assets/9c563e81-5c46-48cd-a297-3f7600443bca.png)

一旦训练或拟合了随机森林模型，模型对象就包含了大量有用的信息。您可以从经过训练的随机森林模型中提取的一个有用属性是关于森林中每棵树的信息。使用`getTree`函数，您可以检索森林中的每棵树是如何构建的。看一下下面的例子:

![](assets/d829463f-5d3e-40ad-9886-e52700eec057.png)

这里我们正在查看关于森林中第一棵树的信息。这给了我们一些关于树的结构的信息。`left daughter`和`right daughter`列告诉我们这个节点在给定树中的位置。`status`列告诉我们该节点是终端(`-1`)还是非终端(`1`)。`prediction`列告诉我们来自这个节点的预测。

我们可以从拟合的随机森林模型中获得的其他信息是森林中每棵树的预测。看一下下面的代码:

```
predict(rfModel, trainX, predict.all=TRUE)
```

通过使用`predict.all=TRUE`标志，`prediction`函数返回森林中每棵树的预测。看一下下面的输出:

![](assets/09bc2153-ddd4-4d9c-bcd7-64668f852017.png)

此输出显示了训练集中前五个记录的前 20 棵树的预测。从这个输出可以看出，森林中的`10^(th)`树预测火车集合中的`5^(th)`记录是`1`的一个类，但是所有其他 19 棵树都预测火车集合中的`5^(th)`记录是`0`的一个类。从这个输出可以看出，不同的树对测试集的每条记录都有不同的预测。这是因为每棵树都是用随机选择的不同特征子集训练的。使用这些信息，您可以看到随机森林模型的最终预测是如何从这些单独的子估计量或树中形成的。

我们可以从经过训练的`randomForest`对象中获得的其他有用信息是特征重要性，通过它我们可以了解每个特征对最终预测的重要性或影响。您可以使用以下代码获得每个特性的特性重要性:

```
# - Feature Importances
importance(rfModel)
```

这段代码的部分输出如下所示:

![](assets/14bab6a6-f5a2-4ff3-9c5c-b40bb0a74b48.png)

从这个输出中可以看出，`EmploymentStatusRetired`特性似乎是做出最终预测的最重要因素，而`Income`、`Total.Claim.Amount`和`Customer.Lifetime.Value`特性紧随其后，成为第二、第三和第四重要的特性。



# 评估分类模型

在本章的前面，我们讨论了查看分类模型性能的五种不同方法。在这一节中，我们将学习如何使用我们刚刚构建的随机森林模型来计算和可视化用于评估 R 中的分类模型的指标。

我们要看的前三个指标是准确度、精确度和召回率。在我们继续评估模型性能之前，我们需要模型预测结果。为了让我们在上一节中构建的随机森林模型对数据集进行预测，我们可以简单地使用`predict`函数。看一下下面的代码:

```
inSamplePreds <- as.double(predict(rfModel, trainX)) - 1
outSamplePreds <- as.double(predict(rfModel, testX)) - 1
```

根据这些预测结果，我们将评估我们的随机森林模型在训练集和测试集中的表现。下面的代码展示了我们如何在 R 中计算准确度、精度和召回率:

```
# - Accuracy
accuracy <- mean(testY == outSamplePreds)

# - Precision
precision <- sum(outSamplePreds & testY) / sum(outSamplePreds)

# - Recall
recall <- sum(outSamplePreds & testY) / sum(testY)
```

使用这种方法，我们可以将样本内训练集`accuracy`、`precision`和`recall`与样本外测试集`accuracy`、`precision`和`recall`进行比较。看一下下面的输出:

![](assets/cc2daec3-a359-482b-b2d6-c4f83f2803b4.png)

这个输出让我们对我们的模型在预测响应方面的表现有一个简要的了解。对于列车组，整体预测的准确性为`0.8756`，这意味着模型预测在大约`88%`的时间内是正确的。对于测试集，整体预测的准确性为`0.8636`。你还可以发现，样本内和样本外预测的精度分别是`0.9717`和`0.8980`，召回是`0.1151`和`0.1065`。由于随机性和您可能使用的不同超参数，您可能会得到不同的结果。

我们要看的下一组指标是 ROC 曲线和 AUC。我们将使用`ROCR` R 包。如果您的 R 环境中没有安装这个包，您可以使用下面的命令安装它:

```
install.packages('ROCR')
```

首先看一下 ROC 曲线和 AUC 数的以下代码:

```
library(ROCR)

inSamplePredProbs <- as.double(predict(rfModel, trainX, type='prob')[,2])
outSamplePredProbs <- as.double(predict(rfModel, testX, type='prob')[,2])

pred <- prediction(outSamplePredProbs, testY)
perf <- performance(pred, measure = "tpr", x.measure = "fpr") 
auc <- performance(pred, measure='auc')@y.values[[1]]

plot(
  perf, 
  main=sprintf('Random Forest Model ROC Curve (AUC: %0.2f)', auc), 
  col='darkorange', 
  lwd=2
) + grid()
abline(a = 0, b = 1, col='darkgray', lty=3, lwd=2)
```

我们需要做的第一件事是从我们建立的模型中获得预测的概率。使用`predict`函数和`type='prob'`标志，我们可以从随机森林模型中获得预测的概率。然后，我们使用`ROCR`包中的`prediction`功能。该函数计算 ROC 曲线所需的不同概率临界值下的真阳性和假阳性的数量。使用`prediction`函数的输出，我们可以通过`ROCR`包中的`performance`函数得到不同概率截止值下的真阳性率和假阳性率。最后，为了获得 AUC 数，我们可以使用带有不同标志的同一个`performance`函数`measure='auc'`。

有了这些数据，我们现在可以绘制 ROC 曲线。使用`plot`函数和`perf`变量，即`performance`函数的输出，我们可以绘制 ROC 曲线。情节看起来如下:

![](assets/6e8169d1-ce56-4e05-b2af-e80266d6f90a.png)

从这个图中可以看出，我们的随机森林模型的 AUC 是`0.76`。与代表随机线的基准直线相比，模型表现得更好，这表明模型预测比随机预测好得多。

这个 R 练习的完整代码可以在下面的链接找到:[https://github . com/Yoon hwang/hands-on-data-science-for-marketing/blob/master/ch . 8/R/predicting engagement。R](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.8/R/PredictingEngagement.R) 。



# 摘要

在本章中，我们讨论了预测分析及其在营销中的应用。我们首先讨论了什么是预测分析，以及它如何用于各种其他行业，如金融和医疗保健行业。然后，我们讨论了预测分析在营销中的四个常见用例——参与可能性、客户终身价值、推荐正确的产品和内容，以及客户获取和保留。预测分析在营销中还有许多其他的用例，因此我们建议您关注预测分析在营销行业中的最新应用。然后，我们讨论了评估预测模型性能的五种不同方法——准确度、精确度、召回率、ROC 曲线和 AUC。

在下一章中，我们将扩展我们的预测分析知识。我们将讨论衡量客户终身价值的概念和重要性，以及为客户终身价值预测建立机器学习模型。