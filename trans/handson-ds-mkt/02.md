

# 数据科学和营销

欢迎来到*营销数据科学实践*的第一章！您可能已经熟悉了，数据科学在营销行业中的重要性和应用在过去几年中一直在显著上升。然而，营销数据科学是一个相对较新的领域，可用于教育和参考的资源数量落后于发展势头。然而，该流程收集和可用的数据量每年都呈指数级增长，这为从数据中学习和获得洞察力提供了更多机会。

随着数据量的增长和数据科学在营销中的应用，我们可以很容易地找到数据科学用于营销工作的例子。公司开始使用数据科学来更好地了解客户行为，并根据他们的活动模式识别不同的客户群。许多组织还使用机器学习来预测未来的客户行为，例如他们可能会购买什么商品，他们可能会访问哪些网站，以及谁可能会流失。随着数据科学用于营销的案例层出不穷，各种规模的公司都可以从将数据科学和机器学习用于营销工作中受益。在这简短的介绍性章节之后，我们将了解如何将数据科学和机器学习应用于个人营销任务。

在本章中，我们将讨论以下主题:

*   营销趋势
*   数据科学在市场营销中的应用
*   设置 Python 环境
*   设置 R 环境



# 技术要求

你需要安装 Python 和 R 来运行整本书的大部分代码，你可以在下面的链接找到安装代码:[https://github . com/packt publishing/Hands-On-Data-Science-for-Marketing/tree/master/chapter 01](https://github.com/PacktPublishing/Hands-On-Data-Science-for-Marketing/tree/master/Chapter01)。



# 营销趋势

随着可用和收集的数据量每年呈指数级增长，访问这些有价值的数据集变得更加容易，数据科学和机器学习已经成为营销不可或缺的一部分。数据科学在市场营销中的应用范围广泛，从构建有洞察力的报告和仪表盘到利用复杂的机器学习算法来预测客户行为或让客户参与产品和内容。近年来，市场营销的趋势是更加数据驱动的目标营销。我们将讨论我们在营销行业看到的一些趋势:

*   数字营销日益重要:随着人们花在网上的时间比以往任何时候都多，数字营销的重要性和有效性也与日俱增。许多营销活动现在都发生在数字渠道上，如搜索引擎、社交网络、电子邮件和网站。例如，谷歌广告通过其搜索引擎、Gmail 或 YouTube 帮助你的品牌获得更多的潜在客户。您可以轻松地定制您的目标受众，您希望向他们展示您的广告。脸书和 Instagram 是两个著名的社交网络，你可以在那里发布广告，以接触到你的目标客户。在互联网时代，这些营销渠道变得比电视广告等传统营销渠道更具成本效益。以下是谷歌提供的不同数字营销渠道的例子(【https://ads.google.com/start/how-it-works/?】T2)subid = us-en-ha-g-aw-c-dr _ df _ 1-b _ ex _ pl！O2 ~-1072012490-284305340539-KWD-94527731):

![](assets/cec322da-75fc-44a4-b1d6-84df1155f5bc.png)

*   **营销分析**:营销分析是一种监控和分析营销工作表现的方法。它不仅可以帮助你了解你从营销中获得了多少销售额或曝光率，还可以帮助你更深入地了解更多个人层面的模式和趋势。在电子商务业务中，您可以利用营销分析分析和可视化不同类型和细分的客户，以及哪种类型的客户最能为您的企业带来收入。在媒体行业，通过营销分析，你可以分析哪些内容最吸引用户，以及关键词搜索的趋势是什么。营销分析还可以帮助您了解营销活动的成本效益。通过研究**投资回报率** ( **投资回报率**)，你可以进一步优化你未来的营销活动。随着营销分析的采用和使用的增加，不难发现各种营销分析软件产品。
*   **个性化和目标营销**:随着数据科学和机器学习在营销中的应用日益增多，营销的另一个趋势是个人层面的目标营销。不同规模的各种组织利用机器学习算法从用户历史数据中学习，并对其用户群中更小和更具体的子群应用不同和专门的营销策略，从而降低每次采购的成本，提高投资回报。在零售业务中，许多公司实施人工智能和机器学习来预测哪些客户更有可能购买，以及他们将从他们的商店购买哪些商品。利用这些预测，他们为每个客户定制营销信息。许多媒体企业还利用人工智能和机器学习来提高个人用户的参与度，以扩大他们的用户群。由于这些定制和目标营销带来了更高的投资回报率，因此有许多 SaaS 公司，如 Sailthru 和 Oracle，提供个性化营销的平台。Sailthru 最近发布了一份*零售个性化指数*报告，该报告分析了各种零售公司如何在不同的营销渠道中使用个性化营销。在这份报告中，我们可以发现零售公司，如丝芙兰、JustFab 和沃尔玛，在其网站、电子邮件和其他营销渠道中大量使用个性化营销。这份报告可以在这个链接找到:【https://www.sailthru.com/personalization-index/sailthru100/[。](https://www.sailthru.com/personalization-index/sailthru100/)

市场营销的总体趋势是更加数据驱动和量化的方法。各种规模的公司越来越多地投资于营销分析和技术。根据 2018 年 2 月的 CMO 调查，对营销分析的依赖在过去 5 年中从 30%上升到 42%。B2C 公司对营销分析的依赖程度甚至更高，增长了 55%。此外，在过去 5 年中，使用定量工具来展示营销影响的公司数量增加了 28%。最后，CMO 的调查表明，利用人工智能和机器学习的公司比例预计将在未来 3 年内增加到 39%。你可以在以下链接找到关于这份 2018 年 2 月 CMO 调查报告的更多细节:[https://www . Forbes . com/sites/Christine moorman/2018/02/27/marketing-analytics-and-marketing-technology-trends-to-watch/# 4 EC 8a 8431 b 8 a](https://www.forbes.com/sites/christinemoorman/2018/02/27/marketing-analytics-and-marketing-technology-trends-to-watch/#4ec8a8431b8a)。



# 数据科学在市场营销中的应用

我们讨论了市场营销的趋势，以及这种趋势如何走向更多的数据驱动和量化营销，通常使用数据科学和机器学习。在营销行业中应用数据科学和机器学习有多种方式，讨论数据科学和机器学习的典型任务和用法对我们来说将是有益的。

在本节中，我们将介绍机器学习的基础知识、不同类型的学习算法以及典型的数据科学工作流程和过程。



# 描述性对比解释性对比预测性分析

当我们在接下来的章节中完成练习和项目时，我们将在本书中主要进行三种不同类型的分析:描述性分析、解释性分析和预测性分析:

*   **描述性分析:**这是为了更好地理解和描述给定的数据集。这种分析的目的是从数量上和统计上总结数据所包含的信息。例如，如果您正在对用户购买历史数据进行描述性分析，您将会回答这样的问题:*什么是最畅销的商品？* *过去一年的月销售额如何？* *售出商品的平均价格是多少？在本书中，每当我们引入一个新的数据集时，我们都会进行描述性分析。特别是，在[第 2 章](1fb7a852-d8fa-43f6-9807-6e3292dfa280.xhtml)、*关键表现指标和可视化*中，我们将更详细地讨论如何使用描述性分析来分析和计算关键汇总统计数据，以及可视化分析结果。*
*   **解释性分析**:当描述性分析的目的是从数据中回答*什么*和*如何*时，解释性分析就是利用数据回答*为什么*。这种类型的分析通常在您有一个想要回答的特定问题时进行。举个电子商务的例子，如果你想分析是什么驱使你的用户购买，你应该进行解释性分析，而不是描述性分析。我们将在[第 3 章](ce2c2775-9817-4b18-972c-db8e8c629b74.xhtml)、*营销参与背后的驱动因素中讨论更多关于此类分析的细节；*和[第 4 章](a9f09970-4826-46d0-8bfd-5796702c5629.xhtml)、*从参与到转化*，我们将使用解释性分析来回答诸如*什么促使用户更多地参与我们的营销活动？*和 **是什么让用户购买我们零售店的物品？**
*   **预测分析**:当有一个特定的未来事件你想要预测时，进行这种分析。这种分析的目的是建立从历史数据中学习的机器学习模型，并对未来将发生的事件进行预测。与前面的电子商务和购买历史数据的示例类似，您可以从这种类型的分析中回答的问题之一可能是，*哪个用户最有可能在未来七天内进行购买？*通常，为了进行预测分析，您必须首先运行描述性和解释性分析，以更好地理解数据，并就给定项目使用何种类型的学习算法和方法产生想法。我们将在[第 6 章](d3ba7047-2873-4b03-9a44-4c1d55b84178.xhtml)、*推荐合适的产品*、[第 8 章](4f5163a1-c34a-495f-bc5f-e02f9b2a2052.xhtml)、*预测营销参与的可能性*和[第 11 章](3d5c7798-6874-40e9-b7e9-6fe39592cc2a.xhtml)、*留住客户*中更详细地讨论预测分析及其在营销中的应用。



# 学习算法的类型

现在让我们讨论更多关于机器学习和机器学习算法的内容。从广义上讲，有三种类型的机器学习算法:监督学习、非监督学习和强化学习。让我们首先了解一下这三种不同类型的机器学习算法之间的区别:

*   **监督学习算法:**当预测目标或结果已知时，使用这些算法。例如，如果我们想使用机器学习来预测未来几天谁会进行购买，那么我们将使用监督学习算法。这里，预测目标或结果是这个人是否在给定的时间窗口内进行了购买。基于历史购买数据，我们将需要构建描述每个数据点的特征，例如用户的年龄、地址、上次购买日期，然后监督学习算法将从这些数据中学习如何将这些特征映射到预测目标或结果。我们将在[第 3 章](ce2c2775-9817-4b18-972c-db8e8c629b74.xhtml)、*营销参与背后的驱动因素中探讨如何在营销中使用这些算法；* [第四章](a9f09970-4826-46d0-8bfd-5796702c5629.xhtml)，*从订婚到皈依；* [第 8 章](4f5163a1-c34a-495f-bc5f-e02f9b2a2052.xhtml)，*预测营销参与的可能性*，最后[第 11 章](3d5c7798-6874-40e9-b7e9-6fe39592cc2a.xhtml)，*留住客户*。
*   **无监督学习算法:**与监督学习算法不同，当我们没有特定的预测目标或结果时，会使用无监督学习算法。这种类型的机器学习算法经常用于聚类和推荐系统。例如，您可以使用无监督学习算法，根据客户的行为，将您的客户群分为不同的子群或细分市场。在这种情况下，我们没有想要预测的具体目标或结果。我们只是将相似的客户分成不同的类别。我们将在[第 6 章](d3ba7047-2873-4b03-9a44-4c1d55b84178.xhtml)、*推荐合适的产品*和[第 10 章](5955002d-2a75-4d5a-aa6a-86710a3bf00e.xhtml)、*数据驱动的客户细分*中探索如何在营销中使用无监督学习算法。
*   **强化学习算法:**当我们希望模型在没有先验知识或经验的情况下，不断地学习和训练自己时，就会用到这些算法。在强化学习的情况下，模型在大量的试验和错误之后学习如何做出预测。强化学习在营销中应用的一个例子是，当有多种营销策略时，你想测试并选择一种最有效的。在这种情况下，你可以运行一个强化学习算法，它一次随机选择一个策略，并在出现积极结果时获得奖励。在多次反复试验和错误之后，强化学习模型将学会根据每种营销策略获得的总回报来选择最佳营销策略。



# 数据科学工作流程

既然我们已经介绍了基础知识和不同类型的机器学习算法，那么让我们讨论一下数据科学中的工作流。典型的工作流如下所示:

1.  **问题定义**:通常，任何数据科学和机器学习项目都是从问题定义开始的。在第一步中，您需要定义您试图用数据科学解决的问题、项目的范围以及解决该问题的方法。当你考虑解决问题的一些方法时，你将需要头脑风暴什么类型的分析(描述性对解释性对预测性)和我们之前讨论的学习算法类型(监督对非监督对强化学习)将适合解决给定的问题。

2.  数据收集:一旦你对项目有了清晰的定义，你将进入数据收集阶段。这是您收集数据科学项目所需的所有数据的地方。您需要从第三方供应商那里购买数据，从 web 上抓取和提取数据，或者使用公开可用的数据，这种情况并不少见。在某些情况下，您还需要从项目的内部系统中收集数据。根据具体情况，数据收集步骤可能是琐碎的，也可能是繁琐的。
3.  **数据准备**:当你从数据收集步骤中收集了所有你需要的数据后，下一步就是数据准备。这一步的目标是转换您的数据，并为以后的步骤做好准备。如果数据源的格式不同，那么您必须转换和统一数据。如果数据没有特定的结构，那么您将不得不结构化数据，通常以表格格式，以便您可以轻松地进行不同的分析并建立机器学习模型。
4.  **数据分析**:当你完成数据准备步骤后，你将不得不开始研究数据。在数据分析步骤中，通常会进行描述性分析，以计算一些描述性汇总统计数据，并构建可视化图表来更好地理解数据。通常，在这个步骤中，您可以找到一些可识别的模式，并从数据中获得一些洞察力。通过这一步，您还可以发现数据中的任何异常，例如缺少的值、损坏的数据或重复的记录。
5.  **特征工程**:特征工程是数据科学和机器学习中最重要的部分，因为它直接影响预测模型的性能。特征工程需要专业知识和良好的数据领域知识，因为它需要您将原始数据转换为更丰富的数据，以便算法进行学习。特征工程的一个很好的例子是将文本数据转换成数字数据。由于机器学习算法只能从数字数据中学习，因此您需要提出一个想法和策略来将文本数据转换为数字数据。当我们阅读这本书和建立机器学习模型时，我们将讨论和实验各种特征工程技术。
6.  **模型构建**:一旦你完成了特征工程步骤，那么你就可以开始训练和测试你的机器学习模型了。在这一步中，您可以尝试各种学习算法，找出最适合您的用例的算法。在这一步要记住的一件事是验证指标。对你的模型性能有一个好的度量是很重要的，因为机器学习算法会尝试对给定的性能度量进行优化。当我们在接下来的章节中开始构建机器学习模型时，我们将根据我们正在处理的问题的类型，更详细地讨论使用什么样的度量标准。

下图显示了典型数据科学项目的整体工作流程:

![](assets/dfaf7e80-93c7-41cf-8f13-3432f6b09620.png)

从这张图中可以看出，数据科学工作通常不会在一次迭代中结束。当您发现模型表现不佳，并且您发现可以改善输入数据的质量时，您可能需要重复数据收集步骤。当您对从原始数据集构建要素有了更好的想法和策略时，您可能需要重新考虑要素工程步骤。如果您认为可以通过调整学习算法的超参数来改善模型结果，您可能还需要多次重复模型构建步骤。当我们学习下面的章节以及本书中的实际项目和练习时，我们将更详细地讨论某些步骤和我们可以使用的不同技术。



# 设置 Python 环境

既然我们已经讨论了数据科学的一些基础知识及其在市场营销中的应用，让我们开始为即将到来的章节和项目准备开发环境。对于那些将在练习中使用 R 语言的人，您可以跳过这一部分，转到*设置 R 环境*部分。对于那些计划使用 Python 语言进行练习的人来说，遵循这些步骤来安装所有必需的 Python 包并准备好 Python 环境将是有益的，即使您已经熟悉 Python。



# 安装 Anaconda 发行版

对于本书中的数据科学和机器学习任务，我们将使用许多不同的 Python 包。举几个例子，我们将使用`pandas`包进行数据管理和数据分析。你可以在以下链接找到更多关于这个套餐的信息:[https://pandas.pydata.org/](https://pandas.pydata.org/)。我们还将使用`scikit-learn`包来构建机器学习模型。更多关于这个套餐的信息，可以访问以下页面:[http://scikit-learn.org/stable/](http://scikit-learn.org/stable/)。另一个我们会经常使用的 Python 包是`numpy`。当我们需要对多维数据进行数学和科学运算时，这个软件包会派上用场。你可以在这个页面找到更多关于这个包的信息:[http://www.numpy.org/](http://www.numpy.org/)。除了我们刚刚提到的这三个包之外，我们还将使用一些其他的 Python 库，在使用它们的时候，我们将分别详细讨论它们。

因为我们需要各种 Python 库来完成数据科学和机器学习任务，所以单独安装它们有时会很麻烦。多亏了 Anaconda 发行版，我们可以一次安装所有需要的包。为了下载 Anaconda 发行版，请访问[https://www.anaconda.com/download/](https://www.anaconda.com/download/)来安装它。当您点击此链接时，网页应该如下所示:

![](assets/f26c6554-80e1-4fc5-a888-d20a39fb9b01.png)

在本书中，我们将在 Python 3 中使用 Anaconda 5.2。一旦下载了 Anaconda 发行版，就可以使用安装程序安装所有的包。在 macOS 上，安装程序如下所示:

![](assets/b7fdf858-628d-46bc-8d30-0de516b96c36.png)

一旦您按照安装程序中的步骤完成了 Anaconda 发行版的安装，我们现在就可以开始运行数据科学和机器学习任务了。在下一节中，我们将构建一个简单的逻辑回归模型，以熟悉如何使用我们刚刚为将来的练习安装的关键 Python 库。



# Python 中一个简单的逻辑回归模型

现在我们已经安装了所有的包，让我们测试一下是否可以使用它们。我们将使用 Jupyter 笔记本进行所有未来的数据分析、数据可视化和机器学习任务。Jupyter Notebook 是一个开源的 web 应用程序，在这里您可以轻松地编写代码、显示图表以及与他人共享笔记本。你可以在这个链接找到更多关于 Jupyter 笔记本的信息:[http://jupyter.org/](http://jupyter.org/)。

因为 Jupyter 笔记本是我们在上一节中刚刚安装的 Anaconda 发行版的一部分，所以您应该已经在您的计算机中安装了它。

要启动 Jupyter 笔记本，您可以打开终端窗口并键入以下命令:

```
jupyter notebook
```

当您键入此命令时，您应该会看到类似于以下屏幕截图的输出:

![](assets/15287607-aba6-40b9-a07e-137e5869c551.png)

最后，它应该会在您的浏览器上打开一个 web 应用程序。web 用户界面应该如下所示:

![](assets/8c27f056-8e1b-4680-a23b-bdf5d111be94.png)

从这张截图可以看出，点击右上角的新建按钮，然后点击 Python 3，就可以创建一个新的 Jupyter 笔记本。这将创建一个新的空笔记本，使用 Python 3 作为编程语言的选择。新笔记本应该如下所示:

![](assets/6a3af3da-81e2-4aa8-86b8-47e31a989584.png)

为了改变这个笔记本的名字，你可以简单的点击顶栏，上面写着`Untitled`，用不同的名字命名。

现在我们已经创建了一个笔记本，让我们开始使用一些 Python 库来构建一个简单的逻辑回归模型。在第一个单元格中，我们将导入`numpy`和`scikit-learn`包。代码如下所示:

```
import numpy as np
from sklearn.linear_model import LogisticRegression
```

从这个代码片段中可以看到，我们已经导入了`numpy`包，并给了它一个别名`np`。这是`numpy`库的标准别名。另外，我们只导入了`scikit-learn`包的`linear_model`模块(`sklearn.linear_model`)中的`LogisticRegression`模块。

为了建立一个模型，我们需要数据。在本章中，出于演示和测试目的，我们将创建二维输入数据和二进制输出。以下代码显示了我们如何创建输入和输出数据:

```
input_data = np.array([
    [0, 0],
    [0.25, 0.25],
    [0.5, 0.5],
   [1, 1],
])

output_data = [
    0,
    0,
    1,
    1
]
```

正如您在这个代码片段中看到的，我们用`numpy`数组数据类型创建了 4 x 2 输入数据。输出是二进制的，这里只能取`0`或`1`。

有了这些数据，我们可以训练一个逻辑回归模型，如下面的代码所示:

```
logit_model = LogisticRegression()
logit_model.fit(input_data, output_data)
```

从这段代码中可以看出，我们用`LogisticRegression`实例化了一个模型对象。然后，我们使用了`fit`函数，它接受输入和输出数据，来训练一个逻辑回归模型。您可以检索此逻辑回归模型的系数和截距，如以下代码所示:

```
logit_model.coef_    # output: array([[0.43001235, 0.43001235]])
logit_model.intercept_    # output: array([-0.18498028])
```

到目前为止，我们的 Jupyter 笔记本如下所示:

![](assets/19cab5a6-5274-480c-bd0a-0a40dcc33d59.png)

为了对新数据进行预测，您可以使用逻辑回归模型对象`logit_model`的`predict`函数。该函数将返回每个输入的预测输出类。代码如下所示:

```
predicted_output = logit_model.predict(input_data)
```

到目前为止，我们已经试验了如何使用`numpy`和`scikit-learn`包来构建机器学习模型。让我们熟悉另一个数据可视化包。在本书的各个章节中，我们将大量利用`matplotlib`库来可视化任何数据分析结果。更多信息，可以访问这个页面:[https://matplotlib.org/](https://matplotlib.org/)。

让我们先来看看下面的代码:

```
import matplotlib.pyplot as plt

plt.scatter(
    x=input_data[:,0], 
    y=input_data[:,1], 
    color=[('red' if x == 1 else 'blue') for x in output_data]
)
plt.xlabel('X')
plt.ylabel('Y')
plt.title('Actual')
plt.grid()
plt.show()
```

从这个代码片段中可以看到，您可以轻松地导入`matplotlib`包，如该代码的第一行所示。为了构建一个散点图，我们使用了`scatter`函数，它接受`x`和`y`值，以及每个点的`color`。您可以使用`xlabel`功能更改 *x* 轴的标签，使用`ylabel`功能更改 *y* 轴的标签。使用`title`功能，您可以更改图表的标题。`grid`函数将显示图形中的网格，您需要调用`show`函数来实际显示图形。

Jupyter 笔记本应该如下所示:

![](assets/eef5e2b7-80c5-4bd8-b0cc-01b01b54e05e.png)

这里需要注意的一点是下面的代码:

```
%matplotlib inline
```

这是在 web 应用程序中显示图所必需的。如果没有这行代码，这些图将不会显示在 web UI 中。为了将实际输出与模型预测进行比较，我们用预测值构建了另一个散点图。

代码和情节如下所示:

![](assets/4ce91ee3-c659-4da0-9e9c-6f8feb5ba05b.png)

如果您将此图表与上一个图表进行比较，您会发现该模型四次中有三次预测正确，一次预测错误。

您可以从以下链接下载我们在本节中使用的完整 Jupyter 笔记本:[https://github . com/Yoon hwang/hands-on-data-science-for-marketing/blob/master/ch . 1/python/Setting % 20 up % 20 python % 20 environment . ipynb](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.1/python/Setting%20Up%20Python%20Environment.ipynb)。

在本书中，我们将会经常用到这三个 Python 库，我们刚刚对它们进行了实验。随着章节的深入，我们将会介绍这些 Python 库的更多高级特性和功能，以及如何在我们的数据科学和机器学习任务中充分利用它们。



# 设置 R 环境

对于那些计划在即将到来的练习和项目中使用 R 语言的人，我们将在本书中讨论如何为数据科学和机器学习任务准备好 R 环境。我们将从安装 R 和 RStudio 开始，然后使用 R 构建一个简单的逻辑回归模型，以熟悉数据科学中的 R。



# 安装 R 和 RStudio

与 Python 一起，R 是数据科学和机器学习中最常用的语言之一。它非常易于使用，并且有大量用于机器学习的 R 库，这一事实吸引了许多数据科学家。为了使用这种语言，你需要从以下链接下载:[https://www.r-project.org/](https://www.r-project.org/)。如果您转到这个网页，它将类似于下面的屏幕截图:

![](assets/de2e1020-8601-4aad-ad8e-1b219960bf91.png)

你可以在这个网页上找到更多关于 R 的信息。为了让你下载，请点击本页的下载链接。它会让你选择一面镜子。你可以选择离你最近的位置下载 R，下载完成后，你就可以按照安装程序里的步骤，在你的电脑里安装 R 了。macOS 上的安装程序如下图所示:

![](assets/fda32aae-ce25-4b89-b391-08ab51fe0c7a.png)

一旦你完成了 R 的安装，我们将为我们的 R 开发环境再安装一个东西。在本书中，我们将使用 RStudio，这是一种流行的 R 编程语言 IDE。你可以在以下链接下载 r studio:[https://www.rstudio.com/products/rstudio/download/](https://www.rstudio.com/products/rstudio/download/)。当您转到这个 RStudio 下载页面时，它应该看起来像下面的屏幕截图:

![](assets/f300bc29-063b-43d4-a084-4f52339d760c.png)

在本书中，我们将使用 RStudio 桌面开源许可版本，但是如果您已经为其他人获得了许可，也可以随意使用其他版本。下载并安装 RStudio 后，当您打开 RStudio 时，将会看到类似下面的屏幕截图:

![](assets/6132f932-c55e-4124-b4eb-d9efd7d92c38.png)

现在我们已经准备好了 R 环境，让我们构建一个简单的逻辑回归模型来进一步熟悉 R。



# R 中一个简单的 logistic 回归模型

让我们通过在 R 中构建一个简单的逻辑回归模型来测试我们的环境设置。您可以使用以下代码在 R 中创建数据框:

```
# Input Data
data <- data.frame(
  "X"=c(0, 0.25, 0.5, 1), 
  "Y"=c(0, 0.5, 0.5, 1), 
  "output"=c(0, 0, 1, 1)
)
```

从这个代码片段中可以看出，我们构建了一个包含列`X`、`Y`和`output`的数据框架。`X`列取值为`0`、`0.25`、`0.5`和`1`。`Y`列的值为`0`、`0.5`、`0.5`和`1`。`output`是一个二进制类，可以是`0`也可以是`1`。`data`外观如下:

![](assets/6320e186-c7c7-478c-a7bd-cad771ff78f0.png)

现在我们已经有了用来训练逻辑回归模型的数据，让我们来看看下面的代码:

```
# Train logistic regression
logit.fit <- glm(
  output ~ X + Y, 
  data = data, 
  family = binomial
)
```

如这段代码所示，我们使用 R 中的`glm`函数来拟合逻辑回归模型。由于`glm`函数用于拟合任何线性模型，我们需要定义我们想要训练的模型的变量`family`。为了训练逻辑回归，我们在`glm`函数中使用`binomial`作为`family`参数。第一个参数`output ~ X + Y`定义了该模型的公式，而`data`参数用于定义用来训练该模型的数据帧。

在 R 中，您可以使用`summary`函数来获得拟合的逻辑回归模型的细节，如下面的代码所示:

```
# Show Fitted Results
summary(logit.fit)
```

这将输出类似下面的截图:

![](assets/08db8d9a-38c7-407e-a559-5d43463f91bd.png)

从这个输出可以看出，我们可以很容易地找到模型的系数和截距。我们将在本书中频繁使用这个`summary`函数，以便更好地理解训练好的模型。

使用经过训练的模型，我们可以使用以下代码对新数据进行预测:

```
# Predict Class Probabilities
logit.probs <- predict(
  logit.fit, 
  newdata=data, 
  type="response"
)

# Predict Classes
logit.pred <- ifelse(logit.probs > 0.5, 1, 0)    
logit.pred    # output: 0 0 1 1
```

正如您在这段代码中看到的，我们使用了`predict`函数来对经过训练的模型`logit.fit`和参数`newdata`中定义的新数据进行预测。该`predict`函数将输出新数据中每个例子的概率或可能性；为了将这个输出转换成一个二进制类，我们可以使用`ifelse`函数将任何高于阈值(在本例中为`0.5`)的输出编码为`1`，其余的编码为`0`。

最后，让我们快速地看一下如何在 R 中构建绘图。我们将使用一个 R 包`ggplot2`来绘制整本书。因此，熟悉如何导入这个绘图库并将其用于数据可视化将对您有所帮助。如果您是第一次使用这个包，那么当您尝试导入`ggplot2`包时，您很可能会看到以下错误消息:

![](assets/9d6a11b3-b01a-4b18-b3d5-3490306685a5.png)

正如消息所说，软件包`ggplot2`尚未安装在您的机器上。为了安装任何 R 包，您可以简单地运行以下命令:

```
install.packages('ggplot2')
```

如果运行此命令，您将看到如下输出:

![](assets/b0ce690c-8af7-4c4b-ae9c-f53fc0944a1e.png)

一旦这个库的安装完成，您就可以导入和使用这个库了。我们将使用`ggplot2`库构建一个简单的散点图，如下面的代码片段所示:

```
# Plotting Library
library(ggplot2)

# Simple Scatterplot
ggplot(data, aes(x=X, y=Y, color=output)) +
  geom_point(size=3, shape=19) +
  ggtitle('Actual') +
  theme(plot.title = element_text(hjust = 0.5))
```

从这段代码中可以看出，您可以使用`ggplot2`包的`ggplot`函数，用`data`构建一个散点图。为了改变散点图上的点的形状和大小，可以使用`geom_point`功能。您也可以使用`ggtitle`功能来更改情节的标题。当您运行此代码时，您将看到下图:

![](assets/ac63a363-159f-4887-a7e3-2a4cc71abbbf.png)

我们将为预测结果运行相同的任务。代码如下所示:

```
ggplot(data, aes(x=X, y=Y, color=logit.pred)) + 
  geom_point(size=3, shape=19) +
  ggtitle('Predicted') +
  theme(plot.title = element_text(hjust = 0.5))
```

输出如下所示:

![](assets/a1d9b743-6dbb-4a3d-a1e4-b3932868564b.png)

在本书中，我们将大量使用这些函数和绘图库，`ggplot2`，所以随着我们章节和练习的进行，你将会越来越熟悉 R 语言的编码，以及使用这些其他的库。

您可以从以下链接查看和下载本节使用的完整 R 代码:[https://github . com/Yoon hwang/hands-on-data-science-for-marketing/blob/master/ch . 1/R/setting up environment。R](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.1/R/SettingUpREnvironment.R) [。](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.1/R/SettingUpREnvironment.R)



# 摘要

在这一章中，我们讨论了营销的整体趋势，并了解了数据科学和机器学习在营销行业中日益增长的重要性。随着数据量的增加，以及我们观察到利用数据科学和机器学习进行营销的好处，各种规模的公司都在投资建立更多数据驱动和量化的营销战略。

我们还学习了不同类型的分析方法，尤其是我们将在本书中经常使用的三种类型的分析——描述性的、解释性的和预测性的——以及这些分析的不同用例。在这一章中，我们讨论了不同类型的机器学习算法，以及数据科学中的典型工作流程。最后，我们花了一些时间在 Python 和 R 中设置我们的开发环境，并通过构建一个简单的逻辑回归模型测试我们的环境设置。

在下一章中，我们将回顾一些**关键表现指标**(**KPI**)以及如何可视化这些关键指标。我们将学习如何使用不同的包，如`pandas`、`numpy`和`matplotlib`，在 Python 中计算和构建这些 KPI 的可视化图。对于那些使用 R 语言学习本书中的练习的人，我们还将讨论如何使用 R 来计算和绘制这些 KPI，使用 R 中的各种统计和数学函数以及用于可视化的`ggplot2`包。