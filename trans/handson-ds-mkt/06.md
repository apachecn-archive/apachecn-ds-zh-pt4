

# 四、从参与到转化

在本章中，我们将扩展您的解释性分析知识，并向您展示如何使用**决策树**来理解消费者行为背后的驱动因素。我们将从比较和解释逻辑回归和决策树模型之间的差异开始，然后我们将讨论决策树是如何构建和训练的。接下来，我们将讨论如何使用经过训练的决策树模型来提取关于个体消费者的属性(或特征)和目标输出变量之间的关系的信息。

对于编程练习，我们将使用来自 UCI 机器学习知识库的银行营销数据集来理解转化背后的驱动因素。我们将从一些数据分析开始，让你更好地理解数据集；然后，我们将通过使用 Python 中的`scikit-learn`包和 r 中的`rpart`包来构建决策树模型。最后，您将学习如何通过使用 Python 中的`graphviz`包和 r 中的`rattle`包来可视化这些经过训练的决策树模型，从而解释它们。在本章结束时，您将熟悉决策树，并将更好地理解何时以及如何在 Python 或 r 中使用它们

在本章中，我们将讨论以下主题:

*   决策树
*   决策树和 Python 解释
*   决策树和 R 解释



# 决策树

在前一章中，我们讨论了解释性分析和回归分析。我们将继续这个主题，并介绍另一种机器学习算法，我们可以用它来从数据中获得对客户行为的见解。在本章中，我们将讨论一种叫做**决策树** : 的机器学习算法，它们如何从数据中学习，以及我们如何解释它们的结果。



# 逻辑回归与决策树

如果你还记得上一章，一个**逻辑回归**模型从数据中学习，找到特征变量的线性组合，最好地估计一个事件发生的对数概率。决策树，顾名思义，通过生长一棵树来学习数据。我们将在下一节中更详细地讨论决策树模型如何增长和构建树，但逻辑回归和决策树模型之间的主要区别在于，逻辑回归算法在特征集中搜索单个最佳线性边界，而决策树算法对数据进行分区，以找到事件发生可能性高的数据子组。用一个例子来解释这个会更容易。让我们来看看下图:

![](assets/8d0bb394-1e86-48ec-9bfd-8c8bda7e1d97.png)

这是一个决策树模型的例子。正如您在此图中看到的，它根据特定标准对数据进行了分区。在这个例子中，根节点通过标准`previous < 0.5`被分割成子节点。如果满足这个条件并且为真，那么它将遍历到左边的子节点。如果不是，那么它遍历到右边的子节点。然后，左边的子节点按照标准`age < 61`被分割成它的子节点。该树一直增长，直到它找到纯节点(意味着每个节点中的所有数据点都属于一个类)或者直到它满足某个停止标准，例如树的最大深度。

正如您在本例中看到的，数据被分成了七个分区。底部最左边的节点或分区是那些值小于`previous`变量的`0.5`和值小于`age`变量的`61`的数据点。另一方面，底部最右边的节点是那些值大于`previous`变量的`0.5`且值不同于`housing`变量的`yes`的数据点。

这里值得注意的一点是，不同变量之间有很多相互作用。在这个示例树中，没有单个叶节点是用一个条件划分的。该树中的每个分区都由多个标准和不同`feature`变量之间的相互作用形成。这是与逻辑回归模型的主要区别。当数据中没有线性结构时，逻辑回归模型将不能很好地执行，因为它们试图在特征变量之间找到线性组合。另一方面，决策树模型对于非线性数据集会表现得更好，因为它们只尝试在最纯粹的级别上对数据进行分区。



# 成长决策树

当我们在生长决策树时，这些树需要提出一个逻辑来将一个节点分割成子节点。常用的数据拆分方法主要有两种:**基尼杂质**和**熵信息增益**。简而言之，*基尼*杂质衡量一个分区的不纯程度，熵信息增益衡量它从使用被测试的标准拆分数据中获得了多少信息。

让我们快速浏览一下计算*基尼系数*杂质指标的等式:

![](assets/dcc06319-5223-49a9-bbff-b4475b53664f.png)

这里， *c* 代表类别标签，*P[I]代表类别标签 *i* 被选择的记录的概率。通过从 1 中减去概率的平方和， *Gini* 杂质度量达到零，也就是说，当树的每个分区或节点中的所有记录都是具有单个目标类别的纯记录时。*

计算熵的方程式如下:

![](assets/85b079d0-d694-434a-a6eb-ae22b25f62f5.png)

像以前一样， *c* 代表类别标签，*P[I]代表类别标签为 *i* 的记录被选中的概率。在生长树时，需要计算每个可能分裂的熵，并与分裂前的熵进行比较。然后，将选择在熵度量中给出最大变化或最高信息增益的分裂来生长树。这个过程将被重复，直到所有的节点都是纯的，或者直到它满足停止标准。*



# 决策树和 Python 解释

在本节中，您将学习如何使用 Python 中的`scikit-learn`包来构建决策树模型，并使用 Python 的`graphviz`包通过可视化来解释结果。对于那些想在这个练习中使用 R 而不是 Python 的读者，您可以跳到下一节。我们将从使用`pandas`和`matplotlib`软件包深入分析银行营销数据集开始这一部分，然后我们将讨论如何构建和解释决策树模型。

在这个练习中，我们将使用来自 https://archive.ics.uci.edu/ml/datasets/bank+marketing[的 UCI 机器学习库的公开可用数据集之一。您可以通过链接下载 ZIP 格式的数据。在这个练习中，我们将使用`bank.zip`文件。当你解压这个文件时，你会看到两个 CSV 文件:`bank.csv`和`bank-full.csv`。在这个 Python 练习中，我们将使用`bank-full.csv`文件。](https://archive.ics.uci.edu/ml/datasets/bank+marketing)

为了将这些数据加载到您的 Jupyter 笔记本中，您可以运行以下代码:

```py
%matplotlib inline

import matplotlib.pyplot as plt
import pandas as pd

df = pd.read_csv('../data/bank-full.csv', sep=";")
```

从这个代码片段中可以看出，我们使用了`%matplotlib inline`命令来显示 Jupyter 笔记本上的绘图。然后，我们导入将用于数据分析步骤的`matplotlib`和`pandas`包。最后，我们可以通过使用`pandas`包中的`read_csv`函数轻松读取数据文件。这里需要注意的一点是`read_csv`函数中的`sep`参数。如果仔细观察数据，您会注意到`bank-full.csv`文件中的字段由分号(`;`)分隔，而不是逗号(`,`)。为了正确地将数据加载到`pandas` DataFrame 中，我们需要告诉`read_csv`函数使用分号作为分隔符，而不是逗号。

一旦您加载了数据，它应该看起来像下面的截图:

![](assets/edd8cfd2-6ceb-4846-aab1-752933a982c3.png)



# 数据分析和可视化

在我们开始分析数据之前，我们将首先对输出变量`y`进行编码，该变量包含关于客户是否转换或订阅了定期存款的信息，并带有数值。您可以使用以下代码用零和一对输出变量`y`进行编码:

```py
df['conversion'] = df['y'].apply(lambda x: 0 if x == 'no' else 1)
```

从这段代码中可以看出，可以使用`apply`函数对输出变量进行编码。我们将这些编码值存储在一个名为`conversion`的新列中。



# 汇率

我们先来看看总转化率。**转换率**简单来说就是定期存款客户的百分比。看一下下面的代码:

```py
conversion_rate_df = pd.DataFrame(
    df.groupby('conversion').count()['y'] / df.shape[0] * 100.0
)
```

从这个代码片段中可以看出，我们按照列`conversion`进行分组，对于那些已经订阅了定期存款的，列编码为`1`，对于那些没有订阅的，列编码为`0`。然后，我们计算每个组中的客户数量，并将其除以数据集中的客户总数。结果如下所示:

![](assets/99f9f19c-3871-4394-bd59-55c3fce7f530.png)

为了更容易查看，您可以通过使用`pandas`数据帧的`T`属性来转置数据帧。如你所见，只有大约 11.7%的人被转换或认购了定期存款。从这些结果中，我们可以看到转换组和非转换组之间存在很大的不平衡，这是常见的，并且在各种营销数据集中经常观察到。



# 按职务列出的转换率

某些工作类别比其他工作类别更容易转换，这可能是真的。让我们来看看不同工作类别的转化率。您可以通过使用以下代码来实现这一点:

```py
conversion_rate_by_job = df.groupby(
    by='job'
)['conversion'].sum() / df.groupby(
    by='job'
)['conversion'].count() * 100.0
```

让我们更深入地看看这段代码。我们首先按照列`job`进行分组，该列包含关于每个客户所属的工作类别的信息。然后，我们对每个工作类别的`conversion`列求和，从中我们得到每个工作类别的转换总数。最后，我们将这些转换率除以每个工作类别中的客户总数，以获得每个工作类别的转换率。

结果如下所示:

![](assets/e5a1ed43-084d-475a-b90a-3346bd87687a.png)

从这些结果中可以看出，`student`组比其他组转换得更频繁，其次是`retired`组。然而，从原始输出中比较这些数据有点困难，我们可以通过使用图表更好地展示这些数据。我们可以使用下面的代码构建一个水平条形图:

```py
ax = conversion_rate_by_job.plot(
    kind='barh',
    color='skyblue',
    grid=True,
    figsize=(10, 7),
    title='Conversion Rates by Job'
)

ax.set_xlabel('conversion rate (%)')
ax.set_ylabel('Job')

plt.show()
```

如果你看看这段代码，我们正在使用`pandas`数据帧的`plot`函数，并且我们通过提供`barh`作为`kind`参数的输入，将该图的类型定义为水平条形图。您可以分别使用`color`、`figsize`和`title`参数简单地调整图表的颜色、大小和标题。您还可以使用`set_xlabel`和`set_ylabel`功能轻松更改 *x* 轴和 *y* 轴标签。

生成的图表如下所示:

![](assets/3b42d4b7-1d54-4889-977a-3a30c5dd02a4.png)

正如你所看到的，用一个水平条形图可以更容易地发现每个工作类别的转换率的差异。我们很容易看到，`student`和`retired`组是转化率最高的两组，而`blue-collar`和`entrepreneur`组是转化率最低的两组。



# 按转换列出的违约率

客户的另一个有趣的属性是违约率，以及定期存款和非定期存款之间的差异。我们将使用`pandas`库中的`pivot_table`函数来分析转换率的违约率。让我们来看看下面的代码:

```py
default_by_conversion_df = pd.pivot_table(
    df, 
    values='y', 
    index='default', 
    columns='conversion', 
    aggfunc=len
)
```

从这段代码中可以看出，我们通过`y`和`default`列旋转了数据帧`df`。通过使用`len`作为聚合函数，我们可以计算数据透视表的每个单元格下有多少客户。结果如下所示:

![](assets/8257487f-4abc-4403-b5d1-6cb79ec4fc94.png)

通过观察这些原始数据，比较转换组和非转换组之间的违约率差异有点困难。直观显示这些数据的一种方式是通过饼图。您可以使用以下代码来构建饼图:

```py
default_by_conversion_df.plot(
    kind='pie',
    figsize=(15, 7),
    startangle=90,
    subplots=True,
    autopct=lambda x: '%0.1f%%' % x
)

plt.show()
```

从这段代码中可以看出，我们只是将`'pie'`作为输入传递给`plot`函数的`kind`参数。生成的饼图如下所示:

![](assets/eba95421-1547-4767-aadd-5494b5440972.png)

从这些饼图中可以看出，比较转换组和非转换组的违约率要容易得多。虽然两组中以前违约的总百分比都很低，但非转换组的违约率大约是转换组的两倍。



# 按兑换列出的银行余额

接下来，我们将尝试查看转换组和非转换组之间的银行余额分布是否有任何差异。箱线图通常是可视化变量分布的好方法。让我们来看看下面的代码:

```py
ax = df[['conversion', 'balance']].boxplot(
    by='conversion',
    showfliers=True,
    figsize=(10, 7)
)

ax.set_xlabel('Conversion')
ax.set_ylabel('Average Bank Balance')
ax.set_title('Average Bank Balance Distributions by Conversion')

plt.suptitle("")
plt.show()
```

现在你应该对这段代码很熟悉了，因为我们已经讨论了如何使用`pandas`包构建盒状图。使用`boxplot`功能，我们可以轻松地构建如下所示的箱线图:

![](assets/f7970841-e6de-49b0-a7b1-1f4c8084aa40.png)

因为有如此多的异常值，所以很难识别这两种分布之间的任何差异。让我们建立另一个没有异常值的箱形图。与前面的代码相比，唯一需要更改的是`boxplot`函数中的`showfliers=True`参数，如下面的代码所示:

```py
ax = df[['conversion', 'balance']].boxplot(
    by='conversion',
    showfliers=False,
    figsize=(10, 7)
)

ax.set_xlabel('Conversion')
ax.set_ylabel('Average Bank Balance')
ax.set_title('Average Bank Balance Distributions by Conversion')

plt.suptitle("")
plt.show()
```

使用此代码，您将看到以下两组银行余额分布的箱线图:

![](assets/5c8dbee9-2db5-4d9d-bb6a-c721e18d129b.png)

从这些箱线图中，我们可以看到，与非转换组相比，转换组的银行余额的中位数略高。此外，转换客户的银行余额似乎比非转换客户的变化更大。



# 按联系人数列出的转换率

最后，我们将看看转化率是如何随着联系人数的变化而变化的。通常，在营销中，更多的营销接触会导致营销疲劳，当你更频繁地接触客户时，转化率会下降。让我们看看我们的数据中是否存在营销疲劳。看一下下面的代码:

```py
conversions_by_num_contacts = df.groupby(
    by='campaign'
)['conversion'].sum() / df.groupby(
    by='campaign'
)['conversion'].count() * 100.0
```

在这个代码片段中，您可以看到我们按照`campaign`列进行分组(该列包含关于在营销活动期间为该客户执行的联系次数的信息),并计算每个联系次数的转化率。结果数据如下所示:

![](assets/db83f22a-027b-4c4c-aac7-b418f88aa2f0.png)

像以前一样，看图表比看原始数据更容易。我们可以使用条形图绘制这些数据，代码如下:

```py
ax = conversions_by_num_contacts.plot(
    kind='bar',
    figsize=(10, 7),
    title='Conversion Rates by Number of Contacts',
    grid=True,
    color='skyblue'
)

ax.set_xlabel('Number of Contacts')
ax.set_ylabel('Conversion Rate (%)')

plt.show()
```

情节看起来如下:

![](assets/6cbe0312-537f-4600-b2f6-e49f6a64e8ef.png)

在更多的接触中有一些噪音，因为他们的样本量较小，但你可以很容易地在这个条形图中看到整体下降的趋势。随着接触次数的增加，转化率慢慢降低。这表明，对于给定的活动，随着您与客户联系的频率增加，预期转化率会降低。



# 编码分类变量

在这个数据集中有八个分类变量:`job`、`marital`、`education`、`default`、`housing`、`loan`、`contact`和`month`。在我们开始构建决策树之前，我们需要用数值对这些分类变量进行编码。在这一节中，我们将看看如何对这些分类变量进行编码。



# 编码月份

我们都知道`month`变量只能有 12 个唯一值。让我们快速看一下我们的数据集中有什么。看一下下面的代码:

```py
df['month'].unique()
```

`pandas`函数`unique`帮助您快速获得给定列中的唯一值。当您运行此代码时，您将获得以下输出:

![](assets/57913c36-6c06-41d1-bea1-943abd0d37bf.png)

正如所料，从 1 月到 12 月，`month`列有 12 个唯一值。由于`month`的值有自然的顺序，我们可以用相应的数字对每个值进行编码。用数字编码`month`字符串值的一种方法如下所示:

```py
months = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']

df['month'] = df['month'].apply(
    lambda x: months.index(x)+1
)
```

使用此代码，列`month`的唯一值如下所示:

![](assets/3311d783-0ac2-4a7f-9157-7083a3a88926.png)

要查看每个月有多少条记录，我们可以使用下面的代码:

```py
df.groupby('month').count()['conversion']
```

结果如下:

![](assets/aae40fb2-16e3-4a60-ba13-4afb2472f525.png)



# 编码作业

接下来，让我们看看如何对`job`列的不同类别进行编码。我们将首先使用以下代码查看该列中的唯一值:

```py
df['job'].unique()
```

`job`列中的唯一值如下所示:

![](assets/b7e7b157-3f55-40e3-b11e-01ce1297c386.png)

正如您在这个输出中看到的，这个变量没有自然的顺序。一个`job`类别不在另一个类别之前，所以我们不能像对`month`那样编码这个变量。我们将为每个`job`类别创建虚拟变量。如果您回忆一下上一章，如果给定的记录属于该类别，那么一个**虚拟变量**是一个用`1`编码的变量，如果不属于该类别，则用`0`编码。我们可以通过使用下面的代码轻松做到这一点:

```py
jobs_encoded_df = pd.get_dummies(df['job'])
jobs_encoded_df.columns = ['job_%s' % x for x in jobs_encoded_df.columns]
```

从这段代码中可以看到，`pandas`包中的`get_dummies`函数为`job`变量中的每个类别创建了一个虚拟变量，如果给定的记录属于相应的类别，则用`1`对每个记录进行编码，否则用`0`进行编码。然后，我们通过在每列前面加上前缀`job_`来重命名这些列。结果如下所示:

![](assets/aa02a263-7126-4b15-a075-8e0c219d860d.png)

从这张截图可以看出，第一条记录(或客户)属于`management`工作类别，而第二条记录属于`technician`工作类别。既然我们已经为每个作业类别创建了虚拟变量，我们需要将这些数据追加到现有的数据框架中。看一下下面的代码:

```py
df = pd.concat([df, jobs_encoded_df], axis=1)
df.head()
```

使用`pandas`包中的`concat`函数，您可以很容易地将新创建的带有虚拟变量`jobs_encoded_df`的数据帧添加到原始数据帧`df`中。`axis=1`参数告诉`concat`函数将第二个数据帧作为列而不是行连接到第一个数据帧。生成的数据帧如下所示:

![](assets/0895e1e0-aa45-40b8-9e99-a680449c2c17.png)

如您所见，新创建的虚拟变量作为每条记录的新列被添加到原始数据帧中。



# 婚姻编码

类似于我们如何对分类变量`job`进行编码，我们将为`marital`变量的每个类别创建虚拟变量。像以前一样，我们使用下面的代码对`marital`列进行编码:

```py
marital_encoded_df = pd.get_dummies(df['marital'])
marital_encoded_df.columns = ['marital_%s' % x for x in marital_encoded_df.columns]
```

编码结果如下:

![](assets/56513a91-bce6-454c-939a-8a8c3b51cb84.png)

如您所见，为原始变量创建了三个新变量，`marital` : `marital_divorced`、`marital_married`和`marital_single`，分别代表给定客户是离婚、结婚还是单身。为了将这些新创建的虚拟变量添加到原始数据帧中，我们可以使用以下代码:

```py
df = pd.concat([df, marital_encoded_df], axis=1)
```

一旦您完成了这一步，您的原始数据框架，`df`，应该包含所有的原始列，加上为`job`和`marital`列新创建的虚拟变量。



# 住房和贷款变量编码

我们将在本节中编码的最后两个分类变量是`housing`和`loan`。`housing`变量有两个唯一的值，`'yes'`和`'no'`，包含客户是否有住房贷款的信息。另一个变量`loan`也有两个唯一值`'yes'`和`'no'`，并告诉我们客户是否有个人贷款。通过使用以下代码，我们可以很容易地对这两个变量进行编码:

```py
df['housing'] = df['housing'].apply(lambda x: 1 if x == 'yes' else 0)

df['loan'] = df['loan'].apply(lambda x: 1 if x == 'yes' else 0)
```

如您所见，我们使用`apply`函数将`yes`编码为`1`，将`no`编码为`0`，用于住房和贷款变量。对于我们在本节中没有讨论的分类变量，如果您希望在本练习之外进行探索，可以使用我们已经讨论过的相同技术对它们进行编码。



# 构建决策树

既然我们已经编码了所有的分类变量，我们终于可以开始构建决策树模型了。我们将在决策树模型中使用以下变量作为特征:

![](assets/33e32db6-b239-4b18-b1f5-13d2e9086fac.png)

为了用 Python 构建和训练决策树模型，我们将使用`scikit-learn` ( `sklearn`)包中的`tree`模块。您可以使用以下代码行导入所需的模块:

```py
from sklearn import tree
```

在`sklearn`包的`tree`模块下，有一个名为`DecisionTreeClassifier`的类，我们可以用它来训练一个决策树模型。看一下下面的代码:

```py
dt_model = tree.DecisionTreeClassifier(
    max_depth=4
)
```

除了我们在这里使用的`max_depth`之外，`DecisionTreeClassifier`类有许多参数。`max_depth`参数控制一棵树可以生长多少，在这里，我们将其限制为`4`，这意味着从根到叶子的最大长度可以是`4`。您还可以使用`criterion`参数在基尼系数和熵信息增益之间进行选择，以衡量分割的质量。还有许多其他方法可以优化您的决策树模型，我们建议您仔细阅读位于[http://sci kit-learn . org/stable/modules/generated/sk learn . tree . decision tree classifier . html](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)的文档，以获取更多信息。

为了训练这个决策树模型，可以使用下面的代码:

```py
dt_model.fit(df[features], df[response_var])
```

从这段代码中可以看出，`fit`函数有两个参数:`predictor`或`feature`变量和`response`或`target`变量。在我们的例子中，`response_var`是数据帧`df`的`conversion`列。一旦运行了这段代码，决策树模型将学习如何进行分类。在下一节中，我们将讨论如何解释这个经过训练的决策树模型的结果。



# 解释决策树

既然我们已经训练了一个决策树模型，我们需要从模型中提取洞察力。在这一节中，我们将使用一个名为`graphviz`的包。您可以在终端中使用以下命令安装该软件包:

```py
conda install python-graphviz
```

正确安装该软件包后，您应该能够按如下方式导入该软件包:

```py
import graphviz
```

现在我们已经用新的包`graphviz`设置了我们的环境，让我们看一下下面的代码，看看我们如何可视化经过训练的决策树:

```py
dot_data = tree.export_graphviz(
    dt_model, 
    feature_names=features, 
    class_names=['0', '1'], 
    filled=True, 
    rounded=True, 
    special_characters=True
) 

graph = graphviz.Source(dot_data)
```

如您所见，我们首先使用`sklearn`包的`tree`模块中的`export_graphviz`函数导出训练好的决策树模型`dt_model`。我们可以通过使用`feature_names`参数来定义用于训练该模型的特征变量。然后，我们可以定义这个模型被训练来分类的类别(转换与非转换)。`export_graphviz`函数将训练好的决策树模型以点格式导出，这是一种图形描述语言。然后您可以将`dot_data`传递给`graphviz` `Source`类。`graph`变量现在包含一个可呈现的图形。根节点及其直接子节点如下所示:

![](assets/d20c75f2-fa12-4a5b-8ee3-bd4e5fc9d310.png)

左半部分的树(或根节点左子节点的子节点)如下所示:

![](assets/5e156f7d-b72b-4e9f-956c-d646b7f276cf.png)

右半部分的树(或根节点右子节点的子节点)如下所示:

![](assets/852140bc-7f6a-4553-b94c-b0373d043921.png)

让我们仔细看看这张图。每个节点包含五行，描述给定节点拥有的信息。最上面一行告诉我们分割的标准。例如，根节点根据`previous`变量的值被分割成子节点。如果这个`previous`变量的值小于或等于`0.5`，那么它将转到左边的子变量。另一方面，如果这个`previous`变量的值大于`0.5`，那么它就转到正确的子变量。

第二行告诉我们分割的质量度量值。这里，我们选择了`gini`杂质度量作为标准，因此我们可以从第二行看到每个节点中杂质度量的变化。第三行告诉我们属于给定节点的记录总数。例如，根节点中有`45,211`个样本，根节点的右子节点中有`8,257`个样本。

每个节点中的第四行告诉我们两个不同类中记录的组成。第一个元素表示非转换组中的记录数，第二个元素表示转换组中的记录数。例如，在根节点中，非转换组中有`39,922`条记录，转换组中有`5,289`条记录。最后，每个节点中的第五行告诉我们给定节点的预测或分类是什么。例如，如果一个样本属于最左边的叶子，这个决策树模型的分类将是`0`，意味着非转换。另一方面，如果一个样本属于左起第八个叶子，则该决策树模型的分类将是`1`，意味着转换。

现在我们知道了每个节点中的每条线的含义，让我们来讨论如何从这个树形图中获得洞察力。为了了解属于每个叶节点的客户，我们需要遍历树。例如，那些属于左起第八个叶节点的客户是那些具有`previous`变量的`0`值、`age`大于`60.5`、具有`1`值的`marital_divorced`变量和具有`1`值的`job_self-employed`变量的客户。换句话说，这次活动之前没有接触过的，年龄大于`60.5`的，离异的，个体户的，都属于这个节点，转化的几率很大。

让我们看另一个例子。属于从右数第二个叶节点的客户是那些对`previous`变量的值为`1`、`housing`变量的值为`1`、`age`大于`60.5`、`balance`小于或等于`4,660.5`的客户。换句话说，在此活动之前联系的那些有住房贷款、年龄大于`60.5`且银行余额小于`4,660.5`的客户属于此节点，并且属于此节点的`29`中的`20`已经转换并订阅了定期存款。

正如您从这两个例子中注意到的，通过可视化训练树，您可以得出关于谁更有可能或更不可能从训练决策树模型转换的有用见解。您只需要跟踪节点，并理解哪些类型的属性与您的目标类高度相关。在本练习中，我们将树限制为只能生长到深度`4`，但是您可以选择生长比我们在本练习中使用的树更大或更小的树。

本章 Python 练习的完整代码可以在资源库中找到，网址为[https://github . com/Yoon hwang/hands-on-data-science-for-marketing/blob/master/ch . 4/Python/From % 20 engagement % 20 to % 20 conversions . ipynb](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.4/python/From%20Engagement%20to%20Conversions.ipynb)。



# 决策树和 R 解释

在本节中，您将学习如何使用 R 中的`rpart`包来构建决策树模型，并通过 R `rattle`包的可视化来解释结果。对于那些想在本练习中使用 Python 而不是 R 的读者，您可以阅读上一节中的 Python 示例。我们将从使用`dplyr`和`ggplot2`库深入分析银行营销数据集开始这一部分，然后我们将讨论如何构建和解释决策树模型。

在这个练习中，我们将使用来自 https://archive.ics.uci.edu/ml/datasets/bank+marketing[的 UCI 机器学习库的公开可用数据集之一。您可以通过链接下载 ZIP 格式的数据。在这个练习中，我们将使用`bank.zip`文件。当你解压这个文件时，你会看到两个 CSV 文件:`bank.csv`和`bank-full.csv`。在这个练习中，我们将使用`bank-full.csv`文件。](https://archive.ics.uci.edu/ml/datasets/bank+marketing)

为了将这些数据加载到 RStudio 中，您可以运行以下代码:

```py
df <- read.csv(
  file="../data/bank-full.csv", 
  header=TRUE, 
  sep=";"
)
```

从这段代码片段中可以看出，我们可以通过使用 r 中的`read.csv`函数轻松读取数据文件。这里需要注意的一点是`read.csv`函数中的`sep`参数。如果仔细观察数据，您会注意到`bank-full.csv`文件中的字段是用分号(`;`)分隔的，而不是逗号(`,`)。为了正确地将数据加载到 DataFrame 中，我们需要告诉`read.csv`函数使用分号作为分隔符，而不是逗号。

一旦您加载了这些数据，它应该看起来像下面的截图:

![](assets/de1dbdf1-84f4-4b82-ad07-743d1e2b754f.png)



# 数据分析和可视化

在我们开始分析数据之前，我们将首先对输出变量`y`进行编码，该变量包含关于客户是否转换或订阅了定期存款的信息，并带有数值。您可以使用以下代码用零和一对输出变量`y`进行编码:

```py
# Encode conversions as 0s and 1s
df$conversion <- as.integer(df$y) - 1
```

从这段代码中可以看出，可以使用`as.integer`函数对输出变量进行编码。由于该函数将把`y`变量中的`no`值编码为`1`，把`y`变量中的`yes`值编码为`2`，我们用`1`减去这些值，分别编码为`0`和`1`。我们将这些编码值存储到一个名为`conversion`的新列中。



# 汇率

我们首先要看的是总转换率。转换率就是定期存款客户的百分比，或者在列`conversion`中用`1`编码的客户的百分比。看一下下面的代码:

```py
sprintf("conversion rate: %0.2f%%", sum(df$conversion)/nrow(df)*100.0)
```

从这个代码片段中可以看到，我们简单地将`conversion`列中的所有值相加，然后除以数据帧中的记录数或客户数`df`。使用`sprintf`函数，我们用两个小数点来格式化这个转换率数字。结果如下所示:

![](assets/c21a0e9b-e719-424d-ba6c-f915041eecc7.png)

正如您从这个输出中看到的，只有大约`11.7%`被转换或订阅为定期存款。从这些结果中，我们可以看到转换组和非转换组之间存在很大的不平衡，这是相当普遍的，并且在各种营销数据集中经常观察到。



# 按职务列出的转换率

某些工作类别比其他工作类别更容易转换，这可能是真的。让我们来看看不同工作类别的转化率。您可以通过运行以下代码来实现这一点:

```py
conversionsByJob <- df %>% 
  group_by(Job=job) %>% 
  summarise(Count=n(), NumConversions=sum(conversion)) %>%
  mutate(ConversionRate=NumConversions/Count*100.0)
```

让我们更详细地看看这段代码。我们首先按照列`job`进行分组，该列包含关于每个客户所属的工作类别的信息。然后，我们使用`n()`函数计算给定工作类别中的客户总数，并使用`sum`函数对每个工作类别的`conversion`列求和。最后，我们用转换总数`NumConversion`除以每个工作类别的客户总数`Count`，然后用这些数字乘以`100.0`得到每个工作类别的转换率。

结果如下所示:

![](assets/d05fb8b6-299f-466b-b73b-4fb7093fff02.png)

从这些结果中可以看出，`student`组比其他组转换得更频繁，其次是`retired`组。然而，将这些与原始输出进行比较有点困难，我们将能够通过使用图表更好地呈现这些数据。我们可以使用下面的代码构建一个水平条形图:

```py
ggplot(conversionsByJob, aes(x=Job, y=ConversionRate)) +
  geom_bar(width=0.5, stat="identity") +
  coord_flip() +
  ggtitle('Conversion Rates by Job') +
  xlab("Job") +
  ylab("Conversion Rate (%)") +
  theme(plot.title = element_text(hjust = 0.5)) 
```

如果你看看这段代码，我们正在使用`ggplot`和`geom_bar`函数用`conversionsByJob`数据(我们在前面的代码中构建的)构建一个条形图，在 *x* 轴中使用`Job`变量，在 *y* 轴中使用`ConversionRate`变量。然后，我们使用`coord_flip`函数将垂直条形图翻转为水平条形图。您可以使用`ggtitle`、`xlab`和`ylab`功能随意更改标题、 *x* 轴标签和 *y* 轴标签。

生成的图表如下所示:

![](assets/cbd51610-3022-4180-b258-0618f507ee19.png)

正如你所看到的，用一个水平条形图可以更容易地看到每个工作类别的转换率的差异。我们很容易看到，`student`和`retired`组是转化率最高的两组，而`blue-collar`和`entrepreneur`组是转化率最低的两组。



# 按转换列出的违约率

客户的另一个有趣的属性是违约率，以及定期存款和非定期存款之间的差异。我们来看看下面的 R 代码:

```py
defaultByConversion <- df %>% 
  group_by(Default=default, Conversion=conversion) %>% 
  summarise(Count=n())
```

从这段代码中可以看出，我们使用`group_by`函数，通过`default`和`conversion`两列对数据帧`df`进行分组。通过使用`n()`作为聚合函数，我们可以计算四种情况下每个单元下有多少客户。让我们看看下面的结果:

![](assets/320df0e0-2b56-4fc7-8c26-e85a4ed037e9.png)

从这些原始数据来看，比较转换组和非转换组之间的违约率差异有点困难。直观显示这些数据的一种方式是通过饼图。您可以使用以下代码来构建饼图:

```py
ggplot(defaultByConversion, aes(x="", y=Count, fill=Default)) + 
  geom_bar(width=1, stat = "identity", position=position_fill()) +
  geom_text(aes(x=1.25, label=Count), position=position_fill(vjust = 0.5)) +
  coord_polar("y") +
  facet_wrap(~Conversion) +
  ggtitle('Default (0: Non Conversions, 1: Conversions)') +
  theme(
    axis.title.x=element_blank(),
    axis.title.y=element_blank(),
    plot.title=element_text(hjust=0.5),
    legend.position='bottom'
  )
```

如您所见，我们在这里使用了三个函数:`ggplot`、`geom_bar`和`coord_polar("y")`。通过`coord_polar("y")`函数，我们可以从条形图中得到饼状图。然后，我们可以使用`facet_wrap`函数将它分成两个饼图:一个是转化组的饼图，另一个是非转化组的饼图。

看看下面的饼图:

![](assets/1fe05b29-dda3-45fa-bd31-a123981a2bc1.png)

从这些饼图中可以看出，比较转换组和非转换组的违约率要容易得多。虽然两组中以前违约的总百分比都很低，但非转换组的违约率大约是转换组的两倍。



# 按兑换列出的银行余额

接下来，我们将尝试查看转换组和非转换组之间的银行余额分布是否有任何差异。箱线图通常是可视化变量分布的好方法。让我们来看看下面的代码:

```py
ggplot(df, aes(x="", y=balance)) + 
  geom_boxplot() +
  facet_wrap(~conversion) +
  ylab("balance") +
  xlab("0: Non-Conversion, 1: Conversion") +
  ggtitle("Conversion vs. Non-Conversions: Balance") +
  theme(plot.title=element_text(hjust=0.5))
```

现在你应该对这段代码很熟悉了，因为我们在上一章讨论了如何使用`ggplot`和`geom_boxplot`函数构建盒状图。当您运行此代码时，您将看到下面的方框图:

![](assets/f3aa26a3-e3d0-4b3d-b3b2-04c62b23b2ab.png)

因为有如此多的异常值，所以很难识别这两种分布之间的任何差异。让我们建立另一个没有异常值的箱形图。与前面的代码相比，唯一需要更改的是`geom_boxplot`函数中的`outlier.shape = NA`参数，如下面的代码所示:

```py
ggplot(df, aes(x="", y=balance)) + 
  geom_boxplot(outlier.shape = NA) +
  scale_y_continuous(limits = c(-2000, 5000)) +
  facet_wrap(~conversion) +
  ylab("balance") +
  xlab("0: Non-Conversion, 1: Conversion") +
  ggtitle("Conversion vs. Non-Conversions: Balance") +
  theme(plot.title=element_text(hjust=0.5))
```

使用此代码，您将看到以下两个组之间银行余额分布的箱线图:

![](assets/237999b5-a990-408b-8fd1-a96d7a52acbe.png)

从这些箱线图中，我们可以看到，与非转换组相比，转换组的银行余额的中位数略高。此外，转换客户的银行余额似乎比非转换客户的变化更大。



# 按联系人数列出的转换率

最后，我们将看看转化率是如何随着联系人数的变化而变化的。通常，在市场营销中，大量的营销接触会导致营销疲劳，当你更频繁地接触客户时，转化率会下降。让我们看看我们的数据中是否存在营销疲劳。看一下下面的代码:

```py
conversionsByNumContacts <- df %>% 
  group_by(Campaign=campaign) %>% 
  summarise(Count=n(), NumConversions=sum(conversion)) %>%
  mutate(ConversionRate=NumConversions/Count*100.0)
```

从这个代码片段中，您可以看到我们正在按`campaign`列分组(该列包含在营销活动期间为该客户执行的联系次数的信息),并计算每个联系次数的转换率。结果数据如下所示:

![](assets/f126d9cd-bfdd-4aa3-a15e-92f5bf715f6a.png)

像以前一样，看图表比看原始数据更容易。我们可以使用以下代码用条形图绘制这些数据:

```py
ggplot(conversionsByNumContacts, aes(x=Campaign, y=ConversionRate)) +
  geom_bar(width=0.5, stat="identity") +
  ggtitle('Conversion Rates by Number of Contacts') +
  xlab("Number of Contacts") +
  ylab("Conversion Rate (%)") +
  theme(plot.title = element_text(hjust = 0.5)) 
```

情节看起来如下:

![](assets/59b26b80-2ed8-46cf-88e9-c12a1b471cac.png)

接触人数越多，样本量就越小，因此会有一些噪声，但在这个条形图中，您可以很容易地看到总体下降趋势。随着接触次数的增加，转化率慢慢降低。这表明，对于给定的活动，随着您与客户联系的频率增加，预期转化率会降低。



# 编码分类变量

在这个数据集中有八个分类变量:`job`、`marital`、`education`、`default`、`housing`、`loan`、`contact`和`month`。在我们开始构建决策树之前，我们需要用数值对这些分类变量进行编码。在这一节中，我们将看看如何对这些分类变量进行编码。



# 月份编码

我们都知道`month`变量只能有 12 个唯一值。让我们快速看一下我们的数据集中有什么。看一下下面的代码:

```py
unique(df$month)
```

`unique`函数帮助您快速获得给定列中的唯一值。当您运行此代码时，您将获得以下输出:

![](assets/bea193fa-38af-45e1-a779-c06d0491a339.png)

正如我们所料，从 1 月到 12 月，`month`列有 12 个唯一值。由于`month`的值有自然的顺序，我们可以用相应的数字对每个值进行编码。用数字对`month`的字符串值进行编码的一种方法如下:

```py
months = lapply(month.abb, function(x) tolower(x))
df$month <- match(df$month, months)
```

让我们仔细看看这段代码。`month.abb`是内置的 R 常量，包含月份名称的三个字母缩写名称，如下所示:

![](assets/2f8db0b0-9ba1-4eea-8438-57e61afed48d.png)

如你所见，每个缩写的`month`名字的第一个字母都是大写的。然而，我们数据的`month`列中的月份名称都是小写的。这就是为什么我们使用`tolower`函数使`month.abb`中的所有值都是小写的。使用`lapply`函数，我们可以在`month.abb`列表中应用这个`tolower`函数。然后，我们使用`match`函数，该函数返回数组中匹配字符串的位置，将 DataFrame 的`month`列中的字符串值转换为相应的数值。

使用此代码，`month`列的唯一值如下所示:

![](assets/423f83ae-563e-48b4-8a30-3c8290e24a1b.png)

要查看每个月有多少条记录，我们可以使用下面的代码:

```py
df %>% 
  group_by(month) %>% 
  summarise(Count=n())
```

结果如下:

![](assets/4271c54d-3965-4a56-a046-162327636d1b.png)



# 对工作、住房和婚姻变量进行编码

接下来，我们将对三个变量进行编码:`job`、`housing`和`marital`。由于这些变量没有自然顺序，我们不需要担心哪个类别用哪个值编码。对 R 中没有顺序的分类变量进行编码的最简单方法是使用`factor`函数。让我们来看看下面的代码:

```py
df$job <- factor(df$job)
df$housing <- factor(df$housing)
df$marital <- factor(df$marital)
```

从这段代码中可以看出，我们只是对这三个变量`job`、`housing`和`marital`应用了`factor`函数，并将编码后的值存储回数据帧`df`。对于我们在本节中没有讨论的分类变量，如果您希望在本练习之外进行探索，可以使用我们在本节中讨论的相同技术对它们进行编码。



# 构建决策树

既然我们已经编码了所有的分类变量，我们终于可以开始构建决策树模型了。我们将使用这些变量作为决策树模型的特征:`age`、`balance`、`campaign`、`previous`、`housing`、`job`和`marital`。为了用 R 构建和训练一个决策树模型，我们将使用`rpart`包。您可以使用以下代码行导入所需的库:

```py
library(rpart)
```

如果您没有安装`rpart`包，您可以使用以下命令安装它:

```py
install.packages("rpart")
```

一旦导入了所需的库，就可以使用下面的代码来构建决策树模型:

```py
fit <- rpart(
  conversion ~ age + balance + campaign + previous + housing + job + marital,
  method="class", 
  data=df,
  control=rpart.control(maxdepth=4, cp=0.0001)
)
```

如您所见，`rpart`模型的第一个参数是`formula`，它定义了特性和目标变量。这里，我们使用上述变量作为特征，使用`conversion`作为目标变量。然后，我们将该决策树模型定义为具有`method="class"`输入的分类模型。最后，您可以使用`control`输入对决策树模型进行微调。使用`control`输入可以调节许多参数。在本例中，我们仅使用`maxdepth`参数将树的最大深度限制为`4`，并将复杂度参数`cp`的值设置为足够小，以使树能够被分割。还有许多其他方法可以优化您的决策树模型，我们建议您通过运行`help(rpart)`或`help(rpart.control)`命令，仔细阅读 R 文档以获取更多信息。



# 解释决策树

既然我们已经训练了一个决策树模型，我们需要从模型中提取洞察力。在本节中，我们将使用一个名为`rattle`的库:

1.  您可以在 RStudio 中使用以下命令安装此软件包:

```py
install.packages("rattle")
```

2.  正确安装该库后，您应该能够按如下方式导入该库:

```py
library(rattle)
```

3.  一旦你用这个新的库`rattle`建立了你的 R 环境，它只需要一行代码来可视化训练好的决策树。看一下下面的代码:

```py
fancyRpartPlot(fit)
```

4.  如您所见，`fancyRpartPlot`函数接受了一个`rpart`模型对象。在这里，模型对象`fit`，是我们在上一步中构建的决策树模型。运行该命令后，将显示下图:

![](assets/7829b6ee-ce98-41ba-9a99-c0b02ba49e54.png)

让我们仔细看看这个树形图。每个节点包含三行描述给定节点拥有的信息。节点顶部的数字是标签和构建节点的顺序。我们将使用这个标签来指代这个树形图中的每个节点。然后，每个节点中的第一行告诉我们给定节点的预测或分类是什么。例如，如果一个样本属于标记为`4`的节点，则该决策树模型的分类将为零，这意味着非转换。另一方面，如果样本属于标记为`23`的节点，则该决策树模型的分类将是 1，这意味着转换。

每个节点中的第二行告诉我们给定节点的每个类中记录的百分比。例如，节点`22`中的`52%`条记录属于`0`类，即非转换组，其余的`48%`属于`1`类，即转换组。另一方面，节点`13`中的`39%`客户属于类别`0`，节点`13`中的剩余`61%`客户属于类别`1`。最后，每个节点中的底线告诉我们属于每个节点的记录占总记录数的百分比。例如，大约`80%`的客户属于节点`4`的类别，而接近`0%`的客户属于节点`13`的类别。

现在我们知道了每个节点中的每条线的含义，让我们讨论一下如何从这个树形图中获得洞察力。为了了解属于每个叶节点的客户，我们需要遍历树。例如，那些属于节点`13`的客户是那些对于`previous`变量的值大于`0.5`的客户，他们有住房贷款并且`age`大于或等于`61`。换句话说，这次活动之前接触的，年龄大于`61`的，有住房贷款的，属于节点`13`，转化几率大。

让我们看另一个例子。为了从根节点到达节点`22`，我们需要有一个`previous`变量的`0`值，一个大于或等于`61`的`age`，一个除了`married`或`single`之外的`marital`状态，以及一个属于以下类别之一的`job`:`admin`、`blue-collar`、`entrepreneur`、`housemaid`、`retired`或`unknown`。换句话说，那些在此活动之前没有联系过的客户，年龄大于`61`的，离婚的，在前面提到的类别中有工作的，属于节点`22`并且有大概`50%`的转化机会。

正如您从这两个例子中注意到的，通过可视化训练树，您可以获得关于谁更有可能或更不可能从训练决策树模型转换的有用见解。您只需要跟踪节点，并理解哪些类型的属性与您的目标类高度相关。在本练习中，我们将树限制为只能生长到深度`4`，但是您可以选择生长比我们在本练习中使用的树更大或更小的树。

本章 R 练习的完整代码可以在资源库中找到，网址为[https://github . com/Yoon hwang/hands-on-data-science-for-marketing/blob/master/ch . 4/R/fromengengementtoconversions。R](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.4/R/FromEngagementToConversions.R) 。



# 摘要

在这一章中，我们介绍了一种新的机器学习算法，决策树，我们可以使用它进行营销分析，以便更好地理解数据，并对客户行为进行洞察。我们讨论了决策树模型与逻辑回归模型的不同之处，您在前一章中已经了解了这些。您看到了决策树模型通过基于特定标准划分数据点来学习数据。我们还讨论了生长决策树时经常使用的两个度量:基尼杂质和熵信息增益。使用这两种方法中的任何一种，决策树都可以增长，直到所有节点都是纯的，或者直到满足停止标准。

在我们用 Python 和 R 进行编程练习的过程中，我们使用了来自 UCI 机器学习知识库的银行营销数据集。我们使用 Python 中的`pandas`和`matplotlib`包以及 r 中的`dplyr`和`ggplot2`库，通过深入分析数据开始编程练习。然后，您学习了如何使用 Python 中的`sklearn`包和 r 中的`rpart`库来训练和扩展决策树。通过这些训练好的决策树模型，您还学习了如何可视化和解释结果。对于可视化，我们使用 Python 中的`graphviz`包和 r 中的`rattle`库。此外，您看到了我们如何解释决策树结果，以及如何通过遍历经过训练的决策树来了解更有可能转换或订阅定期存款的客户群，这在我们想要对客户行为进行解释性分析时非常有用。

在接下来的章节中，我们将转换话题，专注于产品分析。在下一章，我们将讨论探索性分析的种类，我们可以运行这些分析来理解和识别产品数据中的模式和趋势。根据下一章的产品分析结果，我们将展示如何构建产品推荐模型。