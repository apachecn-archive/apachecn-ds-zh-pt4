<title>Drivers behind Marketing Engagement</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# 营销参与背后的驱动因素

当您开展营销活动时，您需要关注和分析的一个重要指标是客户对您营销工作的参与程度。例如，在电子邮件营销中，可以通过您的客户打开或忽略了多少营销电子邮件来衡量客户参与度。客户参与度也可以通过个人客户的网站访问量来衡量。成功的营销活动会吸引大量客户的参与，而无效的营销活动不仅会降低客户的参与，还会对您的业务产生负面影响。客户可能会将您公司的电子邮件标记为垃圾邮件，或者取消订阅您的邮件列表。

为了理解影响客户参与度的因素，在本章中，我们将讨论如何使用解释性分析(更具体地说，回归分析)。我们将简要介绍解释性分析的定义，什么是回归分析，以及如何使用逻辑回归模型进行解释性分析。然后，我们将介绍如何使用`statsmodels`包在 Python 中构建和解释回归分析结果。对于 R 程序员，我们将讨论如何用`glm`构建和解释回归分析结果。

在本章中，我们将讨论以下主题:

*   使用回归分析进行解释性分析
*   使用 Python 进行回归分析
*   R 回归分析

<title>Using regression analysis for explanatory analysis</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# 使用回归分析进行解释性分析

在[第 2 章](1fb7a852-d8fa-43f6-9807-6e3292dfa280.xhtml)、*关键绩效指标和可视化*中，我们讨论了什么是**描述性分析**以及如何使用它来更好地理解数据集。我们尝试使用各种可视化技术，并在 Python 和 r。

在这一章中，我们将扩展我们的知识，并开始讨论为什么、何时以及如何使用**解释性分析**进行营销。

<title>Explanatory analysis and regression analysis</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# 解释分析和回归分析

正如我们在[第 1 章](c169428b-e0db-4624-896c-24316e9b29cc.xhtml)、*数据科学和营销*中简要讨论的，解释性分析的目的是回答我们为什么使用数据，而描述性分析的目的是回答我们使用数据的目的，以及我们如何使用数据。当你开展不同的营销活动时，你会经常注意到一些营销活动比其他的表现好得多；你可能想知道为什么你的一些营销活动效果如此之好，而其他的却不行。例如，您可能想了解哪些类型和群体的客户通常会比其他人更频繁地打开您的营销电子邮件。再举一个例子，您可能想分析客户群的哪些属性与较高的转化率和商品购买量高度相关。

通过解释性分析，您可以分析和理解与您想要的结果高度显著相关的关键因素。**回归分析**和回归模型常用于对属性和结果之间的关系进行建模。简而言之，回归分析通过找到最接近输出值的属性或特征的函数来估计输出变量的值。回归分析的一种常用形式是**线性回归**。顾名思义，在线性回归中，我们试图通过特征的线性组合来估计输出变量。如果我们使用 *Y* 作为输出变量，使用*X[I]作为每个特征，其中 *i* 是第 *i* 个特征，那么线性回归公式将如下所示:*

![](assets/4141c7bf-bbc5-4f2d-9b36-2c3877c5a77c.png)

从前面的公式可以看出，输出变量 *Y* 表示为特征的线性组合，*X[I]。线性回归模型的目的是找到截距 *a* 和系数 *b [i]* ，使用给定的特征对输出变量进行最佳估计。拟合的线性回归线看起来会像下面这样(图片来自[https://towardsdatascience . com/linear-regression-using-python-b 136 c 91 bf0a 2](https://towardsdatascience.com/linear-regression-using-python-b136c91bf0a2)):*

![](assets/d60fa219-a286-4b2c-a92e-209e6f4d3109.png)

该图中的蓝点是数据点，红线是拟合或训练的线性回归线。如图所示，线性回归试图通过特征的线性组合来估计目标变量。

在本章中，我们将讨论如何使用回归分析，更具体地说，**逻辑回归**模型，来了解是什么推动了更高的客户参与度。

<title>Logistic regression</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# 逻辑回归

**逻辑回归**是一种回归分析，在输出变量为二元变量时使用(一表示积极结果，零表示消极结果)。像任何其他线性回归模型一样，逻辑回归模型估计特征变量的线性组合的输出。唯一的区别是模型的估计。与其他线性回归模型不同，逻辑回归模型估计事件的对数概率，或者换句话说，正事件和负事件概率之间的对数比率。该等式如下所示:

![](assets/1946fce3-7d03-485d-a545-bd55a8d47e10.png)

左边的比率是成功的几率，代表成功的概率和失败的概率之比。对数概率曲线，也称为 **logit 曲线**，如下所示:

![](assets/ef7f8d76-83b1-4317-8df0-623cc1512349.png)

逻辑回归模型输出只是 logit 的倒数，范围从 0 到 1。在本章中，我们将使用回归分析来了解是什么驱动了客户参与度，输出变量将是客户是否对营销电话作出了回应。因此，逻辑回归非常适合这种情况，因为输出是一个二元变量，可以有两个值:有响应和没有响应。在接下来的章节中，我们将讨论如何在 Python 和 R 中使用和构建逻辑回归模型，然后我们将讨论如何解释回归分析结果，以了解客户的哪些属性与更高的营销参与度高度相关。

<title>Regression analysis with Python</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# 使用 Python 进行回归分析

在本节中，您将学习如何使用 Python 中的`statsmodels`包来进行回归分析。对于那些喜欢使用 R 而不是 Python 的读者，对于这个练习，您可以跳到下一节。我们将通过使用`pandas`和`matplotlib`包更仔细地查看数据来开始这一部分，然后我们将讨论如何通过使用`statsmodels`库来构建回归模型和解释结果。

在这个练习中，我们将使用 IBM Watson 的一个公开可用的数据集，该数据集可以在[https://www . IBM . com/communities/analytics/Watson-analytics-blog/marketing-customer-value-analysis/](https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/)找到。您可以通过链接下载 CSV 格式的数据文件。为了将这些数据加载到您的 Jupyter 笔记本中，您可以运行以下代码:

```
import matplotlib.pyplot as plt
import pandas as pd

df = pd.read_csv('../data/WA_Fn-UseC_-Marketing-Customer-Value-Analysis.csv')
```

类似于我们在[第 2 章](1fb7a852-d8fa-43f6-9807-6e3292dfa280.xhtml)、*关键性能指标和可视化*中所做的，我们首先导入`matplotlib`和`pandas`包；使用`pandas`中的`read_csv`函数，我们可以将数据读入到`pandas`数据帧中。稍后我们将使用`matplotlib`进行数据分析和可视化。

加载的数据帧`df`如下所示:

![](assets/333d7a69-95a2-4044-bcc1-5b6e92b72fc6.png)

正如我们在[第 2 章](1fb7a852-d8fa-43f6-9807-6e3292dfa280.xhtml)、*关键性能指标和可视化*中所讨论的，DataFrame `shape`属性告诉我们 DataFrame 中的行数和列数，而`head`函数将显示数据集的前五条记录。一旦你成功地将数据读入一个`pandas`数据框，你的数据看起来应该和截图中的一样。

<title>Data analysis and visualizations</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# 数据分析和可视化

在我们开始回归分析之前，我们将首先更详细地查看数据，以便更好地了解我们有哪些数据点以及我们可以在数据中看到哪些模式。如果查看数据，您会注意到一个名为`Response`的列。它包含关于客户是否响应营销电话的信息。我们将使用该字段来衡量客户参与度。对于将来的计算，最好用数值对该字段进行编码。让我们来看看下面的代码:

```
df['Engaged'] = df['Response'].apply(lambda x: 0 if x == 'No' else 1)
```

正如您在这段代码中看到的，使用`pandas`数据帧的`apply`函数，我们对那些没有响应营销电话的人(`No`)进行编码，取值为`0`，对那些响应营销电话的人(`Yes`)进行编码，取值为`1`。我们正在用这些编码值创建一个名为`Engaged`的新字段。

<title>Engagement rate</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# 订婚率

我们要看的第一件事是总参与率。这个参与率就是响应营销电话的客户的百分比。看一下下面的代码:

```
engagement_rate_df = pd.DataFrame(
    df.groupby('Engaged').count()['Response'] / df.shape[0] * 100.0
)
```

从这段代码中可以看出，我们使用`pandas`数据帧的`groupby`函数，通过新创建的字段`Engaged`进行分组。然后，我们用`count`函数统计每个`Engaged`组中的记录(或客户)数量。除以数据框架中的客户总数，再乘以`100.0`，我们就得到了参与度。结果如下:

![](assets/97193318-df6f-461f-9404-86cb8ed4b87b.png)

为了更容易阅读，我们可以转置数据帧，这意味着我们可以翻转数据帧中的行和列。您可以使用数据帧的`T`属性转置一个`pandas`数据帧。它看起来如下:

![](assets/04dd8f15-66c7-4bdd-a2c3-1e04839e1447.png)

如您所见，约 14%的客户回复了营销电话，其余 86%的客户没有回复。

<title>Sales channels</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# 销售渠道

现在，让我们看看能否在销售渠道和参与度中找到任何值得注意的模式。我们将分析敬业和非敬业客户在不同销售渠道中的分布情况。让我们先来看看下面的代码:

```
engagement_by_sales_channel_df = pd.pivot_table(
    df, values='Response', index='Sales Channel', columns='Engaged', aggfunc=len
).fillna(0.0)

engagement_by_sales_channel_df.columns = ['Not Engaged', 'Engaged']
```

正如你在这个代码片段中看到的，我们使用了`pandas`库中的`pivot_table`函数来根据`Sales Channel`和`Response`变量进行分组。一旦运行这段代码，`engagement_by_sales_channel_df`将会有以下数据:

![](assets/0cd77263-2dc4-4680-b552-5a1d92ed0bcb.png)

正如您在上一节中注意到的那样，没有参与营销活动的客户明显更多，因此很难从原始数据中看出参与和未参与客户之间销售渠道分布的差异。为了更直观地识别差异，我们可以使用以下代码构建饼图:

```
engagement_by_sales_channel_df.plot(
    kind='pie',
    figsize=(15, 7),
    startangle=90,
    subplots=True,
    autopct=lambda x: '%0.1f%%' % x
)

plt.show()
```

运行此代码后，您将看到下面的饼图，其中显示了不同销售渠道中参与和未参与客户的分布情况:

![](assets/7e5402ab-645b-41ea-92ef-4e00ba53ac02.png)

与之前显示每个销售渠道中参与和未参与客户的原始计数的表格相比，这些饼图有助于我们更容易地直观发现分布中的差异。从这些图表中可以看出，超过一半的参与客户来自代理，而非参与客户更均匀地分布在所有四个不同的渠道中。正如您从这些图表中看到的，分析和可视化数据可以帮助我们注意到数据中有趣的模式，这将在我们在本章的后面部分运行回归分析时进一步提供帮助。

<title>Total claim amounts</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# 索赔总额

在我们开始回归分析之前，我们要看的最后一件事是参与组和非参与组之间`Total Claim Amount`分布的差异。我们将通过使用箱线图来形象化这一点。让我们首先看看如何在 Python 中构建盒状图，如下所示:

```
ax = df[['Engaged', 'Total Claim Amount']].boxplot(
    by='Engaged',
    showfliers=False,
    figsize=(7,5)
)

ax.set_xlabel('Engaged')
ax.set_ylabel('Total Claim Amount')
ax.set_title('Total Claim Amount Distributions by Engagements')

plt.suptitle("")
plt.show()
```

正如您在这段代码中看到的，从一个`pandas`数据帧构建盒状图非常简单。你可以简单的调用`boxplot`函数。箱线图是可视化连续变量分布的一种很好的方法。它们在一个视图中显示最小值、最大值、第一个四分位数、中间值和第三个四分位数。下面的箱线图显示了`Total Claim Amount`在参与组和非参与组之间的分布:

![](assets/c38b00b9-e2ca-4edd-a34a-cf67ba11ea74.png)

中间的矩形从第一个四分位数跨越到第三个四分位数，绿线表示中间值。下端和上端分别显示分布的最小值和最大值。前面代码中需要注意的一点是`showfliers=False`参数。使用以下代码，让我们看看当我们将该参数设置为`True`时会发生什么:

```
ax = df[['Engaged', 'Total Claim Amount']].boxplot(
    by='Engaged',
    showfliers=True,
    figsize=(7,5)
)

ax.set_xlabel('Engaged')
ax.set_ylabel('Total Claim Amount')
ax.set_title('Total Claim Amount Distributions by Engagements')

plt.suptitle("")
plt.show()
```

使用这个代码和`showfliers=True`标志，产生的盒图现在看起来如下:

![](assets/5ff9f5b8-a67b-4e31-b2df-6f1c2661ac25.png)

正如您在这些盒状图中注意到的，它们在上边界线上方绘制了许多点，这暗示了先前盒状图中的最大值。上边界线上方的点表示根据**四分位距** ( **IQR** )确定的可疑异常值。IQR 只是第一个四分位数和第三个四分位数之间的范围，落在第三个四分位数之上`1.5*IQR`或第一个四分位数之下`1.5*IQR`的点是可疑的异常值，用圆点表示。

<title>Regression analysis</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# 回归分析

到目前为止，我们已经分析了数据中的字段类型，以及参与组和非参与组之间的模式差异。现在，我们将讨论如何使用`statsmodels`包在 Python 中进行和解释回归分析。我们将首先建立一个包含连续变量的逻辑回归模型，您将学习如何解释结果。然后，我们将讨论拟合回归模型时处理分类变量的不同方法，以及这些分类变量对拟合的逻辑回归模型有什么影响。

<title>Continuous variables</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# 连续变量

在线性回归中，包括逻辑回归，当特征变量是连续的时，拟合回归模型是直接的，因为它只需要找到特征变量与用于估计输出变量的数值的线性组合。为了拟合具有连续变量的回归模型，让我们首先来看看如何获得`pandas`数据帧中列的数据类型。看一看以下内容:

![](assets/13cfa30a-b8b2-45db-8b1b-cc3b0b115cd3.png)

正如你在这张 Jupyter 笔记本截图中看到的，一个`pandas` `Series`对象的`dtype`属性告诉你它包含什么类型的数据。从这张快照中可以看出，`Income`变量有整数，`Customer Lifetime Value`特性有浮点数。为了快速查看带有数值的变量分布，您还可以执行以下操作:

![](assets/58348fa5-b7e6-49c3-b9de-5175614c4b24.png)

正如您在这个 Jupyter 笔记本快照中看到的，`pandas` DataFrame 的`describe`函数显示了所有列的数值分布。例如，您可以看到在`Customer Lifetime Value`列中共有`9134`条记录，平均值为`8004.94`，范围从`1898.01`到`83325.38`。

我们将把这个连续变量的名字列表存储在一个单独的变量中，名为`continuous_vars`。看一下下面的代码:

```
continuous_vars = [
    'Customer Lifetime Value', 'Income', 'Monthly Premium Auto', 
    'Months Since Last Claim', 'Months Since Policy Inception', 
    'Number of Open Complaints', 'Number of Policies', 
    'Total Claim Amount'
]
```

现在我们知道了哪些列是连续变量，让我们开始拟合逻辑回归模型。为此，我们需要首先导入`statsmodels`包，如下面的代码所示:

```
import statsmodels.formula.api as sm
```

导入`statsmodels`包后，启动逻辑回归模型的代码非常简单，如下所示:

```
logit = sm.Logit(
    df['Engaged'], 
    df[continuous_vars]
)
```

从这段代码中可以看出，我们在`statsmodels`包中使用了`Logit`函数。我们提供了`Engaged`列作为输出变量，模型将学习对其进行估计，并提供了包含所有连续变量的`continuous_vars`作为输入变量。一旦使用定义的输出和输入变量创建了逻辑回归对象，我们就可以使用以下代码来训练或拟合该模型:

```
logit_fit = logit.fit()
```

正如您在这段代码中看到的，我们使用逻辑回归对象`logit`的`fit`函数来训练逻辑回归模型。一旦运行了这个代码，经过训练的模型`logit_fit`将通过使用输入变量学习到最佳估计输出变量`Engaged`的最优解。为了获得已训练模型的详细描述，可以使用以下代码:

```
logit_fit.summary()
```

当您运行这段代码时，`summary`函数将在 Jupyter 笔记本中显示以下输出:

![](assets/39146c4c-eacf-42ab-80f4-4801a8e3b76b.png)

让我们仔细看看这个模型的输出。`coef`代表每个输入变量的系数，`z`代表*z*-分数，即平均值的标准偏差数。`P>|z|`列代表*p*-值，这意味着偶然观察到特征和输出变量之间关系的可能性有多大。因此，`P>|z|`的值越低，给定特征和输出变量之间的关系越强，而不是偶然的。通常，`0.05`是一个很好的 *p* 值的分界点，任何小于`0.05`的值表示给定特征和输出变量之间的强关系。

查看这个模型输出，我们可以看到`Income`、`Monthly Premium Auto`、`Months Since Last Claim`、`Months Since Policy Inception`和`Number of Policies`变量与输出变量`Engaged`有显著的关系。例如，`Number of Policies`变量显著，与`Engaged`负相关。这表明，客户拥有的保单越多，他们对营销电话做出回应的可能性就越小。作为另一个例子，`Months Since Last Claim`变量是显著的，并且与输出变量`Engaged`负相关。这意味着距离上次索赔时间越长，客户就越不可能对营销电话作出回应。

从这些例子中可以看出，通过查看模型输出的*p*-值和特征系数，可以很容易地解释回归分析结果。这是了解客户的哪些属性与您感兴趣的结果显著且高度相关的好方法。

<title>Categorical variables</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# 分类变量

正如您在上一节中看到的连续变量的情况，从系数和 *p* 值理解输入和输出变量之间的关系是非常简单的。然而，当我们引入**分类变量**时，事情就变得不那么简单了。分类变量通常没有任何自然顺序，或者它们用非数值编码，但是在线性回归中，我们需要输入变量具有表示变量顺序或大小的数值。例如，我们不能很容易地用特定的顺序或值对数据集中的`State`变量进行编码。这就是为什么在进行回归分析时，我们需要以不同于连续变量的方式处理分类变量。在 Python 中，当使用`pandas`包时，有多种方法来处理分类变量。让我们首先来看分解分类变量，如下面的代码所示:

```
gender_values, gender_labels = df['Gender'].factorize()
```

`pandas`函数`factorize`通过枚举数值对分类变量进行编码。我们先来看看下面的输出:

![](assets/6bd1e57a-4ea2-4d5d-b7a6-96c59a34773e.png)

正如您从这个输出中看到的，这个`Gender`变量的值用 0 和 1 编码，其中`0`代表女性(`F`)，而`1`代表男性(`M`)。这是一种用数值对分类变量进行编码的快速方法。然而，当我们想要将自然排序嵌入到编码值中时，这个函数不起作用。例如，我们数据集中的`Education`变量有五个不同的类别:`High School or Below`、`Bachelor`、`College`、`Master`和`Doctor`。当在这个`Education`变量中编码不同的类别时，我们可能想要嵌入排序。

下面的代码展示了使用`pandas`时使用排序对分类变量进行编码的另一种方式:

```
categories = pd.Categorical(
    df['Education'], 
    categories=['High School or Below', 'Bachelor', 'College', 'Master', 'Doctor']
)
```

正如您在这段代码中看到的，我们使用了`pd.Categorical`函数来编码`df['Education']`的值。我们可以用参数`categories`定义我们想要的排序。在我们的例子中，我们分别为类别`High School or Below`、`Bachelor`、`College`、`Master`和`Doctor`给出了`0`、`1`、`2`、`3`和`4`的值。输出如下所示:

我们现在将这些编码变量添加到熊猫数据帧`df`，如以下代码所示:

```
df['GenderFactorized'] = gender_values
df['EducationFactorized'] = categories.codes
```

通过对两个分类变量`Gender`和`Education`的这些编码，我们现在可以使用以下代码拟合逻辑回归模型:

```
logit = sm.Logit(
    df['Engaged'], 
    df[[
        'GenderFactorized',
        'EducationFactorized'
    ]]
)

logit_fit = logit.fit()
```

类似于我们之前如何用连续变量拟合逻辑回归模型，我们可以通过使用`statsmodels`包中的`Logit`函数，用编码的分类变量`GenderFactorized`和`EducationFactorized`拟合逻辑回归模型。使用拟合的逻辑回归模型对象的`summary`函数，我们将得到以下输出:

![](assets/5ebbe76b-7881-455c-923a-8f3a1025b757.png)

正如您在这个输出中看到的，通过查看`P>|z|`列中的*p*-值，`GenderFactorized`和`EducationFactorized`变量似乎都与输出变量`Engaged`有显著的关系。如果我们看看这两个变量的系数，我们可以看到，两者都与产出负相关。这表明，与在`GenderFactorized`变量中用`0`编码的女性客户相比，在`GenderFactorized`变量中用`1`编码的男性客户不太可能参与营销电话。同样，客户的教育水平越高，他们参与营销电话的可能性就越小。

我们已经讨论了在`pandas`中处理分类变量的两种方法，使用`factorize`和`Categorical`函数。通过这些技术，我们可以了解不同类别的分类变量是如何与输出变量相关联的。

<title>Combining continuous and categorical variables</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# 组合连续变量和分类变量

本章中我们要做的最后一个 Python 练习涉及到结合连续变量和分类变量进行回归分析。我们可以通过使用分类变量和连续变量来拟合逻辑回归模型，如以下代码所示:

```
logit = sm.Logit(
    df['Engaged'], 
    df[['Customer Lifetime Value',
        'Income',
        'Monthly Premium Auto',
        'Months Since Last Claim',
        'Months Since Policy Inception',
        'Number of Open Complaints',
        'Number of Policies',
        'Total Claim Amount',
        'GenderFactorized',
        'EducationFactorized'
    ]]
)

logit_fit = logit.fit()
```

与之前代码的唯一区别是我们选择的符合逻辑回归模型的特性。正如您在这段代码中看到的，我们现在正在用连续变量以及我们在上一节中创建的两个编码分类变量`GenderFactorized`和`EducationFactorized`来拟合一个逻辑回归模型。结果如下所示:

![](assets/9d55b21f-2e47-4da4-a572-f517ad414c2a.png)

让我们仔细看看这个输出。`Income`、`Monthly Premium Auto`、`Months Since Last Claim,`、`Months Since Policy Inception`、`Number of Open Complaints`、`Number of Policies`、`GenderFactorized`变量在`0.05`显著性水平上显著，且均与输出变量`Engaged`呈负相关。因此，收入越高，客户参与营销电话的可能性就越小。同样，客户的保单越多，他或她参与营销电话的可能性就越小。

最后，男性客户比女性客户更少参与营销电话，我们可以通过查看`GenderFactorized`的系数来了解这一点。通过查看该回归分析输出，我们可以很容易地看到输入和输出变量之间的关系，并且我们可以了解客户的哪些属性与客户参与营销电话有积极或消极的关系。

本章 Python 练习的完整代码可以在[https://github . com/Yoon hwang/hands-on-data-science-for-marketing/blob/master/ch . 3/Python/regression analysis . ipynb](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.3/python/RegressionAnalysis.ipynb)找到。

<title>Regression analysis with R</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# R 回归分析

在本节中，您将学习如何使用 R 中的`glm`函数进行回归分析。对于那些想在这个练习中使用 Python 而不是 R 的读者来说，Python 的一步一步的说明在前一节中。我们将从使用`dplyr`包更仔细地分析数据开始这一部分，然后我们将讨论如何建立回归模型并使用`glm`函数解释结果。

在这个练习中，我们将使用 IBM Watson 的一个公开可用的数据集，该数据集可以在[https://www . IBM . com/communities/analytics/Watson-analytics-blog/marketing-customer-value-analysis/](https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/)找到。您可以点击此链接下载 CSV 格式的数据文件。为了将这些数据加载到 RStudio 中，您可以运行以下代码:

```
library(dplyr)
library(ggplot2)

# Load data
df <- read.csv(
  file="~/Documents/data-science-for-marketing/ch.3/data/WA_Fn-UseC_-Marketing-Customer-Value-Analysis.csv", 
  header=TRUE, 
  sep=","
)
```

与我们在[第 2 章](1fb7a852-d8fa-43f6-9807-6e3292dfa280.xhtml)、*关键绩效指标和可视化*中所做的类似，我们将首先导入`dplyr`和`ggplot2`包，用于以下部分的数据分析和绘图。使用 R 中的`read.csv`函数，我们可以将数据读入数据帧。因为这个 CSV 文件在第一行包含了标题，并且字段用逗号分隔，所以我们使用了`header=TRUE`和`sep=","`标志来进行正确的解析。

以下屏幕截图显示了数据帧中原始数据的外观:

![](assets/bfe00dbe-78f4-45a4-a4aa-2376f7431410.png)

现在，我们已经将数据加载到 DataFrame 中，让我们开始更仔细地查看和分析数据，以便更好地理解数据的结构。

<title>Data analysis and visualization</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# 数据分析和可视化

在我们深入回归分析之前，让我们先更详细地看看数据，以便更好地了解我们有哪些数据点，以及我们可以在数据中看到哪些模式。如果查看数据，您会注意到一个名为`Response`的列。它包含关于客户是否响应其营销电话的信息。我们将使用该字段来衡量客户参与度。对于将来的计算，最好用数值对该字段进行编码。让我们来看看下面的代码:

```
# Encode Response as 0s and 1s
df$Engaged <- as.integer(df$Response) - 1
```

正如您在这段代码中看到的，使用`as.integer`函数，我们将那些没有响应营销电话的人(`No`)编码为值`0`，将那些响应营销电话的人(`Yes`)编码为值`1`。因为默认情况下`as.integer function`将值编码为`1`和`2`，所以我们用`1`减去这些值，将响应值编码为 0 和 1。然后，我们用这些编码值创建一个名为`Engaged`的新字段。

<title>Engagement rate</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# 订婚率

我们要看的第一件事是总参与率。这个参与率就是响应营销电话的客户的百分比。看一下下面的代码:

```
engagementRate <- df %>% 
  group_by(Engaged) %>% 
  summarise(Count=n()) %>%
  mutate(Percentage=Count/nrow(df)*100.0)
```

正如您在这段代码中看到的，我们使用`group_by`函数，按照新创建的字段`Engaged`进行分组。然后，我们用`n()`函数统计每个`Engaged`组中的记录数或客户数。通过除以数据框架中的客户总数`df`，然后乘以`100.0`，我们得到了参与度。结果如下所示:

![](assets/46c83142-7a95-4635-abf9-0bf6c55b1192.png)

为了更容易阅读，我们可以转置数据帧，这意味着我们可以翻转数据帧中的行和列。您可以使用 r 中的`t`函数转置数据帧。代码如下:

```
# Transpose
transposed <- t(engagementRate)

colnames(transposed) <- engagementRate$Engaged
transposed <- transposed[-1,]
```

转置的数据帧如下所示:

![](assets/61534cae-683e-4984-ae49-6a1f375555b3.png)

如您所见，通过调换数据框架，可以更容易地看到参与和未参与客户的总数和百分比。从这个数据我们可以看到，大概有 14%的客户对营销电话进行了回复，剩下的 86%的客户没有回复。

<title>Sales channels</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# 销售渠道

现在，让我们看看能否在销售渠道和参与度方面找到任何值得注意的模式。我们将分析敬业和非敬业客户在不同销售渠道中的分布情况。让我们先来看看下面的代码:

```
salesChannel <- df %>% 
  group_by(Engaged, Channel=Sales.Channel) %>% 
  summarise(Count=n())
```

正如你在这段代码中看到的，我们在 R 中使用了`group_by`函数来根据`Sales Channel`和`Engaged`变量进行分组。然后，使用`n()`函数，我们将统计每组的客户数量。一旦您运行了这段代码，`salesChannel`数据帧将如下所示:

![](assets/34a46f66-6a8f-4c2d-aa4c-b8ee50112ab4.png)

正如您在上一节中注意到的那样，没有参与营销工作的客户明显更多，因此很难用原始数据来比较和了解参与和未参与客户之间的销售渠道分布差异。为了在视觉上更容易区分，我们可以使用以下代码构建饼图:

```
# pie chart
ggplot(salesChannel, aes(x="", y=Count, fill=Channel)) + 
  geom_bar(width=1, stat = "identity", position=position_fill()) +
  geom_text(aes(x=1.25, label=Count), position=position_fill(vjust = 0.5)) +
  coord_polar("y") +
  facet_wrap(~Engaged) +
  ggtitle('Sales Channel (0: Not Engaged, 1: Engaged)') +
  theme(
    axis.title.x=element_blank(),
    axis.title.y=element_blank(),
    plot.title=element_text(hjust=0.5),
    legend.position='bottom'
  )
```

类似于我们在[第 2 章](1fb7a852-d8fa-43f6-9807-6e3292dfa280.xhtml)、*关键绩效指标和可视化*中所做的，我们正在使用`ggplot`构建 r 中的图表。如果您还记得那一章，我们可以通过使用`geom_bar`和`coord_polar("y")`来构建饼状图。通过使用`face_wrap(~Engaged)`，我们可以将饼状图一分为二:一个用于未签约客户，另一个用于签约客户。运行此代码后，您将看到下面的饼图，其中显示了不同销售渠道中参与和未参与客户的分布情况:

![](assets/8c162b53-d864-4865-93eb-13c38d1fc0a6.png)

与之前显示每个销售渠道中参与和未参与客户的原始计数的数据表相比，这些饼图可以帮助我们更容易地直观了解分布的差异。从这些图表中可以看出，超过一半的参与客户来自代理，而非参与客户更均匀地分布在所有四个不同的渠道中。正如您从这些图表中看到的，分析和可视化数据可以帮助我们注意到数据中有趣的模式，这将在我们在本章的后面部分运行回归分析时进一步帮助我们。

<title>Total claim amounts</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# 索赔总额

在我们开始回归分析之前，我们要看的最后一件事是参与组和非参与组之间`Total Claim Amount`分布的差异。我们将通过使用箱线图来形象化这一点。让我们首先看看如何在 R:

```
ggplot(df, aes(x="", y=Total.Claim.Amount)) + 
  geom_boxplot() +
  facet_wrap(~Engaged) +
  ylab("Total Claim Amount") +
  xlab("0: Not Engaged, 1: Engaged") +
  ggtitle("Engaged vs. Not Engaged: Total Claim Amount") +
  theme(plot.title=element_text(hjust=0.5))
```

正如您在这段代码中看到的，在 r 中构建盒状图非常简单。您可以简单地用`geom_boxplot`调用`ggplot`函数。箱线图是一种可视化连续变量分布的好方法。它在一个视图中显示了最小值、最大值、第一个四分位数、中间值和第三个四分位数。下图显示了`Total Claim Amount`在订婚和未订婚人群中的分布情况:

![](assets/25b89a8f-f883-400c-812b-6866d25c84b7.png)

中间的矩形从第一个四分点延伸到第三个四分点，矩形内的线表示中间值。矩形线的下端和上端分别表示分布的最小值和最大值。从这些盒状图中你会注意到的另一件事是线的上端上面的点。

上线末端以外的点表示可疑异常值，这是根据 IQR 确定的。IQR 只是第一个和第三个四分位数之间的范围，它与盒状图中从第一个四分位数到第三个四分位数的矩形高度相同。落在第三个四分位数以上`1.5*IQR`或第一个四分位数以下`1.5*IQR`的数据点是可疑的异常值，用圆点表示。

根据您的分析目标，您可能不关心(或者您可能不想显示)箱线图中的异常值。让我们看看下面的代码，看看我们如何从箱线图中删除这些异常值:

```
# without outliers
ggplot(df, aes(x="", y=Total.Claim.Amount)) + 
  geom_boxplot(outlier.shape = NA) +
  scale_y_continuous(limits = quantile(df$Total.Claim.Amount, c(0.1, 0.9))) +
  facet_wrap(~Engaged) +
  ylab("Total Claim Amount") +
  xlab("0: Not Engaged, 1: Engaged") +
  ggtitle("Engaged vs. Not Engaged: Total Claim Amount") +
  theme(plot.title=element_text(hjust=0.5))
```

正如您将在这段代码中注意到的，这段代码与前一段代码的唯一区别是`geom_boxplot`函数中的`outlier.shape=NA`。现在让我们来看看箱线图是什么样子的:

![](assets/427c69d6-87c2-4137-bd7d-f9d4d565c7c9.png)

在这些图中，我们再也看不到上线末端以外的点。根据您想要显示和分析的内容，盒图中的异常值可能有帮助，也可能没有帮助。

<title>Regression analysis</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# 回归分析

到目前为止，我们已经分析了数据中的字段类型，以及参与组和非参与组之间的模式差异。现在，我们将讨论如何使用`glm`函数在 R 中进行和解释回归分析。我们将首先建立一个连续变量的逻辑回归模型，你将学习如何解释结果。然后，我们将讨论在拟合 R 中的回归模型时如何处理分类变量，以及这些分类变量对拟合的逻辑回归模型有什么影响。

<title>Continuous variables</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# 连续变量

在线性回归中，包括逻辑回归，当特征变量是连续的时，拟合回归模型是直接的，因为它只需要找到特征变量与数值的线性组合来估计输出变量。为了拟合具有连续变量的回归模型，让我们首先来看看如何获得`R`数据帧中列的数据类型。看一下下面的代码:

```
# get data types of each column
sapply(df, class)
```

使用`R`中的`sapply`函数，我们可以将`class`函数应用于数据帧中的所有列，而`class`函数告诉我们每一列中的数据类型。该代码的结果如下:

![](assets/99e6ea9c-822d-4e6b-8904-853a3b426c2b.png)

如前面的屏幕截图所示，我们可以很容易地看出哪些列有数值，哪些没有。例如，`State`列的类型是`"factor"`，这意味着该变量是一个分类变量。另一方面，`Customer.Lifetime.Value`列的类型是`"numeric"`，这意味着这个变量是一个具有数值的连续变量。除此之外，我们还可以使用一个`R`函数`summary`来获取数据帧中每一列的汇总统计信息，这样我们不仅可以看到每一列的类型，还可以看到每一列的分布情况汇总。代码如下:

```
# summary statistics per column
summary(df)
```

当您运行这段代码时，您将得到如下所示的输出:

![](assets/3fc841d4-179a-4089-b299-b0934b7fd763.png)

在这个输出中，我们可以很容易地看到一个`R`数据帧中每一列的分布快照。例如，对于`State`变量，我们很容易看到有来自`Arizona`的`1703`记录或客户和来自`California`的`3150`客户。另一方面，我们可以很容易地看到`Customer.Lifetime.Value`变量的最小值是`1898`，而平均值是`8005`，最大值是`83325`。

根据前面代码中的信息，我们可以使用下面的代码轻松地只选择带有数值的列:

```
# get numeric columns
continuousDF <- select_if(df, is.numeric)
colnames(continuousDF)
```

正如您在这个代码片段中看到的，我们使用了`select_if`函数，这个函数的参数是数据帧`df`和一个条件语句`is.numeric`，用来定义我们想要从数据帧中进行子选择的列的类型。使用此功能，只有数据框中的数字列`df`被选择并存储为一个名为`continuousDF`的独立变量。使用`colnames`函数，我们可以看到新创建的数据帧`continuousDF`中有哪些列。您应该会看到如下所示的输出:

![](assets/fa4c358f-ccd2-4da8-9e75-a743a319ce02.png)

我们现在准备用连续变量来拟合逻辑回归模型。让我们先来看看下面的代码:

```
# Fit regression model with continuous variables
logit.fit <- glm(Engaged ~ ., data = continuousDF, family = binomial)
```

在 R 中，你可以通过使用`glm`函数来拟合回归模型，它代表**广义线性模型**。R 函数`glm`可用于各种线性模型。默认情况下，family 参数的值是`gaussian`，它告诉算法要拟合一个简单的线性回归模型。另一方面，就像在我们的例子中，如果你用`binomial`代表`family`，那么它将符合逻辑回归模型。有关可用于`family`参数的不同值的更多详细描述，您可以参考[https://stat . ethz . ch/R-manual/R-devel/library/stats/html/family . html](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/family.html)。

我们传递给`glm`函数的另外两个参数是`formula`和`data`。第一个参数，`formula`，是您定义希望模型如何拟合的地方。`~`左侧的变量是输出变量，`~`右侧的变量是输入变量。在我们的例子中，我们告诉模型通过使用所有其他变量作为输入变量来学习如何估计输出变量`Engaged`。如果您只想使用变量的子集作为输入变量，那么您可以对公式使用如下内容:

```
Engaged ~ Income + Customer.Lifetime.Value
```

在这个公式中，我们告诉模型学习如何通过仅使用`Income`和`Customer.Lifetime.Value`作为特征来估计输出变量`Engaged`。最后，我们的`glm`函数中的第二个参数`data`定义了使用哪些数据来训练回归模型。

现在我们已经有了一个训练好的逻辑回归模型，让我们看看下面的代码，它显示了我们如何从这个模型对象中获得详细的回归分析结果:

```
summary(logit.fit)
```

R 中的`summary`函数提供了回归分析结果的详细描述，如下所示:

![](assets/6c37619a-21ef-4ffa-b36e-9fc327da669a.png)

让我们更详细地看看这个输出。`Coefficients`部分的`Estimate`列给出了每个特征系数的计算值。例如，`Income`变量的系数是`0.000002042`，而`Number.of.Policies`的系数是`-0.02443`。我们还可以看到估计的`Intercept`值是`-1.787`。列`z value`为我们提供了*z*-得分，这是总体均值的标准偏差数，列`Pr(>|z|)`是*p*-值，这意味着偶然观察到特征和输出变量之间关系的可能性有多大。因此，`Pr(>|z|)`的值越低，给定特征和输出变量之间的关系就越有可能是强有力的，而不是偶然的。通常，`0.05`是一个很好的 *p* 值的分界点，任何小于`0.05`的值表示给定特征和输出变量之间的强关系。

从输出中的`Coefficients`部分下面的`Signif. codes`部分可以看到，`Coefficients`部分中的*p*-值旁边的`***`符号表示与`0`处的*p*-值的关系最强；`**`表示*p*-值小于 0.001；`*`表示*p*-值小于`0.05`，以此类推。如果您再次查看回归分析输出，只有三个变量`Income`、`Number.of.Policies`和`Total.Claim.Amount`在`0.1`显著性水平上与输出变量`Engaged`有显著关系。此外，我们可以看到`Income`和`Total.Claim.Amount`与`Engaged`正相关，这意味着收入越高或总索赔额越高，客户参与营销电话的可能性就越大。另一方面，变量`Number.of.Policies`与`Engaged`负相关，这表明客户拥有的保单数量越多，给定客户参与营销电话的可能性就越小。

正如您在这些示例中看到的，通过查看模型输出的*p*-值和特征系数，您可以非常容易地解释回归分析结果。这是了解客户的哪些属性与您感兴趣的结果显著且高度相关的好方法。

<title>Categorical variables</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# 分类变量

正如您在上一节中看到的连续变量的情况，从系数和 *p* 值理解输入和输出变量之间的关系是非常简单的。然而，当我们引入分类变量时，事情就不那么简单了。分类变量通常没有任何自然顺序，但是在线性回归中，我们需要`input`变量有数值来表示变量的顺序或大小。例如，我们不能很容易地用某些顺序或值对数据集中的`State`变量进行编码。这就是为什么在进行回归分析时，我们需要以不同于连续变量的方式处理分类变量。在 R 中，`factor`函数帮助您在运行回归分析时轻松处理这些分类变量。看一下下面的代码:

```
# a. Education
# Fit regression model with Education factor variables
logit.fit <- glm(Engaged ~ factor(Education), data = df, family = binomial)
summary(logit.fit)
```

正如您在这段代码中看到的，我们正在拟合一个逻辑回归模型，将`Engaged`作为输出变量，将因式分解的`Education`作为输入变量。在深入探讨这意味着什么之前，我们先来看看下面的回归分析结果:

![](assets/31ab77a5-aeb4-4ed5-8288-144e0ea82443.png)

正如您在这个输出中看到的，`factor`函数创建了四个额外的变量:`factor(Education)College`、`factor(Education)Doctor`、`factor(Education)High School or Below`和`factor(Education)Master`。如果给定客户不属于给定类别，则这些变量用`0`编码，如果给定客户属于给定类别，则用`1`编码。这样，我们就可以了解每个`Education`类别和`output`变量、`Engaged`之间的正或负关系。例如，因子变量`factor(Education)Doctor`具有正系数，这表明如果客户具有博士学位，则给定客户将更有可能参与营销电话。

如果仔细观察，您会注意到这个输出在`Education`变量中没有单独的`Bachelor`类别的因子变量。这是因为`(Intercept)`包含了`Bachelor`类别的信息。如果客户拥有学士学位，那么所有其他因素变量都将被编码为`0` s。因此，所有系数值都被抵消，只有`(Intercept)`值保留。由于估计的`(Intercept)`值为负，如果客户拥有`Bachelor`学位，则给定客户不太可能参与营销电话。

让我们看另一个例子:

```
# b. Education + Gender
# Fit regression model with Education & Gender variables
logit.fit <- glm(Engaged ~ factor(Education) + factor(Gender), data = df, family = binomial)

summary(logit.fit)
```

正如您在这段代码中看到的，我们现在正在用`Education`和`Gender`变量拟合一个回归模型，输出如下:

![](assets/86d48265-182c-4c31-b7e1-755ea30c0488.png)

如果您仔细观察这个输出，您只能看到一个额外的因素变量，`factor(Gender)M`，对于男性客户，其中的数据显然有女性客户。这是因为`Education`变量的`Bachelor`类别和`Gender`变量的`F`(女性)类别被集中在一起作为这个回归模型的`(Intercept)`。因此，所有因素变量的值都是`0`的基本情况是针对具有`Bachelor`度的`female`客户。

对于拥有`Bachelor`学位的男性客户，因子变量`factor(Gender)M`的值现在将为`1`，因此，输出变量`Engaged`的估计值将为`(Intercept)`的值加上`factor(Gender)M`的系数值。

正如我们到目前为止所讨论的，我们可以通过使用 r 中的`factor`函数来处理分类变量。这本质上与为每个分类变量的每个类别创建一个单独的输入变量是一样的。使用这种技术，我们可以了解不同类别的分类变量如何与输出变量相关联。

<title>Combining continuous and categorical variables</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# 组合连续变量和分类变量

本章中我们要做的最后一个练习是结合连续变量和分类变量进行回归分析。让我们首先分解我们在上一节中讨论的两个分类变量`Gender`和`Education`，并通过使用以下代码将它们存储在 DataFrame 中:

```
continuousDF$Gender <- factor(df$Gender)
continuousDF$Education <- factor(df$Education)
```

数据帧`continuousDF`现在包含以下各列:

![](assets/51c0514f-23f0-474c-ae49-53136c894319.png)

现在，我们将使用以下代码来拟合包含分类变量和连续变量的逻辑回归模型:

```
# Fit regression model with Education & Gender variables
logit.fit <- glm(Engaged ~ ., data = continuousDF, family = binomial)
summary(logit.fit)
```

您应该得到如下所示的输出:

![](assets/e3a76724-02ca-4dbb-b3db-9cbb77ee9554.png)

让我们仔细看看这个输出。`Total.Claim.Amount`变量和`EducationDoctor`变量在`0.05`显著性水平上显著，并且都与输出变量`Engaged`呈正相关。因此，索赔总额越高，客户就越有可能打营销电话。此外，拥有博士学位的客户比其他教育背景的客户更有可能参与营销电话。在`0.1`显著性水平上，我们可以看到`Income`、`Number.of.Policies`和`EducationMaster`现在与输出变量`Engaged`有显著关系。通过查看该回归分析输出，我们可以很容易地看到输入和输出变量之间的关系，并且我们可以了解客户的哪些属性与客户参与营销电话有积极或消极的关系。

R 练习的完整代码可以在 https://github . com/Yoon hwang/hands-on-data-science-for-marketing/blob/master/ch . 3/R/regression analysis 的资源库中找到。R 。

<title>Summary</title> <link href="css/style.css" rel="stylesheet" type="text/css">  

# 摘要

在本章中，我们讨论了如何使用解释性分析来洞察客户行为。我们讨论了如何使用回归分析来更深入地理解客户行为。更具体地说，您学习了如何使用逻辑回归来了解客户的哪些属性推动了更高的参与度。在 Python 和 R 练习中，我们采用了在第 2 章[、*关键绩效指标和可视化*中介绍的描述性分析，以及用于解释性分析的回归分析。我们通过分析数据来开始练习，以便更好地理解和识别数据中值得注意的模式。在分析数据时，您学习了另外一种可视化数据的方法，通过箱线图，使用 Python 中的`matplotlib`和`pandas`包和 r 中的`ggplot2`库](1fb7a852-d8fa-43f6-9807-6e3292dfa280.xhtml)

在拟合回归模型时，我们讨论了两种不同类型的变量:连续变量和分类变量。您了解了在拟合逻辑回归模型时处理分类变量的挑战，以及如何处理这些变量。对于 Python，我们介绍了两种处理分类变量的方法:来自`pandas`包的`factorize`和`Categorical`函数。对于 R，我们讨论了在拟合逻辑回归模型时如何使用`factor`函数来处理分类变量。通过回归分析结果，我们展示了如何通过查看系数和 *p* 值来解释结果以及输入和输出变量之间的关系。通过查看回归分析输出，我们可以了解客户的哪些属性显示出与客户营销参与的重要关系。

在下一章，我们将扩展你的解释性分析的知识。我们将分析是什么推动了客户参与后的转化。您还将了解另一种机器学习算法，决策树，以及如何使用它们进行解释性分析。