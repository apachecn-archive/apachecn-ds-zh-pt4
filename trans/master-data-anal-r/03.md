`

# 三、过滤和汇总数据

从平面文件或数据库加载数据后(正如我们在[第 1 章](ch01.html "Chapter 1. Hello, Data!")，*中看到的，你好，数据！*)，或者通过一些 API 直接从网络上获取(如[第 2 章](ch02.html "Chapter 2. Getting Data from the Web")、*从网络上获取数据*中所述)，在实际的数据分析发生之前，我们通常需要聚集、转换或过滤原始数据集。

在本章中，我们将重点介绍如何:

*   过滤数据框中的行和列
*   汇总和汇总数据
*   除了 base R 方法之外，还可以使用`dplyr`和`data.table`包来提高此类任务的性能

# 丢弃不必要的数据

虽然不加载不必要的数据是最佳解决方案(参见[第 1 章](ch01.html "Chapter 1. Hello, Data!")、*您好，数据！*)，我们经常需要过滤 R 中的原始数据集。这可以使用传统的工具和来自 base R 的函数来完成，例如`subset`，通过使用`which`和`[`或`[[`操作符(参见下面的代码)，或者例如使用`sqldf`包的类似 SQL 的方法:

```
> library(sqldf)

> sqldf("SELECT * FROM mtcars WHERE am=1 AND vs=1")

 mpg cyl  disp  hp drat    wt  qsec vs am gear carb

1 22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1

2 32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1

3 30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2

4 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1

5 27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1

6 30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2

7 21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2

```

我确信，所有具有不错的 SQL 背景并且刚刚接触 R 的读者都会喜欢这种过滤数据的替代方式，但是我个人更喜欢下面这个非常相似、原生并且更加简洁的 R 版本:

```
> subset(mtcars, am == 1 & vs == 1)

 mpg cyl  disp  hp drat    wt  qsec vs am gear carb

Datsun 710     22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1

Fiat 128       32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1

Honda Civic    30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2

Toyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1

Fiat X1-9      27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1

Lotus Europa   30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2

Volvo 142E     21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2

```

请注意结果中的细微差别。这是因为默认情况下`sqldf`的`row.names`参数是`FALSE`，当然可以覆盖它以获得完全相同的结果:

```
> identical(

+     sqldf("SELECT * FROM mtcars WHERE am=1 AND vs=1",

+       row.names = TRUE),

+     subset(mtcars, am == 1 & vs == 1)

+     )

[1] TRUE

```

这些例子关注于如何从`data.frame`中删除行，但是如果我们还想删除一些列呢？

SQL 方法非常简单；只需指定所需的列，而不是在`SELECT`语句中指定`*`。另一方面，`subset`也通过`select`参数支持这种方法，它可以采用向量或一个 R 表达式来描述一系列列:

```
> subset(mtcars, am == 1 & vs == 1, select = hp:wt)

 hp drat    wt

Datsun 710      93 3.85 2.320

Fiat 128        66 4.08 2.200

Honda Civic     52 4.93 1.615

Toyota Corolla  65 4.22 1.835

Fiat X1-9       66 4.08 1.935

Lotus Europa   113 3.77 1.513

Volvo 142E     109 4.11 2.780

```

### Tip

通过`c`函数将未加引号的列名作为一个向量进行传递，以按照给定的顺序选择任意的列列表，或者使用-运算符排除指定的列，例如`subset(mtcars, select = -c(hp, wt))`。

让我们把它带到的下一步，看看当我们面对`base`函数的一些性能问题时，我们如何在一些更大的数据集上应用前面提到的过滤器。

## 以有效的方式丢弃不需要的数据

R 最适合可以放在实际物理内存中的数据集，一些 R 包提供了对这些数据的快速访问。

### 注意

一些基准测试(参见本书末尾的*参考文献*部分)提供了比当前开源(例如 MySQL、PostgreSQL 和 Impala)和商业数据库(例如 HP Vertica)提供的更有效的汇总 R 函数的真实例子。

一些相关的包已经在[第一章](ch01.html "Chapter 1. Hello, Data!")，*你好，数据！*，在这里我们对从`hflights`包读取相对大量的数据到 r 中进行了基准测试

让我们看看前面的示例在这个 25 万行的数据集上是如何执行的:

```
> library(hflights)

> system.time(sqldf("SELECT * FROM hflights WHERE Dest == 'BNA'", 

+   row.names = TRUE))

 user  system elapsed 

 1.487   0.000   1.493 

> system.time(subset(hflights, Dest == 'BNA'))

 user  system elapsed 

 0.132   0.000   0.131

```

`base::subset`函数看起来执行得很好，但是我们能让它更快吗？第二代的 `plyr`包叫做`dplyr`(相关细节将在本章的*高性能助手函数*部分和[第 4 章](ch04.html "Chapter 4. Restructuring Data")，*重构数据*中讨论)，它以一种相当直观的方式提供了最常见的数据库操作方法的极快的 C++实现:

```
> library(dplyr)

> system.time(filter(hflights, Dest == 'BNA'))

 user  system elapsed 

 0.021   0.000   0.022

```

此外，我们可以通过从数据集中删除一些列来扩展这个解决方案，就像我们之前对`subset`所做的那样，尽管现在我们调用`select`函数，而不是传递同名的参数:

```
> str(select(filter(hflights, Dest == 'BNA'), DepTime:ArrTime))

'data.frame':  3481 obs. of  2 variables:

 $ DepTime: int  1419 1232 1813 900 716 1357 2000 1142 811 1341 ...

 $ ArrTime: int  1553 1402 1948 1032 845 1529 2132 1317 945 1519 ...

```

所以，这就像是调用了`filter`函数而不是`subset`，我们得到结果的速度比眨眼还快！`dplyr`包可以与传统的`data.frame`或`data.table`对象一起工作，或者可以直接与最广泛使用的数据库引擎交互。请注意，`dplyr`中没有保留行名，所以如果您需要它们，在将它们传递给`dplyr`或直接传递给`data.table`之前，值得将名称复制到显式变量中，如下所示:

```
> mtcars$rownames <- rownames(mtcars)

> select(filter(mtcars, hp > 300), c(rownames, hp))

 rownames  hp

1 Maserati Bora 335

```

## 用另一种有效的方式丢弃不需要的数据

让我们来看一个没有`dplyr`的`data.table`解决方案的简单例子。

### 注意

`data.table`包提供了一种非常有效的方式来处理基于列的、自动索引的内存数据结构中的大型数据集，并向后兼容传统的 `data.frame`方法。

加载完包后，我们必须将`hflights`繁体`data.frame`转换为`data.table`。然后，我们创建一个名为`rownames`的新列，在特定于`data.table`的:=赋值操作符的帮助下，我们将原始数据集的`rownames`赋值给该列:

```
> library(data.table)

> hflights_dt <- data.table(hflights)

> hflights_dt[, rownames := rownames(hflights)]

> system.time(hflights_dt[Dest == 'BNA'])

 user  system elapsed 

 0.021   0.000   0.020

```

嗯，习惯定制的`data.table`语法需要一些时间，对于传统的 R 用户来说，乍一看可能有点奇怪，但从长远来看，绝对值得掌握。您获得了很好的性能，并且在经历了前几个示例的相对陡峭的学习曲线之后，语法变得自然而灵活。

事实上，`data.table`语法与 SQL 非常相似:

```
DT[i, j, ... , drop = TRUE]

```

这可以用 SQL 命令来描述，如下所示:

```
DT[where, select | update, group by][having][order by][ ]...[ ]

```

因此，`[.data.table`(代表应用于`data.table`对象的`[`操作符)与传统的`[.data.frame`语法相比有一些不同的参数，正如您在前面的例子中已经看到的。

### 注意

现在，我们没有详细讨论赋值操作符，因为对于本书的介绍性部分来说，这个例子可能太复杂了，而且我们可能正在走出我们的舒适区。因此，请在[第 4 章](ch04.html "Chapter 4. Restructuring Data")、*重组数据*中找到更多详细信息，或者前往`?data.table`查看更具技术性的概述。

似乎`[.data.table`操作符的第一个参数(`i`)代表过滤，或者换句话说，代表 SQL 术语中的`WHERE`语句，而`[.data.frame`期望索引指定从原始数据集中保留哪些行。这两个参数的真正区别在于，前者可以接受任何 R 表达式，而后者传统方法主要期望整数或逻辑值。

总之，过滤就像将一个 R 表达式传递给特定于`data.table`的`[`操作符的`i`参数一样简单。此外，让我们看看如何在`data.table`语法中选择列，这应该在调用的第二个参数(`j`)中根据上述通用`data.table`语法来完成:

```
> str(hflights_dt[Dest == 'BNA', list(DepTime, ArrTime)]) 

Classes 'data.table' and 'data.frame':     3481 obs. of 2 variables:

 $ DepTime: int  1419 1232 1813 900 716 1357 2000 1142 811 1341 ...

 $ ArrTime: int  1553 1402 1948 1032 845 1529 2132 1317 945 1519 ...

 - attr(*, ".internal.selfref")=<externalptr>

```

好了，现在我们有了两个预期的列，包含 3481 个观察值。注意，`list`用于定义需要保留的列，尽管`c`(一个从基数 R 连接向量元素的函数)更传统地用于`[.data.frame`。用`[.data.table`也可以实现后者，但是你必须将变量名作为一个字符向量传递，并将`with`设置为`FALSE`:

```
> hflights_dt[Dest == 'BNA', c('DepTime', 'ArrTime'), with = FALSE] 

```

### 注意

在`plyr`包的样式中，可以用点代替`list`作为函数名；例如:`hflights_dt[, .(DepTime, ArrTime)]`。

现在，我们或多或少地熟悉了在实时 R 会话中过滤数据的选项，并且知道了`dplyr`和`data.table`包的整体语法，让我们看看如何使用它们来聚合和汇总数据。



# 聚集

汇总数据的最直接的方式是从`stats`包中调用`aggregate`函数，这正是我们正在寻找的:通过分组变量将数据分成子集，然后分别计算它们的汇总统计数据。调用`aggregate`函数最基本的方法是传递要聚合的数字向量，以及一个定义函数拆分的因子变量，该函数在要应用的`FUN`参数中传递。现在，让我们看看每个工作日中转航班的平均比率:

```
> aggregate(hflights$Diverted, by = list(hflights$DayOfWeek),

+   FUN = mean)

 Group.1           x

1       1 0.002997672

2       2 0.002559323

3       3 0.003226211

4       4 0.003065727

5       5 0.002687865

6       6 0.002823121

7       7 0.002589057

```

运行前面的脚本花费了一些时间，但请记住，我们刚刚汇总了大约 25 万行，以查看 2011 年从休斯顿机场起飞的改道航班的日平均数量。

换句话说，对于那些没有进入统计的人来说，这也是有意义的，即每个工作日被转移的航班的百分比。结果相当有趣，因为似乎航班在周中(约 0.3%)比周末(约少 0.05%)更经常改道，至少从休斯顿出发。

调用前面的函数的另一种方法是在`with`函数中提供参数，这似乎是一种更人性化的表达方式，因为它使我们不必重复提及`hflights`数据库:

```
> with(hflights, aggregate(Diverted, by = list(DayOfWeek),

+   FUN = mean))

```

这里没有显示结果，因为它们与前面显示的结果完全相同。`aggregate`功能的手册(见`?aggregate`)指出它以一种方便的形式返回结果。那么，检查上述返回数据的列名似乎并不方便，对吗？我们可以通过使用公式符号来克服这个问题，而不是分别定义数值和因子变量的:

```
> aggregate(Diverted ~ DayOfWeek, data = hflights, FUN = mean)

 DayOfWeek    Diverted

1         1 0.002997672

2         2 0.002559323

3         3 0.003226211

4         4 0.003065727

5         5 0.002687865

6         6 0.002823121

7         7 0.002589057

```

使用公式符号的收益至少是两倍:

*   需要键入的字符相对较少
*   结果中的标题和行名是正确的
*   这个版本也比以前的`aggregate`调用运行得快一点；请参见本节末尾的全面基准测试

使用公式符号的唯一缺点是您必须学习它，这一开始可能看起来有点笨拙，但是由于公式在许多 R 函数和包中被大量使用，特别是在定义模型时，从长远来看，学习如何使用它们绝对是值得的。

### 注意

公式符号继承自 S 语言，具有以下通用语法:`response_variable ~ predictor_variable_1 + … + predictor_variable_n`。该符号还包括一些其他符号，例如`-`用于排除变量，而`:`或`*`用于包括变量之间的相互作用，无论变量本身是否存在。详见[第五章](ch05.html "Chapter 5. Building Models (authored by Renata Nemeth and Gergely Toth)")、*架构模型(作者雷娜塔·内梅特和杰格利·托特)*和 R 控制台中的`?formula`。

## 使用 base R 命令实现更快的聚合

对聚合数据的另一种解决方案可能是调用`tapply`或`by`函数，这可以对一个*参差不齐的*数组应用 R 函数。后者意味着我们可以提供一个或多个`INDEX`变量，这些变量将被强制分解，然后，对每个子集中的所有单元分别运行所提供的 R 函数。下面是一个简单的例子:

```
> tapply(hflights$Diverted, hflights$DayOfWeek, mean)

 1        2        3        4        5        6        7 

0.002998 0.002559 0.003226 0.003066 0.002688 0.002823 0.002589 

```

请注意，`tapply`返回一个`array`对象，而不是方便的数据帧；另一方面，它运行要比上面提到的集合调用快得多。因此，使用`tapply`进行计算，然后使用将结果转换为具有适当列名的`data.frame`可能是合理的。

## 便捷的助手功能

这种转换可以很容易地以非常用户友好的方式完成，例如，使用`plyr`包，这是`dplyr`包的通用版本，代表 *plyr 专业 f* *或数据帧*。

`plyr`包提供了各种函数来应用来自`data.frame`、`list`或`array`对象的数据，并可以以任何提到的格式返回结果。这些函数的命名方案很容易记住:函数名的第一个字符代表输入数据的类，第二个字符代表输出格式，所有情况下后面都跟着 *ply* 。除了上述三个 R 类，还有一些由字符编码的特殊选项:

*   `d`代表`data.frame`
*   `s`代表`array`
*   `l`代表`list`
*   `m`是一种特殊的输入类型，这意味着我们以表格形式为函数提供多个参数
*   `r`输入类型需要一个整数，它指定函数将被复制的次数
*   `_`是一种特殊的输出类型，它不会为函数返回任何内容

因此，以下是最常用的组合:

*   `ddply`以`data.frame`为输入，返回`data.frame`
*   `ldply`将`list`作为输入，但返回`data.frame`
*   `l_ply`不返回任何东西，但是它真的很有用，例如，遍历许多元素而不是一个`for`循环；与设置`.progress`参数一样，该函数可以显示迭代的当前状态，剩余时间

请在[第四章](ch04.html "Chapter 4. Restructuring Data")、*重组数据*中找到`plyr`的更多细节、示例和用例。在这里，我们将只专注于如何汇总数据。为此，我们将在以下所有示例中使用`ddply`(不要与`dplyr`包混淆):将`data.frame`作为输入参数，用同一个类返回数据。

因此，让我们加载这个包，并通过`DayOfWeek`对每个子集应用`Diverted`列上的`mean`函数:

```
> library(plyr)

> ddply(hflights, .(DayOfWeek), function(x) mean(x$Diverted))

 DayOfWeek          V1

1         1 0.002997672

2         2 0.002559323

3         3 0.003226211

4         4 0.003065727

5         5 0.002687865

6         6 0.002823121

7         7 0.002589057

```

### 注意

`plyr`包的`.`函数为我们提供了一种便捷的方式来引用变量(名称);否则，`DayOfWeek`列的内容会被`ddply`解释，导致错误。

这里需要注意的重要一点是`ddply`比我们第一次尝试使用`aggregate`函数要快得多。另一方面，我对的结果还不满意，`V1`和这样有创意的专栏名字总是让我抓狂。让我们调用`summarise`助手函数而不是之前应用的匿名函数，而不是更新`data.frame`后处理的名称；在这里，我们还可以为新计算的列提供所需的名称:

```
> ddply(hflights, .(DayOfWeek), summarise, Diverted = mean(Diverted))

 DayOfWeek    Diverted

1         1 0.002997672

2         2 0.002559323

3         3 0.003226211

4         4 0.003065727

5         5 0.002687865

6         6 0.002823121

7         7 0.002589057

```

好了，好多了。但是，我们能做得更好吗？

## 高性能辅助功能

《T0》、《T1》和其他几个 R 包的作者 Hadley Wickham 在 2008 年开始开发《T2》的第二代，或者更确切地说是一个特殊版本。基本概念是`plyr`最常用于将一个`data.frame`转换为另一个`data.frame`；因此，其操作需要格外注意。专门用于数据帧的`dplyr`包`plyr`提供了用原始 C++编写的 `plyr`函数的更快实现，并且`dplyr`还可以处理远程数据库。

然而，性能改进也与其他一些变化齐头并进；例如，`dplyr`的语法与`plyr`相比发生了很大的变化。虽然前面提到的`summarise`函数确实存在于`dplyr`中，但是我们已经没有了`ddplyr`函数，因为包中的所有函数都被专门用来充当`plyr::ddplyr`的某个组件。

无论如何，为了保持理论背景简短，如果我们想要总结一个数据集的子组，我们必须在聚合之前定义组:

```
> hflights_DayOfWeek <- group_by(hflights, DayOfWeek)

```

产生的对象与我们之前的完全相同`data.frame`,只有一个例外:一堆元数据通过属性的方式被合并到对象中。为了使下面的输出简短，我们没有列出对象的整个结构(`str`)，而是只显示了属性:

```
> str(attributes(hflights_DayOfWeek))

List of 9

 $ names             : chr [1:21] "Year" "Month" "DayofMonth" ...

 $ class             : chr [1:4] "grouped_df" "tbl_df" "tbl" ...

 $ row.names         : int [1:227496] 5424 5425 5426 5427 5428 ...

 $ vars              :List of 1

 ..$ : symbol DayOfWeek

 $ drop              : logi TRUE

 $ indices           :List of 7

 ..$ : int [1:34360] 2 9 16 23 30 33 40 47 54 61 ...

 ..$ : int [1:31649] 3 10 17 24 34 41 48 55 64 70 ...

 ..$ : int [1:31926] 4 11 18 25 35 42 49 56 65 71 ...

 ..$ : int [1:34902] 5 12 19 26 36 43 50 57 66 72 ...

 ..$ : int [1:34972] 6 13 20 27 37 44 51 58 67 73 ...

 ..$ : int [1:27629] 0 7 14 21 28 31 38 45 52 59 ...

 ..$ : int [1:32058] 1 8 15 22 29 32 39 46 53 60 ...

 $ group_sizes       : int [1:7] 34360 31649 31926 34902 34972 ...

 $ biggest_group_size: int 34972

 $ labels            :'data.frame':  7 obs. of  1 variable:

 ..$ DayOfWeek: int [1:7] 1 2 3 4 5 6 7

 ..- attr(*, "vars")=List of 1

 .. ..$ : symbol DayOfWeek

```

从这个元数据来看，`indices`属性很重要。它只是列出了某个工作日的每一行的 id，因此以后的操作可以很容易地从整个数据集中选择子组。因此，让我们来看看由于使用`dplyr`的`summarise`而不是`plyr`而导致的性能提升，分流航班的比例看起来如何:

```
> dplyr::summarise(hflights_DayOfWeek, mean(Diverted))

Source: local data frame [7 x 2]

 DayOfWeek mean(Diverted)

1         1    0.002997672

2         2    0.002559323

3         3    0.003226211

4         4    0.003065727

5         5    0.002687865

6         6    0.002823121

7         7    0.002589057 

```

结果是非常熟悉，这很好。但是，在运行这个示例时，您测量了执行时间吗？这几乎是一瞬间的事，这让`dplyr`变得更好。

## 用数据表汇总

还记得`[.data.table`的第二个论点吗？它叫做`j`，代表一个`SELECT`或者一个`UPDATE` SQL 语句，最重要的特点是它可以是任何 R 表达式。因此，我们可以简单地通过传递一个函数，并在`by`参数的帮助下设置组:

```
> hflights_dt[, mean(Diverted), by = DayOfWeek]

 DayOfWeek          V1

1:         6 0.002823121

2:         7 0.002589057

3:         1 0.002997672

4:         2 0.002559323

5:         3 0.003226211

6:         4 0.003065727

7:         5 0.002687865

```

我很确定你一点也不会对`data.table`返回结果的速度感到惊讶，因为人们可以很快习惯伟大的工具。此外，与之前的两行`dplyr`调用相比，它非常简洁，对吗？这种解决方案的唯一缺点是工作日是按照一些难以理解的等级来排序的。详见[第四章](ch04.html "Chapter 4. Restructuring Data")、*重组数据*；现在，让我们通过设置一个键来快速解决这个问题，这意味着我们首先通过`DayOfWeek`命令`data.table`:

```
> setkey(hflights_dt, 'DayOfWeek')

> hflights_dt[, mean(Diverted), by = DayOfWeek]

 DayOfWeek          V1

1:         1 0.002997672

2:         2 0.002559323

3:         3 0.003226211

4:         4 0.003065727

5:         5 0.002687865

6:         6 0.002823121

7:         7 0.002589057

```

### 注意

要为结果表格对象中的第二列指定一个名称而不是`V1`，可以将`summary`对象指定为一个命名列表，例如，指定为`hflights_dt[, list('mean(Diverted)' = mean(Diverted)), by = DayOfWeek]`，其中可以使用`.`(点号)而不是`list`，就像在`ply` `r`中一样。

除了按照预期的顺序获得结果之外，通过已经存在的键汇总数据也运行得相对较快。让我们在您的机器上用一些经验证据来验证这一点！



# 运行基准

正如前面章节中已经讨论过的，在`microbenchmark`包的帮助下，我们可以在同一台机器上运行任意数量的不同函数指定的次数，以获得一些可重复的性能结果。

为此，我们必须首先定义我们想要进行基准测试的函数。这些是根据前面的示例编译的:

```
> AGGR1     <- function() aggregate(hflights$Diverted,

+   by = list(hflights$DayOfWeek), FUN = mean)

> AGGR2     <- function() with(hflights, aggregate(Diverted,

+   by = list(DayOfWeek), FUN = mean))

> AGGR3     <- function() aggregate(Diverted ~ DayOfWeek,

+   data = hflights, FUN = mean)

> TAPPLY    <- function() tapply(X = hflights$Diverted, 

+   INDEX = hflights$DayOfWeek, FUN = mean)

> PLYR1     <- function() ddply(hflights, .(DayOfWeek),

+   function(x) mean(x$Diverted))

> PLYR2     <- function() ddply(hflights, .(DayOfWeek), summarise,

+   Diverted = mean(Diverted))

> DPLYR     <- function() dplyr::summarise(hflights_DayOfWeek,

+   mean(Diverted))

```

但是，如前所述，`dplyr`中的`summarise`函数需要一些事先的数据重组，这也需要时间。为此，让我们定义另一个函数，它也包括创建新的数据结构和真正的聚合:

```
> DPLYR_ALL <- function() {

+     hflights_DayOfWeek <- group_by(hflights, DayOfWeek)

+     dplyr::summarise(hflights_DayOfWeek, mean(Diverted))

+ }

```

同样，基准测试`data.table`也需要测试环境的一些额外变量；由于`hlfights_dt`已经由`DayOfWeek`排序，让我们创建一个新的`data.table`对象进行基准测试:

```
> hflights_dt_nokey <- data.table(hflights)

```

此外，验证它没有键可能是有意义的:

```
> key(hflights_dt_nokey)

NULL

```

好了，现在我们可以用一个函数定义`data.table`测试用例，这个函数也包括到`data.table`的转换，并且添加一个索引来公平对待`dplyr`:

```
> DT     <- function() hflights_dt_nokey[, mean(FlightNum),

+   by = DayOfWeek]

> DT_KEY <- function() hflights_dt[, mean(FlightNum),

+   by = DayOfWeek]

> DT_ALL <- function() {

+     setkey(hflights_dt_nokey, 'DayOfWeek')

+     hflights_dt[, mean(FlightNum), by = DayOfWeek]

+     setkey(hflights_dt_nokey, NULL)

+ }

```

现在我们已经为测试准备好了所有描述的实现，让我们加载`microbenchmark` 包来完成它的工作:

```
> library(microbenchmark)

> res <- microbenchmark(AGGR1(), AGGR2(), AGGR3(), TAPPLY(), PLYR1(),

+          PLYR2(), DPLYR(), DPLYR_ALL(), DT(), DT_KEY(), DT_ALL())

> print(res, digits = 3)

Unit: milliseconds

 expr     min      lq  median      uq     max neval

 AGGR1() 2279.82 2348.14 2462.02 2597.70 2719.88    10

 AGGR2() 2278.15 2465.09 2528.55 2796.35 2996.98    10

 AGGR3() 2358.71 2528.23 2726.66 2879.89 3177.63    10

 TAPPLY()   19.90   21.05   23.56   29.65   33.88    10

 PLYR1()   56.93   59.16   70.73   82.41  155.88    10

 PLYR2()   58.31   65.71   76.51   98.92  103.48    10

 DPLYR()    1.18    1.21    1.30    1.74    1.84    10

 DPLYR_ALL()    7.40    7.65    7.93    8.25   14.51    10

 DT()    5.45    5.73    5.99    7.75    9.00    10

 DT_KEY()    5.22    5.45    5.63    6.26   13.64    10

 DT_ALL()   31.31   33.26   35.19   38.34   42.83    10

```

结果相当惊人:从 2000 多毫秒开始，我们可以改进我们的工具，在仅仅 1 毫秒多一点的时间内提供完全相同的结果。这种扩散可以很容易地用对数标度在小提琴图上显示出来:

```
> autoplot(res)

```

![Running benchmarks](img/2028OS_03_01.jpg)

因此，`dplyr`似乎是最有效的解决方案，尽管如果我们还考虑到额外的步骤(对`data.frame`进行分组)，它会使原本明显的优势变得相当不可信。事实上，如果我们已经有了一个`data.table`对象，并且我们可以保存一个传统的`data.frame`对象到`data.table`的转换，那么`data.table`比`dplyr`执行得更好。然而，我很确定你不会真的注意到两个高性能解决方案之间的时差；这两种方法在处理更大的数据集时都做得很好。

值得一提的是，`dplyr`也可以处理`data.table`对象；因此，为了确保您不会被任何一个包所束缚，如果需要的话，这两个包都是值得使用的。以下是一个概念验证示例:

```
> dplyr::summarise(group_by(hflights_dt, DayOfWeek), mean(Diverted))

Source: local data table [7 x 2]

 DayOfWeek mean(Diverted)

1         1    0.002997672

2         2    0.002559323

3         3    0.003226211

4         4    0.003065727

5         5    0.002687865

6         6    0.002823121

7         7    0.002589057 

```

好的，现在我们很确定将来会使用`data.table`或`dplyr`来计算群体平均值。但是，更复杂的操作呢？



# 汇总功能

正如我们之前所讨论的，所有的聚合函数都可以采用任何有效的 R 函数来应用于数据的子集。一些 R 包使用户非常容易使用，而一些函数确实需要您完全理解包的概念、定制语法和选项，以充分利用高性能的机会。

关于这类更高级的话题，请参见[第四章](ch04.html "Chapter 4. Restructuring Data")、*重组数据*，以及本书末尾*参考资料*部分列出的进一步阅读材料。

现在，我们将专注于一个非常简单的`summary`函数，它在任何一般的数据分析项目中都极其常见:统计每组的病例数。这个简单的例子还将强调本章中提到的参考备选方案之间的一些差异。

## 统计亚组病例数

现在让我们把注意力集中在`plyr`、`dplyr`和`data.table`上，因为我非常确定你可以构建`aggregate`和`tapply`版本，而不会有任何严重的问题。基于前面的例子，当前的任务看起来相当简单:我们可以简单地调用`length`函数来返回`Diverted`列中的元素数量，而不是`mean`函数:

```
> ddply(hflights, .(DayOfWeek), summarise, n = length(Diverted))

 DayOfWeek     n

1         1 34360

2         2 31649

3         3 31926

4         4 34902

5         5 34972

6         6 27629

7         7 32058

```

现在，我们也知道周六离开休斯顿的航班数量相对较少。然而，这么简单的问题，我们真的要打那么多才能回答吗？此外，我们真的必须指定一个变量来计算病例数吗？你已经知道答案了:

```
> ddply(hflights, .(DayOfWeek), nrow)

 DayOfWeek    V1

1         1 34360

2         2 31649

3         3 31926

4         4 34902

5         5 34972

6         6 27629

7         7 32058

```

简而言之，没有必要从`data.frame`中选择一个变量来确定它的长度，因为简单地检查(子)数据集中的行数要容易得多(也快得多)。

然而，我们也可以用一种更加简单快捷的方式返回完全相同的结果。很可能，您已经想到使用传统的`table`函数来完成这样一个简单的任务:

```
> table(hflights$DayOfWeek)

 1     2     3     4     5     6     7 

34360 31649 31926 34902 34972 27629 32058

```

产生的对象的唯一问题是我们必须进一步转换它，例如，在大多数情况下转换成`data.frame`。嗯，`plyr`已经有一个助手函数一步完成这个了，名字很直观:

```
> count(hflights, 'DayOfWeek')

 DayOfWeek  freq

1         1 34360

2         2 31649

3         3 31926

4         4 34902

5         5 34972

6         6 27629

7         7 32058

```

因此，我们以一些相当简单的数据计数示例结束，但是让我们看看如何用`dplyr`实现汇总表。如果你只是试图修改我们之前的`dplyr`命令，你很快就会意识到传递`length`或`nrow`函数，就像我们在`plyr`中所做的那样，根本不起作用。然而，阅读 StackOverflow 上的手册或一些相关问题很快将我们的注意力引向一个叫做`n`的便利助手函数:

```
> dplyr::summarise(hflights_DayOfWeek, n())

Source: local data frame [7 x 2]

 DayOfWeek   n()

1         1 34360

2         2 31649

3         3 31926

4         4 34902

5         5 34972

6         6 27629

7         7 32058

```

然而，说实话，我们真的需要这种相对复杂的方法吗？如果你记得`hflights_DayOfWeek`的结构，你将很快意识到有一种更容易、更快捷的方法来找出每个工作日的航班总数:

```
> attr(hflights_DayOfWeek, 'group_sizes')

[1] 34360 31649 31926 34902 34972 27629 32058

```

此外，为了确保我们不会忘记`data.table`的自定义(但很漂亮)语法，让我们用另一个帮助函数来计算结果:

```
> hflights_dt[, .N, by = list(DayOfWeek)]

 DayOfWeek     N

1:         1 34360

2:         2 31649

3:         3 31926

4:         4 34902

5:         5 34972

6:         6 27629

7:         7 32058

```



# 总结

在这一章中，我们介绍了一些过滤和汇总数据的有效和方便的方法。我们讨论了一些过滤数据集的行和列的用例。我们还学习了如何汇总数据以供进一步分析。在熟悉了这些任务最流行的实现之后，我们将它们与可重复的例子和基准测试包进行了比较。

在下一章，我们将继续重组数据集和创建新变量的旅程。