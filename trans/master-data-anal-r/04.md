<title>Chapter 4. Restructuring Data</title><link href="epub.css" rel="stylesheet" type="text/css"> 

# 第四章。重构数据

我们已经在[第 3 章](ch03.html "Chapter 3. Filtering and Summarizing Data")、*过滤和汇总数据*中介绍了重组数据的最基本方法，当然，还有其他几个更复杂的任务，我们将在接下来的几页中掌握。

仅举一个简单的例子来说明如何需要多样化的工具来以可用于实际数据分析的形式获得数据:Hadley Wickham，最著名的 R 开发人员和用户之一，花了他博士论文的三分之一来重塑数据。正如他所说，“在进行任何探索性的数据分析或可视化之前，这是不可避免的。”

因此，现在除了前面的数据重组示例(如每组中元素的计数)之外，我们将重点关注一些更高级的功能，如下所示:

*   转置矩阵
*   拆分、应用和连接数据
*   计算表格的边距
*   合并数据框
*   铸造和熔化数据

# 转置矩阵

一种最常用的，但是经常不被提及的重构数据的方法是转置矩阵。这仅仅意味着通过`t`函数切换行和列，反之亦然:

```
> (m <- matrix(1:9, 3))

 [,1] [,2] [,3]

[1,]    1    4    7

[2,]    2    5    8

[3,]    3    6    9

> t(m)

 [,1] [,2] [,3]

[1,]    1    2    3

[2,]    4    5    6

[3,]    7    8    9

```

当然，这个`S3`方法也适用于`data.frame`，实际上，适用于任何表格对象。对于更高级的特性，比如转置多维表，看看`base`包中的 `aperm`函数。

<title>Filtering data by string matching</title><link href="epub.css" rel="stylesheet" type="text/css"> 

# 通过字符串匹配过滤数据

尽管一些过滤算法已经在前面的章节中讨论过，但是`dplyr`包包含了一些还没有被涵盖的神奇特性，在这里值得一提。此时我们都知道，`base`中的 `subset`函数，或者`dplyr`中的 `filter`函数用于过滤行， `select`函数可以用于选择列的子集。

过滤行的函数通常采用 R 表达式，该表达式返回要删除的行的 id，类似于`which`函数。另一方面，对于`select`函数来说，提供这样的 R 表达式来描述列名通常更有问题；在列名上计算 R 表达式更难，如果不是不可能的话。

`dplyr`包提供了一些有用的函数，可以根据列名模式选择一些数据列。例如，我们可以只保留以字符串`delay`结尾的变量:

```
> library(dplyr)

> library(hflights)

> str(select(hflights, ends_with("delay")))

'data.frame':  227496 obs. of  2 variables:

 $ ArrDelay: int  -10 -9 -8 3 -3 -7 -1 -16 44 43 ...

 $ DepDelay: int  0 1 -8 3 5 -1 -1 -5 43 43 ...

```

当然，有一个类似的 helper 函数用`starts_with`来检查列名的第一个字符，这两个函数都可以忽略(默认情况下)或者用`ignore.case`参数来考虑字符的大小写。我们还有更通用的`contains`函数，在列名中查找子字符串:

```
> str(select(hflights, contains("T", ignore.case = FALSE)))

'data.frame':  227496 obs. of  7 variables:

 $ DepTime          : int  1400 1401 1352 1403 1405 ...

 $ ArrTime          : int  1500 1501 1502 1513 1507 ...

 $ TailNum          : chr  "N576AA" "N557AA" "N541AA" "N403AA" ...

 $ ActualElapsedTime: int  60 60 70 70 62 64 70 59 71 70 ...

 $ AirTime          : int  40 45 48 39 44 45 43 40 41 45 ...

 $ TaxiIn           : int  7 6 5 9 9 6 12 7 8 6 ...

 $ TaxiOut          : int  13 9 17 22 9 13 15 12 22 19 ...

```

另一种选择是，我们可能需要一种更复杂的正则表达式方法，这是数据科学家的另一项极其重要的技能。现在，我们将为`matches`函数提供一个正则表达式，它将适合所有的列名。让我们选择名称由 5 或 6 个字符组成的所有列:

```
> str(select(hflights, matches("^[[:alpha:]]{5,6}$")))

'data.frame':  227496 obs. of  3 variables:

 $ Month : int  1 1 1 1 1 1 1 1 1 1 ...

 $ Origin: chr  "IAH" "IAH" "IAH" "IAH" ...

 $ TaxiIn: int  7 6 5 9 9 6 12 7 8 6 ...

```

通过在表达式前使用负号，我们可以保留所有与正则表达式不匹配的列名。例如，让我们确定列名中最常见的字符数:

```
> table(nchar(names(hflights)))

 4  5  6  7  8  9 10 13 16 17 

 2  1  2  5  4  3  1  1  1  1

```

然后，让我们从数据集中删除所有包含 7 或 8 个字符的列。现在，我们将显示筛选数据集中的列名:

```
> names(select(hflights, -matches("^[[:alpha:]]{7,8}$")))

 [1] "Year"              "Month"             "DayofMonth" 

 [4] "DayOfWeek"         "UniqueCarrier"     "FlightNum" 

 [7] "ActualElapsedTime" "Origin"            "Dest" 

[10] "TaxiIn"            "Cancelled"         "CancellationCode"

```

<title>Rearranging data</title><link href="epub.css" rel="stylesheet" type="text/css"> 

# 重新整理数据

有时，我们不想过滤数据的任何部分(既不是行，也不是列)，但是由于便利性或性能问题，数据并没有按照最有用的顺序排列，例如，我们已经在[第 3 章](ch03.html "Chapter 3. Filtering and Summarizing Data")、*过滤和汇总数据*中看到。

除了基本的`sort`和`order`函数，或者提供传递给`[`操作符的变量顺序，我们还可以使用一些类似 SQL 的解决方案和`sqldf`包，或者直接从数据库中查询正确格式的数据。并且前面提到的`dplyr`包也提供了一种有效的数据排序方法。让我们根据 25 万次飞行中每一次的实际飞行时间对`hflights`数据进行排序:

```
> str(arrange(hflights, ActualElapsedTime))

'data.frame':  227496 obs. of  21 variables:

 $ Year             : int  2011 2011 2011 2011 2011 2011 ...

 $ Month            : int  7 7 8 9 1 4 5 6 7 8 ...

 $ DayofMonth       : int  24 25 13 21 3 29 9 21 8 2 ...

 $ DayOfWeek        : int  7 1 6 3 1 5 1 2 5 2 ...

 $ DepTime          : int  2005 2302 1607 1546 1951 2035 ...

 $ ArrTime          : int  2039 2336 1641 1620 2026 2110 ...

 $ UniqueCarrier    : chr  "WN" "XE" "WN" "WN" ...

 $ FlightNum        : int  1493 2408 912 2363 2814 2418 ...

 $ TailNum          : chr  "N385SW" "N12540" "N370SW" "N524SW" ...

 $ ActualElapsedTime: int  34 34 34 34 35 35 35 35 35 35 ...

 $ AirTime          : int  26 26 26 26 23 23 27 26 25 25 ...

 $ ArrDelay         : int  9 -8 -4 15 -19 20 35 -15 86 -9 ...

 $ DepDelay         : int  20 2 7 26 -4 35 45 -8 96 1 ...

 $ Origin           : chr  "HOU" "IAH" "HOU" "HOU" ...

 $ Dest             : chr  "AUS" "AUS" "AUS" "AUS" ...

 $ Distance         : int  148 140 148 148 127 127 148 ...

 $ TaxiIn           : int  3 3 4 3 4 4 5 3 5 4 ...

 $ TaxiOut          : int  5 5 4 5 8 8 3 6 5 6 ...

 $ Cancelled        : int  0 0 0 0 0 0 0 0 0 0 ...

 $ CancellationCode : chr  "" "" "" "" ...

 $ Diverted         : int  0 0 0 0 0 0 0 0 0 0 ...

```

很明显，飞往奥斯汀的航班是最先显示的几条记录之一。为了提高可读性，可以使用自动导入的 `magrittr`包中的管道操作符以更好的方式调用上述三个 R 表达式，这提供了一种简单的方法来传递 R 对象作为后续 R 表达式的第一个参数:

```
> hflights %>% arrange(ActualElapsedTime) %>% str

```

因此，我们现在可以从核心对象开始 R 命令，并将每个 R 表达式的结果传递给链中的下一个表达式，而不是嵌套 R 函数。在大多数情况下，这使得代码更易于阅读。尽管大多数铁杆 R 程序员已经习惯了从内向外读取嵌套的函数调用，但是相信我，习惯这个漂亮的特性是相当容易的！不要让我把你和雷内·马格里特鼓舞人心的画作混淆了，这幅画成了“这不是烟斗”的口号，也是`magrittr`包装的象征:

![Rearranging data](graphics/2028OS_06_01.jpg)

可以链接的 R 表达式和对象的数量没有限制。例如，让我们也用过滤一些案例和变量，看看用`dplyr`遵循数据重组步骤有多容易:

```
> hflights %>%

+     arrange(ActualElapsedTime) %>%

+     select(ActualElapsedTime, Dest) %>%

+     subset(Dest != 'AUS') %>%

+     head %>%

+     str

'data.frame':  6 obs. of  2 variables:

 $ ActualElapsedTime: int  35 35 36 36 37 37

 $ Dest             : chr  "LCH" "LCH" "LCH" "LCH" ...

```

所以，现在我们对原始数据集进行了几次过滤，以查看奥斯汀之后最近的机场，代码确实易于阅读和理解。这是一种很好的、有效的过滤数据的方法，尽管有些人更喜欢在`data.table`包中使用漂亮的一行程序:

```
> str(head(data.table(hflights, key = 'ActualElapsedTime')[Dest !=

+   'AUS', c('ActualElapsedTime', 'Dest'), with = FALSE]))

Classes 'data.table' and 'data.frame':  6 obs. of  2 variables:

 $ ActualElapsedTime: int  NA NA NA NA NA NA

 $ Dest             : chr  "MIA" "DFW" "MIA" "SEA" ...

 - attr(*, "sorted")= chr "ActualElapsedTime"

 - attr(*, ".internal.selfref")=<externalptr>

```

近乎完美！唯一的问题是，由于缺少值，我们得到了不同的结果，这些值在数据集的开始是有序的，而我们将`data.table`对象定义为由`ActualElapsedTime`索引的。为了解决这个问题，让我们删除`NA`值，而不是将列名指定为字符串，并强制将`with`参数指定为`FALSE`，让我们传递一个列名列表:

```
> str(head(na.omit(

+   data.table(hflights, key = 'ActualElapsedTime'))[Dest != 'AUS',

+     list(ActualElapsedTime, Dest)]))

Classes 'data.table' and 'data.frame':  6 obs. of  2 variables:

 $ ActualElapsedTime: int  35 35 36 36 37 37

 $ Dest             : chr  "LCH" "LCH" "LCH" "LCH" ...

 - attr(*, "sorted")= chr "ActualElapsedTime"

 - attr(*, ".internal.selfref")=<externalptr>

```

这与我们之前看到的结果完全相同。请注意，在这个例子中，我们在将`data.frame`转换为`data.table`后省略了`NA`值，由`ActualElapsedTime`变量索引，这比首先在`hflights`上调用`na.omit`，然后计算所有其他 R 表达式要快得多:

```
> system.time(str(head(data.table(na.omit(hflights),

+   key = 'ActualElapsedTime')[Dest != 'AUS',

+     c('ActualElapsedTime', 'Dest'), with = FALSE])))

 user  system elapsed 

 0.374   0.017   0.390 

> system.time(str(head(na.omit(data.table(hflights,

+   key = 'ActualElapsedTime'))[Dest != 'AUS',

+     c('ActualElapsedTime', 'Dest'), with = FALSE])))

 user  system elapsed 

 0.22    0.00    0.22

```

<title>dplyr versus data.table</title><link href="epub.css" rel="stylesheet" type="text/css"> 

# dplyr 对比数据表

您现在可能想知道，“我们应该使用哪个包？”

`dplyr`和`data.table`包提供了一个显著不同的语法和一个稍微不那么决定性的性能差异。虽然`data.table`似乎在大型数据集上更有效，但在这个范围内没有明显的赢家——除了在大量组上进行聚合。老实说，`magrittr`包提供的`dplyr`语法也可以被`data.table`对象使用。

此外，还有另一个 R 包提供了 R 中的管道，称为 `pipeR`包，它声称在大型数据集上比`magrittr`有效得多。这种性能提升是因为`pipeR`操作符不像`magrittr`中兼容 F#语言的`|>`操作符那样聪明。有时，这种性能开销估计是完全不使用管道的性能开销的 5-15 倍。

在花相当多的时间了解它的用法之前，应该考虑一下 R 包背后的社区和支持。简而言之，`data.table`软件包现在已经足够成熟，毫无疑问，可以用于生产，因为大约 6 年前 Matt Dowle 开始开发，当时他在一家大型对冲基金工作。从那时起，发展一直在继续。Matt 和 Arun(该包的共同开发者)不时发布新功能和性能调整，他们似乎都热衷于在公共 R 论坛和渠道上提供支持，如邮件列表和 StackOverflow。

另一方面，`dplyr`是由 Hadley Wickham 和 RStudio 发布的，R 社区中最知名的人和趋势公司之一，这转化为 StackOverflow 和 GitHub 上更大的用户群、社区和即时支持。

简而言之，我建议在花一些时间去发现它们提供的功能和特性之后，使用最适合你需求的软件包。如果您来自 SQL 背景，您可能会发现`data.table`要方便得多，而其他人宁愿选择 Hadleyverse(看看这个名称的 R 包；它安装了一堆有用的哈德利开发的 R 包)。您不应该在一个项目中混合使用这两种方法，因为考虑到可读性和性能问题，最好一次只使用一种语法。

为了更深入地理解不同方法的优缺点，在接下来的几页中，我将继续提供同一问题的多个实现。

<title>Computing new variables</title><link href="epub.css" rel="stylesheet" type="text/css"> 

# 计算新变量

重构数据集时，我们通常执行的最琐碎的操作之一是创建一个新变量。对于一个传统的`data.frame`，它就像给 R 对象的一个新变量赋一个`vector`一样简单。

这个方法也适用于`data.table`，但是不推荐使用，因为有一种更有效的方法可以在数据集中创建一个甚至多个列:

```
> hflights_dt <- data.table(hflights)

> hflights_dt[, DistanceKMs := Distance / 0.62137]

```

我们刚刚通过简单的除法计算了始发地和目的地机场之间的距离，单位为千米；尽管所有的铁杆用户都可以使用`udunits2`包，其中包含了一堆基于 Unidata 的`udunits`库的转换工具。

正如前面所看到的，data.table 在方括号中使用了特殊的:=赋值操作符，乍一看可能很奇怪，但是您会喜欢它的！

### 注意

`:=`操作符可以比传统的`<-`赋值快 500 倍以上，后者是基于官方的`data.table`文档。这种加速是由于没有像 3.1 版本之前的 R 那样将整个数据集复制到内存中。此后 R 使用了浅拷贝，大大提高了列更新的性能，但还是被`data.table`强大的就地更新打败。

比较传统的`<-`操作符和`data.table`操作符运行上述计算的速度:

```
> system.time(hflights_dt$DistanceKMs <-

+   hflights_dt$Distance / 0.62137)

 user  system elapsed 

 0.017   0.000   0.016 

> system.time(hflights_dt[, DistanceKMs := Distance / 0.62137])

 user  system elapsed 

 0.003   0.000   0.002

```

令人印象深刻，对吧？但是值得再次检查我们刚刚做的事情。当然，第一个传统调用会创建/更新`DistanceKMs`变量，但是第二个调用会发生什么呢？`data.table`语法没有返回任何东西(可见的)，但是在后台，`hflights_dt` R 对象由于`:=`操作符而被就地更新。

### 注意

请注意，`:=`操作符在`knitr`内部使用时会产生意想不到的结果，比如在创建一个新变量后返回可见的`data.table`，或者当返回为`echo = TRUE`时命令呈现奇怪。作为一种变通方法，Matt Dowle 建议增加`data.table`的`depthtrigger`选项，或者可以简单地重新分配同名的`data.table`对象。另一个解决方案可能是使用我的`pander`包而不是`knitr`。:)

但是再问一次，怎么会这么快？

## 内存剖析

`data.table`包的神奇之处在于——除了源代码中有超过 50%的 C 代码——只有在真正必要的时候才复制内存中的对象。这意味着 R 经常在内存中复制对象，同时更新这些对象，`data.table`试图将这些资源饥渴的动作保持在最低水平。让我们在 `pryr`包的帮助下，通过分析前面的例子来验证这一点，该包提供了对一些帮助函数的方便访问，用于内存分析和理解 R-internals。

首先，让我们重新创建`data.table`对象，并记下指针值(对象在内存中的位置地址),以便我们稍后能够验证新变量是否只是更新了同一个 R 对象，或者在操作发生时它是否在内存中被复制:

```
> library(pryr)

> hflights_dt <- data.table(hflights)

> address(hflights_dt)

[1] "0x62c88c0"

```

好的，那么`0x62c88c0`指的是`hflights_dt`此刻存放的位置。现在，让我们检查它是否由于传统的赋值操作符而改变:

```
> hflights_dt$DistanceKMs <- hflights_dt$Distance / 0.62137

> address(hflights_dt)

[1] "0x2c7b3a0"

```

这肯定是一个不同的位置，这意味着向 R 对象添加一个新列也需要 R 在内存中复制整个对象。想象一下，由于增加了一列，我们现在在内存中移动了 21 列。

现在，为了实现`data.table`中`:=`的用法:

```
> hflights_dt <- data.table(hflights)

> address(hflights_dt)

[1] "0x8ca2340"

> hflights_dt[, DistanceKMs := Distance / 0.62137]

> address(hflights_dt)

[1] "0x8ca2340"

```

R 对象在内存中的位置没有变化！在内存中复制对象会耗费你大量的资源，从而耗费大量的时间。看看下面的例子，这是上面传统变量赋值调用的一个略微更新的版本，但是增加了一个便利层`within`:

```
> system.time(within(hflights_dt, DistanceKMs <- Distance / 0.62137))

 user  system elapsed 

 0.027   0.000   0.027

```

这里，使用`within`函数可能会在内存中再次复制 R 对象，因此会带来相对严重的性能开销。虽然前面的例子之间的绝对时间差可能看起来不太明显(在统计环境中不明显)，但是想象一下不必要的内存更新会如何影响一些大型数据集的数据分析的处理时间！

## 一次创建多个变量

`data.table`的一个很好的特性是用一个命令创建多个列，这在某些情况下非常有用。例如，我们可能对以英尺为单位的机场距离感兴趣:

```
> hflights_dt[, c('DistanceKMs', 'DiastanceFeets') :=

+   list(Distance / 0.62137, Distance * 5280)]

```

因此，这很简单，只需在左侧提供所需变量名的字符向量，在右侧提供适当值的`list`运算符。这个特性可以很容易地用于一些更复杂的任务。例如，让我们创建航空公司的虚拟变量:

```
> carriers <- unique(hflights_dt$UniqueCarrier)

> hflights_dt[, paste('carrier', carriers, sep = '_') :=

+   lapply(carriers, function(x) as.numeric(UniqueCarrier == x))]

> str(hflights_dt[, grep('^carrier', names(hflights_dt)),

+   with = FALSE])

Classes 'data.table' and 'data.frame': 227496 obs. of  15 variables:

 $ carrier_AA: num  1 1 1 1 1 1 1 1 1 1 ...

 $ carrier_AS: num  0 0 0 0 0 0 0 0 0 0 ...

 $ carrier_B6: num  0 0 0 0 0 0 0 0 0 0 ...

 $ carrier_CO: num  0 0 0 0 0 0 0 0 0 0 ...

 $ carrier_DL: num  0 0 0 0 0 0 0 0 0 0 ...

 $ carrier_OO: num  0 0 0 0 0 0 0 0 0 0 ...

 $ carrier_UA: num  0 0 0 0 0 0 0 0 0 0 ...

 $ carrier_US: num  0 0 0 0 0 0 0 0 0 0 ...

 $ carrier_WN: num  0 0 0 0 0 0 0 0 0 0 ...

 $ carrier_EV: num  0 0 0 0 0 0 0 0 0 0 ...

 $ carrier_F9: num  0 0 0 0 0 0 0 0 0 0 ...

 $ carrier_FL: num  0 0 0 0 0 0 0 0 0 0 ...

 $ carrier_MQ: num  0 0 0 0 0 0 0 0 0 0 ...

 $ carrier_XE: num  0 0 0 0 0 0 0 0 0 0 ...

 $ carrier_YV: num  0 0 0 0 0 0 0 0 0 0 ...

 - attr(*, ".internal.selfref")=<externalptr>

```

虽然它不是一行程序，而且它还引入了一个辅助变量，但是看我们做了什么并不复杂:

1.  首先，我们将`unique`运营商名称保存在一个字符向量中。
2.  然后，我们借助它来定义新变量的名字。
3.  我们也在这个字符向量上迭代匿名函数，如果运营商名称与给定的列匹配，则返回`TRUE`或`FALSE`。
4.  通过`as.numeric`将给定的列转换为`0`或`1`。
5.  然后，简单地检查了名称以`carrier`开头的所有列的结构。

这并不完美，因为我们通常会从虚拟变量中去掉一个标签以减少冗余。在当前情况下，最后一个新列只是其他新创建列的线性组合，因此信息是重复的。为此，在`head`函数中，通过将`-1`传递给`n`参数来省略最后一个类别通常是一个好的做法。

## 使用 dplyr 计算新变量

虽然 `mutate`比`within`快很多，但是`dplyr`包中的`mutate`的用法和基本`within`函数的用法是一样的:

```
> hflights <- hflights %>%

+     mutate(DistanceKMs = Distance / 0.62137)

```

如果前面的例子没有直接说明`mutate`和`within`的相似性，那么在不使用管道的情况下展示相同的例子可能也是有用的:

```
> hflights <- mutate(hflights, DistanceKMs = Distance / 0.62137)

```

<title>Merging datasets</title><link href="epub.css" rel="stylesheet" type="text/css"> 

# 合并数据集

除了前面描述的对单个数据集的基本操作之外，连接多个数据源是日常操作中最常用的方法之一。此类任务最常用的解决方案是简单地调用`merge` S3 方法，该方法可以充当传统的 SQL 内部和左/右/全外部操作的联结器——由 C.L. Moffatt (2008)简要总结如下:

![Merging datasets](graphics/2028OS_06_02.jpg)

`dplyr`包以一种简单的方式提供了一些简单的方法来执行前面提到的从 R 开始的连接操作:

*   `inner_join`:这将所有行的变量连接起来，这些变量在两个数据集中都能找到
*   `left_join`:这包括来自第一个数据集的所有行和来自另一个表的连接变量
*   `semi_join`:这仅包括第一个数据集中的那些在另一个数据集中也能找到的行
*   `anti_join` : This is similar to `semi_join` , But includes only these rows from the first dataset that is not found in the other one

    ### Note

    For more examples, Please refer to the illustrations of *two verbs* `dplyr` and the data debate cheat sheet listed in *Resources* at the end of this book.

这些特性也受到了`data.table`调用的`[`操作符的`mult`参数的支持，但是目前，让我们坚持更简单的用例。

在下面的示例中，我们将把一个小数据集与`hflights`数据合并。让我们通过给`DayOfWeek`变量的可能值命名来创建`data.frame`演示:

```
> (wdays <- data.frame(

+     DayOfWeek       = 1:7,

+     DayOfWeekString = c("Sunday", "Monday", "Tuesday",

+         "Wednesday", "Thursday", "Friday", "Saturday")

+     ))

 DayOfWeek DayOfWeekString

1         1          Sunday

2         2          Monday

3         3         Tuesday

4         4       Wednesday

5         5        Thursday

6         6          Friday

7         7        Saturday

```

让我们看看如何将之前定义的`data.frame`与另一个`data.frame`和其他表格对象左连接，因为`merge`也支持快速操作，例如，`data.table`:

```
> system.time(merge(hflights, wdays))

 user  system elapsed 

 0.700   0.000   0.699 

> system.time(merge(hflights_dt, wdays, by = 'DayOfWeek'))

 user  system elapsed 

 0.006   0.000   0.009

```

前面的例子通过`DayOfWeek`变量自动合并了两个表，该变量是两个数据集的一部分，并在原始的`hflights`数据集中产生了一个额外的变量。然而，我们必须在第二个例子中传递变量名，因为`merge.data.table`的`by`参数默认为对象的关键变量，这在当时是缺失的。需要注意的一点是，与`data.table`的合并比传统的表格对象类型要快得多。

### 注意

对如何改进前面的教学例子有什么想法吗？代替合并，也可以计算新的变量。例如，请参见基数为 R: `weekdays(as.Date(with(hflights, paste(Year, Month, DayofMonth, sep = '-'))))`的工作日函数。

合并数据集的一种简单得多的方法是，您只需向具有相同结构的数据集中添加新行或新列。为此，`rbind`和`cbind`，或者对于稀疏矩阵的`rBind`和`cBind`，做得非常出色。

与这些基本命令一起最常用的函数之一是`do.call`，它可以对一个`list`的所有元素执行`rbind`或`cbind`调用，从而使我们能够，例如，加入一列数据帧。这样的列表通常由`lapply`或`plyr`包中的相关函数创建。类似地，可以调用`rbindlist`以更快的方式合并`data.table`对象的`list`。

<title>Reshaping data in a flexible way</title><link href="epub.css" rel="stylesheet" type="text/css"> 

# 以灵活的方式重塑数据

Hadley Wickham 已经编写了几个 R 包来调整数据结构，例如，他论文的主要部分集中在如何用他的 `reshape`包重塑数据帧。从那以后，这个通用的聚合和重组包被更新为，可以更高效地处理最常用的任务，并且发布了一个新的版本号，附加在名为`reshape2`的包上。

这完全重写了`reshape`包，以牺牲功能为代价提高了速度。目前，`reshape2`最重要的特性是可以在所谓的长(窄)和宽表格数据格式之间转换。这基本上适用于上下堆叠或并排排列的列。

这些特性在 Hadley 的作品中有所体现，如以下关于数据重组的图片，以及相关的`reshape`函数和简单的用例:

![Reshaping data in a flexible way](graphics/2028OS_06_03.jpg)

由于 `reshape`包已经不在开发中，它的部分被外包给了`reshape2`、`plyr`，最近又被外包给了`dplyr`，在接下来的页面中，我们将只关注`reshape2`常用的特性。这将基本上由`melt`和 `cast`函数组成，它提供了一种将数据融合为标准形式的测量和标识符变量(长表格式)的智能方式，稍后可以将其转换为新的形状以供进一步分析。

## 将宽表格转换为长表格格式

融合数据框架意味着我们根据给定的标识符变量，将表格数据转换成键值对。原始列名成为新创建的`variable`列的类别，而这些(测量变量)的所有数值都包含在新的`value`列中。这里有一个简单的例子:

```
> library(reshape2)

> head(melt(hflights))

Using UniqueCarrier, TailNum, Origin, Dest, CancellationCode as id variables

 UniqueCarrier TailNum Origin Dest CancellationCode variable value

1            AA  N576AA    IAH  DFW                      Year  2011

2            AA  N557AA    IAH  DFW                      Year  2011

3            AA  N541AA    IAH  DFW                      Year  2011

4            AA  N403AA    IAH  DFW                      Year  2011

5            AA  N492AA    IAH  DFW                      Year  2011

6            AA  N262AA    IAH  DFW                      Year  2011

```

因此，我们刚刚重组了原始的`data.frame`，它有 21 个变量和 25 万条记录，变成只有 7 列和超过 350 万条记录。七列中有六列是因子类型标识符变量，最后一列存储所有的值。但是为什么有用呢？为什么我们要将传统的宽表格格式转换为更长的数据类型？

例如，我们可能对比较飞行时间的分布和飞行的实际经过时间感兴趣，这可能无法用原始数据格式直接绘制。虽然用软件包`ggplot2`绘制上述变量的散点图非常容易，但是你如何创建两个独立的箱线图来比较分布呢？

这里的问题是我们有两个独立的变量用于时间测量，而`ggplot`需要一个`numeric`和一个`factor`变量，后者将用于提供在 *x* 轴上的标签。为此，让我们用`melt`重新构建我们的数据集，指定两个数字变量作为度量变量，并删除所有其他列——换句话说，没有任何标识符变量:

```
> hflights_melted <- melt(hflights, id.vars = 0,

+   measure.vars = c('ActualElapsedTime', 'AirTime'))

> str(hflights_melted)

'data.frame':  454992 obs. of  2 variables:

 $ variable: Factor w/ 2 levels "ActualElapsedTime",..: 1 1 1 1 1 ...

 $ value   : int  60 60 70 70 62 64 70 59 71 70 ...

```

### 注意

一般来说，在没有标识符变量的情况下融合数据集不是一个好主意，因为稍后对它进行造型会变得很麻烦，如果不是不可能的话。

请注意，现在我们的行数是以前的两倍，而`variable`列是一个只有两个级别的因子，代表两个测量变量。这个结果`data.frame`现在很容易用两个新创建的列来绘制:

```
> library(ggplot2)

> ggplot(hflights_melted, aes(x = variable, y = value)) +

+   geom_boxplot()

```

![Converting wide tables to the long table format](graphics/2028OS_06_04.jpg)

好吧，前面的例子可能看起来不是关键任务，老实说，当我需要一些类似的转换来产生一些漂亮的`ggplot2`图表时，我第一次使用了 `reshape`包——因为如果有人使用`base`图形，前面的问题根本不存在。例如，您可以简单地将原始数据集的两个独立变量传递给`boxplot`函数。

因此，这就像是进入了 Hadley Wickham 的 R 包的世界，这个旅程确实提供了一些很好的数据分析实践。因此，我强烈建议进一步阅读，例如，在不知道如何有效地重塑数据集的情况下，如何使用`ggplot2`是不容易的，如果不是不可能的话。

## 将长表格转换为宽表格格式

对数据集进行强制转换与熔化正好相反，就像将键值对转换成表格数据格式。但是请记住，键值对总是可以以各种方式组合在一起，因此这个过程可以产生极其多样化的输出。因此，您需要一个表和一个公式来转换，例如:

```
> hflights_melted <- melt(hflights, id.vars = 'Month',

+   measure.vars = c('ActualElapsedTime', 'AirTime'))

> (df <- dcast(hflights_melted, Month ~ variable,

+   fun.aggregate = mean, na.rm = TRUE))

 Month ActualElapsedTime  AirTime

1      1          125.1054 104.1106

2      2          126.5748 105.0597

3      3          129.3440 108.2009

4      4          130.7759 109.2508

5      5          131.6785 110.3382

6      6          130.9182 110.2511

7      7          130.4126 109.2059

8      8          128.6197 108.3067

9      9          128.6702 107.8786

10    10          128.8137 107.9135

11    11          129.7714 107.5924

12    12          130.6788 108.9317

```

这个例子展示了如何在熔化和铸造数据集`hflights`的的帮助下合计 2011 年每个月的测量飞行时间:

1.  首先，我们将 id 为`Month`的`data.frame`融为一体，其中我们只为飞行时间保留了两个数字变量。
2.  然后，我们用一个简单的公式计算出结果`data.frame`,以显示所有测量变量每个月的平均值。

我很确定，现在你可以很快地重组这些数据，为这个基本的时间序列绘制两条独立的线:

```
> ggplot(melt(df, id.vars = 'Month')) +

+   geom_line(aes(x = Month, y = value, color = variable)) +

+   scale_x_continuous(breaks = 1:12) +

+   theme_bw() + 

+   theme(legend.position = 'top')

```

![Converting long tables to the wide table format](graphics/2028OS_06_05.jpg)

但是当然，除了聚集之外，熔化和铸造还可以用于各种各样的事情。例如，我们可以重组我们的原始数据库，使其具有一个特殊的`Month`，它包括数据的所有记录。这当然会使数据集中的行数加倍，但也让我们可以轻松地生成带有边距的数据表。这里有一个简单的例子:

```
> hflights_melted <- melt(add_margins(hflights, 'Month'),

+    id.vars = 'Month',

+    measure.vars = c('ActualElapsedTime', 'AirTime'))

> (df <- dcast(hflights_melted, Month ~ variable,

+    fun.aggregate = mean, na.rm = TRUE))

 Month ActualElapsedTime  AirTime

1      1          125.1054 104.1106

2      2          126.5748 105.0597

3      3          129.3440 108.2009

4      4          130.7759 109.2508

5      5          131.6785 110.3382

6      6          130.9182 110.2511

7      7          130.4126 109.2059

8      8          128.6197 108.3067

9      9          128.6702 107.8786

10    10          128.8137 107.9135

11    11          129.7714 107.5924

12    12          130.6788 108.9317

13 (all)          129.3237 108.1423

```

这与我们之前看到的非常相似，但是作为一个中间步骤，我们将`Month`变量转换为具有特殊级别的因子，这导致了该表的最后一行。此行表示相关测量变量的整体算术平均值。

## 调整性能

关于`reshape2`的一些更好的消息是`data.table`对熔化和铸造有不错的支持，性能有了很大的提高。Matt Dowle 发表了一些基准测试，通过在`data.table`对象上使用`cast`和`melt`而不是传统的数据帧，处理时间提高了 5-10 %,这给人留下了非常深刻的印象。

为了在您自己的数据集上验证这些结果，只需在调用`reshape2`函数之前将`data.frame`对象转换为`data.table`，因为`data.table`包已经提供了适当的`S3`方法来扩展`reshape2`。

<title>The evolution of the reshape packages</title><link href="epub.css" rel="stylesheet" type="text/css"> 

# 重塑包装的演变

正如前面提到的,`reshape2`是对`reshape`包的完全重写，基于大约 5 年的使用和开发后者的经验。这次更新还包括一些权衡，因为最初的整形任务被拆分到多个包中。因此，`reshape2`现在提供的功能比`reshape`支持的魔法功能要少得多。随便查查，比如`reshape::cast`；尤其是`margins`和`add.missing`的说法！

但事实证明，即使是`reshape2`也不仅仅是简单地熔化和铸造数据框架。这个事实启发了 `tidyr`包的诞生:在 Hadleyverse 中有一个包，它支持在长和宽的表格式之间进行简单的数据清理和转换。在`tidyr`的说法中，这些操作被称为`gather`和`spread`。

为了给出这种新语法的一个快速示例，让我们重新实现前面的示例:

```
> library(tidyr)

> str(gather(hflights[, c('Month', 'ActualElapsedTime', 'AirTime')],

+   variable, value, -Month))

'data.frame':  454992 obs. of  3 variables:

 $ Month   : int  1 1 1 1 1 1 1 1 1 1 ...

 $ variable: Factor w/ 2 levels "ActualElapsedTime",..: 1 1 1 1 ...

 $ value   : int  60 60 70 70 62 64 70 59 71 70 ...

```

<title>Summary</title><link href="epub.css" rel="stylesheet" type="text/css"> 

# 总结

在这一章中，我们主要讨论了在进行统计测试之前，如何将原始数据转换成适当的结构化格式。这个过程是我们日常活动中非常重要的一部分，占用了数据科学家的大部分时间。但是读完这一章后，你应该对如何在大多数情况下重组你的数据有信心了——所以，这是关注于建立一些模型的正确时间，我们将在下一章中做。