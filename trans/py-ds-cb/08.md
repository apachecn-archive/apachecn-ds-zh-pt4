

# 八、集成方法

在这一章中，我们将看看以下食谱:

*   了解整体——打包方法
*   了解系综——增强方法，AdaBoost
*   理解系综——梯度推进



# 简介

在这一章中，我们将看看涵盖整体方法的食谱。当我们在现实生活中面临不确定性的挑战时，我们通常会向多个朋友征求意见。我们根据从这些朋友那里获得的集体知识来做出决定。集成是机器学习中类似的概念。在前面的章节中，我们为我们的数据集建立了一个单一的模型，并在看不见的测试数据上使用了该模型的预测。如果我们在这些数据的基础上建立许多模型，并根据所有这些模型的预测做出最终的预测，会怎么样呢？这是合奏背后的理念。对于给定的问题，使用集成方法，我们继续建立许多模型，并使用所有这些模型对看不见的数据集进行最终预测。对于回归问题，最终输出可能是所有模型的平均预测值。在分类上下文中，采用多数投票来决定输出类。

基本的想法是有许多模型，每个模型在训练数据集上产生稍微不同的结果。与其他模型相比，一些模型可以很好地了解数据的某些方面。人们相信，所有这些模型的最终输出应该比其中任何一个模型的输出都要好。

如前所述，ensemble 的思想是将许多模型组合在一起。这些模型可以是相同的或不同的类型。例如，我们可以将神经网络模型输出与贝叶斯模型相结合。在这一章中，我们将把我们的讨论限制在使用同类型模型的集合上。通过打包和提升等技术，在数据科学社区中广泛使用组合相同类型的模型。

Bootstrap aggregation，通常被称为 Bagging，是一种生成大量模型并组合它们的输出以做出最终预测的优雅技术。Bagging 集合中的每个模型只使用一部分训练数据。打包背后的想法是减少数据的过度拟合。如前所述，我们希望每个模型都与其他模型略有不同。因此，我们对数据进行采样，并用替换来训练每个模型，从而引入可变性。在模型中引入变化的另一种方法是对属性进行采样。我们并没有为模型提供所有的属性，但是不同的模型会得到一组不同的属性。打包可以很容易地并行化。基于可用的并行处理框架，可以用训练数据集的不同样本并行构建模型。Bagging 不适用于线性预测，如线性回归。

Boosting 是一种集成技术，它产生一系列越来越复杂的模型。它通过基于先前模型中的错误训练较新的模型来连续工作。每个被训练的模型都与一个权重相关联，该权重是基于模型对给定数据的表现而计算的。进行最终预测时，这些权重决定了特定模型对最终输出的影响程度。Boosting 并不像 Bagging 那样自然地支持并行。由于模型是按顺序构建的，因此不能并行化。序列中较早出现的分类器所犯的错误被认为是难以分类的实例。该框架的设计方式是，序列中后来的模型会拾取前一个预测器做出的错误分类或错误预测，并尝试对它们进行改进。通常，在提升中使用非常弱的分类器，例如，在集成中使用决策树桩，它是具有单个分裂节点和两个叶子的决策树。关于 Boosting 的一个非常著名的成功故事是 Viola Jone 人脸检测算法，其中使用了几个弱分类器(决策树桩)来找到好的特征。您可以在以下网站上了解有关这一成功案例的更多信息:

[https://en . Wikipedia . org/wiki/Viola % E2 % 80% 93 Jones _ object _ detection _ framework](https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework)

在本章中，我们将详细研究装袋和升压方法。在最终的配方中，我们将把我们的讨论扩展到一种称为梯度推进的特殊类型的推进。我们还将看看回归和分类问题，看看它们如何通过集成学习来解决。



# 了解整体——装袋方法

集成方法属于被称为基于委员会的学习的方法家族。不是将分类或回归的决策留给单个模型，而是使用一组模型在集合中做出决策。Bagging 是一种著名且广泛使用的集合方法。

Bagging 是也称为 bootstrap 聚合。只有当我们能够在底层模型中引入可变性时，Bagging 才能有效，也就是说，如果我们能够成功地在底层数据集中引入可变性，它将导致模型有轻微的变化。

我们利用 Bootstrapping 来反馈数据集中的模型可变性。Bootstrapping 是由执行的过程，我们对指定数量的实例的给定数据集进行随机采样，有或没有替换。在 bagging 中，我们利用 bootstrapping 来生成不同的数据集，并为每个数据集构建一个模型。最后，我们对所有模型的输出进行平均，以在出现回归问题时产生最终预测。

假设我们引导数据 m 次，我们将有`m`个模型，即`y m`个值，我们的最终预测如下:

![Understanding Ensemble – Bagging Method](../images/00163.jpeg)

在分类问题的情况下，基于投票来决定最终输出。假设我们的集合中有一百个模型，我们有一个两类分类问题，类标签为{+1，-1}。如果超过 50 个模型预测输出为+1，我们声明预测为+1。

随机化是另一种可以在模型构建过程中引入可变性的技术。一个例子是随机选择集合中每个模型的属性子集。这样，不同的模型将具有不同的属性集。这种技术被称为随机子空间方法。

对于非常稳定的模型，Bagging 可能不会取得非常好的结果。如果底层分类器对数据的微小变化都非常敏感，那么装袋最有帮助。比如决策树，非常不稳定。未修剪的决策树是打包的一个很好的候选。但是假设最近邻分类器 K 是一个非常稳定的模型。然而，我们可以利用随机子空间，并在最近邻方法中引入一些不稳定性。

在下面的食谱中，您将学习如何在 K-最近邻算法中利用 Bagging 和随机子空间。我们将讨论一个分类问题，最终的预测将基于多数投票。



## 正在准备…

我们将利用 Scikit learn 类的`KNeighborsClassifier`进行分类，利用`BaggingClassifier`应用 bagging 原理。我们将使用`make_classification`便利功能为该配方生成数据。



## 怎么做

让我们导入必要的库，并编写一个函数`get_data()`给提供一个数据集来完成这个菜谱:

```
from sklearn.datasets import make_classification
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import BaggingClassifier
from sklearn.metrics import classification_report
from sklearn.cross_validation import train_test_split

def get_data():
    """
    Make a sample classification dataset
    Returns : Independent variable y, dependent variable x
    """
    no_features = 30
    redundant_features = int(0.1*no_features)
    informative_features = int(0.6*no_features)
    repeated_features = int(0.1*no_features)
    print no_features,redundant_features,informative_features,repeated_features
    x,y = make_classification(n_samples=500,n_features=no_features,flip_y=0.03,\
            n_informative = informative_features, n_redundant = redundant_features \
            ,n_repeated = repeated_features,random_state=7)
    return x,y
```

让我们继续编写三个函数:

函数 build_single_model 使用给定的数据创建一个简单的 KNearest 邻居模型。

函数 build_bagging_model，一个实现 bagging 例程的函数。

函数 view_model 检查我们已经建立的模型:

```
def build_single_model(x,y):
    model = KNeighborsClassifier()
    model.fit(x,y)
    return model

def build_bagging_model(x,y):
	bagging = BaggingClassifier(KNeighborsClassifier(),n_estimators=100,random_state=9 \
             ,max_samples=1.0,max_features=0.7,bootstrap=True,bootstrap_features=True)
	bagging.fit(x,y)
	return bagging

def view_model(model):
    print "\n Sampled attributes in top 10 estimators\n"
    for i,feature_set in  enumerate(model.estimators_features_[0:10]):
        print "estimator %d"%(i+1),feature_set
```

最后，我们将编写我们的主函数，它将调用其他函数:

```
if __name__ == "__main__":
    x,y = get_data()    

    # Divide the data into Train, dev and test    
    x_train,x_test_all,y_train,y_test_all = train_test_split(x,y,test_size = 0.3,random_state=9)
    x_dev,x_test,y_dev,y_test = train_test_split(x_test_all,y_test_all,test_size=0.3,random_state=9)

    # Build a single model    
    model = build_single_model(x_train,y_train)
    predicted_y = model.predict(x_train)
    print "\n Single Model Accuracy on training data\n"
    print classification_report(y_train,predicted_y)
    # Build a bag of models
    bagging = build_bagging_model(x_train,y_train)
    predicted_y = bagging.predict(x_train)
    print "\n Bagging Model Accuracy on training data\n"
    print classification_report(y_train,predicted_y)
	view_model(bagging)

    # Look at the dev set
    predicted_y = model.predict(x_dev)
    print "\n Single Model Accuracy on Dev data\n"
    print classification_report(y_dev,predicted_y)

    print "\n Bagging Model Accuracy on Dev data\n"
    predicted_y = bagging.predict(x_dev)
    print classification_report(y_dev,predicted_y)
```



## 它是如何工作的……

让我们从主要方法开始。我们首先调用`get_data`函数将数据集作为预测值的矩阵 x 和响应变量的向量 y 返回。让我们来看看`get_data`函数:

```
    no_features = 30
    redundant_features = int(0.1*no_features)
    informative_features = int(0.6*no_features)
    repeated_features = int(0.1*no_features)
 x,y =make_classification(n_samples=500,n_features=no_features,flip_y=0.03,\
n_informative = informative_features, n_redundant = redundant_features \
            ,n_repeated = repeated_features,random_state=7)
```

看看传递给`make_classification`方法的参数。第一个参数是所需实例的数量；在这种情况下，我们说我们需要 500 个实例。第二个参数是每个实例所需的属性的数量。我们说我们需要由变量`no_features`定义的其中的`30`。第三个参数`flip_y`，随机交换 3%的实例。这样做是为了在我们的数据中引入一些噪声。下一个参数指定了那些`30`中的特征的数量，这些特征应该足够丰富以用于我们的分类。我们已经指定了 60%的特征，也就是 30 个特征中的 18 个应该是信息性的。下一个参数是关于冗余功能。这些是作为信息特征的线性组合产生的，以便在特征之间引入相关性。最后，重复特征是从信息特征和冗余特征中随机抽取的重复特征。

让我们使用`train_test_split`将数据分成训练集和测试集。我们保留 30%的数据用于测试:

```
    # Divide the data into Train, dev and test    
    x_train,x_test_all,y_train,y_test_all = train_test_split(x,y,test_size = 0.3,random_state=9)
```

我们再次利用 train_test_split 将测试数据分成开发和测试两部分。

```
    x_dev,x_test,y_dev,y_test = train_test_split(x_test_all,y_test_all,test_size=0.3,random_state=9)
```

在划分了用于构建、评估和测试模型的数据之后，我们继续构建我们的模型。我们将通过调用以下代码，使用`KNeighborsClassifier`构建一个单一模型:

```
model = build_single_model(x_train,y_train)
```

在这个函数中，我们创建一个类型为`KNeighborsClassifier` 的对象，并拟合我们的数据，如下所示:

```
def build_single_model(x,y):
    model = KNeighborsClassifier()
    model.fit(x,y)
    return model
```

正如上一节所解释的，`KNearestNeighbor`是一个非常稳定的算法。让我们看看这个模型的表现如何。我们对训练数据进行预测，并查看我们的模型指标:

```
    predicted_y = model.predict(x_train)
    print "\n Single Model Accuracy on training data\n"
    print classification_report(y_train,predicted_y)
```

`classification_report`是 Scikit learn 中模块指标下的一个方便功能。它给出了`precision`、`recall`和`f1-score`的表格:

![How it works…](../images/00164.jpeg)

在所有的例子中，我们的准确率是 87%。有了这个图，让我们继续构建我们的 bagging 模型:

```
    bagging = build_bagging_model(x_train,y_train)
```

我们使用训练数据调用函数`build_bagging_model`来构建分类器包，如下所示:

```
def build_bagging_model(x,y):
bagging =             BaggingClassifier(KNeighborsClassifier(),n_estimators=100,random_state=9 \
           ,max_samples=1.0,max_features=0.7,bootstrap=True,bootstrap_features=True)
bagging.fit(x,y)
return bagging
```

在方法内部，我们调用了`BaggingClassifier`类。让我们看看我们传递给这个类来初始化它的参数。

第一个论点是潜在的估计或模型。通过传递`KNeighborClassifier`，我们告诉装袋分类器我们想要构建一个`KNearestNeighbor`分类器包。下一个参数指定了我们将构建的估计器的数量。在这种情况下，我们说我们需要他们中的`100`。`random_state`参数是随机数生成器使用的种子。为了在不同的运行中保持一致，我们将其设置为一个整数值。

我们的下一个参数是 max_samples，当我们从输入数据集进行引导时，我们指定为一个估计器选择的实例数量。在这种情况下，我们要求 bagging 例程选择所有实例。

接下来，参数 max_features 指定了在对估计器进行引导时要包括的属性的数量。我们说我们只想包含 70%的属性。因此，对于集合中的每个估计器/模型，它将使用不同的属性子集来构建模型。这是我们在上一节中介绍的随机空间方法。该函数继续拟合模型并将模型返回给调用函数。

```
    bagging = build_bagging_model(x_train,y_train)
    predicted_y = bagging.predict(x_train)
    print "\n Bagging Model Accuracy on training data\n"
    print classification_report(y_train,predicted_y)
```

让我们看看模型的准确性:

![How it works…](../images/00165.jpeg)

您可以看到模型指标的大幅提升。

在我们用开发数据集测试我们的模型之前，让我们通过调用 view_model 函数来查看分配给不同模型的属性:

```
    view_model(bagging)
```

我们打印为前十个模型选择的属性，如下:

```
def view_model(model):
    print "\n Sampled attributes in top 10 estimators\n"
    for i,feature_set in  enumerate(model.estimators_features_[0:10]):
        print "estimator %d"%(i+1),feature_set
```

![How it works…](../images/00166.jpeg)

从结果中可以看出，我们几乎是随机地给每个评估者分配了属性。这样，我们在每个估计量中引入了可变性。

让我们继续检查我们的单个分类器和估计器包在我们的 dev 集中的表现:

```
    # Look at the dev set
    predicted_y = model.predict(x_dev)
    print "\n Single Model Accuracy on Dev data\n"
    print classification_report(y_dev,predicted_y)

    print "\n Bagging Model Accuracy on Dev data\n"
    predicted_y = bagging.predict(x_dev)
    print classification_report(y_dev,predicted_y)
```

![How it works…](../images/00167.jpeg)

正如预期的那样，与单个分类器相比，我们的估计器包在我们的 dev 集中表现得更好。



## 还有更多……

正如我们之前所说的，在分类的情况下，具有多数票数的标签被认为是最终的预测。代替投票方案，我们可以要求成分模型输出标签的预测概率。最终可以取概率的平均值来决定最终的输出标签。在 Scikit 的例子中，API 的文档提供了如何执行最终预测的详细信息:

> 输入样本的预测类别被计算为具有最高平均预测概率的类别。“如果基础评估者没有实施*预测恐惧症*方法，那么它就会诉诸投票。”

[http://sci kit-learn . org/stable/modules/generated/sk learn . ensemble . bagging classifier . html](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html)

在上一章中，我们讨论了交叉验证。虽然交叉验证可能看起来非常类似于装袋，但它们在现实中有不同的用途。在交叉验证中，我们创建 K 折叠，并且基于来自这些折叠的模型输出，我们可以为模型选择参数，就像我们为岭回归选择α值一样。这样做主要是为了避免在模型构建练习中暴露我们的测试数据。交叉验证可以在 bagging 中使用，以确定我们需要添加到 Bagging 模块中的估计量的数量。

然而，打包的一个缺点是我们失去了模型的可解释性。考虑一个修剪后得到的简单决策树。解释决策树模型是非常容易的。但是一旦我们有了 100 个这样的模型，它就变成了一个黑箱。为了提高准确性，我们做了可解释性的交易。

有关装袋的更多信息，请参考 Leo Breiman 的以下论文:

> 利奥·布雷曼。1996.打包预测值。*马赫。学习。*第 24 卷，第 2 期(1996 年 8 月)，第 123—140 页。DOI = 10.1023/A:1018054314350 http://dx.doi.org/10.1023/A:1018054314350



## 参见

*   *使用交叉验证迭代器*第七章[中的配方](part0078_split_000.html#2ACBS1-6b04b7c0b98f44a0b8f82924fef317ec "Chapter 7. Machine Learning 2")，*机器学习 2*
*   *构建决策树解决多类问题*秘方[第六章](part0073_split_000.html#25JP21-6b04b7c0b98f44a0b8f82924fef317ec "Chapter 6. Machine Learning 1")、*机器学习 1*



# 了解集成-增强方法

Boosting 是一种强大的合奏技术。它在大多数数据科学应用中使用得非常多。事实上，它是数据科学家工具包中最重要的工具之一。 Boosting 技术利用了一个类似于 Bagging 的估计包。但这是相似性的终点。在进入我们的食谱之前，让我们快速地看看增强是如何作为一种非常有效的综合技术的。

让我们以熟悉的两类分类问题为例，其中输入是一组预测值(`X`)，输出是一个响应变量(`Y`)，它可以取`0`或`1`作为值。分类问题的输入表示如下:

![Understanding Ensemble – Boosting Method](../images/00168.jpeg)

分类器的工作是找到一个函数，它可以近似:

![Understanding Ensemble – Boosting Method](../images/00169.jpeg)

分类器的误分类率定义为:

![Understanding Ensemble – Boosting Method](../images/00170.jpeg)

让我们说我们构建了一个非常弱的分类器，其错误率略好于随机猜测。在 Boosting 中，我们在稍微修改的数据集上构建一系列弱分类器。我们稍微修改每个分类器的数据，最后，我们得到 M 个分类器:

![Understanding Ensemble – Boosting Method](../images/00171.jpeg)

最后，通过加权多数投票将所有人的预测结合起来:

![Understanding Ensemble – Boosting Method](../images/00172.jpeg)

这种方法称为 AdaBoost。

权重α和建模的顺序方式是助推不同于装袋的地方。如前所述，Boosting 在稍微修改的数据集上为每个分类器构建一个弱分类器序列。让我们看看这一微小的数据修改指的是什么。正是从这个修改中，我们得到了我们的重量α。

最初对于第一个分类器，m=1，我们将每个实例的权重设置为 1/N，也就是说，如果有一百条记录，则每条记录的权重为 0.001。让我们用 w 来表示重量——现在我们有一百个这样的重量:

![Understanding Ensemble – Boosting Method](../images/00173.jpeg)

所有的记录现在都有同等的机会被分类器选中。我们建立分类器，并针对我们的训练数据进行测试，以获得误分类率。参见本节前面给出的误分类率公式。我们将通过略微改变它，包括权重，如下所示:

![Understanding Ensemble – Boosting Method](../images/00174.jpeg)

其中 abs 代表结果的绝对值。有了这个误差率，我们计算我们的 alpha(模型重量)如下:

![Understanding Ensemble – Boosting Method](../images/00175.jpeg)

其中ε是一个非常小的值。

假设我们的模型 1 的错误率为 0.3，也就是说，该模型能够正确分类 70%的记录。因此，该模型的权重大约为 0.8，这是一个很好的权重。基于此，我们将返回并设置单个记录的权重，如下所示:

![Understanding Ensemble – Boosting Method](../images/00176.jpeg)

如您所见，所有被错误分类的属性的权重都会增加。这增加了错误分类的记录被下一个分类器选择的机会。因此，序列中下一个分类器选择权重更大的实例，并尝试适应它。以这种方式，所有未来的分类器开始集中于被先前的分类器错误分类的记录。

这就是助推的力量。它能够将几个弱分类器变成一个强有力的集成。

让我们看看助推的作用。随着我们继续编写代码，我们还将看到 AdaBoost 的一个小变化，称为 SAMME。



## 开始使用…

我们将利用sci kit 学习类`DecisionTreeClassifier`进行分类，利用`AdaBoostClassifier`应用 Boosting 原理。我们将使用`make_classification`便利功能为该配方生成数据。



## 怎么做

让我们导入必要的库，并编写一个函数`get_data()`为我们提供一个数据集来完成这个菜谱。

```
from sklearn.datasets import make_classification
from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import classification_report,zero_one_loss
from sklearn.cross_validation import train_test_split
from sklearn.tree import DecisionTreeClassifier
import numpy as np
import matplotlib.pyplot as plt
import itertools

def get_data():
    """
    Make a sample classification dataset
    Returns : Independent variable y, dependent variable x
    """
    no_features = 30
    redundant_features = int(0.1*no_features)
    informative_features = int(0.6*no_features)
    repeated_features = int(0.1*no_features)
    print no_features,redundant_features,informative_features,repeated_features
    x,y = make_classification(n_samples=500,n_features=no_features,flip_y=0.03,\
            n_informative = informative_features, n_redundant = redundant_features \
            ,n_repeated = repeated_features,random_state=7)
    return x,y

def build_single_model(x,y):
    model = DecisionTreeClassifier()
    model.fit(x,y)
    return model

def build_boosting_model(x,y,no_estimators=20):
    boosting = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1,min_samples_leaf=1),random_state=9 \
    ,n_estimators=no_estimators,algorithm="SAMME")
    boosting.fit(x,y)
    return boosting

def view_model(model):
    print "\n Estimator Weights and Error\n"
    for i,weight in  enumerate(model.estimator_weights_):
        print "estimator %d weight = %0.4f error = %0.4f"%(i+1,weight,model.estimator_errors_[i])

    plt.figure(1)
    plt.title("Model weight vs error")
    plt.xlabel("Weight")
    plt.ylabel("Error")
    plt.plot(model.estimator_weights_,model.estimator_errors_)

def number_estimators_vs_err_rate(x,y,x_dev,y_dev):
    no_estimators = range(20,120,10)
    misclassy_rate = []
    misclassy_rate_dev = []

    for no_estimator in no_estimators:
        boosting = build_boosting_model(x,y,no_estimators=no_estimator)
        predicted_y = boosting.predict(x)
        predicted_y_dev = boosting.predict(x_dev)        
        misclassy_rate.append(zero_one_loss(y,predicted_y))
        misclassy_rate_dev.append(zero_one_loss(y_dev,predicted_y_dev))

    plt.figure(2)
    plt.title("No estimators vs Mis-classification rate")
    plt.xlabel("No of estimators")
    plt.ylabel("Mis-classification rate")
    plt.plot(no_estimators,misclassy_rate,label='Train')
    plt.plot(no_estimators,misclassy_rate_dev,label='Dev')

    plt.show() 

if __name__ == "__main__":
    x,y = get_data()    
    plot_data(x,y)

    # Divide the data into Train, dev and test    
    x_train,x_test_all,y_train,y_test_all = train_test_split(x,y,test_size = 0.3,random_state=9)
    x_dev,x_test,y_dev,y_test = train_test_split(x_test_all,y_test_all,test_size=0.3,random_state=9)

    # Build a single model    
    model = build_single_model(x_train,y_train)
    predicted_y = model.predict(x_train)
    print "\n Single Model Accuracy on training data\n"
    print classification_report(y_train,predicted_y)
    print "Fraction of misclassfication = %0.2f"%(zero_one_loss(y_train,predicted_y)*100),"%"

    # Build a bag of models
    boosting = build_boosting_model(x_train,y_train, no_estimators=85)
    predicted_y = boosting.predict(x_train)
    print "\n Boosting Model Accuracy on training data\n"
    print classification_report(y_train,predicted_y)
    print "Fraction of misclassfication = %0.2f"%(zero_one_loss(y_train,predicted_y)*100),"%"

    view_model(boosting)

    # Look at the dev set
    predicted_y = model.predict(x_dev)
    print "\n Single Model Accuracy on Dev data\n"
    print classification_report(y_dev,predicted_y)
    print "Fraction of misclassfication = %0.2f"%(zero_one_loss(y_dev,predicted_y)*100),"%"

    print "\n Boosting Model Accuracy on Dev data\n"
    predicted_y = boosting.predict(x_dev)
    print classification_report(y_dev,predicted_y)
    print "Fraction of misclassfication = %0.2f"%(zero_one_loss(y_dev,predicted_y)*100),"%"

    number_estimators_vs_err_rate(x_train,y_train,x_dev,y_dev)
```

让我们继续编写以下三个函数:

函数 build_single_model 使用给定的数据创建一个简单的决策树模型。

函数 build_boosting_model，一个实现升压例程的函数。

函数 view_model，检查我们已经建立的模型。

```
def build_single_model(x,y):
    model = DecisionTreeClassifier()
    model.fit(x,y)
    return model

def build_boosting_model(x,y,no_estimators=20):
    boosting = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1,min_samples_leaf=1),random_state=9 \
    ,n_estimators=no_estimators,algorithm="SAMME")
    boosting.fit(x,y)
    return boosting

def view_model(model):
    print "\n Estimator Weights and Error\n"
    for i,weight in  enumerate(model.estimator_weights_):
        print "estimator %d weight = %0.4f error = %0.4f"%(i+1,weight,model.estimator_errors_[i])

    plt.figure(1)
    plt.title("Model weight vs error")
    plt.xlabel("Weight")
    plt.ylabel("Error")
    plt.plot(model.estimator_weights_,model.estimator_errors_)
```

然后我们写一个函数叫做 number_estimators_vs_err_rate。我们使用这个函数来观察我们的错误率是如何随着我们集合中模型的数量而变化的。

```
def number_estimators_vs_err_rate(x,y,x_dev,y_dev):
    no_estimators = range(20,120,10)
    misclassy_rate = []
    misclassy_rate_dev = []

    for no_estimator in no_estimators:
        boosting = build_boosting_model(x,y,no_estimators=no_estimator)
        predicted_y = boosting.predict(x)
        predicted_y_dev = boosting.predict(x_dev)        
        misclassy_rate.append(zero_one_loss(y,predicted_y))
        misclassy_rate_dev.append(zero_one_loss(y_dev,predicted_y_dev))

    plt.figure(2)
    plt.title("No estimators vs Mis-classification rate")
    plt.xlabel("No of estimators")
    plt.ylabel("Mis-classification rate")
    plt.plot(no_estimators,misclassy_rate,label='Train')
    plt.plot(no_estimators,misclassy_rate_dev,label='Dev')

    plt.show()
```

最后，我们将编写我们的主函数，它将调用其他的函数。

```
if __name__ == "__main__":
    x,y = get_data()    
    plot_data(x,y)

    # Divide the data into Train, dev and test    
    x_train,x_test_all,y_train,y_test_all = train_test_split(x,y,test_size = 0.3,random_state=9)
    x_dev,x_test,y_dev,y_test = train_test_split(x_test_all,y_test_all,test_size=0.3,random_state=9)

    # Build a single model    
    model = build_single_model(x_train,y_train)
    predicted_y = model.predict(x_train)
    print "\n Single Model Accuracy on training data\n"
    print classification_report(y_train,predicted_y)
    print "Fraction of misclassfication = %0.2f"%(zero_one_loss(y_train,predicted_y)*100),"%"

    # Build a bag of models
    boosting = build_boosting_model(x_train,y_train, no_estimators=85)
    predicted_y = boosting.predict(x_train)
    print "\n Boosting Model Accuracy on training data\n"
    print classification_report(y_train,predicted_y)
    print "Fraction of misclassfication = %0.2f"%(zero_one_loss(y_train,predicted_y)*100),"%"

    view_model(boosting)

    # Look at the dev set
    predicted_y = model.predict(x_dev)
    print "\n Single Model Accuracy on Dev data\n"
    print classification_report(y_dev,predicted_y)
    print "Fraction of misclassfication = %0.2f"%(zero_one_loss(y_dev,predicted_y)*100),"%"

    print "\n Boosting Model Accuracy on Dev data\n"
    predicted_y = boosting.predict(x_dev)
    print classification_report(y_dev,predicted_y)
    print "Fraction of misclassfication = %0.2f"%(zero_one_loss(y_dev,predicted_y)*100),"%"

    number_estimators_vs_err_rate(x_train,y_train,x_dev,y_dev)
```



## 它是如何工作的……

让我们从主要方法开始。我们首先调用`get_data`函数来返回数据集作为预测值的矩阵 x 和响应变量的向量 y。让我们来看看`get_data`函数:

```
    no_features = 30
    redundant_features = int(0.1*no_features)
    informative_features = int(0.6*no_features)
    repeated_features = int(0.1*no_features)
 x,y =make_classification(n_samples=500,n_features=no_features,flip_y=0.03,\
n_informative = informative_features, n_redundant = redundant_features \
            ,n_repeated = repeated_features,random_state=7)
```

看看传递给`make_classification`方法的参数。第一个参数是所需实例的数量；在这种情况下，我们说我们需要 500 个实例。第二个参数给出了每个实例所需的属性数量。我们说我们需要 30 个，如变量`no_features`所定义的。第三个参数`flip_y`，随机交换 3%的实例。这样做是为了在我们的数据中引入一些噪声。下一个参数指定了这 30 个特征中的特征数量，这些特征应该足够丰富，可以用于我们的分类中。我们已经指定了 60%的特征，也就是 30 个特征中的 18 个应该是信息性的。下一个参数是关于冗余功能。这些是作为信息特征的线性组合产生的，用于在特征之间引入相关性。最后，重复特征是从信息特征和冗余特征中随机抽取的重复特征。

让我们使用`train_test_split`将数据分成训练集和测试集。我们保留 30%的数据用于测试。

```
    # Divide the data into Train, dev and test    
    x_train,x_test_all,y_train,y_test_all = train_test_split(x,y,test_size = 0.3,random_state=9)
```

我们再次利用 train_test_split 将我们的测试数据分成开发和测试两部分。

```
    x_dev,x_test,y_dev,y_test = train_test_split(x_test_all,y_test_all,test_size=0.3,random_state=9)
```

已经划分了用于构建、评估和测试模型的数据，我们继续构建我们的模型。

让我们从拟合单个决策树开始，并查看该树在训练集上的性能:

```
    # Build a single model    
    model = build_single_model(x_train,y_train)
```

我们通过使用预测器和响应变量调用`build_single_model`函数来建立模型。在这里，我们安装了一个决策树，并将该树返回给调用函数。

```
def build_single_model(x,y):
    model = DecisionTreeClassifier()
    model.fit(x,y)
    return model
```

让我们使用`classification_report`来评估该模型有多好，这是 Scikit learn 的一个实用函数，它显示了一组指标，包括`precision`、`recall`和`f1-score`；我们还显示了错误分类率。

```
    predicted_y = model.predict(x_train)
    print "\n Single Model Accuracy on training data\n"
    print classification_report(y_train,predicted_y)
    print "Fraction of misclassfication =     
           %0.2f"%(zero_one_loss(y_train,predicted_y)*100),"%"
```

![How it works…](../images/00177.jpeg)

正如你所看到的，我们的决策树模型已经很好的拟合了数据——我们的错误分类率是 0。在我们在开发数据上测试这个模型之前，让我们构建我们的集合:

```
    # Build a bag of models
    boosting = build_boosting_model(x_train,y_train, no_estimators=85)
```

使用方法 build_boosting_model，我们如下构建我们的集成:

```
    boosting = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1,min_samples_leaf=1),random_state=9 \
    ,n_estimators=no_estimators,algorithm="SAMME")
    boosting.fit(x,y)
```

我们利用 Scikit learn 的`AdaBoostClassifier`来构建我们的 Boosting 合奏。我们用以下参数实例化该类:

评估者——在我们的例子中，我们说我们想要建立一个决策树的集合。因此，我们传递了`DecisionTreeClassifier`对象。

我们不想让完全长大的树出现在我们的服装中。我们只需要树桩——只有两个叶节点和一个分裂节点的树。因此，我们将`max_depth`参数设置为 1。

使用 n_estimators 参数，我们指定了想要生长的树的数量；在这种情况下，我们将种植 86 棵树。

最后我们有一个参数叫算法，设置为`SAMME`。`SAMME`代表使用多级指数损失函数的阶段式加法建模。`SAMME`是对 AdaBoosting 算法的改进。它试图将更多的权重放在错误分类的记录上。模型权重 alpha 是`SAMME`不同于 AdaBoost 的地方。

![How it works…](../images/00178.jpeg)

我们忽略了前面公式中的常数 0.5。让我们看看新增加的:log (K-1)。如果 K = 2，则上述等式简化为 AdaBoost。这里，K 是我们的响应变量中类的数量。如前所述，对于两类问题，SAMME 简化为 AdaBoost。

让我们拟合这个模型，并把它返回给我们的调用函数。我们在训练数据集上运行该模型，并再次查看该模型的表现:

```
    predicted_y = boosting.predict(x_train)
    print "\n Boosting Model Accuracy on training data\n"
    print classification_report(y_train,predicted_y)
    print "Fraction of misclassfication = %0.2f"%(zero_one_loss(y_train,predicted_y)*100),"%"
```

![How it works…](../images/00179.jpeg)

结果与我们最初的模型没有太大的不同。我们已经用这个集合正确地分类了几乎 98%的记录。

在我们的开发集上测试它之前，让我们来看看我们已经建立的增强集合:

```
    view_model(boosting)
```

在 view_model 中，我们首先打印出分配给集合中每个分类器的权重:

```
    print "\n Estimator Weights and Error\n"
    for i,weight in  enumerate(model.estimator_weights_):
        print "estimator %d weight = %0.4f error = %0.4f"%(i+1,weight,model.estimator_errors_[i])
```

![How it works…](../images/00180.jpeg)

这里我们已经展示了前 20 个集合的权重。基于它们的错误分类率，我们给这些评估者分配了不同的权重。

让我们绘制一个图表，显示估计量权重与每个估计量产生的误差的关系:

```
    plt.figure(1)
    plt.title("Model weight vs error")
    plt.xlabel("Weight")
    plt.ylabel("Error")
    plt.plot(model.estimator_weights_,model.estimator_errors_)
```

![How it works…](../images/00181.jpeg)

正如你所看到的，正确分类的模型比那些有更高误差的模型被分配了更多的权重。

现在让我们看看单个采油树和一袋采油树相对于开发数据的表现:

```
    # Look at the dev set
    predicted_y = model.predict(x_dev)
    print "\n Single Model Accuracy on Dev data\n"
    print classification_report(y_dev,predicted_y)
    print "Fraction of misclassfication = %0.2f"%(zero_one_loss(y_dev,predicted_y)*100),"%"

    print "\n Boosting Model Accuracy on Dev data\n"
    predicted_y = boosting.predict(x_dev)
    print classification_report(y_dev,predicted_y)
    print "Fraction of misclassfication = %0.2f"%(zero_one_loss(y_dev,predicted_y)*100),"%"
```

就像我们处理训练数据一样，我们打印分类报告和错误分类率:

![How it works…](../images/00182.jpeg)

如你所见，单棵树表现不佳。虽然它对训练数据显示了 100%的准确性，但对 dev 数据，它却错误分类了近 40%的记录——这是过度拟合的迹象。相比之下，Boosting 模型能够更好地拟合开发数据。

我们如何着手改进助推模型？一种方法是根据我们希望包含在打包中的集成数量来测试训练集中的错误率。

```
    number_estimators_vs_err_rate(x_train,y_train,x_dev,y_dev)
```

下面的函数继续拟合增加的系综数并绘制误差率:

```
def number_estimators_vs_err_rate(x,y,x_dev,y_dev):
    no_estimators = range(20,120,10)
    misclassy_rate = []
    misclassy_rate_dev = []

    for no_estimator in no_estimators:
        boosting = build_boosting_model(x,y,no_estimators=no_estimator)
        predicted_y = boosting.predict(x)
        predicted_y_dev = boosting.predict(x_dev)        
        misclassy_rate.append(zero_one_loss(y,predicted_y))
        misclassy_rate_dev.append(zero_one_loss(y_dev,predicted_y_dev))

    plt.figure(2)
    plt.title("No estimators vs Mis-classification rate")
    plt.xlabel("No of estimators")
    plt.ylabel("Mis-classification rate")
    plt.plot(no_estimators,misclassy_rate,label='Train')
    plt.plot(no_estimators,misclassy_rate_dev,label='Dev')

    plt.show()
```

如您所见，我们声明了一个列表，以 10s 的步长从 20 开始，以 120 结束。在`for`循环中，我们将列表中的每个元素作为估计器参数的数量传递给`build_boosting_model`，然后继续访问模型的错误率。然后我们检查 dev 集中的错误率。现在我们有两个列表—一个包含来自训练数据的所有错误率，另一个包含来自开发数据的错误率。我们将它们都绘制出来，其中 *x* 轴是估计器的数量，而 *y* 轴是 dev 和 train 集中的错误分类率。

![How it works…](../images/00183.jpeg)

前面的图给出了一个线索，在大约 30 到 40 个估计量中，dev 的误差率非常低。我们可以进一步试验树模型参数，以得到一个好的模型。



## 还有更多……

Boosting】是在以下开创性论文中介绍的:

> *Freund，Y. & Schapire，R. (1997)，“在线学习的决策理论概括及其在 boosting 中的应用”，《计算机与系统科学杂志》55(1)，119–139。*

最初，大多数 Boosting 方法将多类问题简化为两类问题和多个两类问题。下面的论文将 AdaBoost 扩展到多类问题:

> *多类 AdaBoost 统计及其接口，第 2 卷第 3 期。(2009 年)，第 349-360 页，邹慧朱记 Saharon Rosset 的 Trevor Hastie 撰写的 doi:10.4310/sii . 2009 . v2 . n3 . A8*

本文还介绍了 SAMME，我们在食谱中使用的方法。



## 参见

*   *构建决策树解决多类问题*菜谱[第六章](part0073_split_000.html#25JP21-6b04b7c0b98f44a0b8f82924fef317ec "Chapter 6. Machine Learning 1")，*机器学习 I*
*   *使用交叉验证迭代器*配方[第七章](part0078_split_000.html#2ACBS1-6b04b7c0b98f44a0b8f82924fef317ec "Chapter 7. Machine Learning 2")，*机器学习 II*
*   *了解总体——装袋法*第八章、*中[的配方及](part0083_split_000.html#2F4UM1-6b04b7c0b98f44a0b8f82924fef317ec "Chapter 8. Ensemble Methods")*



# 了解集成——梯度推进

让我们回忆一下上一个配方中解释的升压算法。在 boosting 中，我们以向前、逐级的方式拟合了一个附加的模型。我们按顺序建立分类器。在建立每个分类器之后，我们估计分类器的权重/重要性。基于权重/重要性，我们调整了训练集中实例的权重。错误分类的实例的权重高于正确分类的实例。我们希望下一个模型选择那些错误分类的实例，并对它们进行训练。使用这些权重来识别数据集中不合适的实例。从另一个角度来看，这些记录是之前模型的缺陷。下一个模型试图克服这些缺点。

梯度增强使用梯度而不是权重来识别那些缺点。让我们快速看看如何使用渐变来改进模型。

让我们来看一个简单的回归问题，我们得到了所需的预测变量 *X* 和响应 *Y* ，它是一个实数。

![Understanding Ensemble – Gradient Boosting](../images/00184.jpeg)

梯度推进过程如下:

它从一个非常简单的模型开始，比如说平均值。

![Understanding Ensemble – Gradient Boosting](../images/00185.jpeg)

预测值只是响应变量的平均值。

然后继续进行拟合残差。残差是实际值 y 和预测值 y hat 之差。

![Understanding Ensemble – Gradient Boosting](../images/00186.jpeg)

下一个分类器在数据集上训练如下:

![Understanding Ensemble – Gradient Boosting](../images/00187.jpeg)

在先前模型的残差上训练随后的模型，因此，该算法继续在集合内构建所需数量的模型。

让我们试着理解为什么我们训练残差。到目前为止，应该很清楚助推会产生可加模型。假设我们建立两个模型`F1 (X)`和`F2(X)`来预测`Y1`。根据加法原理，我们可以将这两个模型组合如下:

![Understanding Ensemble – Gradient Boosting](../images/00188.jpeg)

也就是说，我们结合两个模型的预测来预测 y1。

等价地，我们可以说:

![Understanding Ensemble – Gradient Boosting](../images/00189.jpeg)

残差是模型没有做好的部分，或者简单地说，残差是前一个模型的缺点。因此，我们使用残差改进我们的模型，即改进以前模型的缺点。基于这种讨论，你可能会想为什么这种方法被称为梯度增强而不是残差增强。

给定一个可微的函数，梯度代表该函数在特定值的一阶导数。在回归的情况下，目标函数是:

![Understanding Ensemble – Gradient Boosting](../images/00190.jpeg)

其中`F(xi)`是我们的回归模型。

线性回归问题是关于最小化这个前面的函数。我们找到该函数在值`F(xi)`处的一阶导数，如果我们用该导数值的负值更新我们的权重系数，我们将在搜索空间中向最小解移动。前述成本函数相对于`F(xi)`的一阶导数为`F(xi ) – yi`。请参考以下链接了解推导过程:

[https://en.wikipedia.org/wiki/Gradient_descent](https://en.wikipedia.org/wiki/Gradient_descent)

`F(xi ) – yi`，梯度，是我们残差`yi – F(xi)`的负数，因此得名梯度增强。

有了这个理论，让我们进入梯度推进的食谱。



## 开始使用…

我们将使用波士顿数据集来演示梯度增强。波士顿数据有 13 个属性和 506 个实例。目标变量是一个实数，以千为单位的房屋中值。波斯顿的数据可以从 UCI 链接下载:

[https://archive . ics . UCI . edu/ml/machine-learning-databases/housing/housing . names](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.names)

我们打算生成二次多项式特征，并且只考虑交互作用的影响。



## 怎么做

让我们导入必需的库，并编写一个函数`get_data()`来为我们提供一个数据集，以完成这个食谱:

```
# Load libraries
from sklearn.datasets import load_boston
from sklearn.cross_validation import train_test_split
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import PolynomialFeatures
import numpy as np
import matplotlib.pyplot as plt

def get_data():
    """
    Return boston dataset
    as x - predictor and
    y - response variable
    """
    data = load_boston()
    x    = data['data']
    y    = data['target']
    return x,y    

def build_model(x,y,n_estimators=500):
    """
    Build a Gradient Boost regression model
    """
    model = GradientBoostingRegressor(n_estimators=n_estimators,verbose=10,\
            subsample=0.7, learning_rate= 0.15,max_depth=3,random_state=77)
    model.fit(x,y)
    return model    

def view_model(model):
    """
    """
    print "\n Training scores"
    print "======================\n"
    for i,score in enumerate(model.train_score_):
        print "\tEstimator %d score %0.3f"%(i+1,score)

    plt.cla()
    plt.figure(1)
    plt.plot(range(1,model.estimators_.shape[0]+1),model.train_score_)
    plt.xlabel("Model Sequence")
    plt.ylabel("Model Score")
    plt.show()

    print "\n Feature Importance"
    print "======================\n"
    for i,score in enumerate(model.feature_importances_):
        print "\tFeature %d Importance %0.3f"%(i+1,score)

def model_worth(true_y,predicted_y):
    """
    Evaluate the model
    """
    print "\tMean squared error = %0.2f"%(mean_squared_error(true_y,predicted_y))

if __name__ == "__main__":

    x,y = get_data()

    # Divide the data into Train, dev and test    
    x_train,x_test_all,y_train,y_test_all = train_test_split(x,y,test_size = 0.3,random_state=9)
    x_dev,x_test,y_dev,y_test = train_test_split(x_test_all,y_test_all,test_size=0.3,random_state=9)

    #Prepare some polynomial features
    poly_features = PolynomialFeatures(2,interaction_only=True)
    poly_features.fit(x_train)
    x_train_poly = poly_features.transform(x_train)
    x_dev_poly   = poly_features.transform(x_dev)

    # Build model with polynomial features
    model_poly = build_model(x_train_poly,y_train)
    predicted_y = model_poly.predict(x_train_poly)
    print "\n Model Performance in Training set (Polynomial features)\n"
    model_worth(y_train,predicted_y)  

    # View model details
    view_model(model_poly)

    # Apply the model on dev set
    predicted_y = model_poly.predict(x_dev_poly)
    print "\n Model Performance in Dev set  (Polynomial features)\n"
    model_worth(y_dev,predicted_y)  

    # Apply the model on Test set
    x_test_poly = poly_features.transform(x_test)
    predicted_y = model_poly.predict(x_test_poly)

    print "\n Model Performance in Test set  (Polynomial features)\n"
    model_worth(y_test,predicted_y)  
```

让我们写下面三个函数的。

函数 build _model，它实现了梯度增强例程。

函数 view_model 和 model_worth，用于检查我们构建的模型:

```
def build_model(x,y,n_estimators=500):
    """
    Build a Gradient Boost regression model
    """
    model = GradientBoostingRegressor(n_estimators=n_estimators,verbose=10,\
            subsample=0.7, learning_rate= 0.15,max_depth=3,random_state=77)
    model.fit(x,y)
    return model    

def view_model(model):
    """
    """
    print "\n Training scores"
    print "======================\n"
    for i,score in enumerate(model.train_score_):
        print "\tEstimator %d score %0.3f"%(i+1,score)

    plt.cla()
    plt.figure(1)
    plt.plot(range(1,model.estimators_.shape[0]+1),model.train_score_)
    plt.xlabel("Model Sequence")
    plt.ylabel("Model Score")
    plt.show()

    print "\n Feature Importance"
    print "======================\n"
    for i,score in enumerate(model.feature_importances_):
        print "\tFeature %d Importance %0.3f"%(i+1,score)

def model_worth(true_y,predicted_y):
    """
    Evaluate the model
    """
    print "\tMean squared error = %0.2f"%(mean_squared_error(true_y,predicted_y))
```

最后，我们编写我们的主函数，它将调用其他函数:

```
if __name__ == "__main__":

    x,y = get_data()

    # Divide the data into Train, dev and test    
    x_train,x_test_all,y_train,y_test_all = train_test_split(x,y,test_size = 0.3,random_state=9)
    x_dev,x_test,y_dev,y_test = train_test_split(x_test_all,y_test_all,test_size=0.3,random_state=9)

    #Prepare some polynomial features
    poly_features = PolynomialFeatures(2,interaction_only=True)
    poly_features.fit(x_train)
    x_train_poly = poly_features.transform(x_train)
    x_dev_poly   = poly_features.transform(x_dev)

    # Build model with polynomial features
    model_poly = build_model(x_train_poly,y_train)
    predicted_y = model_poly.predict(x_train_poly)
    print "\n Model Performance in Training set (Polynomial features)\n"
    model_worth(y_train,predicted_y)  

    # View model details
    view_model(model_poly)

    # Apply the model on dev set
    predicted_y = model_poly.predict(x_dev_poly)
    print "\n Model Performance in Dev set  (Polynomial features)\n"
    model_worth(y_dev,predicted_y)  

    # Apply the model on Test set
    x_test_poly = poly_features.transform(x_test)
    predicted_y = model_poly.predict(x_test_poly)

    print "\n Model Performance in Test set  (Polynomial features)\n"
    model_worth(y_test,predicted_y)  
```



## 它是如何工作的……

让我们从主模块开始并遵循代码。我们使用 get_data 函数加载预测值 x 和响应变量 y:

```
def get_data():
    """
    Return boston dataset
    as x - predictor and
    y - response variable
    """
    data = load_boston()
    x    = data['data']
    y    = data['target']
    return x,y    
```

该函数调用 Scikit learn 的便利函数`load_boston()`以 numpy 数组的形式检索波士顿房价数据集。

我们继续使用 Scikit 库中的 train_test_split 函数将数据分为训练集和测试集。我们保留 30%的数据集进行测试。

```
x_train,x_test_all,y_train,y_test_all = 
train_test_split(x,y,test_size = 0.3,random_state=9)
```

在这 30%中，我们再次提取下一行中的 dev 集:

```
x_dev,x_test,y_dev,y_test = train_test_split(x_test_all,y_test_all,test_size=0.3,random_state=9)
```

我们继续构建多项式特征，如下所示:

```
poly_features = PolynomialFeatures(interaction_only=True)
poly_features.fit(x_train)
```

如您所见，我们已经将 interaction_only 设置为 True。通过将 interaction_only 设置为 true，给定 x1 和 x2 属性，只创建 x1*x2 属性。不创建 x1 的平方和 x2 的平方，假设次数为 2。默认度数为 2 度。

```
x_train_poly = poly_features.transform(x_train)
x_dev_poly = poly_features.transform(x_dev)
x_test_poly = poly_features.transform(x_test)
```

使用转换函数，我们转换我们的训练、开发和测试数据集，以包括多项式特征:

让我们继续构建我们的模型:

```
    # Build model with polynomial features
    model_poly = build_model(x_train_poly,y_train)
```

在 build_model 函数中，我们实例化了 GradientBoostingRegressor 类，如下所示:

```
    model = GradientBoostingRegressor(n_estimators=n_estimators,verbose=10,\
            subsample=0.7, learning_rate= 0.15,max_depth=3,random_state=77)
```

让我们看看参数。第一个参数是集合中模型的数量。第二个参数是 verbose——当该参数设置为大于 1 的数字时，它会在构建每个模型(在本例中是树)时打印进度。下一个参数是子样本，它规定了模型将使用的训练数据的百分比。在这种情况下，0.7 表示我们将使用 70%的训练数据集。下一个参数是学习率。它是控制每棵树贡献的收缩参数。下一个参数 Max_depth 决定了构建的树的大小。random_state 参数是随机数生成器使用的种子。为了在不同的运行中保持一致，我们将其设置为一个整数值。

由于我们已经将 verbose 参数设置为大于 1，因此在拟合模型时，我们会在每次模型迭代期间在屏幕上看到以下结果:

![How it works…](../images/00191.jpeg)

正如你所看到的，训练损失随着每次迭代而减少。第四列是袋外改善得分。对于子样本，我们只选择了 70%的数据集；OOB 分数是用剩下的 30%来计算的。与以前的型号相比，损耗有所改善。例如，在迭代 2 中，与迭代 1 中构建的模型相比，我们有 10.32 的改进。

让我们继续检查集合在训练数据上的性能:

```
    predicted_y = model_poly.predict(x_train_poly)
    print "\n Model Performance in Training set (Polynomial features)\n"
    model_worth(y_train,predicted_y)  
```

![How it works…](../images/00192.jpeg)

如你所见，我们的 boosting 系综完美地拟合了训练数据。

model_worth 函数打印模型的更多细节。它们如下:

![How it works…](../images/00193.jpeg)

我们在详细输出中看到的每个不同模型的得分作为属性存储在模型对象中，并按如下方式检索:

```
print "\n Training scores"
print "======================\n"
for i,score in enumerate(model.train_score_):
print "\tEstimator %d score %0.3f"%(i+1,score)
```

让我们把它绘制成图表:

```
plt.cla()
plt.figure(1)
plt.plot(range(1,model.estimators_.shape[0]+1),model.train_score_)
plt.xlabel("Model Sequence")
plt.ylabel("Model Score")
plt.show()
```

*x* 轴代表型号，y 轴显示训练分数。请记住，推进是一个循序渐进的过程，每个模型都是对上一个模型的改进。

![How it works…](../images/00194.jpeg)

正如您在图中看到的，均方差，即模型得分，随着每个连续的模型而降低。

最后，我们还可以看到每个特性的重要性:

```
    print "\n Feature Importance"
    print "======================\n"
    for i,score in enumerate(model.feature_importances_):
        print "\tFeature %d Importance %0.3f"%(i+1,score)
```

让我们看看这些特征是如何相互叠加的。

![How it works…](../images/00195.jpeg)

梯度推进将特征选择和模型构建统一到一个操作中。它可以自然地发现特征之间的非线性关系。请参考以下关于梯度提升如何用于特征选择的论文:

> 徐志祥，，Kilian Q. Weinberger 和 Alice X .郑。2014.梯度增强特征选择。在*第 20 届 ACM SIGKDD 知识发现和数据挖掘国际会议论文集* (KDD '14)。美国纽约州纽约市 ACM，电话:522-531。

让我们将开发数据应用到模型中，看看它的性能:

```
    # Apply the model on dev set
    predicted_y = model_poly.predict(x_dev_poly)
    print "\n Model Performance in Dev set  (Polynomial features)\n"
    model_worth(y_dev,predicted_y)  
```

![How it works…](../images/00196.jpeg)

最后，我们来看看测试集的性能。

![How it works…](../images/00197.jpeg)

正如你所看到的，与开发组相比，我们的测试组表现得非常好。



## 还有更多……

有关梯度增强的更多信息，请参考以下文件:

> J. H .弗里德曼(2001 年)。贪婪函数逼近:梯度推进机。统计年鉴，第 1189-1232 页。
> 
> 在这份收据中，我们解释了使用平方损失函数的梯度推进。然而，梯度推进应被视为一个框架，而不是一种方法。在这个框架中可以使用任何可微损失函数。用户可以选择任何学习方法和可微分损失函数，并将其应用到梯度提升框架中。
> 
> *Scikit Learn 还提供了一种用于分类的梯度推进方法，称为 GradientBosstingClassifier。*

[http://sci kit-learn . org/stable/modules/generated/sk learn . ensemble . gradientboostingclassifier . html](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)



## 参见

*   *了解系综，装袋方法*第八章[中的配方](part0083_split_000.html#2F4UM1-6b04b7c0b98f44a0b8f82924fef317ec "Chapter 8. Ensemble Methods")，*模型选择和评估*
*   *了解系综*、*升压方法 AdaBoost* 配方[第八章](part0083_split_000.html#2F4UM1-6b04b7c0b98f44a0b8f82924fef317ec "Chapter 8. Ensemble Methods")、*选型及评估*
*   *在[第 7 章](part0078_split_000.html#2ACBS1-6b04b7c0b98f44a0b8f82924fef317ec "Chapter 7. Machine Learning 2")、*机器学习 II* 中使用回归*公式预测实数值
*   *变量选择使用套索回归*配方[第七章](part0078_split_000.html#2ACBS1-6b04b7c0b98f44a0b8f82924fef317ec "Chapter 7. Machine Learning 2")，*机器学习 II*
*   *使用交叉验证迭代器*配方[聊天工具](part0078_split_000.html#2ACBS1-6b04b7c0b98f44a0b8f82924fef317ec "Chapter 7. Machine Learning 2")，*机器学习 II*