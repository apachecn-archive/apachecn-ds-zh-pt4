<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 第八章。重采样方法和蒙特卡罗试验的应用

上一章解释了重采样方法的一般思想，并给出了各种简单的例子。在这一章中，我们来看看最成功的重采样方法——自举法的更复杂的应用。这些例子将表明，bootstrap 可以用于不同类型的复杂问题，但也将表明，bootstrap 的概念调整是必要的。换句话说，我们将看到自举必须被修改。

首先，我们看到 bootstrap 应用于回归分析，然后我们看到 bootstrap 在缺失值插补方面的应用，接着是在时间序列分析和复杂调查设计中的应用。

之后，我们关注重采样测试。我们将会看到，每一个统计检验都可以被公式化为蒙特卡罗重采样检验，其(巨大的)优势是检验统计量的分布不必像经典检验那样是固定的。

# 回归分析中的自助法

我们已经在第 7 章、*的[中看到](ch07.xhtml "Chapter 7. Resampling Methods")对于基于 MCD 的相关系数标准误差的方差估计，重采样方法可能是估计复杂估计量方差的唯一选择。一旦经典的、**普通最小二乘法** ( **OLS** )回归被跳过，并且选择了更稳健的方法，回归分析也是如此。*

## 使用自举的动机

有人可能会问:“当分析表达式已知时，为什么我们需要 bootstrap 来估计回归系数的方差？”。答案很简单:因为除了许多模型假设之外，只有对于普通的最小二乘回归，解析表达式才有效。

让我们先来看看如何选择更复杂的回归方法，一个简单的例子使用了最能显示实践中经常出现的问题的人工数据:

```
library("robustbase")
data("hbk")
## structure of the data
str(hbk)
## 'data.frame':    75 obs. of  4 variables:
##  $ X1: num  10.1 9.5 10.7 9.9 10.3 10.8 10.5 9.9 9.7 9.3 ...
##  $ X2: num  19.6 20.5 20.2 21.5 21.1 20.4 20.9 19.6 20.7 19.7 ...
##  $ X3: num  28.3 28.9 31 31.7 31.1 29.2 29.1 28.8 31 30.3 ...
##  $ Y : num  9.7 10.1 10.3 9.5 10 10 10.8 10.3 9.6 9.9 ...

```

接下来，我们使用`Y`作为响应，所有其他变量作为预测值，拟合 OLS 回归:

```
lm_ols <- lm(Y ~ ., data = hbk)
## print summary
summary(lm_ols)
## 
## Call:
## lm(formula = Y ~ ., data = hbk)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max
## -9.3717 -0.7162 -0.0230  0.7083  4.5130
##
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)
## (Intercept)  -0.3875     0.4165  -0.930  0.35527
## X1            0.2392     0.2625   0.911  0.36521
## X2           -0.3345     0.1551  -2.158  0.03434 *
## X3            0.3833     0.1288   2.976  0.00399 **
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.25 on 71 degrees of freedom
## Multiple R-squared:  0.6018, Adjusted R-squared:  0.585
## F-statistic: 35.77 on 3 and 71 DF,  p-value: 3.382e-14

```

从这个输出来看，一切都很好。对于`X2`和`X3`我们不能拒绝回归系数为`0`、`R2`相对较高且整个模型显著的零假设。

我们也可以看一个剩余诊断图，见*图 8.1* 。

```
plot(lm_ols, which = 3)

```

![Motivation to use the bootstrap](Images/B05113_08_01.jpg)

图 8.1:剩余诊断图。相对于绝对标准化残差平方根的拟合值

所有标准化残差都很小，因此在*图 8.1* 中没有检测到异常值。对于较大的拟合值，绝对残差略大于其余值。总的来说，模型看起来不错。但这真的是真的吗？模型是否已经受到异常值的影响，以至于模型结果已经被扰乱到我们无法检测异常的程度？

让我们拟合一个稳健的基于 MM 的回归(Maronna、Martin 和 Yohai，2006 年),并将其与之前基于 OLS 的结果进行比较:

```
lm_rob <- lmrob(Y ~ ., data = hbk)
## print summary
summary(lm_rob)
##
## Call:
## lmrob(formula = Y ~ ., data = hbk)
##  \--> method = "MM"
## Residuals:
##      Min       1Q   Median       3Q      Max
## -0.92734 -0.38644  0.05322  0.71808 10.80013
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)
## (Intercept) -0.18962    0.11674  -1.624   0.1088
## X1           0.08527    0.07329   1.164   0.2485
## X2           0.04101    0.02956   1.387   0.1697
## X3          -0.05371    0.03195  -1.681   0.0971 .
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
##
## Robust residual standard error: 0.7892 
## Multiple R-squared:  0.03976,    Adjusted R-squared:  -0.0008186
## Convergence in 9 IRWLS iterations
##
## Robustness weights:
##  10 observations c(1,2,3,4,5,6,7,8,9,10)
##   are outliers with |weight| = 0 ( < 0.0013);
##  7 weights are ~= 1\. The remaining 58 ones are summarized as
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
##  0.8522  0.9268  0.9624  0.9532  0.9865  0.9986
## further output suppressed

```

我们看到`R2`几乎为零，我们必须拒绝模型中的每个变量。此外，诊断图中的残差看起来不同，参见*图 8.2* 。

```
plot(lm_rob, which = 5)

```

![Motivation to use the bootstrap](Images/B05113_08_02.jpg)

图 8.2:剩余诊断图。稳健方法中相对于绝对标准化残差平方根的拟合值

从图 8.2 的*中我们可以清楚地看到，存在一些异常值，从前面对`lm_rob`和的总结中我们可以看到`X`和`Y`之间没有依赖关系。*

如果我们观察成对散点图，我们会发现稳健回归方法是正确的，而 OLS 方法完全失效，见*图 8.3* 。

```
pairs(hbk, pch = 20, cex = 0.6)

```

![Motivation to use the bootstrap](Images/B05113_08_03.jpg)

图 8.3:hbk 数据的成对散点图

从*图 8.3* 中，我们可以观察到变量之间的相关性为零，我们还可以看到少数异常值的存在。这些异常值以如此显著的方式影响 OLS 模型，以至于它完全被破坏，并且`R2`将变高，两个回归系数变得非常显著。

使用经典的 OLS 回归方法，可以使用众所周知的分析表达式轻松估算回归系数的标准误差。然而，对于更可靠的稳健回归方法，这样的解析表达式几乎是未知的。Bootstrap 也是估计相应标准误差的选择方法。它的应用和 OLS 方法一样简单，也就是说；自举应用的复杂性与估计量的复杂性无关。

### 最流行但往往是最差的方法

我们在下文中看到，用 bootstrap 估计回归系数的标准误差有两种不同的方法。

首先，我们展示了一种方法，这种方法在大约 95%的情况下被使用，但是它通常高估了置信区间。然后，在模型具有良好预测能力的情况下，我们给出了一个更好的方法。第一种方法从整个数据集中抽取引导样本。

回归模型![The most popular but often worst method](Images/B05113_08_21.jpg)的估计在本节中起着核心作用。因此，数据基础是 n 个观测值， **X** 包含 p + 1 个预测值，包括截距的 1 个向量。整个数据集(比如说 **Z** 可以表示为成对的 **y** 和 **X** 。在其他符号中，这是![The most popular but often worst method](Images/B05113_08_22.jpg)。

对于 **Z** ，抽取 R 个 bootstrap 样本，并对每个 bootstrap 样本进行模型估计，得到回归系数的 R 个估计值(bootstrap 复制)。从这些 bootstrap 分布中，可以计算置信区间，例如，Efron 的百分位数法(见[第 7 章](ch07.xhtml "Chapter 7. Resampling Methods")、*重采样方法*)。

让我们再次使用来自`car`包的`Prestige`数据，并让我们估计回归模型:

*声望~日志(收入)+女人+类型*

这意味着我们希望用收入、女性在职人员的百分比和职业类型(蓝领、白领和专业人员)的对数值来预测变量`prestige`。注意，有更好的模型，但是为了简单解释这种方法的问题，我们使用一个简单的例子。

可以使用稳健的方法来拟合该模型。由于对于 MM 回归，bootstrap 已经以一种非常好的方式实现，我们选择另一种稳健的回归方法:最小修整平方回归(Rousseeuw 和 Leroy 1987)。在如下所示的摘要输出中，我们看到通过函数`ltsReg`的实现估计的标准误差大约为。`2.36`。我们记住这个值供以后使用:

```
data(Prestige, package = "car")
rob <- ltsReg(prestige ~ log(income) + women + type, data = Prestige)
summary(rob)
##
## Call:
## ltsReg.formula(formula = prestige ~ log(income) + women + type,
##     data = Prestige)
##
## Residuals (from reweighted LS):
##     Min      1Q  Median      3Q     Max
## -11.257  -3.562   0.000   4.252  12.927
##
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)
## Intercept   -186.19502   20.57510  -9.050 2.71e-14 ***
## log(income)   25.62408    2.36002  10.858  < 2e-16 ***
## women          0.17433    0.03364   5.182 1.34e-06 ***
## typeprof      13.48480    2.30026   5.862 7.42e-08 ***
## typewc         1.69518    1.96566   0.862    0.391
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
##
## Residual standard error: 6.467 on 90 degrees of freedom
## Multiple R-Squared: 0.8604,  Adjusted R-squared: 0.8542
## F-statistic: 138.7 on 4 and 90 DF,  p-value: < 2.2e-16

```

如果我们想使用 R 包`boot`中的函数`boot`，我们应该仔细准备一个`boot`包可以处理的`boot`函数:

```
boot.lts <- function(x, indices){
 x <- x [indices,]
 model <- ltsReg(prestige ~ log(income) +
 women + type, data = x)
 coefficients(model)
}

```

定义了函数后，我们可以将所有内容放入函数`boot`:

```
library("boot")
set.seed(123)
rob_boot <- boot(Prestige, boot.lts, 1000)
## estimated standard errors
rob_boot
##
## ORDINARY NONPARAMETRIC BOOTSTRAP
##
##
## Call:
## boot(data = Prestige, statistic = boot.lts, R = 1000)
##
##
## Bootstrap Statistics :
##         original       bias    std. error
## t1* -188.9846989 -7.631124780 64.32621578
## t2*   25.9405809  0.882198382  7.37310316
## t3*    0.1789914 -0.001773418  0.07992569
## t4*   11.2511897  2.018062069  6.34813577
## t5*    1.5686363  0.919839439  3.94373349

```

让我们更详细地看看`log(income)`的系数。我们看到标准误差约为。`3.84`而从函数`ltsReg`估算出来的是`2.36`。

也很容易看出，自举复制的分布是双峰的，并且出现了偏差，尤其是在分布的上尾部，见*图 8.4* 。

```
hist(rob_boot$t[,2], 50, xlab = "bootstrap repl., log(income)", main = "")

```

![The most popular but often worst method](Images/B05113_08_04.jpg)

图 8.4:回归系数对数(收入)的自举分布(和 QQ 图)的直方图

此外，关于女性的系数的 bootstrap 复制的分布看起来并不近似。正常，如*图 8.5* 所示:

```
hist(rob_boot$t[,3], 50, xlab = "bootstrap repl., women", main = "")

```

![The most popular but often worst method](Images/B05113_08_05.jpg)

图 8.5:女性回归系数的自助分布(重复)直方图

我们可以做一些进一步的计算，比如估计回归系数的置信区间。使用函数`boot.ci`可以估计不同类型的置信区间，如偏差修正置信区间、Efron 百分位法置信区间和![The most popular but often worst method](Images/B05113_08_23.jpg)法置信区间。对于系数`log(income)`,结果如下:

```
boot.ci(rob_boot, index = 2,
 type = c("norm", "perc", "bca"))
## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 1000 bootstrap replicates
##
## CALL :
## boot.ci(boot.out = rob_boot, type = c("norm", "perc", "bca"),
##     index = 2)
##
## Intervals :
## Level      Normal             Percentile            BCa
## 95%   (10.61, 39.51 )   (14.58, 43.66 )   (13.96, 41.85 )
## Calculations and Intervals on Original Scale

```

在[第 7 章](ch07.xhtml "Chapter 7. Resampling Methods")、*重采样方法*中，我们学习了*bootstrap 后刀切*图，以观察单次观察对 bootstrap 分布分位数的影响。下图 8.6 显示了系数`log(income)`和女性的曲线图:

```
par(mfrow = c(2,1), mar = c(4,4,2,0.5))
jack.after.boot(rob_boot, index = 2, main = 'log (income) coefficient')
jack.after.boot(rob_boot, index = 3, main = 'woman coefficient')

```

![The most popular but often worst method](Images/B05113_08_06.jpg)

图 8.6:对数(收入)和女性的 bootstrap 图后的折叠图

从这些图形(*图 8.6* )我们可以观察到，观察值 58 和 54 对自举分布有很大影响；通过排除这些观察值，bootstrap 分布变得更大。例如，观察值 40 也对自举分布有很大影响，但是当被排除在外时会降低分布。因此，观察值 2 可以被视为异常值。

在之后，我们回到这些图，我们提出了一个在回归环境中进行引导的更好的方法。

### 从残差中提取自举

在经典的回归中，人们认为 **X** 部分是固定的(并且是独立的)。这可以通过从残差中提取来考虑，而不是从 **Z** 中提取自举样本。这种方法被称为残差自举。

为了获得自举样本，基于(自举)残差![Bootstrapping by draws from residuals](Images/B05113_08_26.jpg)的随机误差被加到预测值![Bootstrapping by draws from residuals](Images/B05113_08_25.jpg)上。

理由是 **y** 可以被![Bootstrapping by draws from residuals](Images/B05113_08_24.jpg)复制。

让我们在一个简单的二维玩具数据集上激发这个概念:

```
set.seed(12)
df <- data.frame(x = 1:7, y = 1:7 + rnorm(7))

```

在下面的代码中，我们估计了回归线，并将其绘制到数据点上。然后，我们抽取一个残差的 bootstrap 样本，并将这些残差添加到拟合值中，即:我们获得新的值![Bootstrapping by draws from residuals](Images/B05113_08_27.jpg),将其用作回归问题的输入，以获得新的回归线:

```
par(mfrow = c(2,1), mar = c(4,4,1,0.3))
## fit to original data
lm_orig <- lm(y ~ x, data = df)
## plot original data
plot(y ~ x, data = df)
## add regression line from original data
abline(lm_orig)
## show the connection lines
## between original and fitted y
segments(x0 = df$x, x1=df$x,
 y0=df$y, y1=lm_orig$fit)
## fitted y
points(df$x, lm_orig$fit, pch=20, col="red")
legend("topleft", legend = c("y", expression(hat(y))),
 pch = c(1,20), col = c(1,2))
## second plot ---------------------
## plot of fitted values
plot(lm_orig$fit ~ df$x, col="red", pch = 20,
 ylab="y", xlab = "x")
## bootstrap sample by adding sampled residuals
y1 <- lm_orig$fit + sample(lm_orig$res, replace = TRUE)
## new bootstrap sample
points(df$x, y1, col="blue", pch = 3)
## connection lines new bootstrap sample to
## fitted values from original data
segments(x0 = df$x, x1 = df$x,
 y0 = lm_orig$fit, y1 = y1, col ="blue")
## regression line from original data
abline(lm_orig)
## regression line from bootstrap sample
abline(lm(y1 ~ df$x), col = "blue", lty = 2)
legend("topleft", legend = c("original", "bootstrap repl. 1"), lty = c(1,2), col = c(1,4))

```

![Bootstrapping by draws from residuals](Images/B05113_08_07.jpg)

图 8.7:顶部:原始值(圆形圆圈)、拟合值![Bootstrapping by draws from residuals](Images/B05113_08_25.jpg)(红色填充圆圈)和原始数据拟合的回归线。底部:拟合值(红色实心圆)，一个由![Bootstrapping by draws from residuals](Images/B05113_08_24.jpg)代表的引导样本，以及来自原始值(黑色实线)和引导样本(蓝色虚线)的回归线

这种方法不能重复，也就是说；新的 bootstrap 样本将导致图 8.7 中*新的回归线。*

让我们回到一个真实的案例。我们再次从 R `car`包中获取*声望*数据，并通过最小修剪平方回归估计稳健回归模型系数的标准误差。让我们首先根据原始数据拟合模型:

```
Prestige <- na.omit(Prestige)
## fit model on original data
rob2 <- ltsReg(prestige ~ log(income) + women + type,
 data = Prestige)

```

我们提取残差和拟合值以备后用，并且我们稍后还需要模型矩阵。注意，该模型矩阵是固定的，因此仅根据原始样本进行估计:

```
residuals <- residuals(rob2)
fit <- fitted(rob2)
## fix X, model matrix
X <- model.matrix(rob2, Prestige)[, -1]

```

同样，我们需要一个用于 *boot* 的函数来创建引导样本，这次是通过将随机抽取的残差添加到原始样本的预期/拟合值:

```
ltsBoot2 <- function(x, indices){
 y <- fit + residuals[indices]
 model <- ltsReg(y ~ X)
 coefficients(model)
}

```

最后，我们可以进行基于残差的自举:

```
rob2_boot <- boot(Prestige, ltsBoot2, R = 2000)
## show results
rob2_boot
## 
## ORDINARY NONPARAMETRIC BOOTSTRAP
## 
## 
## Call:
## boot(data = Prestige, statistic = ltsBoot2, R = 2000)
## 
## 
## Bootstrap Statistics :
##         original       bias    std. error
## t1* -188.9846989  3.847338290 23.93016057
## t2*   25.9405809 -0.422141347  2.73913510
## t3*    0.1789914  0.001174141  0.04058027
## t4*   11.2511897  2.652930311  2.67849883
## t5*    1.5686363 -0.055049721  2.42259399

```

我们可以看到的标准误差比之前的方法(从 **Z** 采样)要小。此外，与`log(income)`和女性相关的 bootstrap 复制的分布现在接近正态分布(见*图 8.8* )，并且看起来比之前的方法成形得更好:

```
par(mfrow = c(1,2), mar = c(4,4,1,0.2))
hist(rob2_boot$t[,2], 50, xlab = "bootstrap repl., log(income)", main = "")
hist(rob2_boot$t[,3], 50, xlab = "bootstrap repl., women", main = "")

```

![Bootstrapping by draws from residuals](Images/B05113_08_08.jpg)

图 8.8:回归系数对数(收入)(左)和女性(右)的自助分布(重复)直方图

*自举后刀切*图证实了基于残差的自举比之前从 **Z** 自举具有更好的特性；

```
par(mfrow = c(2,1), mar = c(4,4,2,0.5))
jack.after.boot(rob2_boot, index = 2, main = 'log (income) coefficient')
jack.after.boot(rob2_boot, index = 3, main = 'woman coefficient')

```

![Bootstrapping by draws from residuals](Images/B05113_08_09.jpg)

图 8.9:对数(收入)和从残差法的自举中获得的妇女的自举图后的折叠图

### 注意

在结合稳健方法使用残差自举的情况下，可以通过从 n - m 个无异常值残差(m)中采样 n 个残差来改进自举...检测到的异常值的数量)。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 有缺失值的适当方差估计

在实践中，缺少值通常是一个主要问题。评估的标准程序通常不是为处理缺失值而设计的。在下文中，我们将讨论一种在估计估计量的方差/不确定性时充分处理缺失值的方法。

由于未回答的问题或测量错误，数据通常具有以下数据结构:

![Proper variance estimation with missing values](Images/B05113_08_28.jpg)

这里我们看到了 **n** 个观测值和 **p** 个变量以及一些缺失值(NA)。

人们通常会忽略那些包含数据集中缺失值的观察值。然而，这减少了样本量，从而增加了估计量的方差，此外，如果缺失值是随机缺失的，也就是说，这可能导致有偏估计；如果缺失的概率取决于协变量。

要解决这个问题，另一个更好的解决方案是估算缺失值。对于某些应用来说，插补是以最小化预测误差的方式进行的。对于其他应用，重要的是估计量的方差以适当的方式估计(鲁宾 1987)。如果用估算值来最小化预测误差，那么估计量的方差就会被低估。但是，如果用单一的估算方法估算缺失值，方差就会被低估，因为固定值被用作估算，排除了估算的可变性。因此，为了进行适当的插补，通常采用多种插补方法。这意味着使用概率插补方法进行的插补不止一次，而是多次。这就产生了多个数据集，每个数据集包含一轮插补。从这些多个文件中，估计量的适当方差可以通过使用每个估计方差的所谓组合规则来获得(Rubin 1987)。

但是，想象你在一个机构或者公司工作，一个部门负责数据采集，一个部门负责数据预处理，一个部门负责分析，一个部门负责发布。假设你在数据预处理部门工作。如果你把一个数据集的 10 个估算数据发送给其他部门，你相信他们会高兴吗？你认为其他部门可以处理 10 个数据集吗？从理论上讲，多重插补是一个非常好的概念，但在实践中，单一插补往往是唯一可行的方法。但是，当你提供一个估算数据集，而你知道方差会被低估时，你会感觉良好吗？

摆脱这种困境的一种方法是使用重采样方法，如自举或折叠法。Little 和 Rubin 在 2002 年已经展示了这种方法，但后来不知何故被遗忘了。但是，我们会看到它在实践中非常有用。

设 **X** 为包含缺失值的 **p** 变量和 **n** 独立观测值的样本。关于来自总体参数![Proper variance estimation with missing values](Images/B05113_08_30.jpg)的点估计![Proper variance estimation with missing values](Images/B05113_08_29.jpg)的置信区间估计如下。请注意，技巧是估算引导样本，而不是原始数据。再次强调，原始样本是你所拥有的最佳信息，这个原始样本的 bootstrap 样本模拟了总体，也考虑了缺失值。

对于![Proper variance estimation with missing values](Images/B05113_08_31.jpg)重复:

1.  从原始(非估算)样本 **X** 中抽取一个 bootstrap 样本![Proper variance estimation with missing values](Images/B05113_08_32.jpg)。
2.  输入![Proper variance estimation with missing values](Images/B05113_08_32.jpg)中缺失的值。
3.  估计参数![Proper variance estimation with missing values](Images/B05113_08_33.jpg)。

这导致了对![Proper variance estimation with missing values](Images/B05113_08_35.jpg)的 R 个引导复制。然后，该自举复制分布用于确定相对于![Proper variance estimation with missing values](Images/B05113_08_29.jpg)的置信区间或标准误差，例如，通过使用 Efron 的百分位数方法，参见[第 7 章](ch07.xhtml "Chapter 7. Resampling Methods")、*重采样方法*。

让我们在实践中这样做。在下面的例子中，使用提到的 bootstrap 来估计具有缺失值的数据的置信区间。简单来说，![Proper variance estimation with missing values](Images/B05113_08_30.jpg)应该是一个变量的算术平均值。可重复地，从样本中抽取 bootstrap 样本，估算 bootstrap 样本中的缺失值，最后从 bootstrap 样本中估计算术平均值。我们使用包含缺失值的睡眠数据集:

```
library("VIM")
data("sleep")

```

让我们首先分析一下缺失值的结构。图 8.9 中*的左图显示了睡眠数据集的每个变量中缺失值的数量，图 8.10* 中*的右图显示了缺失模式结构:*

```
aggr(sleep, numbers = TRUE, prop = FALSE, cex.axis = 0.75)

```

![Proper variance estimation with missing values](Images/B05113_08_10.jpg)

图 8.10:根据睡眠数据集中缺失值的简单统计。左:每个变量缺少数字。右图:缺失模式的频率

例如，42 个观察值是完全观察到的，9 个观察值在第三和第四个变量中都有缺失值，依此类推。

*图 8.11* 中所谓的 matrixplot (Templ，Alfons，and Filzmoser 2011)显示了整个数据矩阵，按变量`BrainWgt`排序。线条越黑，数据矩阵的相应值越高。红线对应于数据矩阵中缺失的值。从*图 8.11* 中我们看到 **NonD** 、 **Dream** 和 **Sleep** 中的丢失概率可能会随着`BrainWgt`值的增加而增加:

```
par(mar = c(6,4,0.2,0.2))
matrixplot(sleep, sortby = "BrainWgt", interactive = FALSE)

```

![Proper variance estimation with missing values](Images/B05113_08_11.jpg)

图 8.11:睡眠数据集的矩阵曲线图。数据按照变量 BrainWgt 排序

自举样本(必须)表现出类似的行为，因为我们从样本中用替换物重新取样。从*图 8.12* 我们可以观察到缺失值的数量略有变化。根据缺失模式的频率(右图，*图 8.12* )不同。不是没有缺失值的 42 个观察值，而是只有 38 个观察值不包括引导样本中的任何缺失。此外，例如， **NonD** 和 **Dream** 中缺失的频率现在是 **11** 而不是之前的 **9** ，请比较*图 8.11* 和*图 8.12* :

```
set.seed(123)
sleep_boot1 <- sleep[sample(1:nrow(sleep), replace = TRUE), ]
aggr(sleep_boot1, numbers = TRUE, prop = FALSE,
 cex.axis = 0.75)

```

![Proper variance estimation with missing values](Images/B05113_08_12.jpg)

图 8.12:根据睡眠数据集的一个引导样本中缺失值的简单统计。左:每个变量的缺失数。右图:缺失模式的频率

在 matrixplot 中，可以看到 **NonD** 和**Dream**missing 组合选择的图案略多，参见*图 8.13* 。同样在变量`Gest`中，与之前一样，对于小的`BrainWgt`值，遗漏的概率更高。更多详情参见图 8.13 :

```
par(mar = c(6,4,0.2,0.2))
matrixplot(sleep_boot1, sortby = "BrainWgt")

```

![Proper variance estimation with missing values](Images/B05113_08_13.jpg)

图 8.13:睡眠数据集的一个引导样本的矩阵图。数据按照变量 BrainWgt 排序

许多其他的图会显示引导样本的缺失结构与原始数据之间的差异。重要的是也看到缺失的结构变化，也就是说；我们使用 bootstrap 来模拟人口分布中可能出现的所有情况。因此，这个 bootstrap 似乎是一个有效的概念，用于估计包含缺失值的数据的方差。接下来我们展示一个实际的例子，我们使用一些完全观察到的数据(同样是睡眠数据集)并设置一些值缺失。这个模拟缺少一点，因为我们假设缺失值是固定的。然而，在实践中，缺失值有自己的分布。一种解决方法是查看置信区间的覆盖率。然而，我们希望保持简单，并希望展示如何应用这种自举方法。

我们给出单一插补的结果:

```
n <- nrow(sleep)
imputed <- kNN(sleep, imp_var = FALSE)
## Time difference of 0.0347321 secs
ci_single <- quantile(replicate(10000, mean(imputed[sample(1:n, replace = TRUE), "Sleep"])), c(0.025, 0.975))
ci_single
##      2.5%     97.5%
##  9.280565 11.579073

```

最后，我们用我们提出的 bootstrap 方法估计置信区间。这里，bootstrap 样本取自非估算数据。下面一行代码需要更长的计算时间:

```
ci_boot <- quantile(replicate(10000, mean(kNN(sleep[sample(1:n, replace = TRUE), ], imp_var = FALSE)$Sleep)), c(0.025, 0.975))
ci_boot
##      2.5%     97.5%
##  9.201613 11.658105

```

我们看到这导致了一个稍大的置信区间，因为我们考虑了插补的不确定性。

当然，当数据包含缺失值时，我们也可以使用刀切法来估计置信区间。该方法与自举方法非常相似。

对于![Proper variance estimation with missing values](Images/B05113_08_36.jpg):

1.  输入折叠样本![Proper variance estimation with missing values](Images/B05113_08_37.jpg)。
2.  估计估算数据集的参数![Proper variance estimation with missing values](Images/B05113_08_30.jpg)。
3.  根据由此产生的重叠重复分布，使用第 7 章[、*重采样方法*中的重叠法估计置信区间。](ch07.xhtml "Chapter 7. Resampling Methods")

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 时间序列中的自举

时间序列的自举通常使用两种方法:

*   估计模型并从残差中提取(参见倒数第二节通过自举残差自举回归模型)
*   移动块自助方法

我们在下面集中讨论移动块引导。这是一种在文献中经常应用和提及的方法，但是成功有限。展示这种方法的局限性是本节的目标之一。

其思想是将数据分成块，并在块内进行替换采样。这使得我们不能完全忽略观察值之间的关系。观察值之间的关系通常存在于时间序列中。例如，下一个值将依赖于前一个值。还要考虑趋势、季节性和周期性。

原则上，时间序列可以分为不重叠或重叠的块。

我们将展示用于估计自相关的重叠移动块自举。首先，我们生成一些玩具数据:

```
set.seed(123)
tseries <- rnorm(50)
## introduce auto-correlation
tseries[-1] <- tseries[-1] + tseries[-50]

```

时间序列如下图所示:

```
plot(ts(tseries), ylab = "values")

```

![Bootstrapping in time series](Images/B05113_08_014.jpg)

图 8.14:时间序列示例

我们的移动数据块引导需要数据、数据块大小和复制次数作为输入:

```
mbb <- function(x, R=1000, blocksize=6){
 ## initialization
 nc <- length(x)
 lagCorMBB <- ct <- numeric(R)
 seriesBl <- numeric(nc)
 ## function for moving blocks bootstrap
 corT <- function(x=tseries, N=nc, bl=blocksize){
 ## for N/bl blocks
 for(i in 1:ceiling(N/bl)) {
 ## endpoint of block
 endpoint <- sample(bl:N, size=1)
 ## put blocks together, bootstrap sample
 seriesBl[(i-1)*bl+1:bl] <- x[endpoint-(bl:1)+1]
 }
 seriesBl <- seriesBl[1:N]
 ## autocorrelation
 a <- cor(seriesBl[-1],seriesBl[-N])
 return(a)
 }
 ct <- replicate(R, corT(x))
 return(ct)
}

```

现在让我们将这个函数应用于我们的时间序列:

```
mb <- mbb(x=tseries, R=10000)
## first 10 bootstrap replicates
mb[1:10]
##  [1] 0.2899296 0.1966638 0.0771300 0.4065762 0.2561444 0.4276909 0.4419033
##  [8] 0.2332383 0.3501899 0.2468474
## auto-correlation coefficient from mean 
of bootstrap replicates
mean(mb)
## [1] 0.3410245

```

很自然，如果时间序列不是白噪声，那么移动块自举复制的算术平均值小于来自数据本身的点估计，因为我们通过将时间序列分割成新的块而丢失了一些自相关。我们可以看到数据的自相关性(滞后 1 ):

```
acf(tseries)$acf[2]
## [1] 0.4302483

```

然而，在任何情况下，我们只对估计自相关系数的 95%置信区间(百分位数法)感兴趣:

```
qu_mbb <- quantile(mb, c(0.025,0.975))
cat("CI(mbb) : [", round(qu_mbb[1], 2), ",", round(qu_mbb[2], 2), "]")
## CI(mbb) : [ 0.12 , 0.57 ]

```

相比之下，`forecast`包(Hyndman 和 Khandakar 2008)中自相关系数置信区间的默认方法是报告如下:

```
library("forecast")
ac <- taperedacf(tseries)
cat("CI(classical) : [", round(ac$lower[1], 2), ",", round(ac$upper[1], 2), "]")
## CI(classical) : [ -0.02 , 0.43 ]

```

我们看到了如何实现移动块引导，但我们没有提到在什么情况下移动块引导可能无法正常工作。切割块并重新连接它们会自动破坏趋势，并且每当时间序列不稳定时会导致不可靠的结果。因此，在应用移动块引导之前，必须对时间序列进行去趋势处理。此外，移动块 bootstrap 可能只适用于简单的时间序列模型，如自回归滞后 1 (AR 1)过程。这里假设下一个值只取决于前一个值。对于更复杂的方法，如一般的 ARIMA 过程，移动块引导可能不会给出有效的推断统计。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 复杂抽样设计情况下的自举

我们已经看到许多应用程序，所有这些样本都是完全随机抽取的。然而，当一个人对有限的人口了解甚少时，或者当数据收集是基于复杂的调查设计时，情况往往不是这样。当然，这些信息用于以最低成本的方式抽取样本。换句话说，举一个商业统计数据的例子:奥地利有很多中小型公司，但大型公司不多。对于精确的估计，我们需要所有最大的公司(选择概率为 1)，但是选择小公司的概率可以低得多。一个复杂的调查设计允许我们以最小的成本得出一个好的样本。

因此，在复杂调查抽样中，以已知的包含概率![Bootstrapping in the case of complex sampling designs](Images/B05113_08_38.jpg)从 N 大小的总体中对个体进行抽样，最终得到 N 大小的样本。包含概率可能因阶层(总体的分区)而异，甚至可能因抽样框架中的每个个体而异。

对于总体总数，如果个体 I 被抽样，我们有一个无偏估计量![Bootstrapping in the case of complex sampling designs](Images/B05113_08_39.jpg)是![Bootstrapping in the case of complex sampling designs](Images/B05113_08_42.jpg)和![Bootstrapping in the case of complex sampling designs](Images/B05113_08_40.jpg)，如果没有被抽样，则为![Bootstrapping in the case of complex sampling designs](Images/B05113_08_41.jpg)。

通常将总体划分为 K 层，从第 K 层抽取![Bootstrapping in the case of complex sampling designs](Images/B05113_08_43.jpg)个观测值。然后，可以通过从第 K 层重新采样![Bootstrapping in the case of complex sampling designs](Images/B05113_08_44.jpg)个观测值并替换来构建 bootstrap 样本。同样，如果观察值是成组地而不是单独地被抽取到样本中，例如；当绘制家庭图并收集每个家庭成员的信息时，bootstrap 应该对集群而不是个人进行重新采样。这通常被称为天真的引导。几位作者讨论了这种简单方法的局限性(Rao 和 Wu，1988 年)，(Deville 和 s rndal，1992 年)，(Deville，s rndal 和 Sautory，1993 年)。

当我们估算![Bootstrapping in the case of complex sampling designs](Images/B05113_08_45.jpg)时，用设计重量![Bootstrapping in the case of complex sampling designs](Images/B05113_08_46.jpg)，我们从总体中知道一些特征。例如，我们从样本的一个变量 **x** 中知道总体的真实总数![Bootstrapping in the case of complex sampling designs](Images/B05113_08_47.jpg)和![Bootstrapping in the case of complex sampling designs](Images/B05113_08_49.jpg)。然后我们用![Bootstrapping in the case of complex sampling designs](Images/B05113_08_48.jpg)和![Bootstrapping in the case of complex sampling designs](Images/B05113_08_50.jpg)和![Bootstrapping in the case of complex sampling designs](Images/B05113_08_51.jpg)搜索新的权重![Bootstrapping in the case of complex sampling designs](Images/B05113_08_103.jpg)。如果我们有更多的约束/已知的群体特征，并且如果数据具有聚类结构，这将变得更加复杂。

当然，通过以与从总体中选择原始样本相同的方式从样本数据中重新采样，bootstrap 可以应用于复杂的采样设计(包括例如分层、聚类和病例加权)。然而，如前所述，应考虑校准。

让我们用一个非常简单的玩具数据例子来说明这个问题。考虑下面的简单样本数据集，让我们忽略这一点，通常，此类数据具有家庭结构:

```
x <- data.frame("location" = rep("Asten", 8),
 "income" = c(2000,2500,2000,2500,1000,1500,2000,2500),
 "weight" = c(1000,500,1000,500,1500,1000,1000,2000))
x
##   location income weight
## 1    Asten   2000   1000
## 2    Asten   2500    500
## 3    Asten   2000   1000
## 4    Asten   2500    500
## 5    Asten   1000   1500
## 6    Asten   1500   1000
## 7    Asten   2000   1000
## 8    Asten   2500   2000

```

我们看到阿斯滕的八个人报告了收入和抽样权重。我们假设抽样权重已经校准，例如，第一个观察值代表总体中的 1000 个观察值，第二个观察值代表总体中的 500 个观察值，依此类推。因此，总而言之，我们可以假设阿斯滕的人口规模为 8500 人。

```
sum(x$weight)
## [1] 8500

```

阿斯滕所有人的加权总收入(Horwitz Thompson 估计)或估计总收入为:

```
sum(x$income * x$weight)
## [1] 16500000

```

让我们画一个引导样本:

```
set.seed(123)
y <- x[sample(1:8, replace = TRUE), ] # Bootstrap Sample
y
##     location income weight
## 3      Asten   2000   1000
## 7      Asten   2000   1000
## 4      Asten   2500    500
## 8      Asten   2500   2000
## 8.1    Asten   2500   2000
## 1      Asten   2000   1000
## 5      Asten   1000   1500
## 8.2    Asten   2500   2000

```

阿斯滕村居民的总收入估计为:

```
# non-calibrated estimation
sum(y$income * y$weight)
## [1] 23750000

```

挺高的不是吗？条件 *N = 8500* 被违反，因此总收入的估计被扭曲。对于这个 bootstrap 样本，Asten 的总体规模为:

```
sum(y$weight)
## [1] 11000

```

这肯定不等于 8.500。这解释了为什么估计的收入从第一个 bootstrap 样本就被完全高估了。

因为我们知道有 8500 人生活在阿斯滕，而肯定不是 11000 人，我们将使用这一人口信息，并根据这一人口信息校准自助样本。在这种情况下，这很容易，我们只需将每个权重乘以常数 8.500/11.000:

```
constant <- sum(x$weight) / sum(y$weight)
## calibrated estimation
sum(y$x * y$w * constant)
## [1] 0

```

这个例子演示了最简单的情况。通常样品必须根据各种已知的总体特征进行校准。然而，这个例子清楚地显示了校准自举的需要，正式显示如下。

记住，估计标准误差的朴素自举算法由下式给出:

1.  从 **x** 中选择 R 个独立 bootstrap 样本![Bootstrapping in the case of complex sampling designs](Images/B05113_08_52.jpg)。
2.  估计每个引导样本的引导复制。
3.  ![Bootstrapping in the case of complex sampling designs](Images/B05113_08_53.jpg)。
4.  使用 R 个 bootstrap 复制的标准偏差估算标准误差![Bootstrapping in the case of complex sampling designs](Images/B05113_08_56.jpg)，使用![Bootstrapping in the case of complex sampling designs](Images/B05113_08_55.jpg)估算![Bootstrapping in the case of complex sampling designs](Images/B05113_08_54.jpg)

校准的自举需要在简单自举的第 1 点和第 2 点之间增加一个步骤:

首先，校准抽样权重，使引导样本完全符合已知总体特征，即抽样权重应尽可能少地变化；采样权重乘以所谓的 g 权重，g 权重应该接近 1(优化问题)。这些 g-重量通常是通过诸如迭代比例拟合或最小二乘回归法等方法来估计的。

下面，我们将这个校准的引导应用于更复杂的数据集。下面的例子是关于如何从**欧盟收入和生活条件调查统计数据** ( **EU-SILC** )中估计贫困风险率。

贫困风险率被定义为家庭收入相等的人在贫困线以下的比率。贫困线相当于人口中值收入的 60%。

因此，贫困率的定义是:

![Bootstrapping in the case of complex sampling designs](Images/B05113_08_57.jpg)

人口的平均家庭收入。![Bootstrapping in the case of complex sampling designs](Images/B05113_08_59.jpg)是收入的分布函数。

为了估计贫困率，必须考虑抽样权重。首先，我们必须通过以下方式估算贫困线:

![Bootstrapping in the case of complex sampling designs](Images/B05113_08_60.jpg)

其中 **x** 是样本中的均衡家庭收入，`wmed`是加权中位数，定义为:

![Bootstrapping in the case of complex sampling designs](Images/B05113_08_61.jpg)

如![Bootstrapping in the case of complex sampling designs](Images/B05113_08_62.jpg)其中 I 是奇数，如果 I 是偶数，则为![Bootstrapping in the case of complex sampling designs](Images/B05113_08_63.jpg)。

贫困率可以借助指数![Bootstrapping in the case of complex sampling designs](Images/B05113_08_64.jpg)来估算

![Bootstrapping in the case of complex sampling designs](Images/B05113_08_65.jpg)

否则为:

![Bootstrapping in the case of complex sampling designs](Images/B05113_08_66.jpg)

这些估计实际上可以用 R 包`laeken`来完成(Alfons 和 Templ 2013)。校准的自举可用于函数方差。请注意，总数通常由总体决定。这里我们从样本中估算一下:

```
library("laeken")
data("eusilc")
## point estimate of poverty rate
a <- arpr("eqIncome", weights = "rb050", data = eusilc)
## bootstrap with calibration
## define auxiliary 0-1 variables for regions
aux <- sapply(levels(eusilc$db040),
 function(l, x) as.numeric(x == l),
 x = eusilc$db040)
## retrieve population totals from underlying sample
totals <- sapply(levels(eusilc$db040),
 function(l, x, w) sum(w[x == l]),
 x = eusilc$db040, w = eusilc$rb050)
# bootstrap variance
variance("eqIncome", weights = "rb050", design = "db040",
 data = eusilc, indicator = a, X = aux, totals = totals,
 seed = 123)
## Value:
## [1] 14.44422
##
## Variance:
## [1] 0.09192744
##
## Confidence interval:
##    lower    upper
## 13.87865 15.19303
## 
## Threshold:
## [1] 10859.24

```

我们看到，贫困风险率的点估计值为 14，444，校准自助法估计的置信区间为[13，937；15,012].请注意，在 R 中，没有可用的公式来通过分析表达式估计贫困风险率的方差。许多其他贫困估计数也是如此。现有的文献中的公式是复杂的，取决于假设和不同的抽样设计。校准的自举是以用户友好的方式估计方差的唯一机会。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 蒙特卡洛测试

你知道多元正态性的多元 Anderson-Darling 检验的统计量吗？不用担心，这些测试统计量只是在模拟实验方面对几个显著性水平进行了近似，一般是未知的。但是，对于给定数量的观察值、变量数量和某个显著性水平，我们如何估计检验统计量的值呢？答案很简单，程序就像简单得多的测试一样简单。我们可以用测试的重采样方法来做——蒙特卡罗测试。

## 一个激励人心的例子

在我们对这些测试进行更正式的描述之前，我们用一个很长的介绍性例子来介绍蒙特卡罗重采样测试。这应该能说明为什么蒙特卡洛测试有效。以下使用体温数据的例子是受 Friedrich Leisch 在维也纳技术大学的一次演讲的启发，并被本书作者的进一步后续演讲所改编。

我们首先从 65 名男性和 65 名女性身上获取了一些数据，体温和心率数据:

```
temp <- read.table("http://venus.unive.it/romanaz/statistics/data/bodytemp.txt", header = TRUE)
temp$gen <- factor(temp$gen, labels = c("male", "female"))
str(temp)
## 'data.frame':    130 obs. of  3 variables:
##  $ tf : num  96.3 96.7 96.9 97 97.1 97.1 97.1 97.2 97.3 97.4 ...
##  $ gen: Factor w/ 2 levels "male","female": 1 1 1 1 1 1 1 1 1 1 ...
##  $ hr : int  70 71 74 80 73 75 82 64 69 70 ...

```

使用摄氏温度而非华氏温度的人可以进行以下转换:

```
temp$celsius <- (temp$tf - 32) * 5 / 9

```

让我们来想象一下首先，在*图 8.15* 中与男性和女性温度相关的密度:

```
library("ggplot2")
ggplot(temp, aes(x = celsius, colour = gen, linetype = gen)) + geom_density(size = 1.2) + theme(text = element_text(size=16)) + theme_bw()

```

![A motivating example](Images/B05113_08_015.jpg)

图 8.15:女性和男性体温的密度估计值

从 *Fi* *图 8.15* 我们看到了根据男性和女性的不同分布。在这个数据集中，女性的平均温度更高。我们回到是否可以拒绝相等总体均值的零假设的问题上来。

第一个问题是测试数据集是否近似正常，这也是许多其他测试中的一个重要假设。更准确地说，我们想知道从正态分布中抽取的零假设样本是否可以被拒绝。我们将温度保存在它自己的向量中，只是为了以后更好地查看代码:

```
temperature <- temp$celsius

```

首先，让我们设想在每个排序的观察值处给出质量 1/n 的经验分布函数:

```
n <- length(temperature)
temperature <- sort(temperature)
y <- (0:(n-1)) / n

```

我们现在可以绘制出经验分布函数，即相对于`0`和`1`之间等距值的长度为`n`的向量排序的温度值。结果可见于*图 8.16* :

```
plot(temperature, y, pch=20, cex = 0.3)
lines(temperature, y, type="S")

```

![A motivating example](Images/B05113_08_016.jpg)

图 8.16:温度数据的经验累积分布函数图

我们现在可以问这些经验值是否来自正态分布。一种可能是使用 QQ plot 等诊断工具，但这次我们想用数值工具做决定。让我们从我们的经验数据中计算出平均值和标准偏差的理论正态分布，绘制并添加到图中:

```
plot(temperature, y, type="S")
m <- mean(temperature)
s <- sd(temperature)
yn <- pnorm(temperature, mean = m, sd = s)
lines(temperature, yn, col=2)

```

![A motivating example](Images/B05113_08_017.jpg)

图 8.17:温度数据和理论值(红线)的经验累积分布函数图(黑线)

这还不算太糟，但是我们如何得到这条红线的置信带呢？

我们可以做一些数学计算，或者模拟置信带。既然懒，那就更喜欢模拟。但是如何做到这一点呢？诀窍总是一样的。我们使用从经验样本数据估计的参数，根据零假设抽取随机样本。在这种情况下，我们从温度数据的平均值和标准偏差为的正态分布中提取，并查看最终的经验累积分布函数波动有多大。一次绘制如下(注意，我们将模拟数据四舍五入到一位数，因为我们的原始温度数据是这样表示的):

```
z <- round(sort(rnorm(n, mean = m, sd = s)), 1)

```

我们可以重复这个过程，在图中画出这些线:

```
set.seed(123)
plot(temperature, y, type="S")
for(k in 1:100){
 z <- rnorm(n, mean=m, sd=s)
 lines(sort(z), y, type="S", col="green")
}

```

![A motivating example](Images/B05113_08_018.jpg)

图 8.18:从温度数据的平均值和标准偏差的正态分布得出的经验累积分布函数

我们原始数据的经验累积分布函数现在应该已经消失了，也就是；在图 8.18 的*中，代表我们的温度数据的经验累积分布函数的黑色逐步线应该不再可见。因此，常态假设并不完全是胡说八道。*

让我们将来自正态分布的 1000 次模拟的结果保存在数据集中:

```
Z <- NULL
for(k in 1:1000){
 z = rnorm(n, mean = m, sd = s)
 Z = cbind(Z, sort(z))
}
dim(Z)
## [1]  130 1000

```

`Z`在每一列中包含一个大小为 130 的排序样本，该样本来自具有均值 m 和标准差 s 的正态分布。另一种观点认为`Z`在每一行中包含对于具有均值 m 和标准差`s`的正态分布的 *n / 130 分位数*的 1000 个估计值。

让我们看看这个:

```
## mean of original temperature data
m
## [1] 36.80513
## simulated mean
(mean(Z[65, ]) + mean(Z[66, ])) / 2
## [1] 36.80581
## simulated median
(median(Z[65, ]) + median(Z[66, ])) / 2
## [1] 36.80621

```

下一张图显示了基于我们从正态分布中随机抽取的正态分布的估计值。我们还添加了下限和上限——显著性水平为`0.05`的置信区间。结果见*图 8.19* :

```
plot(temperature, y, type="S")
middle <- apply(Z, 1, median)
lines(middle, y, col = "blue", lwd = 2, type = "S")
## lower and upper bounds
lower <- apply(Z, 1, quantile, prob = 0.025)
upper <- apply(Z, 1, quantile, prob = 0.975)
lines(lower, y, col = 2, lwd = 2, type = "S")
lines(upper, y, col = 2, lwd = 2, type = "S")

```

![A motivating example](Images/B05113_08_19.jpg)

图 8.19:从理论正态分布模拟得到的置信区间

由累积分布函数(黑色逐步线)表示的经验数据几乎总是在置信区间内。这再次表明正态假设可能不会被拒绝。

可能最流行的分布测试是 Kolmogorov-Smirnov 测试。它的检验统计量由观察到的经验累积分布函数与理论分布函数的最大偏差给出。

让我们来看看每个给定温度下的这些偏差，报告在*图 8.20* 的底部图形中。我们还用一个大圈标出最大偏差:

```
par(mfrow = c(2,1), mar = rep(1,4))
plot(temperature, y, type="S")
lines(temperature, yn, col=2)
lines(lower, y, col=2, lwd=2, type="S")
lines(upper, y, col=2, lwd=2, type="S")
plot(temperature, y - yn, type="h")
abline(h = 0)
## maximum deviation
D <- max(abs(y - yn))
w <- which.max(abs(y - yn))
points(temperature[w], y[w] - yn[w], col=2, pch=16, cex=3)

```

![A motivating example](Images/B05113_08_020.jpg)

图 8.20:顶部:经验数据的 ECDF(逐步黑线)，理论 ECDF(中线)和模拟置信区间。下图:原始数据的 ECDF 和理论 ECDF 之间的相关差异

正态分布的经验累积分布函数至少有观测偏差的可能性有多大？

我们已经模拟了 1000 个样本。我们通过再次执行之前对温度执行的操作来查看它们的最大偏差:

```
## theoretical distribution
Z1 <- pnorm(Z, mean = m, sd = s)
## y will be recycled column-wise,
## extract the maximum for each column
D1 <- apply(abs(y - Z1), 2, max)

```

如果我们观察`D1`的分布，并将其与原始数据的最大偏差(`D`)进行比较，我们会发现`D`的值并没有那么不寻常:

```
summary(D1)
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## 0.02514 0.05457 0.06777 0.07163 0.08401 0.19120
D
## [1] 0.0607473

```

我们可以问模拟的最大偏差比原始数据集的最大偏差大多少倍。更好的是，我们可以问它的比率。已经是 *p 值*了！

```
mean(D1>D)
## [1] 0.638

```

让我们来看看 Kolmogorov-Smirnov 测试:

```
ks.test(temperature, "pnorm", mean = m, sd = s)
## 
##  One-sample Kolmogorov-Smirnov test
## 
## data:  temperature
## D = 0.064727, p-value = 0.6474
## alternative hypothesis: two-sided

```

如果我们增加`Z`的列数，也就是；从一个正态分布中抽取的次数，那么平均值(D1>D)应该等于 Kolmogorov-Smirnov 检验的 p 值。(除了具有舍入值的 Kolmogorov-Smirnov 测试的问题之外)。

## 排列测验作为一种特殊的 MC 测验

通常，我们用两组观察值的算术平均值进行比较，并根据算术平均值的显著性差异进行分析。在这种情况下，零假设是具有大小为![The permutation test as a special kind of MC test](Images/B05113_08_68.jpg)和![The permutation test as a special kind of MC test](Images/B05113_08_69.jpg)的 **x** 和 **y** 向量的![The permutation test as a special kind of MC test](Images/B05113_08_67.jpg)。经典(t-)检验的假设由两个总体组成，正态分布，并且方差相等。如果具有算术平均值![The permutation test as a special kind of MC test](Images/B05113_08_74.jpg)和![The permutation test as a special kind of MC test](Images/B05113_08_75.jpg)的两个样本![The permutation test as a special kind of MC test](Images/B05113_08_70.jpg)和![The permutation test as a special kind of MC test](Images/B05113_08_71.jpg)是独立的，并且它们的平均值和方差由![The permutation test as a special kind of MC test](Images/B05113_08_72.jpg)和![The permutation test as a special kind of MC test](Images/B05113_08_76.jpg)给出，那么下面的检验统计量遵循具有自由度![The permutation test as a special kind of MC test](Images/B05113_08_73.jpg)的 t 分布:

![The permutation test as a special kind of MC test](Images/B05113_08_77.jpg)

对于测试![The permutation test as a special kind of MC test](Images/B05113_08_81.jpg)，单边测试的临界区域(替代方案![The permutation test as a special kind of MC test](Images/B05113_08_78.jpg)由![The permutation test as a special kind of MC test](Images/B05113_08_80.jpg)决定)。对于双面测试

![The permutation test as a special kind of MC test](Images/B05113_08_102.jpg)

必须替换为![The permutation test as a special kind of MC test](Images/B05113_08_79.jpg)。

在以下示例中，比较了 1950 年以来 45 名美国人(工人和雇员)的算术平均值:

```
data(Duncan, package = "car")
x <- subset(Duncan, type %in% c("bc", "wc"), select = c("income", "type"))
x$type <- factor(x$type)
## first four observations on income and type
head(x, 4)
##              income type
## reporter         67   wc
## conductor        76   wc
## bookkeeper       29   wc
## mail.carrier     48   wc

```

测试前面提到的零假设的经典 t 检验是:

```
t.test(income ~ type, data=x)
## 
##  Welch Two Sample t-test
## 
## data:  income by type
## t = -3.045, df = 7.6945, p-value = 0.01669
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -47.42134  -6.38818
## sample estimates:
## mean in group bc mean in group wc 
##         23.76190         50.66667

```

p 值为`0.01669`。因此，对于显著性水平`0.01`，可以拒绝零假设，但是对于显著性水平`0.05`，不能拒绝零假设。

两个独立样本的经典 t 检验的一个严格假设是总体是正态分布的，方差应该相等。此外，当我们用稳健估计量代替算术平均值时，我们基本上不知道检验统计量。

在将算术平均值检验转化为其他位置估计的过程中，所有这些假设和弱点在蒙特卡罗检验中都不存在。

总的想法是模仿零假设，也就是说；要模拟零假设的值，将相同的检验统计应用于原始数据和模拟数据，并比较这些检验统计。

之前显示的 t 检验的 p 值现在也可以通过排列检验来计算(其他蒙特卡罗检验随后介绍)。

1.  估计原始样本(有原始类别)中两组均值的绝对差。将此标记为![The permutation test as a special kind of MC test](Images/B05113_08_29.jpg)。
2.  通过置换分组/类别从零假设模拟。随机组模拟了均值相等的零假设。计算随机分组结构的平均值之间的绝对差值。将结果表示为![The permutation test as a special kind of MC test](Images/B05113_08_83.jpg)。至少重复这个:![The permutation test as a special kind of MC test](Images/B05113_08_84.jpg)
3.  p 值由![The permutation test as a special kind of MC test](Images/B05113_08_82.jpg)给出。

要置换分组结构，我们只需使用函数 sample(无需替换):

```
## first 6 observations with permuted grouping structure
head(cbind(x, "p1" = sample(x$type), 
 "p2" = sample(x$type), 
 "p3" = sample(x$type)))
##                 income type p1 p2 p3
## reporter            67   wc wc bc bc
## conductor           76   wc bc bc wc
## bookkeeper          29   wc bc wc wc
## mail.carrier        48   wc bc bc bc
## insurance.agent     55   wc bc wc bc
## store.clerk         29   wc bc bc wc

```

这些组仍然有![The permutation test as a special kind of MC test](Images/B05113_08_68.jpg)和![The permutation test as a special kind of MC test](Images/B05113_08_69.jpg)观察值，但是它们的观察值是根据组属性随机排列的。这模仿了均值相等的零假设。

现在让我们用 R 编写一个置换测试。我们使用 R 的类`htest`来接收标准化的打印输出:

```
## define test statistics (workhorse)
teststat <- function(vals, group, lev){
 g <- sample(group)
 abs(mean(vals[g == lev[1]]) - mean(vals[g == lev[2]]))
}
## permutation test
permtest <- function(x, g, R = 1000, conf.level = 0.95){
 ## levels of the group vector
 lg <- levels(g)
 ## test statistics for original groups
 mdiff <- abs(mean(x[g==lg[1]]) - mean(x[g==lg[2]]))
 ## test statistics for permuted group data
 z <- replicate(R, teststat(x, g, lg))
 ## make nice print output
 DATA <- paste(deparse(substitute(x)),
 "by",
 deparse(substitute(g)))
 alpha <- 1 - conf.level
 conf.int <- quantile(z, prob = c(alpha/2, (1 - alpha)/2))
 attr(conf.int, "conf.level") <- conf.level
 res <- list(statistic=c(mdiff = mdiff),
 p.value = mean(abs(z) > abs(mdiff)),
 parameter = c(nrep = R),
 conf.int = conf.int,
 data.name = DATA,
 method = "Permutation test for difference in means")
 class(res) <- "htest"
 res
}

```

现在我们可以对收入和类型的邓肯数据应用排列检验:

```
permtest(x$income, x$type, R = 10000)
## 
##  Permutation test for difference in means
## 
## data:  x$income by x$type
## mdiff = 26.905, nrep = 10000, p-value = 0.0039
## 95 percent confidence interval:
##  0.3095238 6.5238095

```

同样，置换测试会拒绝显著性水平为`0.05`的测试，但也会拒绝`0.01`的测试。排列测试可以应用于任何测试问题，其中变量的组/类扮演着核心角色。

## 针对多组的蒙特卡洛测试

如果要比较一个以上的组，通常选择方差分析。然而，这也可以通过成对 t 检验来完成。

```
data(Duncan, package = "car")
pairwise.t.test(Duncan$income, Duncan$type)
##
##  Pairwise comparisons using t tests with pooled SD
##
## data:  Duncan$income and Duncan$type
##
##      bc      prof
## prof 2.9e-07 -
## wc   0.0039  0.2634
##
## P value adjustment method: holm

```

p 值调整是什么意思？拒绝(当零假设为真时拒绝零假设)所有 k 检验的概率是所有显著性水平的乘积，即:![A Monte Carlo test for multiple groups](Images/B05113_08_85.jpg)。如果![A Monte Carlo test for multiple groups](Images/B05113_08_86.jpg)和 k = 100，那么拒绝的概率是![A Monte Carlo test for multiple groups](Images/B05113_08_88.jpg)。例如，如果从正态分布中抽取数据，随机选择 100 组并进行正态性测试，这也是正确的，因为当从正态分布中抽取数据并进行正态性测试时，每个单一测试将以 0.05 的概率拒绝。因此，显著性检验中的一个常见问题是多重比较倾向于产生虚假的显著差异，即使零假设为真。因此，p 值必须针对多重比较进行调整。

Bonferroni 校正将所有 p 值乘以测试次数，Holm 校正将最小的 p 值乘以 n，第二个乘以 n–1，依此类推。

对于`pairwise.t.test`，我们寻找任何两两组合的组之间的差异。另一个可能的问题是所有组的平均值是否相同:

```
mean(Duncan$income)
## [1] 41.86667
library("dplyr")
Duncan %>% group_by(type) %>% summarize(mean = mean(income))
## Source: local data frame [3 x 2]
## 
##     type     mean
##   (fctr)    (dbl)
## 1     bc 23.76190
## 2   prof 60.05556
## 3     wc 50.66667

```

我们的测试统计量是所有测试统计量的最大绝对值，计算方法如下:

```
tstat <- function(x, mu=0){
 (mean(x)-mu) / (sd(x) / sqrt(length(x)))
}
stats <- tapply(Duncan$income, Duncan$type, tstat, mu=mean(Duncan$income))
stat <- max(abs(stats))
stat
## [1] 4.725815

```

我们没有想出一种以分析的方式找到测试统计数据的方法，而是懒惰地记住了蒙特卡洛的简单生活方式。请注意，对于蒙特卡洛测试，重要的是通过尊重零假设来获得测试统计值。因此，我们可以从零假设中模拟随机数，或者如果我们知道一些关于检验统计的分布，我们可以直接从这个分布中模拟随机数。在我们的例子中，我们知道 z 检验的检验统计量的分布是 t 分布:

```
maxt.test <- function(x, g, R = 10000, conf.level = 0.05){
 m <- mean(x)
 stat <- tapply(x, g, tstat, mu = m)
 stat <- max(abs(stat))
 gsize = table(g)
 z <- NULL
 for(k in 1:length(gsize)){
 ## from a t-distribution:
 z <- cbind(z, rt(n=n, df=gsize[k]-1))
 }
 ## z now is a list with length(gsize) elements
 ## we need the maximum absolute value for each element
 z <- abs(z)
 z <- z[cbind(1:n,max.col(z))]
 ## make nice print output
 DATA <- paste(deparse(substitute(x)),
 "by",
 deparse(substitute(g)))
 alpha <- 1 - conf.level
 conf.int <- quantile(z, prob = c(alpha/2, (1 - alpha)/2))
 attr(conf.int, "conf.level") <- conf.level
 res <- list(statistic=c(stat = stat),
 p.value =  mean(z > stat),
 parameter = c(nrep = R),
 conf.int = conf.int,
 data.name = DATA,
 method = "Maximum t-test")
 class(res) <- "htest"
 res
}

```

现在让我们用三组类型对 Duncan 数据集进行测试:

```
maxt.test(Duncan$income, Duncan$type)
## 
##  Maximum t-test
## 
## data:  Duncan$income by Duncan$type
## stat = 4.7258, nrep = 10000, p-value = 0.007692
## 5 percent confidence interval:
##  1.271122 0.436830

```

我们看到我们可以拒绝零假设。

另一种可能性是进行排列测试:

```
maxp.test <- function(x, g, R = 10000, conf.level = 0.05){
 m <- mean(x)
 stat <- tapply(x, g, tstat, mu=m)
 stat <- max(abs(stat))
 z <- numeric(n)
 for(k in 1:n){
 g1 <- sample(g)
 z[k] <- max(abs(tapply(x, g1, tstat, mu = m)))
 }

 retval <- list(tstat=stat, pval=mean(z>stat),
 name="Permutation maximum t-test")
 class(retval) <- "ttest"
 retval
 ## make nice print output
 DATA <- paste(deparse(substitute(x)),
 "by",
 deparse(substitute(g)))
 alpha <- 1 - conf.level
 conf.int <- quantile(z, prob = c(alpha/2, (1 - alpha)/2))
 attr(conf.int, "conf.level") <- conf.level
 res <- list(statistic=c(stat = stat),
 p.value =  mean(z > stat),
 parameter = c(nrep = R),
 conf.int = conf.int,
 data.name = DATA,
 method = "Permutation maximum test")
 class(res) <- "htest"
 res
}

```

我们再次对邓肯数据进行测试:

```
maxp.test(Duncan$income, Duncan$type)
## 
##  Permutation maximum test
## 
## data:  Duncan$income by Duncan$type
## stat = 4.7258, nrep = 10000, p-value < 2.2e-16
## 5 percent confidence interval:
##  0.9895857 0.2037640

```

对于排列测试，p 值甚至略小。

## 使用 bootstrap 进行假设检验

一般来说， bootstrap 也可以作为蒙特卡罗测试的变体。

我们继续对相等总体均值进行 2 样本检验的假设检验。bootstrap 双样本测试的工作原理与排列测试非常相似。最基本的区别是我们用替换抽取样本。

1.  抽取 R 个尺寸为![Hypothesis testing using a bootstrap](Images/B05113_08_89.jpg)的 bootstrap 样本进行替换。第一批 n1 个观测值现在属于由![Hypothesis testing using a bootstrap](Images/B05113_08_90.jpg)表示的样本 1，其余的![Hypothesis testing using a bootstrap](Images/B05113_08_69.jpg)个观测值属于第二个样本![Hypothesis testing using a bootstrap](Images/B05113_08_93.jpg)。
2.  对于每个引导样本估计值![Hypothesis testing using a bootstrap](Images/B05113_08_91.jpg)。
3.  然后，p 值由![Hypothesis testing using a bootstrap](Images/B05113_08_92.jpg)给出，其中![Hypothesis testing using a bootstrap](Images/B05113_08_29.jpg)是从原始样本估计的。

现在让我们看看 R，这一次我们保持简单，不提供打印输出作为类`htest`:

```
boottest <- function(x, g, n=10000){
 lg <- levels(g)
 n1 <- length(x[g == lg[1]])
 N <- length(x)
 mdiff <- abs(mean(x[g == lg[1]]) - mean(x[g == lg[2]]))
 z <- double(n)
 for(k in 1:n){
 x1 <- sample(x, replace=TRUE)
 z[k] <- abs(mean(x1[1:n1]) - mean(x1[(n1+1):N]))
 }
 mean( z > mdiff )
}

```

bootstrap 检验给出的 p 值为 0，这意味着抽样组结构的检验统计没有提供比从原始数据获得的检验统计更大的检验统计值:

```
Duncan$type <- factor(Duncan$type)
boottest(Duncan$income, Duncan$type)
## [1] 0

```

## 多元正态性检验

作为最后一个测试，我们展示了一个更高级的测试，其中测试统计数据未知。我们要展示一个多元正态分布的测试，即**安德森-达林** ( **公元**)测试。多元正态性检验很重要，因为大多数多元统计方法都假设数据是多元正态的。测试可以检查这个假设是否有效。

对于测试来说，通常重要的是测试的*大小*和测试的*功率*。在 AD 测试的情况下，无论何时选择显著性水平`0.05`并且从多元正态分布中抽取随机样本，测试的大小都应该是`0.05`，即:对于重复抽取，拒绝的平均值应等于显著性水平。测试的功效用于比较测试。在测试规模正确的情况下，具有最高功率的测试是最佳测试。

许多多元正态性检验是基于马氏距离。

如果 **X** 是具有 *p* 变量、n 个观测值和样本方差![A test for multivariate normality](Images/B05113_08_94.jpg)的样本，那么目标是![A test for multivariate normality](Images/B05113_08_95.jpg)估计的马氏距离大约为。![A test for multivariate normality](Images/B05113_08_96.jpg)以 p 个自由度分布。

单变量安德森-达林检验(安德森和达林 1952 年)的检验统计量定义为:

![A test for multivariate normality](Images/B05113_08_97.jpg)

，其中![A test for multivariate normality](Images/B05113_08_98.jpg)，F 为正态分布的累积分布函数。![A test for multivariate normality](Images/B05113_08_99.jpg)是数据向量的值，按升序排列，![A test for multivariate normality](Images/B05113_08_100.jpg)是按降序排列。

这是一个片面的测试和零假设；*样本取自正态分布总体*，如果检验统计量 A 大于临界值，则被拒绝。对于 p、n 和显著性水平的一些情况，临界值是列表值，见 Stephens，1974。

在多元情况下，用![A test for multivariate normality](Images/B05113_08_96.jpg)分布和![A test for multivariate normality](Images/B05113_08_99.jpg)、![A test for multivariate normality](Images/B05113_08_101.jpg)的累积分布函数代替前面公式中的 F，就是马氏距离的![A test for multivariate normality](Images/B05113_08_96.jpg)分布的分位数。

安德森-达林检验统计量通常会乘以一个常数，具体取决于样本大小 n。

为了获得 p 值，可以实施蒙特卡罗方法。使用原始数据的均值和协方差对 n x p 大小的数据进行重复随机采样，以模拟零假设(多元正态性)。结果检验统计值(来自 R 人工模拟数据)与原始数据的检验统计值之比反过来充当 p 值。模拟次数越多，结果越稳定。

作为蒙特卡罗测试，我们可以在 R 中编写如下 AD 测试:

```
mvad.test <- function(x, R=1000){ 
 n <- nrow(x)
 ## test statistics
 stat <- function(x, N = n){
 cmean <- colMeans(x)
 cvar  <- var(x)
 u <- mahalanobis(x, center = cmean, cov = cvar)
 z <- pchisq(u, ncol(x))
 p <- sort(z)
 h <- (2 * seq(1:N) - 1) * (log(p) + log(1 - rev(p)))
 A <- -N - mean(h)
 return(A)
 }
 ## value of test statistics for original sample 
 A <- stat(x)
 cmean <- colMeans(x)
 cvar <- var(x)
 p <- numeric(R)
 ## values of test statistics for draws of mvn
 p <- replicate(R, stat(mvrnorm(n, cmean, cvar)))
 pvalue <- mean(p > A)
 RVAL <- list(statistic = c(A = A),
 method = "A-D radius test",
 p.value = pvalue)
 class(RVAL) <- "htest" 
 RVAL
}

```

## 测试的规模

如果选择了性能良好的随机数发生器，且数据来自多元正态分布，则拒绝百分比应等于所选的显著性水平。

这很容易检查。

我们模拟多元正态数据，协方差为零，我们重复这个 1000 次，也就是说；蒙特卡洛测试被应用 1000 次。显著性级别设置为![Size of the test](Images/B05113_08_86.jpg)。然后我们检查 p 值比`0.05`小多少倍。结果应该是大约的。`0.05`如果测试的尺寸正确:

```
library("MASS")
set.seed(123)
r <- replicate(1000, mvad.test(mvrnorm(100, mu=rep(0,3),
 Sigma=diag(3)))$p.value)
size <- mean(r < 0.05)
size
## [1] 0.05

```

## 力量对比

一旦构建了一个测试，使其大小适合不同的值、显著性水平和数据集的维度，就可以与其他测试进行比较。检查测试规模的目的是从零假设(多元正态性)中重复采样数据。现在，功效比较的目的是从另一个假设中可重复地模拟数据。如果数据来源于替代假设，当然拒绝率(=检验的功效)应该尽可能高。

我们比较了蒙特卡罗 AD 检验和偏度检验(Kankainen，Taskinen 和 Oja 2007)。

为此，数据将从多元 t 分布中提取:

```
library("mvtnorm")
library("ICS")
## Monte Carlo AD test 100 times replicated
r <- replicate(100, mvad.test(rmvt(30, diag(3), df = 5), R=100)$p.value)
mean(r  < 0.05)
## [1] 0.51
## Skewness test 1000 times replicated
r2 <- replicate(1000, mvnorm.skew.test(rmvt(30, diag(3), df = 5))$p.value)
mean(r2  < 0.05)
## [1] 0.368

```

我们看到我们的蒙特卡罗 AD 测试与众所周知的偏斜度测试具有同样高的功效。然而，我们必须提到，在这种情况下，评估形状的所谓峰度测试可能比主要目标是评估分布对称性的偏斜度测试更成功。

<title>Unknown</title>  <link href="../stylesheet.css" rel="stylesheet" type="text/css"> <link href="../page_styles.css" rel="stylesheet" type="text/css">

# 总结

从这一章我们了解到，bootstrap 可以应用于几乎任何复杂的问题，但我们也了解到 bootstrap 必须适应每个复杂的问题。对于回归分析，这是通过从残差而不是整个数据矩阵中取样来完成的。对于时间序列分析，bootstrap 的修改是通过将时间序列分割成块并在块内重新采样来完成的。

我们还看到，对于包含缺失值的数据，可以估计不确定性和适当的方差。每当在一个公司或组织中由于逻辑原因不能应用多重插补时，这具有巨大的优势。

bootstrap 还被应用于通过复杂调查设计抽取的复杂调查样本。这里我们定义了校准的 bootstrap 来充分估计统计的方差。

蒙特卡洛测试是一种非常通用的假设检验工具。数据科学家可以利用它们进行任何统计测试。我们没有使用任何关于零假设下统计量分布的理论知识，这是经典检验的通常情况。相反，我们模拟了零假设的分布。蒙特卡洛测试适用于所有的测试统计分布，无需对它们做出假设。这意味着，在违反中心极限定理(小样本和非正态总体)的情况下，蒙特卡罗测试比经典测试提供更可靠的结果。当然也有一个缺点:计算时间。然而，以台式个人电脑或笔记本电脑目前的计算能力，这应该不再是一个问题。

## 参考文献

*   阿尔方斯和 m .坦普尔。2013."复杂调查中社会排斥指标的估计:R 包 laeken . "*统计软件杂志*54(15):1–25。http://www.jstatsoft.org/v54/i15/[。](http://www.jstatsoft.org/v54/i15/)
*   安德森 T.W .和达林检察官。1952."基于随机过程的某些拟合优度标准的渐近理论."*数理统计年鉴*23:193–212。
*   德维尔、J.-C .和 C.-E .桑达尔。1992."调查抽样中的校准估计量."《美国统计协会杂志》87(418):376–82。
*   Deville、J.-C .、c .-e . s rndal 和 O. Sautory。1993."调查抽样中的广义筛选程序."*美国统计协会杂志*88(423):1013–20。
*   hynd man r .和 Y. Khandakar .2008.“自动时间序列预测:r .*的预测包统计软件学报* 27 (1)。
*   Kankainen，a .，S. Taskinen 和 H. Oja。2007."基于位置向量和散布矩阵的多正态性检验."*统计方法与应用*16(3):357–79。
*   利特尔、R.J.A .和 D.B .鲁宾。2002.*有缺失数据的统计分析*。第二版。约翰·威利&的儿子们。
*   Maronna、D. Martin 和 V. Yohai。2006.*稳健统计*。奇切斯特:约翰·威利&的儿子们。
*   饶，金乃光，吴振杰。1988."复杂调查数据的重采样推理."美国统计协会杂志 83:231–41。
*   罗瑟夫，P.J .和 A.M .勒罗伊。1987.*稳健回归和异常值检测*。威利；纽约之子。
*   鲁宾博士，1987 年。*对调查中无回答的多重插补*。T2 父子公司，纽约州。
*   斯蒂芬斯，文学硕士，1974 年。"拟合优度的 EDF 统计和一些比较."美国统计协会杂志 69:730–37。
*   Templ，m .，A. Alfons 和 P. Filzmoser。2011."使用可视化技术探索不完整的数据."*数据分析和分类的进展*6(1):29–47。