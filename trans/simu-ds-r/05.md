

# 五、最优化问题的蒙特卡罗方法

函数优化应用于[第 4 章](ch04.xhtml "Chapter 4. Simulation of Random Numbers")、*随机数模拟*中，以找到正态密度除以柯西密度的最大值，以及找到贝塔分布函数的极值。在这一章中，我们将集中讨论二维问题，并注意到所提到的方法可以扩展到多维问题。为了传达最优化方法如何工作的感觉，我们从一个发生在奥地利阿尔卑斯山的故事开始。

当我写下这些诗句的时候，奥地利突然出现了大雾天气。我想象一个澳大利亚人去奥地利旅游的场景。请注意，袋鼠只存在于奥地利的动物园里，而且奥地利 70%的地方都被山脉(阿尔卑斯山的一部分)覆盖。假设这个澳大利亚人事先没有任何信息(没有地图，没有对话，没有向导)，他开始爬山。换句话说，这些山脉代表了一个三维复杂的非凹函数。澳大利亚人将到达维也纳机场，但是由于奥地利今天的大雾天气，他没有看到太多。他的目标是爬上奥地利最高的山峰(3.799 米)，见*图 5.1* :

![Monte Carlo Methods for Optimization Problems](Images/B05113_05_01.jpg)

图 5.1:显示阿尔卑斯山浮雕的谷歌地图照片。最高的山峰——大格洛克纳山——的位置由一个红色标记显示出来

他有什么选择来找到最高点？

*   **第一个策略(无处可去的最陡梯度)**:澳大利亚小伙沿着最陡的方向，直到他燃烧了 50 卡路里(由他的卡路里计数手表测得)。在这之后，只要他再燃烧 50 卡路里，他就再次沿着当前点的最陡方向前进。使用这种策略，他将在 1.132 米高的一座名为*Hohe*Wand 的山上结束，甚至在下一个大约 200 米高的非常小的山上结束。当然，他的策略(最优化方法)不是很成功。他被困在当地的一个极大点上。大多数更简单的传统优化方法最终都会达到这个水平，大多数优化方法的工作方式都类似。在到达的每个点上，选择最陡路径的方向，并且行走的长度通常取决于该点的陡度。
*   **第二种策略(第一枪打得好但是死了)**:他等到雾消失。然后从机场，这座名为*施内贝格*的山是他所能看到的最高点。当然，他会爬上*峰* (2.076 米)，因为他相信他可以在那里达到他的目标(最高)。当他沿着通常的路线走时，他不会发现施内贝格山远不是奥地利最高的山。在山顶上，他筋疲力尽，不会四处张望，他会相信自己站在奥地利的最高峰。他用策略一到达了一个更高的水平，但是他被困在了一个当地的千里马，这仍然是一个不错的地方，但是离他到达奥地利最高峰的目标还很远。优化方法必须某种程度上是复杂的(良好的视觉)，通过选择一个路径/步骤(在数字和函数的现实中通常是不可能的)来达到 *Schneeberg* 的顶点。通常，仅采用一个路径/步骤是不可能找到局部最优的。然而，一个算法可能跳出局部最优，正如我们接下来将看到的。
*   第三个策略(钢铁侠向导):澳大利亚人可能很强壮，不会因为爬*山*或任何山而筋疲力尽。在 *Schneeberg* 的山顶上，他会看到一座名为*groer Priel*的山(2.515 米)更高，但在这座山的山顶上，他会意识到大约 70 公里外还有一座更高的山峰，名为 *Dachstein* (2.995 米)。在达赫斯坦，他确信他已经达到了他的目标，因为地球的曲率，他看不到更高的点，因为一些几乎一样高的山挡住了泰洛更高的山的视线。就语言而言，他几乎成功地达到了他的目标:他到达了最高的山峰，不是奥地利的，而是上奥地利联邦区的。他再次陷入局部极大值。优化方法已经非常复杂，因为它几次跳出局部最大值。大部分的优化方法都不会跳出这样的局部极大值，也不可能一步达到一个局部极大值。更现实的选择是:沿着最陡的体面路径到达一个最大值，这个局部最大值可以通过查看一个人为了以另一种方式向上爬而必须向下爬的最小高度来拒绝(参见拓扑分水岭算法，Bertrand，2005)。
*   第四个策略(星际迷航):他在地图上取一个网格，比如 1000 个点，并假设他是一个经验丰富的登山者，能够徒步到达这些点。这不太可能，但使用这种方法有可能在*达赫斯坦*达到更高的顶峰。无论如何，根据这个策略，他将花费几个月的时间去攀登，尽管他需要几乎半年的时间去到达所有的点，以证明哪一个点是最高的。这种优化方法只有在选择了非常多的点(精细网格)时才有效，如果通过攀爬无法到达，传送是可能的，因为否则要花太长时间才能在提到的 1000 个点中找到最高点。
*   **第五种策略(太空球)**:类似的策略是随机选择 1000 个点。到达最高点的概率等于前面的策略。然而，如果他明年也回来完成这个任务，如果他再次选择 1000 点，他很可能会达到比只使用策略四更高的顶点。如果新画的点以第一个点中最高的点为条件，这甚至更有效(*太空球公主*)。
*   **第六个策略(转瓶子)**:我们在奥地利的澳大利亚人认为最好拿一个瓶子，在他到达的每个点玩转瓶子游戏。所以他旋转瓶子直到它停下来，然后选择这个随机选择的方向，条件是这个随机选择的方向在高度上向上。让我们假设，起初他有完全的权力，所以他可以在这个方向上走更长的路。每次转瓶子游戏后，路径变得更短，因为他累了。很可能采用这种策略，他将到达机场南部附近的山 *Sonnenberg* (484 米)，但也有可能他将到达*卡伦贝尔* (447 米)或可能到达东南部的*Rax*(2.007 米)。
*   **第七个策略(喝醉的幸运水手)**:他会寻找从维也纳机场出发的最佳方向和当地步行的一定长度，但他是疯狂的，在一定程度上随机选择最佳方向，并且他还将最佳的长度乘以机场服务员提供的半升啤酒容量的两倍。他会在完成的每一步(到达的地方)重复这个方法。角度的选择也可能取决于其他因素，例如他已经喝了多少啤酒以及啤酒在哪里供应。这种策略很可能更耗时，但如果啤酒量选择得当，他可能不会陷入局部极大值。这当然具有挑战性。他可能不会到达奥地利的最高峰*大格洛克纳山* (3.798 米)，但如果参数选择得当，他可能有(最小的)机会。

我们也许能够继续报道许多其他可能的场景，但是由于这不仅仅是一本关于优化的书，我们将在这里停下来，并询问所提到的场景是否有任何相似之处。还应该提到的是，澳大利亚人要解决的优化问题太复杂了，因为奥地利的山脉远不是凹形的。注意，对于凹或凸问题，解是平凡的。请注意，澳大利亚人的问题是在三维曲面上找到一个最优解。在统计学中，更高维度的问题也经常出现。

如果我们仔细看看上面的场景，我们可以将场景 1-4 归为确定性规则(传统优化方法)的主题。每个场景都从维也纳机场开始，到达相同的顶点。情景 5 至情景 7 在这方面有所不同。假设路径的角度和长度是不固定的，这高度依赖于服务员的命运，我们可以将这两种情况归为随机随机规则的主题(也称为随机(蒙特卡洛)优化)。

在我们讨论随机方法之前，我们将简要地触及经典方法。

# 数值优化

目标是找到函数 *f(x)* 或隐式方程 *g(x) = 0* 的极值(例如，最大值或最小值)。因此，重点是优化问题*最大 h(x)* 。换句话说，我们搜索一个值![Numerical optimization](Images/B05113_05_11.jpg)，它包含:

*   ![Numerical optimization](Images/B05113_05_10.jpg)(全局最小值)
*   ![Numerical optimization](Images/B05113_05_12.jpg)(全局极大值)

如前所述，基本上有两种方法可以解决复杂的优化问题:

*   纯确定性方法
*   随机方法

在本章中，确定性意味着遵循严格的规则来达到最大值，而不包括任何随机性。虽然问题的数值确定性解决方案取决于目标函数`h`的分析属性(例如，凸性和平滑性)，但随机方法具有更广泛的用途。

对于下面的例子，我们使用下面的函数，然后我们想找到它的最小值。我们改进的 2D·罗森布罗克函数(`mountains`)的最佳值应该在`(1,1)`:

```
mountains <- function(v) { 
 (1 - v[1])^2 + 100 * (v[2] - v[1]*v[1])^2 +
 0.3*(0.2 - 2*v[2])^2 + 100 * (v[1] - v[2]*v[2])^2 -
 0.5*(v[1]^2 +5*v[2]^2)
}

```

等高线图将两个变量的函数的等高线(也称为等值线或等厚线)显示为曲线，其中该线/曲线上的点具有恒定值。从我们的`mountains`得到的等高线图如图 5.2 中的*所示(牛顿-拉夫森法的解已经可视化)。*

## 梯度上升/下降

梯度下降法是无约束非线性函数优化的一阶导数优化方法。对于函数最大化我们讲上升法，对于最小化，我们称之为下降法。我们展示这种方法是出于教学上的原因，之后会继续展示更有力的方法。

最速下降搜索是在梯度线方向上的延伸。在每一步中，基本上完成了最佳步骤，也称为最速步骤。

目标是找到一个函数的最大值/最小值。对于初始化，必须选择一个起始点。对于这个点以及随后到达的任何点，计算函数的导数。在距离当前点(步长参数)的函数导数的梯度方向上选择下一个(新的)点。

我们没有展示这个方法的实现，因为它在应用到函数`mountains`时完全失败，但是我们参考了在 R 包动画中实现的更简单的例子。此处显示了一个非常简单的成功示例:

```
library("animation")
grad.desc()

```

通过执行以下代码，可以看到这个简单方法已经失败的函数:

```
ani.options(nmax = 70)
par(mar = c(4, 4, 2, 0.1))
f2 = function(x, y) sin(1/2 * x^2 - 1/4 * y^2 + 3) * cos(2 * x + 1 -
 exp(y))
grad.desc(f2, c(-2, -2, 2, 2), c(-1, 0.5), gamma = 0.3, tol = 1
e-04)

```

## 牛顿-拉夫森方法

牛顿-拉夫森方法是最著名的确定性优化方法。在每个点，一阶导数决定了跟随到下一个点的线，二阶导数用于选择线的方向。更准确地说，牛顿-拉夫森方法基于递归:

![Newton-Raphson methods](Images/B05113_05_13.jpg)

其中一阶导数的矩阵称为梯度，二阶导数的矩阵称为 Hessian 矩阵。这种方法强烈依赖于初始值。

在 R 中，牛顿型算法在函数`nlm`中实现。第一个函数参数是要最小化的函数。在下面的例子中，我们插入我们的函数`mountains` ，存储前 10 个步骤的每个解决方案，并在*图 5.2* 中可视化它们。我们开始有点糟糕，这样我们可以看到这个算法如何陷入局部最小值:

```
n <- 300
## to define a grid
x <- seq(-1, 2, length.out = n)
y <- seq(-1, 2, length.out = n)
## evaluate on each grid point
z <- mountains(expand.grid(x, y))
## contour plot
par(mar = c(4,4,0.5,0.5))
contour(x, y,  matrix(log10(z), length(x)), 
 xlab = "x", ylab = "y", nlevels = 20)
## Warning in matrix(log10(z), length(x)): NaNs produced
## starting value
sta <- c(0.5,-1)
points(sta[1], sta[2], cex = 2, pch = 20)
## solutions for each of 20 steps
sol <- matrix(, ncol=2, nrow = 21)
sol[1, ] <- sta
for(i in 2:20){
 sol[i, ] <- nlm(mountains, sta, iterlim = i)$est
}
## optimal solution
sol[21, ] <- nlm(mountains, sta)$est
points(sol[21, 1], sol[21, 2], cex = 3, col = "red", pch = 20)
## path visually
lines(sol, pch=3, type="o")
## now let's start better (dashed line)
sta <- c(0,-1)
for(i in 2:20){
 sol[i, ] <- nlm(mountains, sta, iterlim = i)$est
}
sol[1, ] <- sta
sol[21, ] <- nlm(mountains, sta)$est
points(sta[1], sta[2], cex = 2, pch = 20)
points(sol[21, 1], sol[21, 2], cex = 3, col = "red", pch = 20)
lines(sol, pch=3, type="o")

```

![Newton-Raphson methods](Images/B05113_05_02.jpg)

图 5.2:我们两座山的等高线图(定义了修正的 Rosenbrock 函数)。最大值在(1，1)。示出了具有不同初始值的两个解(红色填充的圆)，而牛顿-拉夫逊解的每一步由十字和路径(线)指示。起始值用黑色圆圈表示。

我们可以看到对于这个二维例子，如果选择的起点不是太差，牛顿-拉夫森梯度法工作得很好。

如前所述，牛顿-拉夫森方法是确定性的，也就是说，它总是以相同的解达到相同的初始初始值。

如果函数是凸/凹的，可以很快很容易地找到全局最优解。然而，如果要优化的函数不是凸/凹的，并且存在几个局部最优解，则牛顿-拉夫森方法可能只找到一个局部最优解。

## 进一步的通用优化方法

R 中解决通用优化问题的标准函数是`optim`。实现了几种方法:

*   内尔德-米德方法(内尔德和米德 1965 年):这是默认方法，相对较慢。对于不可微的函数来说，它会工作得相当好。
*   BFGS 方法:这是一种类似牛顿的方法，特别是在海森方法不可用或者每次迭代都太贵而无法计算的情况下。与 Nelder 和 Mead 1965 的方法一样，它对错误的步长相对稳健。
*   **CG 方法(Fletcher 和 Reeves 1964)** :这是一种共轭梯度法，通常比 BFGS 方法更脆弱，但计算效率更高，因此用于更大的问题。
*   **“L-BFGS-B”法(Byrd，Nocedal，和 Zhu 1995)** :这允许框约束每个变量。当然，初始值必须满足这些约束。
*   SANN 方法(Belisle 1995) :使用模拟退火方法实现。它使用一个 Metropolis 函数来表示接受概率。这不是一种通用的方法，而且相对较慢，但在非常粗糙的表面上获得良好的解决方案时，它会非常有用。

我们将把这些方法应用到我们的函数`mountains`中。注意，我们需要一个`for`循环来保存每步后的解决方案，以观察算法如何处理这个问题。从*图 5.3* 我们看到，如果达到局部或全局最大值，它高度依赖于初始值。注意，对于所有的方法，在 *(1，1)* 处的全局最优是近似达到的，而不是精确达到的，但是越来越接近 *(1，1)* 是计算时间的问题:

```
## wrapper for all methods of optim
optims <- function(x, meth = "Nelder-Mead", start = c(0.5, -1)){
 sol <- matrix(, ncol = 2, nrow = 21)
 sol[1, ] <- start
 for(i in 2:20){
 sol[i, ] <- optim(start, mountains, method = meth,
 control = list(maxit=i))$par
 }
 sol[21,] <- optim(start, mountains)$par
 points(start[1], start[2], pch=20, cex = 2)
 points(sol[21, ], sol[21, ], pch = 20, col = "red", cex = 3)
 lines(sol[, 1], sol[, 2], type = "o", pch = 3)
}
## plot lines for all methods
par(mar=c(4,4,0.5,0.5))
contour(x, y,  matrix(log10(z), length(x)), xlab = "x", ylab = "y", nlevels = 20)
optims()  # Nelder-Mead
optims("BFGS")
optims("CG")
optims("L-BFGS-B")
optims("SANN")
optims("Brent")
optims(start = c(1.5,0.5))

```

![Further general-purpose optimization methods](Images/B05113_05_03.jpg)

图 5.3:我们两座山的等高线图(定义了修正的 Rosenbrock 函数)。最大值在(1，1)。对于在(0.5，-1)处的起点，由函数 optim 支持的所有方法收敛到局部最小值，而在(1.5，0.5)处的起点，它们甚至在相同的路径上都达到全局最优。解的每一步都由从起点(黑色实心圆)到最终解(红色实心圆)的线表示

需要注意的是，其他函数和包也是有用的，比如 R 包`nloptr` (Johnson 2014)和`optimx` (Nach 和 Varadhan 2005)。最后，应该提到的是，R 包`ROI` (Hornik，Meyer 和 Theussl 2013)为许多解算器提供了一个接口/包装器。它由一个优化基础设施组成，这是一个复杂的框架，用于处理 r。



# 处理随机优化

与确定性优化不同的是，通过使用随机优化，可以找到具有相同初始值的不同解。这也应该允许我们不(总是)陷入局部最优。

## 简化程序(星际迷航、太空球和太空球公主)

正如本章介绍中提到的，在原理中，一个(精细的)网格，应该覆盖 *f* 的整体分布，可以对每个网格点(*星际迷航*)进行使用和评估。那些具有最大值/最小值的网格坐标提供了优化问题的近似解。其他问题的基于网格的确定性解决方案有，例如，用于异常值检测的斯塔赫尔-多诺霍估计器(斯塔赫尔 1981 年 a)(斯塔赫尔 1981 年 b)或使用基于网格的投影寻踪方法对数据集的主要成分进行基于光栅的搜索(克罗克、菲尔茨莫瑟和奥利维拉 2007 年)。

为了从这种确定性方法转移到一种包含随机性的方法，人们可以只对整个分布的点进行采样 *f(空间球*)。如果选择一个点的概率在整个空间上是相等的，找到一个解的概率，比如说 *A* ，等于确定性方法。

这种方法对于低维问题可以产生好的结果，但是对于高维问题，它在计算上太慢而不能找到好的解决方案。自然地，这种方法可以通过顺序绘制点来修改，例如，通过绘制一组点开始，并根据第一组点的值来绘制下一组点。对于二维问题中的最大化，这意味着在更高的点周围选择更多的数据点(用于点的后续绘制)。这个我们就不考虑了，只选择一组点，标最高的。对于这些点中的每一个点，f 被评估，并且最大值是近似的极值。如果 *f* 是紧的，我们可以，例如，从一个均匀分布中得出 *m* 的观测模拟:

![Simplified procedures (Star Trek, Spaceballs, and Spaceballs princess)](Images/B05113_05_14.jpg)

是下式的近似解:

![Simplified procedures (Star Trek, Spaceballs, and Spaceballs princess)](Images/B05113_05_15.jpg)

红色的最大值(见下图，*图 5.4* ，发现的评估值为

*m = 1.500* 从二元均匀分布的`-2`和`5`之间得出:

```
## define grid
n <- 1500
set.seed(1234567)
x1 <- runif(n, min = -2, max = 5)
y1 <- runif(n, min = -2, max = 5)
z1 <- matrix(, ncol = n, nrow = n)
## evaluate on each grid point
for(i in 1:n){
 for(j in 1:n){
 z1[i,j] <- mountains(c(x1[i], y1[j]))
 }
}
## determine optima
w <- which(z1 == min(z1), arr.ind=TRUE)
## plot results
par(mar=c(4,4,0.5,0.5))
contour(x, y,  matrix(log10(z), length(x)), xlab = "x", ylab = "y", nlevels = 20)
## Warning in matrix(log10(z), length(x)): NaNs produced
points(x1[w[1]], y1[w[2]], pch = 20, col = "red", cex = 3)
points(x1, y1, pch=3)

```

![Simplified procedures (Star Trek, Spaceballs, and Spaceballs princess)](Images/B05113_05_04.jpg)

图 5.4:显示空间球解的两座山的等高线图(定义了修正的 Rosenbrock 函数)

当然，这种方法过于简单，但是记住我们已经提到过对*太空球*的改进。让我们考虑一下*太空球公主*的方法，也就是说，让我们迭代得到更好的解决方案。想法是这样的:

1.  随机采样点，计算函数值，并选择具有最高值的点。
2.  *重复*，在找到的最适合的点，从正态分布中抽取数值，再次选择最适合的点。

这在包`RCEIM` (Krone-Martins 2014)中实现，可用于多维函数优化。方法并没有对要优化的函数施加强条件，我们可以很容易地将其应用于我们的两座大山问题。同样，我们保存所有即时解决方案，并显示算法每一步的所有最合适点。*图 5.5* 中的曲线显示了从浅灰色(早期阶段)到黑色(第 20 步中最合适的点)的点。我们还在中为每一步的最佳解决方案标上红叉。所有这些都位于最佳位置附近。最终的解决方案是由一个红色的大圆圈标记的:

```
library("RCEIM")
set.seed(123)
sol <- best <- list()
## save solution for each step
for(i in 2:20){
 a <- ceimOpt(mountains, nParam = 2, maxIter = i)
 sol[[i]] <- a$EliteMembers
 best[[i]] <- a$BestMember
}
## plot the results for each step
par(mar=c(4,4,0.5,0.5))
contour(x, y,  matrix(log10(z), length(x)), xlab = "x", ylab = "y", nlevels = 20)
## Warning in matrix(log10(z), length(x)): NaNs produced
greys <- grey(rev(2:20 / 20 - 0.099))
for(i in 2:20){
 points(sol[[i]][,1], sol[[i]][,2], col = greys[i])
 points(best[[i]][1], best[[i]][2], col = "red", pch = 3)
}
points(best[[i]][1], best[[i]][2], col = "red", pch = 20, cex = 3)

```

![Simplified procedures (Star Trek, Spaceballs, and Spaceballs princess)](Images/B05113_05_05.jpg)

图 5.5:我们两座山的等高线图(定义了修正的 Rosenbrock 函数)。示出了具有相等起始值的两个解，而随机游走 Metropolis-Hastings 解的每一步由实心圆(对于第一个解)或十字(对于第二个解)表示

很明显，这种简化的工序对于更高的 T2 尺寸来说是无效的。另一方面，有广泛的应用，特别是在如果目标函数非常复杂的情况下。

## 大都会-黑斯廷斯重游

一个简单的随机搜索算法，一个随机的蒙特卡罗 Metropolis-Hastings 算法，然后可以被用来产生一个序列![Metropolis-Hastings revisited](Images/B05113_05_16.jpg)和 *f* 将被评估给定的参数![Metropolis-Hastings revisited](Images/B05113_05_17.jpg)和![Metropolis-Hastings revisited](Images/B05113_05_18.jpg)。如果的值对于![Metropolis-Hastings revisited](Images/B05113_05_18.jpg)更高我们进去接受，否则我们不动。![Metropolis-Hastings revisited](Images/B05113_05_19.jpg)可能选自方差变化的正态分布:序列越长，方差越低。

对于我们的二维示例(`mountains`)，一种随机游走 Metropolis-Hastings 算法可以被定义为序列![Metropolis-Hastings revisited](Images/B05113_05_23.jpg)的![Metropolis-Hastings revisited](Images/B05113_05_20.jpg)和![Metropolis-Hastings revisited](Images/B05113_05_21.jpg)，其中![Metropolis-Hastings revisited](Images/B05113_05_22.jpg)随着更大的 *t* 而减小。

以下代码实现了这种随机游走 Metropolis-Hastings 算法，用于二维优化问题:

```
## Simple random walk Metropolis Hastings:
rmh <- function(n = 20, start = c(0,-0.5), stepmult = 10){
 x <- matrix(, ncol = 2, nrow = n)
 x[1, ] <- start
 sol <- mountains(start)
 for(i in 2:n){
 x[i, ] <- x[i-1, ] + rmvnorm(1, mean = c(0, 0),
 sigma = stepmult * diag(2) / n)
 solnew <- mountains(x[i, ])
 # accept only a better solution:
 if(solnew > sol) x[i, ] <- x[i-1, ]
 if(solnew < sol) sol <- solnew
 }
 return(x)
}

```

让我们从同一个起点走两步:

```
library("mvtnorm")
set.seed(12345)
n <- 200
x1 <- rmh(n, start = c(1.5,0))
x2 <- rmh(n, start = c(1.5,0))

```

同样，算法的每一步的解都是可视化的。在*图 5.6* 中可以看出，一旦算法在同一起点陷入局部极小值，另一次该算法成功找到最优解:

```
par(mar=c(4,4,0.5,0.5))
contour(x, y,  matrix(log10(z), length(x)), xlab = "x", ylab = "y", nlevels = 20)
## Warning in matrix(log10(z), length(x)): NaNs produced
points(x1[1, 1], x1[1, 2], pch = 4, cex = 3)
points(x2[n, 1], x2[n, 2], pch = 20, col = "red", cex = 3)
points(x1[n, 1], x1[n, 2], pch = 20, col = "red", cex = 3)
lines(x1[, 1], x1[, 2], type = "o", pch = 3)
lines(x2[, 1], x2[, 2], type = "o", col = "blue", lty = 2)

```

![Metropolis-Hastings revisited](Images/B05113_05_06.jpg)

图 5.6:我们两座山的等高线图(定义了修正的 Rosenbrock 函数)。示出了具有相等起始值的两个解，而随机游走 Metropolis-Hastings 解的每一步由实心圆(对于第一个解)或十字(对于第二个解)表示

## 基于梯度的随机优化

还记得本章介绍中描述的*醉酒水手*的场景吗？我们注意到梯度算法的方向和步长可以使用一种随机化来修改。

基于牛顿-拉夫逊法，基本上是一个![Gradient-based stochastic optimization](Images/B05113_05_24.jpg)的序列，对于随机梯度法，画出一个在单位圆上均匀分布的随机误差![Gradient-based stochastic optimization](Images/B05113_05_25.jpg)。

前一公式中的梯度关于中心差商![Gradient-based stochastic optimization](Images/B05113_05_26.jpg)用正实数的![Gradient-based stochastic optimization](Images/B05113_05_27.jpg)序列来修改。差商是局部导数的近似值。

新的值![Gradient-based stochastic optimization](Images/B05113_05_18.jpg)、![Gradient-based stochastic optimization](Images/B05113_05_28.jpg)并不完全在![Gradient-based stochastic optimization](Images/B05113_05_29.jpg)中最陡上升的方向，因为每次都有一些随机的方向依赖于![Gradient-based stochastic optimization](Images/B05113_05_30.jpg)和![Gradient-based stochastic optimization](Images/B05113_05_31.jpg)的大小被选中。在![Gradient-based stochastic optimization](Images/B05113_05_32.jpg)较大的情况下，此处优先考虑这些方向。

要实现趋同，必须注意以下几点(无需证明):

*   确定性序列![Gradient-based stochastic optimization](Images/B05113_05_33.jpg)包括正的单调递增的数
*   确定性序列(![Gradient-based stochastic optimization](Images/B05113_05_31.jpg))包括正的单调递增数
*   ![Gradient-based stochastic optimization](Images/B05113_05_34.jpg)应该分歧
*   ![Gradient-based stochastic optimization](Images/B05113_05_35.jpg)应该收敛

通过随机选择方向，可以(有时)避免陷入和停留在局部最优。方向越大越好。该算法的性能很大程度上取决于对![Gradient-based stochastic optimization](Images/B05113_05_38.jpg)和![Gradient-based stochastic optimization](Images/B05113_05_39.jpg)的选择，而选择这两个参数实际上是一项非常困难、几乎无法解决的任务。

下面的代码实现了前面描述的随机梯度方法。起始值以及![Gradient-based stochastic optimization](Images/B05113_05_36.jpg)和![Gradient-based stochastic optimization](Images/B05113_05_37.jpg)序列的参数作为功能参数包括在内:

```
stoGrad <- function(start = c(0, -0.5), j = 1500, p = 0.1){
 theta <- matrix(start, ncol=2)
 diff <- iter <- 1
 alpha <- sapply(1:100, function(x) 1 / (j+1) )
 beta  <- sapply(1:100, function(x) 1 / (j+1)^(p) )

 while( diff > 10^-5 & !is.nan(diff) & !is.na(diff) ){
 zeta <- rnorm(2)
 zeta <- zeta / sqrt(t(zeta) %*% zeta)
 grad <- alpha[iter] * zeta * (mountains(theta[iter, ] + beta[iter] * zeta) -
 mountains(theta[iter, ] - beta[iter] * zeta)) / beta[iter]
 theta <- rbind(theta, theta[iter, ] - grad)
 diff <- sqrt(t(grad) %*% grad )
 iter <- iter + 1
 } 
 list(theta = theta[1:(iter-1), ], diff = diff, iter = iter-1)
}

```

下面的图(*图 5.7* )显示了随机梯度法的解。即使是一个简单的二维例子，也需要一些时间来为![Gradient-based stochastic optimization](Images/B05113_05_37.jpg)和![Gradient-based stochastic optimization](Images/B05113_05_36.jpg)的序列找到一个好的选择，以实现收敛并找到一个好的解决方案:

```
set.seed(123)
s1 <- stoGrad()
par(mar=c(4,4,0.5,0.5))
contour(x, y,  matrix(log10(z), length(x)), xlab = "x", ylab = "y", nlevels = 20)
## Warning in matrix(log10(z), length(x)): NaNs produced
plotLine <- function(x, ...){
 lines(x$theta[,1], x$theta[,2], type = "o", ...)
 points(x$theta[x$iter, 1], x$theta[x$iter, 1], pch = 20, col = "red", cex = 3)
}
plotLine(s1, pch = 3)
points(0, -0.5, pch = 20, cex = 1.5)
plotLine(stoGrad(), col = "blue", pch = 4)
plotLine(stoGrad(start = c(1.5, 0)), pch = 3, lty = 2)
plotLine(stoGrad(start = c(1.5, 0)), col = "blue", pch = 4, lty = 2)
points(1.5, 0, pch = 20, cex = 1.5)

```

![Gradient-based stochastic optimization](Images/B05113_05_07.jpg)

图 5.7。:我们两座山的等高线图(定义的修正 Rosenbrock 函数)。显示了四个解，其中两个具有相同的初始值，而解的每一步都是可视化的。起点用黑色实心圆表示，最终解决方案用红色实心圆表示

实现的随机梯度方法对参数`j`和`p`敏感。我们可以看到，将参数`p`修改为更高的值会导致更好的结果(参见*图 5.8)* :

```
set.seed(123)
s1 <- stoGrad(p = 2.5)
par(mar=c(4,4,0.5,0.5))
contour(x, y,  matrix(log10(z), length(x)), xlab = "x", ylab = "y", nlevels = 20)
## Warning in matrix(log10(z), length(x)): NaNs produced
plotLine <- function(x, ...){
 lines(x$theta[,1], x$theta[,2], type = "o", ...)
 points(x$theta[x$iter, 1], x$theta[x$iter, 1], pch = 20, col = "red", cex = 3)
}
plotLine(s1, pch = 3)
points(0, -0.5, pch = 20, cex = 1.5)
plotLine(stoGrad(p = 2.5), col = "blue", pch = 4)
plotLine(stoGrad(start = c(1.5, 0), j=1500, p=2.5), pch = 3, lty = 2)
plotLine(stoGrad(start
 = c(1.5, 0), j=1500, p=2.5), col = "blue", pch = 4, lty = 2)
points(1.5, 0, pch = 20, cex = 1.5)

```

![Gradient-based stochastic optimization](Images/B05113_05_08.jpg)

图 5.8:我们的两座山的等高线图(定义的修正 Rosenbrock 函数)。显示了四个解决方案，其中两个具有相同的起始值，而解决方案的每个步骤都是可视化的。起点用黑色实心圆表示，最终解决方案用红色实心圆表示

软件包`nloptr` (Johnson 2014)具有改进的随机排序进化策略，用于实现非线性约束全局优化(Runarsson 和 Yao 2005):

```
library("nloptr")
set.seed(123)
## mountains function with modified function parameters
mountains1 <-
function(x) ((1 - x[1])^2 + 100 * (x[2] - x[1]*x[1])^2 +
 0.3*(0.2 - 2*x[2])^2 + 100 * (x[1] - x[2]*x[2])^2 -
 0.5*(x[1]^2 +5*x[2]^2))
x0 <- c(0.5, -1)
lb <- c(-3, -3)
ub <- c(3, 3)
sol <- matrix(, ncol=2,nrow=21)
## solution on each step
for(i in 1:20){
 sol[i, ] <- isres(x0 = x0, fn = mountains1, lower = lb, upper = ub, maxeval = i)$par
}
par(mar=c(4,4,0.5,0.5))
contour(x, y,  matrix(log10(z), length(x)), xlab = "x", ylab = "y", nlevels = 20)
## start
points(sol[1, 1], sol[1, 2], pch = 20, cex = 2)
## optima found
sol[21,] <- isres(x0 = x0, fn = mountains1, lower = lb, upper = ub)$par
points(sol[21, 1], sol[21, 2], pch = 20, col = "red", cex = 3)
## way to optima
lines(sol[,1], sol[,2], type = "o", pch = 3)

```

![Gradient-based stochastic optimization](Images/B05113_05_09.jpg)

图 5.9:我们两座山的等高线图(定义了修正的 Rosenbrock 函数)。通过 ISRES 实现的解决方案的每一步都是可视化的。起点用黑色实心圆表示，最终解决方案用红色实心圆表示



# 总结

记住本书中介绍的所有方法，人们应该能够为任何给定的问题找到最佳的优化器。在选择优化器时，问题的维度和复杂性以及要优化的函数的形状都会发挥作用。

本章介绍了数值优化方法，但特别关注解决优化问题的随机方法。传统数值优化方法的优点通常是计算效率高并且更快地达到最优。R 中的`optim`函数实现了许多这样的方法，并且`optimx`和`ROI`包是许多优化器的包装器。

然而，只要要优化的函数不是凸的或凹的，由通用数值优化方法找到的最优值就一定不等于全局最优值。随机梯度方法(我们的*醉酒水手*)可能会避免陷入局部极值，但在任何情况下重新运行它们时都会找到不同的路径，即使是在相同的起点开始。随机梯度方法依赖于各种参数，并且随机梯度方法的主要缺点是试图找到一组好的参数。只有选择好一组参数，随机梯度方法才能找到好的解，否则只能选择局部极值作为最优解。

即使是非常简单的方法，如我们的 *Spaceballs 方法，但特别是我们的 Spaceball princess 方法*通常可以避免陷入局部极值，但在高维问题中获得好的解决方案的成本可能是巨大的。然而，如果要优化的函数有许多局部极值，这种方法通常是获得良好解决方案的唯一可能性——想想我们的澳大利亚人在雾天想要找到奥地利最高的山峰时不得不面对的问题。*太空球公主*及其在 RCEIM 包中的实现将很可能找到*格罗斯洛克纳*的顶点，而其他解算器将很可能陷入局部极值。

我们还发现 Metropolis-Hastings 方法易于实现，并且对于我们的两座山问题，我们在短时间内获得了良好的结果。



# 参考文献

*   贝利索，1995 年最高法院判例汇编。“Rd 上一类模拟退火算法的收敛定理”， *J .应用概率*29:885–95
*   伯特兰，G. 2005。“论拓扑流域”，*数学成像与视觉杂志*22(2-3):217–30
*   Byrd，R.H .，J. Nocedal 和 C. Zhu。1995.“用于边界约束优化的有限内存算法”， *SIAM J .科学计算*16:1190–1208
*   Croux，c .，P. Filzmoser 和 M. Oliveira。2007.“投影寻踪稳健主成分分析算法”，*化学计量学和智能实验室系统*87:218–25
*   弗莱彻和 C.M .里维斯。1964.“通过共轭梯度实现函数最小化”，*计算机杂志*7:148–54
*   Hornik，k .，D. Meyer 和 S. Theussl。2013. *ROI: R 优化基础设施*，【https://CRAN.R-project.org/package=ROI 
*   约翰逊，2014 年。*改进的随机排序进化策略*，【https://CRAN.R-project.org/package=nloptr】T2
*   克朗马丁斯，2014 年。 *RCEIM: RCEIM - R 交叉熵启发优化方法*，【https://CRAN.R-project.org/package=RCEIM】T2
*   Nach，J.C .和 R. Varadhan。2005.“帮助软件系统用户的统一优化算法:Optimx”，*统计软件杂志* 43 (9)。IEEE:1–14
*   内尔德 J.A .和 r .米德。1965.“函数最小化的单纯形法”，*《计算机杂志》* 7 (4)。*牛津大学出版社*:308–13 页
*   鲁纳松，T.P .和 x .姚。2005.“约束进化优化中的搜索偏差”，*系统，人和控制论，C 部分:应用和评论，IEEE 汇刊*35(2)。IEEE:233–43
*   斯塔赫尔，西澳大利亚 1981 年 a。*协方差估计量的分解。研究报告* 31。*研究报告* 31
*   1981b . "可靠的估计数。协方差矩阵的无穷小最优和估计，“*PhD 论文，瑞士联邦理工学院* (ETH)