

# 增强数据库

在本章中，我们将解释什么是统计增强，它是如何工作的，并介绍使用统计增强来更好地理解数据库中的数据的概念。

为清晰起见，我们再次将本章中的主题分为以下几个重要方面:

*   统计增强的定义和目的
*   你能从提升(帮助)数据库中学到什么
*   用 R 来说明升压方法



# 定义和目的

首先，我们可以考虑一个你可能在网上找到的常见定义:

Boosting 是一种机器学习集成元算法，主要用于减少监督学习中的偏差和差异，是一个将弱学习者转化为强学习者的机器学习算法家族。
-维基百科
[https://en . Wikipedia . org/wiki/Boosting _(机器学习)](https://en.wikipedia.org/wiki/Boosting_(machine_learning))

提醒:在统计学中，集成方法使用多种学习算法来获得比任何基础或基本学习算法更好的预测性能(尽管结果因数据和数据模型而异)。

在我们进入统计增强背后的细节之前，我们必须花一些时间来理解偏差、方差、噪声，以及弱学习者和强学习者的含义。

以下部分将涵盖这些术语和相关概念。



# 偏见

让我们从讨论统计偏差开始。

如果一个统计量的计算方式与被估计的总体参数在分析上不相似，那么这个统计量就是有偏的。

我所遇到的对偏差的最好解释之一是偏离零点一点点的标度的概念。在这种情况下，规模将给出稍微高估的结果。换句话说，当有人站在体重秤上时，总重量可能会过高或过低(这可能会让那个人得出结论，他们正在进行的饮食比实际情况要好)。

在统计学中，数据科学家需要认识到，实际上有几个类别通常用于定义统计偏差。下一节列出了这些偏见的类别和例子。

分类偏见是有点主观的，因为一些类别似乎会重叠。



# 分类偏差

偏见有许多种类，包括以下具体例子:

*   选择偏差(Selection bias):这是指个体观察结果比其他观察结果更有可能被选中进行研究。
*   **光谱偏差**:当数据科学家评估有偏差样本的结果时，会出现这种情况，导致测试的灵敏度和特异性被高估。
*   **估计偏差**:这是估计者的期望值和被估计参数的真实值之间的差异。
*   **遗漏变量偏差**:当假设的规格忽略了一个独立变量时，在回归分析中估计参数时会出现这种偏差。
*   **检测偏差**:当某个人物或事件更有可能被一组特定的研究对象观察到时，就会出现这种情况。
*   **采样偏差**:这种偏差发生在由于采样数据中的错误而产生统计误差的时候。
*   **测量偏差**:当检测内容、检测管理和/或评分程序存在系统性问题时，就会出现这种情况。
*   **资助偏差**:这种类型的偏差会导致特定结果、观察结果、测试样本或测试程序的选择有利于研究的资助者。
*   **报告偏差**:这种类型的偏差涉及数据可用性方面的偏差，这导致某种类型或集合的观察结果更有可能被报告或影响性能。
*   **分析偏差**:这是基于用于评估某些观察结果或统计模型整体性能的方法或过程而产生的。
*   **排除偏倚**:这类偏倚可能是基于某个过程或程序而产生的，该过程或程序有可能从统计研究中系统地排除某些样本或观察结果。
*   **流失偏差**:当研究或统计项目的参与者离开项目或过程时。换句话说，一个项目的一个组或类别可能会离开或被删除，并且不再被数据科学家考虑。
*   **回忆偏差**:由于对过去事件或正在研究的特征的错误回忆，研究参与者的准确性或完整性不一致。这导致对结果的高估或低估。
*   **观察者偏差**:这种偏差发生在研究人员由于认知偏差而下意识地影响数据时，在这种情况下，判断可能会改变观察或研究如何进行/结果如何记录。
*   **混杂偏倚**:当研究中影响相同信息的因素对研究人员或数据科学家产生误导或混淆时，就会出现这种类型的偏倚。
*   **负面偏见**:当数据科学家倾向于给予负面特征、事件或结果更多的权重或价值时，就会出现这种情况，仅仅因为它们是负面的。
*   **代表性偏差**:当数据科学家基于在一个群体或某些观察中确定的某些观察到的特征而想当然地认为某些事情时，就会出现这种情况。
*   **最近偏差**:当数据科学家最近的经验和观察被用于(或被赋予更多价值)预测未来结果时，这种偏差就会出现。

我最喜欢的类型之一是:

*   **数据窥探偏见**:当数据科学家形成一个不正确的观点或做出一个假设，然后继续挖掘特别是为了捍卫那个观点的数据时，就会发生这种情况。



# 偏见的原因

*偏见*是一个你会发现在统计学领域经常使用的术语，几乎总是，偏见等同于(或伴随着)一个负面或不好的事件。事实上，即使在统计学领域之外，偏见几乎总是会导致麻烦或某种形式的痛苦。

认为偏见是偏袒。例如，数据收集过程中存在的偏袒通常会导致误导性的结果或不正确的假设。

偏差可能以各种方式出现，作为一名数据科学家，必须熟悉这些情况。实际上，偏差可以在任何时候或任何阶段引入统计项目。

引入偏差的最常见时间之一是在一个项目刚开始或开始收集或选择数据时。这是最糟糕的，因为几乎所有的努力和工作完成后都会被怀疑，或者很可能是不正确的。



# 偏倚数据收集

偏见的一个主要来源是数据收集的方式。坦率地说，缺乏经验或希望获得某种结果的研究人员可能会使用低劣的数据收集方法或做法，或者实际上以暴露特定重点或导致预期或期望结果的方式收集数据。

数据收集方法中需要注意的一些事项:

*   带有特定倾向或重点的调查
*   选择具有特定背景的已知群体来回答调查
*   误导性分类组中的数据报告
*   非随机性样本选择
*   系统测量误差



# 偏倚样本选择

样本选择或取样的过程也容易引入偏差。当样本不能准确代表总体时，就会出现样本偏差。非代表性样本产生的偏差称为**选择偏差**。

可能导致统计样本出现偏差的问题包括:

*   取样的时间
*   样本的长度或大小
*   问题的难度
*   (人口)覆盖不足
*   样本中不正确使用的无响应
*   样本中错误使用的自愿回答
*   联系样本中受试者的方式(电话、邮件、上门等)，或观察数据的分割方式

偏见说够了。让我们继续下一节，我们将讨论统计方差。



# 差异

在统计理论([https://en.wikipedia.org/wiki/Statistics](https://en.wikipedia.org/wiki/Statistics))中，方差的概念定义如下:

随机变量与其均值的平方偏差的期望值([https://en.wikipedia.org/wiki/Expected_value](https://en.wikipedia.org/wiki/Expected_value))，或者换句话说，它是一组随机数与其平均值相差多远的度量。

方差分析(或简称为方差分析)的实践包括数据科学家评估两个数字之间的差异。通常，此流程会应用财务或运营数据来尝试识别和确定差异的原因。在应用统计学中，有不同形式的方差分析。

方差和方差分析是统计学领域和研究中的一个大课题，它在以下统计实践中起着关键作用:

*   描述性统计([https://en.wikipedia.org/wiki/Descriptive_statistics](https://en.wikipedia.org/wiki/Descriptive_statistics))
*   拟合优度([https://en.wikipedia.org/wiki/Goodness_of_fit](https://en.wikipedia.org/wiki/Goodness_of_fit))
*   假设检验([https://en . Wikipedia . org/wiki/Statistical _ hypothesis _ testing](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing))
*   蒙特卡罗抽样([https://en.wikipedia.org/wiki/Monte_Carlo_method](https://en.wikipedia.org/wiki/Monte_Carlo_method))
*   统计推断([https://en.wikipedia.org/wiki/Statistical_inference](https://en.wikipedia.org/wiki/Statistical_inference))

你会发现下面的变化是真实的:

*   每当需要对数据进行统计分析时，数据科学家很可能会从方差分析开始
*   统计方差为数据科学家提供了一个测量标尺，来衡量数据如何分布(关于平均值或期望值)
*   与 range(仅查看极值)不同，variance 查看所有数据点并推断它们的分布



# 方差分析

作为一名数据科学家，当你谈到**方差**分析的过程或实践时，你指的是**方差分析。** ANOVA 可以理解为一种方法的分类，用于调查组均值之间已发现的或潜在的差异(方差)及其伴随程序。

方差分析在统计学领域以三种不同的方式被研究和使用。这些风格由数据科学家正在处理或感兴趣的独立变量的数量决定和定义:

*   单向 ANOVA(只处理一个自变量)
*   双向 ANOVA(使用或关注两个独立变量)
*   n 向 ANOVA(当数据科学家对两个以上的独立变量感兴趣时)

当数据科学家或研究人员进行方差分析时，他们正在努力得出结论，在他们的人群中，群体之间是否存在统计上的显著差异。如果他们发现有差异，他们将继续确定群体差异在哪里。



# 噪音

噪声，或者对数据科学家来说，统计噪声，是对样本、人群或数据源中无法解释的变异或可变性的公认数量的流行表达。

术语*噪声*的实际使用可以追溯到早期的信号处理，当时它被创造出来作为一种指不需要的(电磁)能量的方式，这种能量被发现会降低信号和数据的质量。

对于数据或数据库开发人员来说，请考虑运行一个简单的数据库查询来确定某个组织的特定销售区域的绩效的示例。如果您的 SQL 查询返回每个销售区域的销售额，您可能会认为额外的销售区域(在本练习的上下文中)可能会使销售信息变得无用(同样，在尝试关注特定销售区域的上下文中)。当然，要解决这种情况，可以重新构造查询，以便过滤掉不想要的区域，或者处理查询结果以消除不想要的区域的干扰。请记住，在统计学中，重新创建数据源可能不现实。



# 噪声数据

在统计学之外，人们经常使用统计噪声这个术语来排除任何他们不感兴趣的数据。这方面的一个例子是职业足球队的体育场，球迷的欢呼干扰了客队的沟通能力。噪音是一种不便。

然而，在统计学中，当数据科学家承认样本中存在噪声时，这意味着如果重复该过程，统计抽样的任何结果都可能不会重复。在这种情况下，由于存在太多的变异，样本可能会成为有噪声的数据，变得毫无意义。

将噪声从真实信号中分离出来的努力几乎一直是统计学中的一个重点(以便研究人员可以使用有意义的数据)，然而，有意义的噪声数据的百分比往往太微不足道，没有多大用处。

随着时间的推移，术语*噪音数据*已经发展到也指*任何非机器可读的数据*，例如非结构化文本，甚至任何以某种方式改变的数据，这些数据不再与用于创建它的程序兼容。令人高兴的是，分析工具的进步正在稳步克服这些类型的统计障碍(想想 IBM Watson analytics，但还有许多其他的障碍)。

一些最普遍接受的统计噪声示例包括高斯噪声、散粒噪声和白噪声。关于(统计)噪音的噪音已经够多了！

让我们继续学习。



# 弱势和强势学习者

一个很好的话题是统计算法或模型提高预测时间的能力，也就是它的性能。

如果你正在读这本书，并且已经读到了本章的这一节，假设你已经理解了机器学习的概念，因为它与统计预测有关。学习是计算机或模型在没有明确编程的情况下学习(如何根据数据进行预测)的能力。

我们使用术语*明确地表示基于数据值的*硬编码的*选择。*

如果你建立在这个概念之上，你可以理解一台计算机或一个模型，它的意图或目标是基于数据做出好的预测(正确地猜测一个结果)，它将执行或产生介于不正确(坏)和正确(好)之间的结果。

人们还可以说，计算机或模型也许可以通过更多的经验(更多的数据)来提高其性能，并以某种速度提高学习。

因此，数据科学家会根据计算机或模型(学习者)的性能(或其预测或猜测结果的能力)将其标记为弱学习者或强学习者。

在统计学和数据科学领域，人们也可以将*学习者*称为分类器或预测器。

那么，什么样的学习者有资格成为强者或弱者呢？

弱学习者是这样一种人，无论数据看起来是什么样的(意味着模型正在被训练的数据中的值的分布)，当它试图标记数据时，总是表现得比机会更好。

我们把“做得比机会好”定义为错误率总是少于一半。



# 由弱变强

*优于随机* *猜测*从根本上说是弱学习者的唯一先决条件。因此，只要算法或模型能够持续击败随机猜测，应用 boosting 算法将能够提高模型预测的准确性(其性能)，并因此将模型从弱学习者转换为强学习者。

请注意，数据科学家一致认为，提高模型的预测能力或性能，甚至比随机猜测的结果稍微好一点，就意味着成功。

当数据科学家考虑提高模型性能的选项(或将弱学习者转化为强学习者)时，需要考虑许多因素。

这些因素包括模型偏差、处理时间和复杂性。让我们逐一解释一下。



# 模型偏差

我们在本章的前面部分讨论了统计偏差。需要考虑统计模型中确定的偏差水平。通常情况下，偏差量越低越好，因为一些改善弱学习者的方法——如 boosting——可能会过度适应，导致误导性结果。



# 训练和预测时间

无论是否，提高弱学习者表现的方法显著增加了模型在数据子集上学习、训练或预测的时间。通常，您对模型进行的训练越多，结果就越好，因此如果您预计需要数百次训练迭代，您需要考虑如果您的改进将训练迭代增加 100%，那么这项工作或过程将花费多长时间。



# 复杂性

通常，有一个假设，弱学习者在设计中计算简单(这是弱学习者，对不对？)，但事实并非总是如此。在选择提高性能的方法之前，了解算法或模型的复杂程度在决策过程中至关重要。



# 哪条路？

数据科学家将走哪条路(哪种方法)来提高模型的性能，并将其从弱学习者转换为强学习者，这最终取决于许多因素，但最终，采取的方法取决于个体问题。

AdaBoost(也称为**自适应增强**)是一种迭代算法，使用指定数量的迭代或回合来改进弱学习器。该算法从训练/测试数据上的弱学习者开始，对每个例子进行同等加权。被错误分类的例子的权重在下一轮增加，而被正确分类的例子的权重减少。

我们将在本章后面了解 AdaBoost。



# 回到助推

至此，我们已经讨论了与提升最相关的所有主题，现在让我们回到主要事件，统计提升。

我们已经描述了什么是统计增强及其用途(一种学习算法，旨在减少偏差和方差，并将弱学习者转化为强学习者)。

这个概念的关键是学习者内在行为的想法，弱学习者被定义为与真正的分类只有轻微关联的学习者(它可以比随机猜测更好地标记例子)。相比之下，强学习者是与真正的分类有很好相关性的人。



# 怎么开始的

事实上，试图提高算法的性能是一种假设。也就是说，对于他们的统计算法或模型，这是每个数据科学家都应该问的问题。

这在统计学中被称为假设提升问题，完全是关于数据科学家找到一种方法来稍微改善学习过程(将弱学习者变成强学习者)。

强学习者的想法仅仅意味着学习者有一点点提高——实际上，仅仅比随机猜测好一点点。

在数据科学或统计世界中，假设提升问题还意味着实际存在一种有效的算法，该算法为正在解决的问题输出任意精度的假设。这些算法(改善学习者)很快被简单地称为**助推**。

像往常一样，数据科学家互换使用术语来标识同一事物，boosting 也不例外，因为一些数据科学家将 boosting 称为*重采样*或*组合*。



# adaboost 算法

回到我们之前提到的一个名为 **AdaBoost** 的包，是**自适应增强**的简称。AdaBoost 是一种被称为*集成学习算法*的增强方法。集成学习是指将多个学习器相互结合使用，以构建更强的学习算法。

AdaBoost 的工作原理是选择一个基本算法，然后通过考虑训练数据集中分类不正确的示例来迭代改进它。

关于 boosting 和 AdaBoost 的精彩解释可以在网上找到:*通过 AdaBoost 更好地生活*【http://bbacon.org/Better-Living-Through-AdaBoost】T2。

前述文章描述了 AdaBoost 的工作原理:

*   AdaBoost 在数据子集上训练模型
*   弱势学习者(基于表现)被加权
*   重复该过程

在叙述形式中，AdaBoost 升压逻辑可以用以下方式解释:

*   该流程的工作原理是:基于训练数据构建模型，然后测量训练数据的结果准确性，然后:
    *   模型中错误的单个结果被赋予比正确结果更大的权重(或加权更多)，然后使用这些新权重再次对模型进行*重新训练*。然后这个逻辑被重复多次，每次根据它们在最后一次迭代中是否被正确分类来调整单个观察值的权重！

AdaBoost 算法最初是由 *Freund* 和 *Schapire* 在*计算机和系统科学杂志*1997 年的一篇题为*在线学习的决策理论概括和 Boosting 应用*的论文中提出的。



# 你能从提升(帮助)数据库中学到什么

从数据库开发人员的角度来考虑，您可能会尝试将升压过程概念化。正如我们在本书中所做的那样，在这里，我们将尝试使用一个面向数据库的示例来帮助我们理解 boosting:

![](assets/00e1ee93-b618-4764-9d70-0ecfb9466878.png)

我们的例子从关系数据库开始。在这里，有效的索引是提高数据库应用程序性能的最佳方式之一。没有一个有效的(强？)索引，数据库引擎就像一个读者试图通过花时间检查每一页来查找参考书中的短语。但是，如果读者使用参考书的索引，那么读者可以在更短的时间内完成任务(更好的性能=更好的结果)。

在数据库术语中，当没有可识别的索引来提高数据库查询的性能时，就会发生表扫描。在表扫描中，数据库引擎检查表中的每一行，以满足查询结果。

数据库开发人员最重要的工作之一是在生成执行计划(用于查询)时找到最佳索引。大多数主流数据库都提供了工具来显示查询的执行计划，并帮助优化和调优查询索引。

可以将前面的情况与重复测试数据库中的查询进行比较，对各个性能(在返回查询结果时)进行评分，直到确定一个有效(或强)的索引。

这将有助于提高数据库查询的性能，使其成为一个强响应者(或者，如果您愿意，也可以说是一个强学习者)。



# 用 R 来说明升压方法

为了进一步说明 boosting 的用法，我们应该举个例子。

在这一节中，我们将从高层次上审视一个发人深省的预测问题，它来自于 2017 年 8 月詹姆斯·d·米勒(James D. Miller)和鲁伊·米盖尔·福特(Rui Miguel Forte)出版的*掌握预测分析第二版*([)https://www . packtpub . com/big-data-and-business-intelligence/Mastering-Predictive-Analytics-R-Second-Edition](https://www.packtpub.com/big-data-and-business-intelligence/mastering-predictive-analytics-r-second-edition)。

在这个原始的例子中，分析了望远镜相机上的辐射图案，试图预测某个图案是来自泄漏到大气中的伽马射线还是来自常规的背景辐射。

伽马射线会留下独特的椭圆形图案，因此我们可以创建一组特征来描述这些图案。使用的数据集是 *MAGIC Gamma 望远镜数据集*，由 *UCI 机器学习* *知识库*托管在[http://archive . ics . UCI . edu/ml/datasets/MAGIC+Gamma+Telescope](http://archive.ics.uci.edu/ml/datasets/MAGIC+Gamma+Telescope)。

该数据由 19，020 个观察值组成，包含以下属性列表:

| **列名** | **类型** | **定义** |
| `FLENGTH` | 数字的 | 椭圆的长轴(毫米) |
| `FWIDTH` | 数字的 | 椭圆的短轴(毫米) |
| `FSIZE` | 数字的 | 相机照片中所有像素内容总和的以十为底的对数 |
| `FCONC` | 数字的 | 两个最高像素的总和与`FSIZE`的比值 |
| `FCONC1` | 数字的 | 最高像素与`FSIZE`的比率 |
| `FASYM` | 数字的 | 从最高像素到中心的距离，投影到主轴上(mm) |
| `FM3LONG` | 数字的 | 沿主轴的第三个力矩的三次方根(mm) |
| `FM3TRANS` | 数字的 | 沿短轴的三阶矩的三次方根(mm) |
| `FALPHA` | 数字的 | 向量到
原点的长轴角度(度) |
| `FDIST` | 数字的 | 从原点到椭圆中心的距离(mm) |
| `CLASS` | 二进制的 | 伽马射线(g)或背景强子辐射(b) |



# 准备数据

首先，需要对我们的示例数据执行各种步骤。

数据首先被加载到一个名为`magic`的 R 数据框对象中，重新编码`CLASS`输出变量，以使用类`1`和`-1`分别用于伽马射线和背景辐射:

```
> magic <- read.csv("magic04.data", header = FALSE) 
> names(magic) <- c("FLENGTH", "FWIDTH", "FSIZE", "FCONC", "FCONC1", 
  "FASYM", "FM3LONG", "FM3TRANS", "FALPHA", "FDIST", "CLASS") 
> magic$CLASS <- as.factor(ifelse(magic$CLASS =='g', 1, -1)) 
```

接下来，使用 80-20 分割将数据分割成两个文件:训练数据和测试数据帧:

```
> library(caret) 
> set.seed(33711209) 
> magic_sampling_vector <- createDataPartition(magic$CLASS,  
                             p = 0.80, list = FALSE) 
> magic_train <- magic[magic_sampling_vector, 1:10] 
> magic_train_output <- magic[magic_sampling_vector, 11] 
> magic_test <- magic[-magic_sampling_vector, 1:10] 
> magic_test_output <- magic[-magic_sampling_vector, 11] 
```

用于增强的模型是一个简单的多层感知器，具有一个利用 R 的`nnet`包的隐藏层。

神经网络(包含在第 9 章、*数据库和神经网络*中)通常在输入标准化时产生更高的精度，因此，在本例中，在训练任何模型之前，执行以下预处理:

```
> magic_pp <- preProcess(magic_train, method = c("center",  
                                                 "scale")) 
> magic_train_pp <- predict(magic_pp, magic_train) 
> magic_train_df_pp <- cbind(magic_train_pp,  
                             CLASS = magic_train_output) 
> magic_test_pp <- predict(magic_pp, magic_test) 
```



# 培养

Boosting 被设计为最适合弱学习者，因此在模型的隐藏层中使用了非常少量的隐藏神经元。

具体地说，我们将从使用单个隐藏神经元的最简单的多层感知器开始。为了理解使用 boosting 的效果，通过训练单个神经网络(并测量其性能)来建立基线性能。

这是为了完成以下任务:

```
> library(nnet) 
> n_model <- nnet(CLASS ~ ., data = magic_train_df_pp, size = 1) 
> n_test_predictions <- predict(n_model, magic_test_pp, 
                                type = "class") 
> (n_test_accuracy <- mean(n_test_predictions ==   
                           magic_test_output)) 
[1] 0.7948988 
```

这表明我们的基线准确率约为 79.5%。不算太坏，但能在这个分数上提高吗？

为此，使用如下所示的函数`AdaBoostNN()`。该函数将接受来自数据框的输入、输出变量的名称、要构建的单个隐藏层神经网络模型的数量，以及这些神经网络将具有的隐藏单元的数量。

然后，该函数将实现 AdaBoost 算法，并返回一个带有相应权重的模型列表。

下面是函数:

```
AdaBoostNN <- function(training_data, output_column, M,   
                       hidden_units) { 
  require("nnet") 
  models <- list() 
  alphas <- list() 
  n <- nrow(training_data) 
  model_formula <- as.formula(paste(output_column, '~ .', sep = '')) 
  w <- rep((1/n), n) 
  for (m in 1:M) { 
    model <- nnet(model_formula, data = training_data,  
                size = hidden_units, weights = w) 
    models[[m]] <- model 
    predictions <- as.numeric(predict(model,  
                    training_data[, -which(names(training_data) == 
                    output_column)], type = "class")) 
    errors <- predictions != training_data[, output_column] 
    error_rate <- sum(w * as.numeric(errors)) / sum(w) 
    alpha <- 0.5 * log((1 - error_rate) / error_rate) 
    alphas[[m]] <- alpha 
    temp_w <- mapply(function(x, y) if (y) { x * exp(alpha) }  
                    else { x * exp(-alpha)}, w, errors) 
    w <- temp_w / sum(temp_w) 
  } 
  return(list(models = models, alphas = unlist(alphas))) 
} 
```

上述函数使用以下逻辑:

1.  首先，初始化模型和模型权重的空列表(`alphas`)。计算训练数据中的观察次数，将其存储在变量`n`中。然后，所提供的输出列的名称用于创建一个公式，该公式描述将要构建的神经网络。
2.  在所使用的数据集中，该公式将为`CLASS ~ .`，这意味着神经网络将把`CLASS`作为所有其他列的输入特征的函数来计算。
3.  接下来，初始化权重向量并定义一个循环，该循环将运行`M`次迭代以构建`M`模型。
4.  在每次迭代中，第一步是使用权重向量的当前设置，使用输入中指定的尽可能多的隐藏单元来训练神经网络，`hidden_units`。
5.  然后，使用`predict()`函数计算模型根据训练数据生成的预测向量。通过将这些预测与定型数据的输出列进行比较，计算当前模型对定型数据产生的错误。这样就可以计算误差率。
6.  该错误率被设置为当前模型的权重，并且最后，根据每个观察是否被正确分类来更新将在循环的下一次迭代中使用的观察权重。

7.  权重向量然后被归一化，我们准备开始下一次迭代！
8.  完成`M`次迭代后，输出一个模型列表及其对应的模型权重。



# 准备推进

现在有一个函数能够使用 AdaBoost 训练我们的集成分类器，但我们还需要一个函数来进行实际预测。这个函数将接收由我们的训练函数`AdaBoostNN()`产生的输出列表，以及一个测试数据集。

该功能为`AdaBoostNN.predict()`，显示如下:

```
AdaBoostNN.predict <- function(ada_model, test_data) { 
  models <- ada_model$models 
  alphas <- ada_model$alphas 
  prediction_matrix <- sapply(models, function (x)  
             as.numeric(predict(x, test_data, type = "class"))) 
  weighted_predictions <- t(apply(prediction_matrix, 1,  
             function(x) mapply(function(y, z) y * z, x, alphas))) 
  final_predictions <- apply(weighted_predictions, 1, 
              function(x) sign(sum(x))) 
  return(final_predictions) 
} 
```

这个函数首先提取模型和模型权重(从上一个函数生成的列表中)。创建预测矩阵，其中每一列对应于由特定模型做出的预测向量。因此，该矩阵中的列数将与我们用于提升的模型数一样多。

然后，我们将每个模型产生的预测与它们相应的模型权重相乘。例如，来自第一模型的每个预测都在预测矩阵的第一列中，并且将使其值乘以第一模型权重 *α [1]* 。

最后，通过对每个观测值的加权预测求和并取结果的符号，加权观测值矩阵被简化为单个观测值向量。这个预测向量随后由函数返回。

作为一项实验，我们将训练 10 个具有单个隐藏单元的神经网络模型，并观察增强是否会提高准确性:

```
> ada_model <- AdaBoostNN(magic_train_df_pp, 'CLASS', 10, 1) 
> predictions <- AdaBoostNN.predict(ada_model, magic_test_pp,  
                                    'CLASS') 
> mean(predictions == magic_test_output) 
 [1] 0.804365 
```

在这个例子中，提升 10 个模型显示了精确度的边际改善，但是也许训练更多的模型可能会产生更大的差异。

正如我们在本章中多次提到的，即使是成绩的微小提高也足以将一个弱学习者转变为强学习者！



# 示例结果

从前面的示例中，您可以得出结论，对于具有一个隐藏单元的神经网络，随着增强模型数量的增加，我们会看到准确性的提高，但在 100 个模型之后，这种情况会逐渐减少，实际上对于 200 个模型来说会稍有减少。对这些网络来说，相对于单一模型基线的改进是实质性的。当我们通过具有三个隐藏神经元的隐藏层来增加我们的学习器的复杂性时，我们在性能上获得的改善要小得多。在 200 个模型时，两个集合的表现水平相似，这表明，在这一点上，我们的准确性受到训练模型类型的限制。



# 摘要

在这一章中，我们发现了*s*statistical boosting，首先解释了与 boosting 主题相关的统计学中使用的关键概念，从而有助于定义 boosting 本身。

我们还考虑了使用统计增强来更好地理解几乎每个数据库中的数据的想法。

在下一章中，将再次努力使用开发人员术语，这一次是为了定义支持向量机，确定支持向量机的各种应用，并通过一个示例演示如何使用简单的 SVM 对数据库中的数据进行分类。