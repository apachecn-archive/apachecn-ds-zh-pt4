

# 八、数据库开发和评估

在这一章中，我们将讨论数据(数据库)评估的实践。我们将提供对什么是统计评估的理解，以及为什么它对数据科学家是重要的，同时提供使用 R 执行各种统计评估方法的有指导意义的例子。

正如我们在本书中一直努力做的那样，我们将找出某些数据开发人员和数据科学家概念之间的相似之处，查看数据或数据库开发和数据(数据库)评估之间的差异，并提供数据评估实践和数据(质量)保证之间的比较。

我们将本章中的信息分为以下几个部分:

*   评估和统计评估的比较
*   发展与评估
*   数据评估是数据质量的保证吗？
*   使用 R 将统计评估的思想应用到您的数据中

我们开始吧！



# 评估和统计评估

韦氏词典将评估定义为:

对某事做出判断的行为或事例。

下图显示了评估统计数据的流程:

**![](assets/1516aa4f-3b3a-46d4-8b55-bf5ab8a2ef3f.png)**

对于统计评估，我们需要记住一些要点。它们如下所列。



# 目标

考虑到这一点，为了能够对某件事(实际上是任何事)做出合理的评估——也就是说，做出判断，一个人必须首先设定目标。评估目标帮助数据科学家确定如何评估数据、数据库或统计数据模型。没有明确的目标，您将浪费宝贵的时间，并可能对不满足业务需求的模型抱有信心，甚至可能导致不正确的假设(预测)。



# 基线

接下来，(根据您设定的目标)需要建立标准、最低可接受的绩效或基线，以建立对被评估内容的看法。换句话说，与你认为可以接受的相比，你所评估的有多好？

尽管我们不会在数据库评估过程上花费太多时间(而是集中在统计数据或统计数据模型评估上)，但我们会提到具体的性能度量(性能度量或指标)的使用。

在评估统计模型的预测准确性时，数据科学家会经常使用非常具体的(性能)指标。这些度量标准取决于被评估问题的类别或类型，并且需要使用稍微不同的方法来评估(模型的)性能。这种方法也作为评估标准的非统计数据和数据库的规则而存在。例如，有一些特定的性能指标用于评估一个**在线事务处理** ( **OLTP** )数据模型，这些指标将与那些用于评估一个**企业数据仓库** ( **EDW** )模型的指标大不相同。

更深入地看，在评估、性能测试或评估(非统计)数据库时，作为工作的一部分，人们会关注各种基准(即基准测试)、容量确定和规划、执行浸泡或浸泡测试、高峰-休息间隔(仅举几个例子)的识别。



# 评估规划

正如非统计数据库的类型(OLTP、EDW 等)将决定使用什么样的测试来执行评估一样，统计模型的类型(例如，回归、分类、二元分类等)也将决定数据科学家用来评估统计模型的适当评估技术或方法(本章稍后将详细介绍)。

一旦您设定了评估的目标并建立了基线，就可以制定执行计划。该计划通常概述了要执行的整个过程。该计划将列出要执行的测试以及测试目标、要比较的基线，甚至预期的结果。



# 估价

在统计学中，术语**性能**通常与模型准确性的概念互换。当谈到非统计数据库或模型时，性能可能完全与速度(查询返回值需要多长时间，提交事务需要多长时间，等等)和准确性有关，并且通常围绕质量保证的思想，而不是预测值的能力！

评估统计模型时，数据科学家将查看模型的错误率、错误分类的数量(由模型产生)、正确预测的数量与预测实例总数(由模型产生)的比率等。同样，所有这些都依赖于统计模型类型和目标。

最后，一旦完成，数据库和统计数据模型评估的结果通常将使用普遍接受的方法以各种方式可视化，以便于评估(同样，如何公开或可视化过程结果将取决于准备可视化的人的目标或模型的目标)。应当理解，一旦评估结果已经被评估，重复评估过程的各个部分(或者甚至整个评估过程)并不罕见。这可能是为了进一步澄清所展示的结果中确定的某些内容，或者是为了重新验证某些结果。在某些情况下，可能会开发和执行新的项目目标、基线，甚至新的计划。

总而言之，从广义上讲，执行数据库或(统计)数据模型评估的过程类似于两者都需要以下内容:

*   设定(数据库或数据模型的)目标
*   建立基线(也是为了比较绩效)
*   确定(进行评估的)计划
*   评估结果



# 发展与评估

虽然评估过程确实产生了输出，但最终可能只是一个决策(也就是说，根据目标，被观察的数据、数据库或统计数据模型是否满足可接受的性能限制？)，发展就意味着建设。

发展也意味着通过扩展、扩大或改进来提高。这意味着(或者至少暗示着)一个人正在开发的东西可能永远不会完全完成。事实上，发展和评估是相辅相成的。

开发任何东西的业内公认的实践建议如下:

*   建造(或发展)
*   试验
*   评定
*   重复

当开发一个关系数据模型时，可以使用一个`create` SQL 语句，类似于下面的代码:

```
mysql> CREATE TABLE test (a INT NOT NULL AUTO_INCREMENT,
-> PRIMARY KEY (a), KEY(b))
-> ENGINE=MyISAM SELECT b,c FROM test2;
```

剖析前面的代码，我们可以看到结果是生成了一个表对象`test`。或许，记住这一点，评估(关系)数据库或数据模型可能会使用以下代码示例的某种形式:

```
USE AdventureWorks;
GO
SET STATISTICS IO ON
SET STATISTICS TIME ON
SELECT p.Name, pr.ProductReviewID
FROM Production.Product p
JOIN Production.ProductReview pr
ON p.ProductID = pr.ProductID
SET STATISTICS IO OFF
SET STATISTICS TIME OFF
```

类似前面的语句执行性能工具，返回可以可视化和分析的相关统计数据。

一个可比较的(尽管过于简单的)统计开发(或创建)例子可能看起来像下面的 R 代码(摘自[第 7 章](da24875e-1b5e-42da-a0e8-c697ae5b940d.xhtml)，*数据库改进的正则化*):

```
# --- using the R lm function to create an ordinary least squares (OLS) # -- fit of 3-variable model using x3 as an independent x3 variable
ols <- lm(y~ x1 + x2 + x3)
summary(ols)
```

同样从[第 7 章](da24875e-1b5e-42da-a0e8-c697ae5b940d.xhtml)、*数据库改进的正则化*开始，我们使用 R 函数摘要开始对生成的线性回归模型的性能进行一些评估:

![](assets/b8ea70eb-741d-420b-8e75-12a40f42cbae.png)

如前所述，根据统计问题的**类**，数据科学家将使用不同的途径或方法来评估(模型的)性能(包括 R 函数总结)。



# 规划

在本章的前一节中，我们比较了评估和统计评估之间的相似之处，并指出作为任何评估项目的一部分(或者至少是您希望成功的项目)，您需要创建一个计划。

转到我们将发展和评估联系起来的这一部分，我们再次看到发展过程的第一步可能是创建一个计划。

作者认为，制定计划的行为是生活中任何努力的基本要求，甚至是早上起床！

一个人在考虑数据库开发时创建的计划既可以用作实现时的指南(在这种情况下，是数据库或统计数据模型)，也可以用作实现后的功能规范(针对数据库)。

评估数据库(或者统计学中的数据模型)的任务是什么？嗯，同样适用。第一步是制定详细的评估计划，该计划同样可用于指导整个评估过程，然后在评估完成后成为功能规范参考。

规划总是会有回报的。一个好的开发或评估计划可以成为一个详细的项目计划、验收测试计划、部署文档，以及前面提到的功能规范参考。

数据库设计是数据或数据库开发过程的一部分。设计数据库可能是一项复杂的任务。设计过程的一部分是让数据建模师(或非常有经验的数据开发人员)研究数据、其来源、需求等等，然后生成详细的数据模型。该数据模型将包含所有需要的逻辑和物理设计选择，以及以**数据定义语言** ( **DDL** )生成设计所需的物理存储参数，然后可以使用这些参数实际创建数据库。

一个全面的数据库开发计划将包括数据库设计阶段(从建模到创建)以及沿途的多个测试和评估步骤。

统计建模(实际上被认为是数学建模的一种形式)包括体现或汇集一组假设，这些假设涉及或关于从(希望)更大的(数据)总体中生成一些样本数据和类似数据。

生成统计模型的计划(类似于生成数据库模型的计划)将包括对(样本)数据、其来源、所有需求等的检查。同样，与前面提到的计划一样，统计建模计划将包括提到数据科学家计划在统计模型上使用的每个评估和评价。

通常，统计模型评估计划还将包括对可视化的引用，数据科学家计划在每次评估测试后提出观点或总结结果。

正如 Madhuri Kulkarni 所说，统计建模被描述为研究一个系统或过程以预测其未来行为:

有了系统的观测数据，模型可以帮助推断系统的各种替代方案。

在所有可用于统计建模(以及理解和操作数据)的通用工具中，R 似乎是最强大和最受欢迎的。

从非统计建模的角度来看，数据建模定义并分析支持业务流程的需求(在组织中特定信息系统的空间内)。在这里，Erwin Data Modeler 和 MySQL Workbench 等工具似乎是最常被成功使用的工具。

最后，虽然发展和评估是分开的努力，但它们是密切相关的，无论是统计上的还是非统计上的，没有另一个的存在，一个也就不存在。



# 数据评估和数据质量保证

为了让我们在这里的讨论有条不紊，让我们看看数据评估如何与数据质量(保证)相比较。

数据质量保证，或通常被数据科学家称为**整理数据**，是解决(可能察觉到的)在数据中发现的问题或顾虑的过程。这些问题影响数据库或数据模型的使用、质量和结果(性能)——当然，数据质量与(数据、数据库或数据模型的)使用目的相关。



# 分类质量

通常，数据质量问题可分为以下几类:

*   准确(性)
*   完全
*   更新状态
*   关联
*   一致性(跨来源)
*   可靠性
*   适当
*   易接近

您会发现统计数据和非统计数据之间存在大量的数据质量分类重叠。有时，数据质量问题可能看起来严格适用于特定的类型—统计与非统计—但在进一步调查或至少有更多的数据或实地经验后，您可能会发现质量就是质量。

数据的质量会影响结果，数据的质量会受到其输入、存储和管理方式的影响，解决数据质量的流程(通常称为质量保证、**数据质量保证**(**))需要对数据进行例行和定期的审查和评估，并执行持续的流程(称为分析和清理)。(这一点至关重要，即使数据存储在多个不同的系统中，使这些过程变得困难。)**

 **虽然数据质量保证和整理数据的概念在许多方面都很相似，但 DQA 通常更关注可重复的过程，而整理通常是根据统计模型的目标，由数据科学家根据需要自行决定的(尽管有经验的数据科学家最有可能努力创建可重用的例程或脚本，供他们以后在这个特定项目或其他项目中操作或整理数据)。



# 关联

在统计相关性上可以找到许多值得注意的重点。统计信息的相关性反映了它满足特定项目实际需要的程度。它关注的是可用的信息是否揭示了对项目重要的关注点。评估相关性是主观的，取决于用户的不同需求。

建立和测量数据相关性的关键方法之一是通过一个称为**添加上下文**或**分析**的过程。

让我们看看，这是什么侧写？

一般来说，看起来相似的数据实际上可能意味着非常不同的东西。例如，平均每分钟**转数** ( **RPM** )如果数据代表跑车与经济型轿车甚至卡车相比，则具有不同的含义。

对于数据，应该通过我们提到的称为概要分析的过程来开发上下文线索，以便数据消费者在使用时可以更好地理解(数据)。此外，对您正在处理的数据有一个背景和观点是决定应该执行哪种评估的关键步骤，或者在非统计模型的情况下，哪种性能评估可能最适合。

向数据添加上下文的另一个动机可能是获得数据的新视角。这方面的一个例子可能是识别和检查数据中存在的比较。例如，住宅或房屋价值可以通过邮政编码或其他标准进行比较。

作为开发和评估过程的一部分，向数据(统计的或其他的)添加上下文(回想一下，我们提到过这两者是齐头并进的)当然可以使它(数据)更加相关，但是上下文仍然不能代替价值。

在您考虑数据中的任何变量之前，例如平均转速、扭矩、最高速度、轴距、重量(或其他任何东西)，首先，评估测试需要让那些将要使用它的人受益，换句话说，就是数据科学家有兴趣预测的任何东西。例如，如果我们要扩展这个车辆数据示例，即预期的 MPG 或 miles per gallon，那么建立适当的上下文要求将是至关重要的。

对于数据分析(或将上下文添加到您将在项目中使用的数据中)，规则如下:

**在上下文之前，认为>** **值**

类似于我们如何对数据质量问题的类型进行分类，有几个上下文类别，可用于论证或增加可视化数据的价值和理解:

*   定义和解释
*   比较
*   对比
*   倾向
*   散布

评估价值和数据质量，甚至数据或数据模型价值，虽然可能有重叠的领域，但具有不同的目标。



# 交叉验证

我们不能在一本专注于统计(和评估统计模型)的书中有一章没有交叉验证的章节。你可能会听到一些数据科学家将交叉验证称为旋转估计或简单的评估模型的一般技术。

交叉验证是数据科学家用来评估统计模型的准确性的最常用方法之一。交叉验证的关键概念是测试模型的归纳能力，或者具体来说，测试模型将从数据样本训练中推断出的内容应用到整个群体或数据集的能力。

交叉验证有两个目标——使用一种算法根据可用数据估计模型的性能，比较两种或更多种不同算法的性能，并找出适用于可用数据的最佳算法**。**

在高层次上，交叉验证的过程是确定一个称为**验证数据集**的已知数据集，在该数据集上进行训练，然后是未知数据(或第一次看到的数据)的第二个数据集，算法或数据模型将根据该数据集进行测试(这被称为您的**测试数据集**)。这里的目标是试图确保诸如过度拟合(允许非包容性信息影响结果)之类的复杂性得到控制，以及提供关于模型将如何概括真实问题或真实数据文件的一些理解。



# 准备数据

为了执行交叉验证，数据科学家必须准备数据。这项工作包括通过概要分析(我们在本章前面提到过)来了解数据，以便将数据分成可比较子集的样本。然后，数据的一个子集被确定为训练集，并对其进行分析。接下来，一旦分析(或训练)完成，使用另一个子集(称为**验证集**或**测试集**)来验证结果(或性能)。

为了减少可变性，交叉验证的多次迭代(也称为**折叠**或**回合**)使用不同的分区来执行，并且在回合上对验证结果进行平均。

通常，数据科学家将使用模型的稳定性来确定应该执行的交叉验证的实际次数:

![](assets/3a938053-dffe-42ad-af6d-2c943f7ead1e.png)

正如您在前面的屏幕截图中看到的，通过思考数据科学家将大量数据组织成两个子集:**已知数据**和**未知数据**，或许可以更好地理解**交叉验证**方法(您将在本章的下一节看到如何实现这一点的示例)。然后，数据科学家对数据进行分析，并手动计算结果。一旦建立了预期或正确的结果，就可以将它们与统计模型产生的结果进行比较(使用单独的未知数据子集)。

前面是一个回合。将进行多轮比较，然后对比较结果进行平均和审查，最终提供模型预测性能的合理估计。

让我们想一个真实世界的用例。

在[第 6 章](da24875e-1b5e-42da-a0e8-c697ae5b940d.xhtml)、*数据库改进正则化*中，我们再次回顾了一些由咨询项目结果组成的样本数据。在这个例子中，我们研究了项目的总计费时间、项目的总项目管理时间和项目的预期盈利能力之间的关系。

回顾这些数据来说明这一点，我们可以考虑各种项目特征(而不是变量):

*   该项目是否在组织的核心技术优势范围内？
*   这个项目有专职项目经理吗？
*   项目是否分配了全职客户资源？
*   项目工作被分包出去了吗？
*   该项目是时间和材料类型的项目吗？
*   该项目是一个不超过类型的项目吗？
*   项目中有正式的**质量保证** ( **QA** )部分吗？
*   工作主要是在现场进行的吗？
*   工作主要是在远程(远离客户现场)执行的吗？

同样，我们的预测模型想要预测一个有利可图的咨询项目有什么特征。

以下是使用五轮交叉验证流程预测我们的模型的预期准确性的结果表示:

![](assets/384c80bf-c79a-4d86-a313-fc8cae5940d4.png)

根据前面的数据，我认为我们的预测模型应该非常准确！

总之，交叉验证结合了(平均)拟合(预测误差)的度量，以获得对模型预测性能的更准确的估计。这种方法通常用在没有足够的数据进行测试而又不损失建模或测试质量的情况下。

现在让我们进入本章的最后一节，看看一些使用 R 编程语言的评估示例。



# r 和统计评估

那么，让我们从一些统计评估工作开始吧！

正如我们在上一节中讨论的那样，交叉验证不是使用所有数据(全部观察值)来训练统计模型(然后使用其中一些数据进行测试)，而是将数据分成训练和测试数据集。

当数据科学家对使用交叉验证来评估统计模型的性能感兴趣时，他或她需要采取的第一步是将数据组织(或拆分)成两个独立的子集。

实际上有几种交叉验证的方法:

*   **留一交叉验证** ( **LOOCV** )
*   坚持
*   k 倍和重复 k 倍
*   重新替代(大多数人认为这种方法是最简单的方法)

这种交叉验证方法都集中在如何为训练、测试和验证拆分数据。各有千秋(利弊)。

(一如既往地)有许多解决问题的方法。下面就是这样一个简单的方法。此示例使用 70 比 30 的分割比例随机分割整个文件:

```
# --- setting seed so we get same data split each time
# --- we'll use 100 for seed
set.seed(100)
# --- determine the total number of rows in the data
# --- using nrow function
nall = nrow(MyData)
# --- number of rows for train subset is 70%
# --- of the total rowsntrain = floor(0.7 * nall)
# --- number of rows for test subset is 30%
# --- of the total rows
ntest = floor(0.3* nall)
index = seq(1:nall)
# --- create the train data subsettrainIndex = sample(index, ntrain)
testIndex = index[-train]
train = mydata[trainIndex,]
test = mydata[test,]
```

一旦我们创建了我们想要的文件，我们就可以继续训练并验证我们的统计模型。

正如我们在本书中多次提到的，一个行之有效的做法是保存前面的代码，以便可以在新的数据集上反复使用。



# 要问的问题

在本章的前几节中，我们讨论了交叉验证的各种途径或方法、交叉验证的轮数(事实上，我们展示了五轮交叉验证的结果)，以及如何组织和拆分数据以在统计模型上执行交叉验证。

在进行交叉验证过程之前，需要考虑几个要点。(创建了一个计划！)这就带来了以下问题:

1.  我应该使用哪种交叉验证的方法或途径？答案是最好的方法。于是又出现了一个新问题——最佳意味着什么？每种方法都有自己的优点和缺点。最佳交叉验证方法是最适合您的数据和目标的方法。通常情况下，在尝试其他方法之前，您应该使用哪种方法可能不会被发现。
2.  一个人应该完成多少回合或折叠才合适？通常越多越好！然而，这将由多种因素决定，例如您选择使用的交叉验证方法以及可用的数据和时间。
3.  创建每一轮数据的方法是什么？同样，这将由您选择使用的交叉验证方法、可用的数据量和时间以及数据科学家的能力等因素决定！



# 学习曲线

评估统计模型性能的另一种方法是通过评估模型的学习增长或模型利用额外经验(例如，多轮交叉验证)改善学习(获得更好的分数)的能力。

短语 **with additional experience** 在统计学中至关重要，因为我们不仅要寻找一个对给定数据群体表现良好的统计模型，而且我们希望该模型的性能会随着对越来越多数据的训练和测试而提高。

指示模型的性能、结果或数据文件填充分数的信息通常与其他分数相结合，以显示直线或曲线，这称为统计模型的学习曲线。

这意味着学习曲线是学习(分数显示在纵轴上)和实践(单个数据文件或回合显示在横轴上)增长的图形表示。

这也可以概念化如下:

*   一系列重复的相同任务
*   随着时间的推移学到的知识



# 学习曲线示例

举例来说，假设我们想要可视化统计模型在多轮性能结果中的学习增长率，比较测试数据与选定特征的训练数据。

这一点在本章前面的章节中已有介绍:

![](assets/e8a60e82-a39e-456d-8ec7-b338b5c2b2bf.png)

以下是显示学习曲线的可视化图，该曲线使用所选特征的交叉验证回合的先前结果分数来指示预测模型的学习速率:

![](assets/00e514b1-d1a4-4452-93d8-37b8c5dd763b.png)

核心技术

以下是生成上述可视化效果的示例 R 代码:

```
# --- load scores from 5 rounds of testing
v <-c(90,80, 89,72, 90)
# -- plot the model scores round by round
plot(v, type = "o", col = "red", xlab = "Round", ylab = "Score", main = "Core Technology")
```

同样，在执行模型评估时，尤其是在执行多轮测试时(或者在确定统计模型上使用的正确交叉验证方法的分析工作中)，通常会使用将统计模型的性能与经验相关联的学习曲线。

在这一点上，简单地执行几轮测试，然后检查结果是不够的。经验丰富的数据科学家将确保正确记录测试的每个迭代，以及相应的结果和结论。

再看前面的例子，我们可以添加使用 R 函数`png`，它可以用来自动创建和保存您在评估过程中创建的任何可视化的图像文件。如果您预先定义了一个文件结构来保存您的评估结果，这种方法或类似的方法将会节省很多时间。

R 函数`png`可以很容易地转换成许多其他位图格式，并且都可以在现代网络浏览器中显示！

以下是我们的示例 R 代码语句，显示了数据的设置、图像文件的创建以及绘图可视化的生成:

```
# --- load scores from 5 rounds of testing
v <-c(90,80, 89,72, 90)
# -- create an image file for the visualization for later use
png(file = "c:/provenpratice/learning curve.png", type = c("windows", "cairo", "cairo-png"))
# -- plot the model scores round by round
plot(v, type = "o", col = "red", xlab = "Round", ylab = "Score", main = "Learning Curve")
# -- close output
dev.off()
```

你应该注意，如果你期待一个互动的结果，你不会收到它！前面的代码使用了`png`，它只是将`plot`函数的输出写到那个文件中。

好的实践建议:使用`dev.off()`来确保文件被关闭。

这将创建以下图形文件:

![](assets/f9ff6269-bc1b-4a5b-99b5-36760d5fca14.png)

# 摘要

在这一章中，我们定义了评估，然后研究了评估和统计评估之间的异同。接下来，我们讨论了开发与评估，然后解释了数据评估和数据质量保证是如何有一些重叠的，并且是携手并进的，但是也有不同的目标。最后，我们使用编程工具 r 应用了统计评估的思想。

在下一章中，我们将定义神经网络模型，并利用开发人员的数据模型知识来帮助理解神经网络在数据科学中的用途和使用。**