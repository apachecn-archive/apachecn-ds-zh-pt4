

# 六、如何评估表现

概观

本章将向您介绍模型评估，在您决定将模型投入生产之前，您需要对您训练的每个模型的性能进行评估。本章结束时，您将能够创建评估数据集。你将能够使用平均绝对误差(MAE)和均方误差(MSE)来评估线性回归模型的性能。您还将能够使用准确度、精确度、召回率和 F1 分数来评估逻辑回归模型的性能。

# 简介

当您评估模型的性能时，您会查看某些测量值或数值，这些测量值或数值会告诉您模型在某些条件下的表现如何，并帮助您做出是否使用您在现实世界中训练的模型的明智决策。在这一章中，你将会遇到一些测量方法，如 MAE、precision、recall 和 R2 评分。

您在*第 2 章回归*中学习了如何训练回归模型，在*第 3 章二元分类*中学习了如何训练分类模型。考虑预测客户是否可能购买定期存款的任务，你在*第三章，二元分类*中提到了这个任务。您已经学习了如何训练一个模型来执行这种分类。你现在关心的是这个模型有多有用。您可以从训练一个模型开始，然后评估该模型的预测正确的频率。然后，您可以继续训练更多的模型，并评估它们是否比您以前训练的模型表现得更好。

你已经看到了使用`train_test_split`拆分数据的例子，最近一次是在*练习 3.06* 的*步骤 7* 中。您将在第 7 章*机器学习模型的概括*中进一步探讨拆分数据的必要性和应用，但现在，您应该注意，将您的数据拆分为一个用于训练模型的集合和另一个用于验证模型的集合是很重要的。正是这个验证步骤帮助您决定是否将模型投入生产。

# 拆分数据

您将在第 7 章“机器学习模型的一般化”中了解更多关于拆分数据的信息，我们将在该章中介绍以下内容:

*   使用`train_test_split`进行简单的数据分割
*   使用交叉验证的多重数据分割

现在，您将学习如何使用来自`sklearn`的名为`train_test_split`的函数分割数据。

不要使用所有数据来训练模型，这一点非常重要。您必须留出一些数据用于验证，并且这些数据必须以前没有用于培训。当您训练一个模型时，它会尝试生成一个适合您的数据的方程。你训练的时间越长，方程就变得越复杂，因此它会通过尽可能多的数据点。

当你打乱数据并留出一些数据进行验证时，它可以确保模型学会不过度拟合你试图生成的假设。

## 练习 6.01:导入和拆分数据

在本练习中，您将从存储库中导入数据，并将其拆分为训练集和评估集来训练模型。需要分割您的数据，以便您可以在以后评估模型。这个练习将使你熟悉拆分数据的过程；这是你会经常做的事情。

注意

您将在本章中使用的 Car 数据集可以在我们的 GitHub 资源库中找到:[https://packt.live/30I594E](https://packt.live/30I594E)。

它取自 UCI 机器学习资料库。

这个数据集是关于汽车的。提供了一个包含以下信息的文本文件:

*   `buying`–购买这辆车的费用
*   `maint`–车辆的维护费用
*   `doors`–车辆的车门数量
*   `persons`–车辆能够运送的人数
*   `lug_boot`–车辆的载重量
*   `safety`–车辆的安全等级
*   `car`–这是模型试图预测的类别

以下步骤将帮助您完成练习:

1.  打开新的 Colab 笔记本。
2.  Import the required libraries:

    ```
    import pandas as pd
    from sklearn.model_selection import train_test_split
    ```

    您首先在第一行中导入了一个名为`pandas`的库。这个库对于将文件读入一个叫做`DataFrame`的数据结构很有用，你在前面的章节中已经使用过了。这种结构就像一个电子表格或一个我们可以操作的带有行和列的表格。因为你可能需要多次引用这个库，我们为它创建了一个别名`pd`。

    在第二行中，您从一个名为`model_selection`的模块中导入一个名为`train_test_split`的函数，该模块在`sklearn`中。您将利用该函数来拆分使用`pandas`读入的数据。

3.  Create a Python list:

    ```
    # data doesn't have headers, so let's create headers
    _headers = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'car']
    ```

    您正在读入的数据存储为 CSV 文件。

    浏览器会将文件下载到您的计算机上。您可以使用文本编辑器打开该文件。如果这样做，您将会看到类似于以下内容的内容:

    ![Figure 6.1: The car dataset without headers
    ](image/B15019_06_01.jpg)

    图 6.1:没有标题的汽车数据集

    文件通常将每一列的名称写在数据的第一行。例如，看看这个数据集的 CSV 文件，你在*第 3 章，二进制分类*中使用过:

    ![Figure 6.2: CSV file without headers
    ](image/B15019_06_02.jpg)

    图 6.2:没有标题的 CSV 文件

    但是，在本例中，列名是 missi ng。然而，这不是问题。这一步中的代码创建了一个名为`_headers`的 Python 列表，其中包含每一列的名称。当您在下一步中读入数据时，您将提供这个列表。

4.  Read the data:

    ```
    df = pd.read_csv('https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter06/Dataset/car.data', names=_headers, index_col=None)
    ```

    在这一步中，代码使用一个名为`read_csv`的函数读入文件。第一个参数`'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter06/Dataset/car.data'`是必需的，是文件的位置。在我们的案例中，文件在互联网上。也可以选择下载，然后我们可以指向本地文件的位置。

    第二个参数(`names=_headers`)要求函数在读入数据后将行标题添加到数据中。第三个参数(`index_col=None`)要求函数为表生成一个新的索引，因为数据不包含索引。该函数将产生一个数据帧，我们将其赋给一个名为`df`的变量。

5.  Print out the top five records:

    ```
    df.head()
    ```

    此步骤中的代码用于打印数据帧的前五行。该操作的输出显示在下面的屏幕截图中:

    ![Figure 6.3: The top five rows of the DataFrame
    ](image/B15019_06_03.jpg)

    图 6.3:数据框的前五行

6.  Create a training and an evaluation DataFrame:

    ```
    training, evaluation = train_test_split(df, test_size=0.3, random_state=0)
    ```

    前面的代码会将包含您的数据的数据帧拆分成两个新的数据帧。第一个称为`training`，用于训练模型。第二个叫做`evaluation`，下一步会进一步一分为二。我们之前提到过，您必须将数据集分为训练数据集和评估数据集，前者用于训练模型，后者用于评估模型。

    此时，`train_test_split`函数接受两个参数。第一个参数是我们要拆分的数据。第二个是我们想要分割它的比率。我们所做的是指定我们希望我们的评估数据是我们数据的 30%。

7.  Create a validation and test dataset:

    ```
    validation, test = train_test_split(evaluation, test_size=0.5, random_state=0)
    ```

    该代码类似于*第 6 步*中的代码。在这一步中，代码将我们的评估数据分成两个相等的部分，因为我们指定了`0.5`，这意味着`50%`。

    在前面的章节中，我们已经了解了如何将数据分为训练集和测试集，但在这里，我们将更进一步，将数据分为三部分:一部分用于训练模型，一部分用于在训练过程中评估模型，一部分用于在投入生产之前评估模型。

    现在您已经将数据分成不同的集合，您可以继续训练和评估模型。

# 评估回归模型的模型性能

当你创建一个回归模型时，你创建了一个预测连续数值变量的模型，正如你在*第 2 章，回归*中所学的。当您将评估数据集放在一边时，您就有了可以用来比较模型质量的东西。

要评估模型质量，您需要做的是将您的预测质量与所谓的基础事实进行比较，基础事实是您试图预测的实际观察值。看一下*图 6.4* ，其中第一列包含实际值(称为实际值)，第二列包含预测值:

![Figure 6.4: Actual versus predicted values
](image/B15019_06_04.jpg)

图 6.4:实际值与预测值的对比

输出中的第`0`行将评估数据集中的实际值与我们的模型预测值进行了比较。来自我们评估数据集的实际值是`4.891`。模型预测的值是`4.132270`。

第`1`行将`4.194`的实际值与模型预测值进行比较，即`4.364320`。

实际上，评估数据集将包含大量记录，因此您不会直观地进行这种比较。相反，你将利用一些方程式。

你可以通过计算损失来进行比较。损失是前面截图中实际值和预测值之间的差异。在数据挖掘中，它被称为距离度量。有各种方法来计算产生不同损失函数的距离度量。其中两个是:

*   曼哈顿距离
*   欧几里得距离

回归有多种损失函数，但在本书中，我们将着眼于两种常用的回归损失函数，它们是:

*   平均绝对误差(MAE)–这是基于曼哈顿距离
*   均方误差(MSE)–这是基于欧几里得距离

这些函数的目标是通过给你一个数值来衡量你的模型的有用性，这个数值显示了实际值和你的模型的预测值之间有多少偏差。

你的任务是训练新的模型，并保持较低的误差。在此之前，让我们快速介绍一些数据结构。

## 数据结构——向量和矩阵

在本节中，我们将研究不同的数据结构，如下所示。

### 标量

标量变量是一个简单的数字，如 23。每当你单独使用数字时，它们就是标量。您可以将它们赋给变量，如以下表达式所示:

```
temperature = 23
```

如果您必须存储 5 天的温度，您需要将这些值存储在 5 个不同的值中，如以下代码片段所示:

```
temp_1 = 23
temp_2 = 24
temp_3 = 23
temp_4 = 22
temp_5 = 22
```

在数据科学中，您会经常处理大量的数据点，例如一整年的每小时温度测量值。存储大量值的一种更有效的方法叫做向量。下一个主题我们来看看向量。

### 矢量

向量是标量的集合。考虑前面代码片段中的五种温度。向量是一种数据类型，它允许您将以前的所有温度收集到一个支持算术运算的变量中。向量看起来类似于 Python 列表，可以从 Python 列表中创建。考虑以下用于创建 Python 列表的代码片段:

```
temps_list = [23, 24, 23, 22, 22]
```

您可以使用来自`numpy`的`.array()`方法从列表中创建一个向量，首先导入`numpy`，然后使用下面的代码片段:

```
import numpy as np
temps_ndarray = np.array(temps_list)
```

您可以使用以下代码片段继续验证数据类型:

```
print(type(temps_ndarray))
```

代码片段将使编译器打印出以下内容:

![Figure 6.5: The temps_ndarray vector data type
](image/B15019_06_05.jpg)

图 6.5:temps _ ndarray 向量数据类型

您可以使用以下代码片段检查 vector 的内容:

```
print(temps_ndarray)
```

这将生成以下输出:

![Figure 6.6: The temps_ndarray vector
](image/B15019_06_06.jpg)

图 6.6:temps _ ndarray 向量

注意，输出包含单个方括号、`[`和`]`，数字由空格分隔。这不同于 Python 列表的输出，后者可以使用以下代码片段获得:

```
print(temps_list)
```

代码片段产生以下输出:

![Figure 6.7: List of elements in temps_list
](image/B15019_06_07.jpg)

图 6.7:temps _ List 中的元素列表

注意，输出包含单个方括号、`[`和`]`，数字用逗号分隔。

向量有形状和维度。这两者都可以通过使用以下代码片段来确定:

```
print(temps_ndarray.shape)
```

输出是一个称为元组的 Python 数据结构，如下所示:

![Figure 6.8: Shape of the temps_ndarray vector
](image/B15019_06_08.jpg)

图 6.8:temps _ ndarray 向量的形状

注意，输出由括号、`(`和`)`组成，带有一个数字和一个逗号。后跟逗号的单个数字意味着这个对象只有一个维度。数字的值是元素的个数。输出被读作“一个有五个元素的向量”这一点非常重要，因为它与矩阵有很大不同，我们接下来将讨论矩阵。

### 矩阵

矩阵也是由标量组成的，但它不同于标量，因为矩阵既有行又有列。如果你想到你一直在处理的 CSV 文件，那就是矩阵的一个很好的表示。文件中的特征数量将是矩阵中的列数，而文件中的行数将是矩阵中的行数。

有时候你需要在向量和矩阵之间转换。让我们重温一下`temps_ndarray`。你可能记得它有五个元素，因为形状是`(5,)`。要将其转换为一个五行一列的矩阵，可以使用下面的代码片段:

```
temps_matrix = temps_ndarray.reshape(-1, 1)
```

代码片段使用了`.reshape()`方法。第一个参数`-1`指示解释器保持第一个维度不变。第二个参数`1`，指示解释器添加一个新的维度。这个新维度就是列。要查看新形状，请使用以下代码片段:

```
print(temps_matrix.shape)
```

您将获得以下输出:

![Figure 6.9: Shape of the matrix
](image/B15019_06_09.jpg)

图 6.9:矩阵的形状

注意，元组现在有两个数字，`5`和`1`。第一个数字`5`代表行，第二个数字`1`代表列。您可以使用以下代码片段打印出矩阵的值:

```
print(temps_matrix)
```

代码的输出如下所示:

![Figure 6.10: Elements of the matrix
](image/B15019_06_10.jpg)

图 6.10:矩阵的元素

请注意，输出与向量的输出不同。首先，我们有一组外部方括号。然后，每一行的元素都用方括号括起来。每行只包含一个数字，因为矩阵只有一列。

您可以调整矩阵的形状，使其包含`1`行和`5`列，并使用以下代码片段打印出值:

```
print(temps_matrix.reshape(1,5))
```

输出如下所示:

![Figure 6.11: Reshaping the matrix
](image/B15019_06_11.jpg)

图 6.11:重塑矩阵

请注意，现在所有的数字都在一行上，因为这个矩阵有一行五列。外部方括号表示矩阵，而内部方括号表示行。

最后，您可以通过使用以下代码片段删除列，将矩阵转换回向量:

```
vector = temps_matrix.reshape(-1)
```

您可以打印出向量的值，以确认您得到了以下内容:

![Figure 6.12: The value of the vector
](image/B15019_06_12.jpg)

图 6.12:向量的值

请注意，您现在只有一组方括号。你仍然有相同数量的元素。

现在让我们来看一个重要的指标——R2 分数。

## R2 评分

R2 分数(读作“r 的平方”)有时被称为“分数”，衡量模型的决定系数。可以把它想象成模型做出良好可靠预测的能力。使用模型的`score()`方法来访问该度量，并且该度量可用于每个模型。

你的目标是用更高的 R2 分数训练连续的模型。R2 分数的范围在 **0** 和 **1** 之间。你的目标是尝试让模型的分数接近 **1** 。

## 练习 6.02:计算线性回归模型的 R2 分数

如前所述，R2 分数是评估模型性能的一个重要因素。因此，在本练习中，我们将创建一个线性回归模型，然后计算它的 R2 分数。

注意

您将在本章中使用的鱼类毒性数据集可以在我们的 GitHub 资源库中找到:[https://packt.live/2sNChvv](https://packt.live/2sNChvv)。

这个数据集取自 https://packt.live/2TSyJTB 的 UCI 机器学习库。

以下属性对我们的任务很有用:

*   CIC0
*   SM1 市
*   GATS1i
*   NdsCH
*   NdssC
*   MLOGP
*   定量反应，LC50[-对数(摩尔/升)]

以下步骤将帮助您完成练习:

1.  在这一步中，您将利用笔记本来编写和执行您的代码。
2.  Next, import the libraries mentioned in the following code snippet:

    ```
    # import libraries
    import pandas as pd
    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import LinearRegression
    ```

    在这一步中，您将导入`pandas`，您将使用它来读取您的数据。您还将导入`train_test_split()`，您将使用它将您的数据分成训练集和验证集，并且您将导入`LinearRegression`，您将使用它来训练您的模型。

3.  Now, read the data from the dataset:

    ```
    # column headers
    _headers = ['CIC0', 'SM1', 'GATS1i', 'NdsCH', 'Ndssc', 'MLOGP', 'response']
    # read in data
    df = pd.read_csv('https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter06/Dataset/qsar_fish_toxicity.csv', names=_headers, sep=';')
    ```

    在本步骤中，您将创建一个 Python 列表来保存数据中的列名。这样做是因为包含数据的 CSV 文件没有包含列标题的第一行。您继续读入文件，并使用 pandas 中的`read_csv()`方法将其存储在一个名为`df`的变量中。通过将列表传递给`names`参数，可以指定包含列标题的列表。这个 CSV 使用分号作为列分隔符，所以您可以使用`sep`参数来指定。您可以使用`df.head()`来查看数据帧的样子:

    ![Figure 6.13: The first five rows of the DataFrame
    ](image/B15019_06_13.jpg)

    图 6.13:数据帧的前五行

4.  Split the data into features and labels and into training and evaluation datasets:

    ```
    # Let's split our data
    features = df.drop('response', axis=1).values
    labels = df[['response']].values
    X_train, X_eval, y_train, y_eval = train_test_split(features, labels, test_size=0.2, random_state=0)
    X_val, X_test, y_val, y_test = train_test_split(X_eval, y_eval, random_state=0)
    ```

    在这一步中，您创建了两个名为`features`和`labels`的`numpy`数组。然后，您继续将它们拆分两次。第一次分割产生一个`training`集合和一个`evaluation`集合。第二次分割创建了一个`validation`集合和一个`test`集合。

5.  Create a linear regression model:

    ```
    model = LinearRegression()
    ```

    在这一步中，您创建了一个`LinearRegression`的实例，并将其存储在一个名为`model`的变量中。您将利用这一点在训练数据集上进行训练。

6.  Train the model:

    ```
    model.fit(X_train, y_train)
    ```

    在这一步中，您使用`fit()`方法和在*步骤 4* 中制作的训练数据集来训练模型。第一个参数是`features` NumPy 数组，第二个参数是`labels`。

    您应该会得到类似如下的输出:

    ![Figure 6.14: Training the model
    ](image/B15019_06_14.jpg)

    图 6.14:训练模型

7.  Make a prediction, as shown in the following code snippet:

    ```
    y_pred = model.predict(X_val)
    ```

    在这一步中，您将利用验证数据集进行预测。这存储在`y_pred`中。

8.  Compute the R2 score:

    ```
    r2 = model.score(X_val, y_val)
    print('R^2 score: {}'.format(r2))
    ```

    在这一步中，您将计算`r2`，这是模型的 R2 分数。使用模型的`score()`方法计算 R2 分数。下一行让解释器打印出 R2 分数。

    输出类似于以下内容:

    ![Figure 6.15: R2 score
    ](image/B15019_06_15.jpg)

    图 6.15: R2 分数

9.  你可以看到我们得到的 R2 分数是`0.530731`，并不接近 1。下一步，我们将进行比较。
10.  Compare the predictions to the actual ground truth:

    ```
    _ys = pd.DataFrame(dict(actuals=y_val.reshape(-1), predicted=y_pred.reshape(-1)))
    _ys.head()
    ```

    在这一步中，您粗略地看了一下与实际情况相比的预测。在*步骤 8* 中，您会注意到您为模型计算的 R2 分数远非完美(完美是 1 分)。在这一步中，在第一行中，您通过使用 pandas 中的`DataFrame`方法创建一个 DataFrame。您提供了一个字典作为参数。字典有两个键:`actuals`和`predicted`。`actuals`包含`y_vals`，它是验证数据集中的实际标签。`predicted`包含`y_pred`，包含预测。`y_vals`和`y_pred`都是二维矩阵，所以您可以使用`.reshape(-1)`将它们重塑为 1D 向量，这将删除第二个轴。

    第二行使解释器显示前五条记录。

    输出如下所示:

![Figure 6.16: The actual versus predicted values of the model
](image/B15019_06_16.jpg)

图 6.16:模型的实际值和预测值

在本练习中，我们计算了 R2 分数，这是一个可用于比较模型的评估指标。

在下一个主题中，我们将讨论平均绝对误差，这是另一个评估指标。

## 平均绝对误差

平均绝对误差(MAE)是回归模型的评估指标，用于测量预测值和实际值之间的绝对距离。绝对距离是与符号无关的距离，无论是正的还是负的。例如，如果地面实况是 6，而你预测的是 5，那么距离就是 1。但是，如果你预测 7，距离就变成了-1。在不考虑符号的情况下，绝对距离在两种情况下都是 1。这被称为**震级**。MAE 的计算方法是将所有的量值相加，然后除以观测值的数量。

## 练习 6.03:计算模型的 MAE

本练习的目的是使用与*练习 6.02* 相同的数据集来查找模型的得分和损失。

在本练习中，我们将计算模型的 MAE。

以下步骤将有助于您完成这项练习:

1.  打开一个新的 Colab 笔记本文件。
2.  Import the necessary libraries:

    ```
    # Import libraries
    import pandas as pd
    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import LinearRegression
    from sklearn.metrics import mean_absolute_error
    ```

    在这一步中，您从`sklearn.metrics`导入名为`mean_absolute_error`的函数。

3.  Import the data:

    ```
    # column headers
    _headers = ['CIC0', 'SM1', 'GATS1i', 'NdsCH', 'Ndssc', 'MLOGP', 'response']
    # read in data
    df = pd.read_csv('https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter06/Dataset/qsar_fish_toxicity.csv', names=_headers, sep=';')
    ```

    在前面的代码中，您读入了数据。这些数据是在线托管的，包含一些关于鱼类毒性的信息。数据存储为 CSV 格式，但不包含任何标题。此外，该文件中的列不是用逗号分隔，而是用分号分隔。名为`_headers`的 Python 列表包含列标题的名称。

    在下一行中，您将使用包含在`pandas`库中的函数`read_csv`来加载数据。第一个参数指定文件位置。第二个参数指定包含数据中列名的 Python 列表。第三个参数指定用于分隔数据中各列的字符。

4.  Split the data into `features` and `labels` and into training and evaluation sets:

    ```
    # Let's split our data
    features = df.drop('response', axis=1).values
    labels = df[['response']].values
    X_train, X_eval, y_train, y_eval = train_test_split(features, labels, test_size=0.2, random_state=0)
    X_val, X_test, y_val, y_test = train_test_split(X_eval, y_eval, random_state=0)
    ```

    在此步骤中，您将数据分为定型数据集、验证数据集和测试数据集。在第一行中，您分两步创建了一个`numpy`数组。在第一步中，`drop`方法接受一个参数，该参数带有要从 DataFrame 中删除的列的名称。在第二步中，使用`values`将 DataFrame 转换成一个二维的`numpy`数组，这是一个包含行和列的表格结构。这个数组存储在一个名为`features`的变量中。

    在第二行中，您将该列转换成一个包含您想要预测的标签的`numpy`数组。您可以通过从数据帧中挑选出列，然后使用`values`将其转换为`numpy`数组来实现。

    在第三行中，您使用`train_test_split`和 80:20 的比率分割`features`和`labels`。特征的训练数据包含在`X_train`中，标签的训练数据包含在`y_train`中。评估数据集包含在`X_eval`和`y_eval`中。

    在第四行，您使用`train_test_split`将评估数据集分为验证和测试。因为没有指定`test_size`，所以使用了一个值`25%`。验证数据存储在`X_val` 和`y_val`中，而测试数据存储在`X_test`和`y_test`中。

5.  Create a simple linear regression model and train it:

    ```
    # create a simple Linear Regression model
    model = LinearRegression()
    # train the model
    model.fit(X_train, y_train)
    ```

    在此步骤中，您将利用您的训练数据来训练模型。在第一行中，您创建了一个`LinearRegression`的实例，您称之为`model`。在第二行，你使用`X_train`和`y_train`训练模型。`X_train`包含`features`，而`y_train`包含`labels`。

6.  Now predict the values of our validation dataset:

    ```
    # let's use our model to predict on our validation dataset
    y_pred = model.predict(X_val)
    ```

    至此，您的模型已经可以使用了。您利用`predict`方法对您的数据进行预测。在这种情况下，您将把`X_val`作为参数传递给函数。回想一下，`X_va` l 是您的验证数据集。结果被分配给一个名为`y_pred`的变量，并将在下一步中用于计算模型的 MAE。

7.  Compute the MAE:

    ```
    # Let's compute our MEAN ABSOLUTE ERROR
    mae = mean_absolute_error(y_val, y_pred)
    print('MAE: {}'.format(mae))
    ```

    在这一步中，您通过使用`mean_absolute_error`函数并传入`y_val`和`y_pred`来计算模型的 MAE。`y_val`是提供给你的训练数据的标签，`y_pred` 是模型的预测。

    `y_val`和`y_pred`都是包含相同数量元素的`numpy`数组。`mean_absolute_error`功能从`y_val`中减去`y_pred`。这会产生一个新的数组。结果数组中的元素应用了 absolute 函数，因此所有负号都被删除。然后计算元素的平均值。

8.  Compute the R2 score of the model:

    ```
    # Let's get the R2 score
    r2 = model.score(X_val, y_val)
    print('R^2 score: {}'.format(r2))
    ```

    您应该会得到类似如下的输出:

    ![Figure 6.17: The MAE and R2 score of the model
    ](image/B15019_06_17.jpg)

图 6.17:模型的梅和 R2 评分

注意

梅伊和 R2 评分可能因数据集的分布而异。

更高的 R2 分数意味着更好的模型，并且使用计算决定系数的方程。

在本练习中，我们计算了 MAE，这是评估模型时的一个重要参数。

现在，您将训练第二个模型，并将其 R2 分数和 MAE 与第一个模型进行比较，以评估哪个模型的性能更好。

## 练习 6.04:计算第二个模型的平均绝对误差

在本练习中，我们将设计新功能，并找出新模型的得分和损失。

以下步骤将有助于您完成这项练习:

1.  打开一个新的 Colab 笔记本文件。
2.  Import the required libraries:

    ```
    # Import libraries
    import pandas as pd
    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import LinearRegression
    from sklearn.metrics import mean_absolute_error
    # pipeline
    from sklearn.pipeline import Pipeline
    # preprocessing
    from sklearn.preprocessing import MinMaxScaler
    from sklearn.preprocessing import StandardScaler
    from sklearn.preprocessing import PolynomialFeatures
    ```

    在第一步中，您将导入库，如`train_test_split`、`LinearRegression`和`mean_absolute_error`。我们利用管道快速转换我们的功能，并使用`MinMaxScaler`和`PolynomialFeatures`设计新功能。`MinMaxScaler`通过将所有值调整到 0 到 1 之间的范围来减少数据中的方差。它通过减去数据的平均值并除以范围(最大值减去最小值)来实现这一点。`PolynomialFeatures`将设计新功能，将列中的值提升到一定的幂，并在数据框架中创建新列来容纳它们。

3.  Read in the data from the dataset:

    ```
    # column headers
    _headers = ['CIC0', 'SM1', 'GATS1i', 'NdsCH', 'Ndssc', 'MLOGP', 'response']
    # read in data
    df = pd.read_csv('https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter06/Dataset/qsar_fish_toxicity.csv', names=_headers, sep=';')
    ```

    在这一步中，您将读入数据。虽然数据存储在 CSV 中，但它没有列出列名的第一行。名为`_headers`的 Python 列表将保存您将提供给名为`read_csv`的`pandas`方法的列名。

    在下一行中，您调用`read_csv` `pandas`方法并提供要读入的文件的位置和名称，以及文件头名称和文件分隔符。文件中的列用分号分隔。

4.  Split the data into training and evaluation sets:

    ```
    # Let's split our data
    features = df.drop('response', axis=1).values
    labels = df[['response']].values
    X_train, X_eval, y_train, y_eval = train_test_split(features, labels, test_size=0.2, random_state=0)
    X_val, X_test, y_val, y_test = train_test_split(X_eval, y_eval, random_state=0)
    ```

    在这一步中，首先将名为`df`的数据帧一分为二。第一个数据框架被称为`features`，它包含所有你将用来做预测的独立变量。第二个名为`labels`，包含您试图预测的值。

    在第三行，你使用`train_test_split`将`features`和`labels`分成四组。`X_train`和`y_train`包含 80%的数据，用于训练你的模型。`X_eval`和`y_eval`包含剩下的 20%。

    在第四行，你将`X_eval`和`y_eval`分成另外两组。`X_val`和`y_val`包含 75%的数据，因为您没有指定比率或大小。`X_test`和`y_test`包含剩下的 25%。

5.  Create a pipeline:

    ```
    # create a pipeline and engineer quadratic features
    steps = [
        ('scaler', MinMaxScaler()),
        ('poly', PolynomialFeatures(2)),
        ('model', LinearRegression())
    ]
    ```

    在这一步中，首先创建一个名为`steps`的 Python 列表。该列表包含三个元组，每个元组代表一个模型的转换。第一个元组表示缩放操作。元组中的第一项是步骤的名称，我们称之为`scaler`。这使用`MinMaxScaler`来转换数据。第二个称为`poly`，通过将数据列交叉到您指定的程度来创建附加特性。在本例中，您指定了`2`，因此它跨越这些列达到 2 的幂。接下来是你的`LinearRegression`型号。

6.  Create a pipeline:

    ```
    # create a simple Linear Regression model with a pipeline
    model = Pipeline(steps)
    ```

    在这一步中，您创建了一个`Pipeline`的实例，并将其存储在一个名为`model`的变量中。`Pipeline`执行一系列转换，这些转换在您在上一步中定义的步骤中指定。这个操作之所以有效，是因为变压器(`MinMaxScaler`和`PolynomialFeatures`)实现了两种方法`fit()`和`fit_transform()`。您可能还记得以前的例子，模型是使用`LinearRegression`实现的`fit()`方法训练的。

7.  Train the model:

    ```
    # train the model
    model.fit(X_train, y_train)
    ```

    在下一行，您调用`fit`方法并提供`X_train`和`y_train`作为参数。因为模型是一个管道，所以会发生三个操作。首先，`X_train`会被缩放。接下来，将设计附加功能。最后，将使用`LinearRegression`模型进行培训。此步骤的输出类似于以下内容:

    ![Figure 6.18: Training the model
    ](image/B15019_06_18.jpg)

    图 6.18:训练模型

8.  使用验证数据集进行预测:

    ```
    # let's use our model to predict on our validation dataset
    y_pred = model.predict(X_val)
    ```

9.  Compute the MAE of the model:

    ```
    # Let's compute our MEAN ABSOLUTE ERROR
    mae = mean_absolute_error(y_val, y_pred)
    print('MAE: {}'.format(mae))
    ```

    在第一行中，您利用`mean_absolute_error`来计算平均绝对误差。你提供`y_val`和`y_pred`，结果存储在`mae`变量中。在下面一行，你打印出`mae`:

    ![Figure 6.19: MAE score
    ](image/B15019_06_19.jpg)

    图 6.19: MAE 评分

    您在此步骤中计算的损失称为验证损失，因为您使用了验证数据集。这不同于使用训练数据集计算的训练损失。当您研究其他文档或书籍时，注意到这种区别是很重要的，因为它们可能会涉及到这两者。

10.  Compute the R2 score:

    ```
    # Let's get the R2 score
    r2 = model.score(X_val, y_val)
    print('R^2 score: {}'.format(r2))
    ```

    在最后两行中，您计算并显示了 R2 分数，如下面的屏幕截图所示:

    ![Figure 6.20: R2 score
    ](image/B15019_06_20.jpg)

图 6.20: R2 分数

此时，您应该看到第一个模型和第二个模型的`R` 2 分数和 MAE 之间的差异(在第一个模型中，`MAE`和`R` 2 分数分别为`0.781629`和`0.498688`)。

在本练习中，您设计了新功能，为您提供了一个具有更高多项式次数假设的模型。在某种程度上，这个模型应该比更简单的模型表现得更好。在设计和训练了新模型之后，您计算了 R2 分数和 MAE，您可以用它们来比较这个模型和您以前训练的模型。我们可以得出结论，该模型更好，因为它具有更高的 R2 分数和更低的 MAE。

### 其他评估指标

虽然我们使用了`mean_absolute_error`，但是还有其他模型评估函数用于回归。回想一下，这些都是成本(或损失)函数。这些包括`max_error`、`mean_squared_error`、`mean_squared_log_error`和`median_absolute_error`。如果你和一个数据科学家一起做一个项目，他们通常会负责告诉你使用什么评估指标。如果不是，那么你可以选择任何你喜欢的度量标准。

MAE 的计算方法是从基本事实中减去每个预测值，找到绝对值，将所有绝对值相加，然后除以观察值的数量。这种距离度量在数据挖掘中被称为曼哈顿距离。

均方误差(MSE)的计算方法是，取实际值和预测值之间差值的平方，将它们相加，然后除以观察值的数量。MSE 很大，有时使用它的平方根，即均方根误差(RMSE)。

均方对数误差(MSLE)通过在取对数之前将地面真实值和预测值都加 1，然后对差值求平方，然后求和，再除以观测值的数量，从而将对数引入到方程中。MSLE 的特性是，高于地面真相的预测比低于地面真相的预测成本更低。

最后，`median_absolute_error`找出绝对误差的中间值，即实际值和预测值之间的差异。

现在让我们来评估分类模型的性能。

# 评估分类模型的模型性能

分类模型用于预测一组特征将属于哪个类别。你在*第 3 章*、*二进制分类*中学习了创建二进制分类模型，在*第 4 章【随机森林多类分类】中学习了创建多类分类模型。*

当您考虑分类模型时，您可能会开始问自己该模型有多准确。但是如何评价准确性呢？

在开始评估之前，您需要创建一个分类模型。

## 练习 6.05:创建用于计算评估指标的分类模型

在本练习中，您将创建一个分类模型，稍后您将使用该模型进行模型评估。

您将使用来自 UCI 机器学习知识库的 cars 数据集。您将使用此数据集根据以下分类特征将汽车分类为可接受或不可接受:

*   `buying`:汽车的购买价格
*   `maint`:汽车的保养费用
*   `doors`:轿厢上的门数
*   `persons`:车辆的承载能力
*   `lug_boot`:行李箱的尺寸
*   `safety`: the estimated safety of the car

    注意

    你可以在这里找到数据集:[https://packt.live/30I594E](https://packt.live/30I594E)。

以下步骤将帮助您完成任务:

1.  打开一个新的 Colab 笔记本文件。
2.  Import the libraries you will need:

    ```
    # import libraries
    import pandas as pd
    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import LogisticRegression
    ```

    在这一步中，您导入`pandas`并将其别名为`pd`。`pandas`用于将数据读入数据帧。您还需要导入`train_test_split`，这是将您的数据分割成训练和评估数据集所需要的。最后，您还导入了`LogisticRegression`类。

3.  Import your data:

    ```
    # data doesn't have headers, so let's create headers
    _headers = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'car']
    # read in cars dataset
    df = pd.read_csv('https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter06/Dataset/car.data', names=_headers, index_col=None)
    df.head()
    ```

    在这一步中，您将创建一个名为`_headers`的 Python 列表来保存将要导入的文件中的列名，因为该文件没有标题。然后，通过使用`pd.read_csv`并指定文件位置以及包含文件头的列表，将文件读入名为`df`的数据帧。最后，使用`df.head()`显示前五行。

    您应该会得到类似如下的输出:

    ![Figure 6.21: Inspecting the DataFrame
    ](image/B15019_06_21.jpg)

    图 6.21:检查数据帧

4.  Encode categorical variables as shown in the following code snippet:

    ```
    # encode categorical variables
    _df = pd.get_dummies(df, columns=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'])
    _df.head()
    ```

    在这一步中，您将使用一种称为 one-hot 编码的技术将分类列转换为数值列。你在*练习 3.04* 的*步骤 13* 中看到了这样的例子。您需要这样做，因为模型的输入必须是数字。您可以使用来自`pandas`库的`get_dummies`从分类变量中获得数值变量。您提供数据帧作为输入，并指定要编码的列。您将结果分配给一个名为`_df`的新数据帧，然后使用`head()`检查结果。

    输出现在应该类似于下面的屏幕截图:

    ![Figure 6.22: Encoding categorical variables
    ](image/B15019_06_22.jpg)

    图 6.22:编码分类变量

    注意

    出于演示目的，输出已被截断。请在[https://packt.live/3aBNlg7](https://packt.live/3aBNlg7)找到完整的输出。

5.  Split the data into training and validation sets:

    ```
    # split data into training and evaluation datasets
    features = _df.drop('car', axis=1).values
    labels = _df['car'].values
    X_train, X_eval, y_train, y_eval = train_test_split(features, labels, test_size=0.3, random_state=0)
    X_val, X_test, y_val, y_test = train_test_split(X_eval, y_eval, test_size=0.5, random_state=0)
    ```

    在这一步中，首先将特性列和标签提取到两个名为`features`和`labels`的 NumPy 数组中。然后你开始抽取 70%给`X_train`和`y_train`，剩下的 30%给`X_eval`和`y_eval`。然后你进一步将`X_eval`和`y_eval`分成两个相等的部分，将它们分配给`X_val`和`y_val`进行验证，将`X_test`和`y_test`分配给稍后的测试。

6.  Train a logistic regression model:

    ```
    # train a Logistic Regression model
    model = LogisticRegression()
    model.fit(X_train, y_train)
    ```

    在这一步中，您创建了一个`LogisticRegression`的实例，并通过将`X_train`和`y_train`传递给`fit`方法来根据您的训练数据训练模型。

    您应该会得到如下所示的输出:

    ![Figure 6.23: Training a logistic regression model
    ](image/B15019_06_23.jpg)

    图 6.23:训练逻辑回归模型

7.  Make a prediction:

    ```
    # make predictions for the validation set
    y_pred = model.predict(X_val)
    ```

    在这一步中，您对验证数据集`X_val`进行预测，并将结果存储在`y_pred`中。查看前 10 个预测应该会得到类似如下的输出:

    ![Figure 6.24: Prediction for the validation set
    ](image/B15019_06_24.jpg)

图 6.24:验证集的预测

这个模型之所以有效，是因为你可以用它来做预测。预测基于汽车的特征将每辆汽车分类为可接受(`acc`)或不可接受(`unacc`)。此时，您已经准备好对模型应用各种评估了。

因此，我们已经成功地创建了一个分类模型来进行预测，并且我们将在未来的练习中评估该模型的性能。

在本练习中，我们对这个逻辑回归模型进行了一次训练，这样我们就不需要因为涉及的步骤数量而重复进行训练。在下一节中，您将看到混淆矩阵。

# 混乱矩阵

你在*第三章二进制分类*中遇到了混淆矩阵。您可能还记得，混淆矩阵将模型预测的类的数量与这些类在验证数据集中的实际出现次数进行了比较。输出是一个正方形矩阵，其行数和列数等于您预测的类数。列代表实际值，而行代表预测值。通过使用来自`sklearn.metrics`的`confusion_matrix`可以得到一个混淆矩阵。

## 练习 6.06:为分类模型生成混淆矩阵

本练习的目标是为您在*练习 6.05* 中训练的分类模型创建一个混淆矩阵。

以下步骤将帮助您完成任务:

1.  打开一个新的 Colab 笔记本文件。
2.  Import `confusion_matrix`:

    ```
    from sklearn.metrics import confusion_matrix
    ```

    在这一步中，您从`sklearn.metrics`导入`confusion_matrix`。这个函数可以让你生成一个混淆矩阵。

3.  Generate a confusion matrix:

    ```
    confusion_matrix(y_val, y_pred)
    ```

    在这一步中，您通过提供实际类`y_val`和预测类`y_pred`来生成混淆矩阵。

    输出应该类似于以下内容:

    ![Figure 6.25: Confusion matrix
    ](image/B15019_06_25.jpg)

图 6.25:混淆矩阵

我们可以看到我们的数据有四类。第一列显示应该属于第一类的所有数据。第一行显示了正确放置在第一类中的预测数。在这个例子中，这个数字是`48`。第二行显示了放在第二类中但应该在第一类中的预测数。在这个例子中，这个数字是`7`。在第三行中，您会看到预计属于第三类但本应属于第一类的项目数量。那个号码是`3`。最后，在第四行中，您会看到错误地归类到第四类的项目数量，而这些项目本应属于第一类。在这种情况下，编号为`5`。

### 关于混淆矩阵的更多信息

混淆矩阵帮助您分析如果将模型投入生产，您必须做出的选择的影响。让我们考虑基于模型的输入来预测疾病存在的例子。这是一个二元分类问题，1 表示疾病存在，0 表示疾病不存在。这个模型的混淆矩阵有两列和两行。

第一列将显示属于类别 **0** 的项目。第一行将显示被正确分类到类别 **0** 并被称为`true negatives`的项目。第二行将显示被错误分类为 **1** 但应该是 **0** 的项目。这些是`false positives`。

第二列将显示属于类别 **1** 的项目。第一行将显示错误分类为 0 类的项目，而它们本应是 **1** 并被称为 `false negatives`。最后，第二行显示了被正确分类到类别 1 并被称为`true positives`的项目。

假阳性是指样本实际上是健康的，却被错误地预测为被感染。这意味着这些病例将被治疗他们没有的疾病。

假阴性是指那些被错误地预测为健康的病例，而实际上他们已经患病。这意味着这些病例不会因为他们实际患有的疾病而得到治疗。

关于这个模型，你需要问的问题取决于疾病的性质，并且需要关于疾病的领域专业知识。例如，如果疾病是传染性的，那么未经治疗的病例将被释放到普通人群中，并可能感染其他人。与将病例隔离并观察其症状相比，这意味着什么？

另一方面，如果这种疾病没有传染性，那么问题就变成了对没有患病的人进行治疗的影响与不对患病病例进行治疗的影响。

很明显，这些问题没有明确的答案。需要对模型进行调整，以提供用户可以接受的性能。

## 精度

精度在*第 3 章，二进制分类*中介绍；然而，我们将在本章中更详细地研究它。精度是被正确分类为阳性的案例总数(称为真阳性，缩写为 TP)除以该预测中的案例总数(即，该行中正确分类(TP)和错误分类(FP)的条目总数)。假设 10 个条目被分类为阳性。如果 7 个条目实际上是正的，那么 TP 将是 7，FP 将是 3。因此，精度应为 0.7。该方程式如下所示:

![Figure 6.26: Equation for precision
](image/B15019_06_26.jpg)

图 6.26:精度方程

在前面的等式中:

*   `tp`为真阳性–被正确分类为属于该类别的预测数。
*   `fp`为假阳性–被错误分类为属于该类别的预测数。
*   `sklearn.metrics`中计算精度的函数称为`precision_score`。去试一试吧。

## 练习 6.07:计算分类模型的精度

在本练习中，您将计算您在*练习 6.04* 中训练的分类模型的精度。

以下步骤将帮助您完成任务:

1.  Import the required libraries:

    ```
    from sklearn.metrics import precision_score
    ```

    在这一步中，您从`sklearn.metrics`导入`precision_score`。

2.  Next, compute the precision score as shown in the following code snippet:

    ```
    precision_score(y_val, y_pred, average='macro')
    ```

    在这一步中，使用`precision_score`计算精度分数。

    输出是一个介于 0 和 1 之间的浮点数。它可能看起来像这样:

    ![Figure 6.27: Precision score
    ](image/B15019_06_27.jpg)

图 6.27:精度分数

注意

精度分数可能因数据而异。

在本练习中，您会看到分类模型的精度分数是`0.9245`。 **92%** 可能是一个不错的分数，在某些领域是可以接受的，但在某些领域是一个较低的分数。所以还有改进的余地。

把精度分数想成是问这个模型多久对一个类做出一次正确的预测？该值需要比我们刚刚获得的分数更接近 1。

## 回忆

召回率是正确预测的总数除以该类别的正确和错误预测数。把它想成是真正的正数除以列中条目的总和。该方程式如下所示:

![Figure 6.28: Equation for recall
](image/B15019_06_28.jpg)

图 6.28:召回方程式

此功能为`recall_score`，可从`sklearn.metrics`获得。

## 练习 6.08:计算分类模型的召回率

本练习的目标是计算您在*练习 6.04* 中训练的分类模型的召回率。

以下步骤将帮助您完成任务:

1.  打开一个新的 Colab 笔记本文件。
2.  Now, import the required libraries:

    ```
    from sklearn.metrics import recall_score
    ```

    在这一步中，您从`sklearn.metrics`导入`recall_score`。这是您将在第二步中使用的函数。

3.  Compute the recall:

    ```
    recall_score(y_val, y_pred, average='macro')
    ```

    在这一步中，您使用`recall_score`来计算召回。你需要指定`y_val`和`y_pred`作为函数的参数。`recall_score`的文档解释了可以提供给`average`的值。如果你的模型做二元预测，标签是`0`和`1`，可以设置`average`到`binary`。其他选项有`micro`、`macro`、`weighted`和`samples`。您应该阅读文档，看看它们是做什么的。

    您应该会得到如下所示的输出:

    ![Figure 6.29: Recall score
    ](image/B15019_06_29.jpg)

图 6.29:回忆分数

注意

根据数据的不同，召回分数会有所不同。

如你所见，我们已经计算了练习中的回忆分数，即`0.622`。这意味着在预测的类别总数中，有`62%`个被正确预测。在与另一个模型的召回分数进行比较之前，这个值本身可能没有多大意义。

现在让我们来计算 F1 分数，这也非常有助于评估模型性能，进而有助于在选择模型时做出更好的决策。

## F1 分数

F1 分数是帮助我们评估模型性能的另一个重要参数。它使用下面的等式来考虑精确度和召回率的贡献:

![Figure 6.30: F1 score
](image/B15019_06_30.jpg)

图 6.30: F1 得分

F1 分数范围从 0 到 1，1 是可能的最佳分数。您使用`sklearn.metrics`中的`f1_score`计算 F1 分数。

## 练习 6.09:计算分类模型的 F1 分数

在本练习中，您将计算您在*练习 6.04* 中训练的分类模型的 F1 分数。

以下步骤将帮助您完成任务:

1.  打开一个新的 Colab 笔记本文件。
2.  Import the necessary modules:

    ```
    from sklearn.metrics import f1_score
    ```

    在这一步中，您从`sklearn.metrics`导入`f1_score`方法。此分数将允许您计算评估指标。

3.  Compute the F1 score:

    ```
    f1_score(y_val, y_pred, average='macro')
    ```

    在这一步中，您通过传入`y_val`和`y_pred`来计算 F1 分数。您还指定了`average='macro'`，因为这不是二进制分类。

    您应该会得到类似如下的输出:

    ![Figure 6.31: F1 score
    ](image/B15019_06_31.jpg)

图 6.31: F1 得分

在本练习结束时，您将看到我们获得的`F1`分数是`0.6746`。有很大的改进空间，你会设计新的功能，训练新的模型，试图获得更好的 F1 成绩。

## 精确度

准确性是应用于分类模型的评估标准。它是通过计算正确预测的标签数来计算的，这意味着预测的标签与地面实况完全相同。`accuracy_score()`函数存在于`sklearn.metrics`中来提供这个值。

## 练习 6.10:计算分类模型的模型精度

本练习的目标是计算在*练习 6.04* 中训练的模型的准确度分数。

以下步骤将帮助您完成任务:

1.  从笔记本中*练习 6.04* 的代码结束处继续。
2.  Import `accuracy_score()`:

    ```
    from sklearn.metrics import accuracy_score
    ```

    在这一步中，您将导入`accuracy_score()`，您将使用它来计算模型精度。

3.  Compute the accuracy:

    ```
    _accuracy = accuracy_score(y_val, y_pred)
    print(_accuracy)
    ```

    在这一步中，您通过将`y_val`和`y_pred`作为参数传递给`accuracy_score()`来计算模型精度。解释器将结果分配给一个名为`c`的变量。`print()`方法使解释器呈现`_accuracy`的值。

    结果类似于以下内容:

    ![Figure 6.32: Accuracy score
    ](image/B15019_06_32.jpg)

图 6.32:准确度得分

因此，我们已经成功地计算出模型的精度为`0.876`。本练习的目标是向您展示如何计算模型的精度，并将该精度值与您将在未来训练的另一个模型的精度值进行比较。

## 对数损失

对数损失(或对数损失)是分类模型的损失函数。它也被称为范畴交叉熵。它试图惩罚不正确的预测。`sklearn`文档将其定义为“给定模型预测的真实值的负对数似然性。”

## 练习 6.11:计算分类模型的对数损失

本练习的目标是预测在*练习 6.04* 中训练的模型的对数损失。

以下步骤将帮助您完成任务:

1.  打开您的 Colab 笔记本，从*练习 6.04* 停止的地方继续。
2.  Import the required libraries:

    ```
    from sklearn.metrics import log_loss
    ```

    在这一步中，您从`sklearn.metrics`导入`log_loss()`。

3.  计算测井损失:

    ```
    _loss = log_loss(y_val, model.predict_proba(X_val))
    print(_loss)
    ```

在这一步中，您计算日志损失并将其存储在一个名为`_loss`的变量中。你需要观察一些非常重要的东西:之前，你使用了`y_val`，地面真相，和`y_pred`，预测。

在这一步中，您不需要使用预测。相反，你利用预测的概率。您可以在指定`model.predict_proba()`的代码中看到这一点。您指定验证数据集，它返回预测的概率。

`print()`函数使解释器呈现日志丢失。

这应该如下所示:

![Figure 6.33: Log loss output
](image/B15019_06_33.jpg)

图 6.33:日志丢失输出

注意

不同数据的损失值可能不同。

因此，我们已经成功地计算了分类模型的`log_loss`。

# 接收机工作特性曲线

回想一下我们之前讨论过的真实正利率。也叫**灵敏度**。还记得我们尝试用逻辑回归模型做的事情是找到一个阈值，在该阈值之上，我们预测我们的输入属于某个类别，而在该阈值之下，我们预测它不属于某个类别。

受试者工作特征(ROC)曲线是一个曲线图，显示了当阈值改变时，模型的真阳性率和假阳性率如何变化。

让我们做一个练习来增强对 ROC 曲线的理解。

## 练习 6.12:计算并绘制二元分类问题的 ROC 曲线

本练习的目标是绘制二元分类问题的 ROC 曲线。这个问题的数据用于预测母亲是否需要剖腹产分娩。

注意

您将在本章中使用的数据集可以在我们的 GitHub 资源库中找到:[https://packt.live/36dyEg5](https://packt.live/36dyEg5)。

从 UCI 机器学习库中，该数据集的摘要如下:“该数据集包含关于 80 名孕妇的剖腹产结果的信息，这些孕妇具有医学领域中分娩问题的最重要特征。”感兴趣的属性是年龄、分娩次数、分娩时间、血压和心脏状态。

以下步骤将帮助您完成这项任务:

1.  打开 Colab 笔记本文件。
2.  Import the required libraries:

    ```
    # import libraries
    import pandas as pd
    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import LogisticRegression
    ```

    在这一步中，您将导入`pandas`，您将使用它来读入数据。您还可以导入`train_test_split`来创建训练和验证数据集，导入`LogisticRegression`来创建模型。

3.  Read in the data:

    ```
    # data doesn't have headers, so let's create headers
    _headers = ['Age', 'Delivery_Nbr', 'Delivery_Time', 'Blood_Pressure', 'Heart_Problem', 'Caesarian']
    # read in cars dataset
    df = pd.read_csv('https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter06/Dataset/caesarian.csv.arff', names=_headers, index_col=None, skiprows=15)
    df.head()
    # target column is 'Caesarian'
    ```

    在这一步中，您读入数据。数据集的格式很有趣。底部包含 CSV 格式的数据，但上部包含一些文件描述符。如果您从[https://packt.live/38qJe4A](https://packt.live/38qJe4A)下载并打开该文件，并使用记事本打开该文件，您将看到以下内容:

    ![Figure 6.34: Reading the dataset
    ](image/B15019_06_34.jpg)

    图 6.34:读取数据集

    您需要做一些事情来处理这个文件。跳过 15 行并指定列标题，读取没有索引的文件。

    代码展示了如何通过创建一个 Python 列表来保存列标题，然后使用`read_csv()`读入文件。您传入的参数是文件的位置、Python 列表形式的列标题、索引列的名称(在本例中为 None)以及要跳过的行数。

    `head()`方法将打印出前五行，看起来应该如下所示:

    ![Figure 6.35: The top five rows of the DataFrame
    ](image/B15019_06_35.jpg)

    图 6.35:数据框的前五行

4.  Split the data:

    ```
    # target column is 'Caesarian'
    features = df.drop(['Caesarian'], axis=1).values
    labels = df[['Caesarian']].values
    # split 80% for training and 20% into an evaluation set
    X_train, X_eval, y_train, y_eval = train_test_split(features, labels, test_size=0.2, random_state=0)
    # further split the evaluation set into validation and test sets of 10% each
    X_val, X_test, y_val, y_test = train_test_split(X_eval, y_eval, test_size=0.5, random_state=0)
    ```

    在这一步中，首先创建两个`numpy`数组，分别称为`features`和`labels`。然后将这些数组分成一个`training`和一个`evaluation`数据集。您进一步将`evaluation`数据集分成`validation`和`test`数据集。

5.  Now, train and fit a logistic regression model:

    ```
    model = LogisticRegression()
    model.fit(X_train, y_train)
    ```

    在此步骤中，首先创建一个逻辑回归模型的实例。然后，继续在训练数据集上训练或拟合模型。

    输出应该类似于以下内容:

    ![Figure 6.36: Training a logistic regression model
    ](image/B15019_06_36.jpg)

    图 6.36:训练逻辑回归模型

6.  Predict the probabilities, as shown in the following code snippet:

    ```
    y_proba = model.predict_proba(X_val)
    ```

    在这一步中，模型预测验证数据集中每个条目的概率。它将结果存储在`y_proba`中。

7.  Compute the true positive rate, the false positive rate, and the thresholds:

    ```
    _false_positive, _true_positive, _thresholds = roc_curve(y_val, y_proba[:, 0])
    ```

    在这一步中，您调用`roc_curve()`并指定基本事实和预测概率的第一列。结果是假阳性率、真阳性率和阈值的元组。

8.  Explore the false positive rates:

    ```
    print(_false_positive)
    ```

    在这一步中，您指示解释器打印出假阳性率。输出应该类似于以下内容:

    ![Figure 6.37: False positive rates
    ](image/B15019_06_37.jpg)

    图 6.37:假阳性率

    注意

    假阳性率可能因数据而异。

9.  Explore the true positive rates:

    ```
    print(_true_positive)
    ```

    在这一步中，您指示解释器打印出真正的阳性率。这应该类似于以下内容:

    ![Figure 6.38: True positive rates
    ](image/B15019_06_38.jpg)

    图 6.38:真实正比率

10.  Explore the thresholds:

    ```
    print(_thresholds)
    ```

    在这一步中，您指示解释器显示阈值。输出应该类似于以下内容:

    ![Figure 6.39: Thresholds
    ](image/B15019_06_39.jpg)

    图 6.39:阈值

11.  Now, plot the ROC curve:

    ```
    # Plot the RoC
    import matplotlib.pyplot as plt
    %matplotlib inline
    plt.plot(_false_positive, _true_positive, lw=2, label='Receiver Operating Characteristic')
    plt.xlim(0.0, 1.2)
    plt.ylim(0.0, 1.2)
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic')
    plt.show()
    ```

    在这一步中，您导入`matplotlib.pyplot`作为您的绘图库。你把它别名为`plt`。然后，通过指定假阳性率和真阳性率来绘制折线图。代码的其余部分用标题以及水平轴和垂直轴的标签来修饰图表。

    输出应该类似于以下内容:

    ![Figure 6.40: ROC curve
    ](image/B15019_06_40.jpg)

图 6.40: ROC 曲线

在本练习中，您学习了绘制模型的真阳性率和假阳性率随着预测阈值的变化而变化的曲线。回想一下，模型的作用是输出一个 0 到 1 之间的值。这个值称为 logit。作为一名数据科学家，您的工作是确定一个阈值，例如 0.5。如果 logit 高于该阈值，则预测输入属于一个类别(如果是正或负预测，则为正)。如果 logit 低于阈值，您将预测输入属于负类。

例如，如果阈值为 0.5，则 0.33 的 logit 预测为负，而 0.80 的 logit 预测为正。

但是，如果您的阈值为 0.95，则 0.33 的 logit 预测为负，0.80 的 logit 仍然预测为负。

现在，回想一下，您希望您的模型做的是正确分类尽可能多的数据点。分类由您选择的阈值控制。来自模型的 logit(预测概率)将总是相同的，但是分配给预测的类别将取决于阈值。

当您改变阈值时，预测会改变，真阳性和真阴性的数量也会改变。

RoC 向您展示了真阳性和真阴性的百分比如何随着阈值从 0 到 1 的变化而变化。

阈值越高，在将预测归类为肯定之前，模型就需要越有信心。回想一下，logit 是输入属于某个类的概率，是一个从 0 到 1 的置信度得分。

# ROC 曲线下面积

受试者工作特征曲线下的面积(ROC AUC)是对模型将随机选择的阳性样本排序高于随机选择的阴性样本的可能性的度量。换句话说，这个度量值越高，模型就越能准确预测负面类别为负面，正面类别为正面。该值的范围从 0 到 1。如果 AUC 为 0.6，这意味着该模型有 60%的概率基于输入正确区分负类和正类。该度量用于比较模型。

## 练习 6.13:计算剖腹产数据集的 ROC AUC

本练习的目标是计算您在*练习 6.12* 中训练的二元分类模型的 ROC AUC。

以下步骤将帮助您完成任务:

1.  打开一个 Colab 笔记本，找到*练习 6.12* 的代码，继续编写代码。
2.  Predict the probabilities:

    ```
    y_proba = model.predict_proba(X_val)
    ```

    在这一步中，您将计算验证数据集中类的概率。您将结果存储在`y_proba`中。

3.  Compute the ROC AUC:

    ```
    from sklearn.metrics import roc_auc_score
    _auc = roc_auc_score(y_val, y_proba[:, 0])
    print(_auc)
    ```

    在这一步中，您计算 ROC AUC 并将结果存储在`_auc`中。然后将这个值打印出来。结果应该类似于以下内容:

    ![Figure 6.41: Computing the ROC AUC
    ](image/B15019_06_41.jpg)

图 6.41:计算 ROC AUC

注意

AUC 可能不同，取决于数据。

在本练习中，您学习了如何计算 ROC AUC，它是对模型将随机选择的正面示例排序高于随机选择的负面示例的可能性的度量。在这个例子中，AUC 是 0.1944，这个模型还有改进的余地。

当您选择完一个模型后，您可能会有兴趣保存它以供将来使用。下一个主题探索保存和加载模型。

# 保存和加载模型

您最终需要将您训练的一些模型转移到不同的计算机上，以便它们可以投入生产。有各种各样的实用程序可以做到这一点，但是我们将要讨论的这个实用程序叫做`joblib`。

`joblib`支持保存和加载模型，它以其他机器学习架构支持的格式保存模型，如`ONNX`。

`joblib`位于`sklearn.externals`模块中。

## 练习 6.14:保存和加载模型

在本练习中，您将训练一个简单的模型并将其用于预测。然后，您将继续保存模型，然后将其重新加载。您将使用加载的模型进行第二次预测，然后将第一个模型的预测与第二个模型的预测进行比较。在本练习中，您将使用汽车数据集。

以下步骤将引导你实现目标:

1.  打开 Colab 笔记本。
2.  导入所需的库:

    ```
    import pandas as pd
    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import LinearRegression
    ```

3.  读入数据:

    ```
    _headers = ['CIC0', 'SM1', 'GATS1i', 'NdsCH', 'Ndssc', 'MLOGP', 'response']
    # read in data
    df = pd.read_csv('https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter06/Dataset/qsar_fish_toxicity.csv', names=_headers, sep=';')
    ```

4.  Inspect the data:

    ```
    df.head()
    ```

    输出应该类似于以下内容:

    ![Figure 6.42: Inspecting the first five rows of the DataFrame
    ](image/B15019_06_42.jpg)

    图 6.42:检查数据帧的前五行

5.  将数据分成`features`和`labels`，并分成训练集和验证集:

    ```
    features = df.drop('response', axis=1).values
    labels = df[['response']].values
    X_train, X_eval, y_train, y_eval = train_test_split(features, labels, test_size=0.2, random_state=0)
    X_val, X_test, y_val, y_test = train_test_split(X_eval, y_eval, random_state=0)
    ```

6.  Create a linear regression model:

    ```
    model = LinearRegression()
    ```

    输出如下所示:

    ![Figure 6.43: Training a linear regression model
    ](image/B15019_06_43.jpg)

    图 6.43:训练线性回归模型

7.  将训练数据拟合到模型:

    ```
    model.fit(X_train, y_train)
    ```

8.  使用模型进行预测:

    ```
    y_pred = model.predict(X_val)
    ```

9.  导入`joblib` :

    ```
    from sklearn.externals import joblib
    ```

10.  Save the model:

    ```
    joblib.dump(model, './model.joblib')
    ```

    输出应该类似于以下内容:

    ![Figure 6.44: Saving the model
    ](image/B15019_06_44.jpg)

    图 6.44:保存模型

11.  将其作为新模型加载:

    ```
    m2 = joblib.load('./model.joblib')
    ```

12.  使用新模型进行预测:

    ```
    m2_preds = m2.predict(X_val)
    ```

13.  Compare the predictions:

    ```
    ys = pd.DataFrame(dict(predicted=y_pred.reshape(-1), m2=m2_preds.reshape(-1)))
    ys.head()
    ```

    输出应该类似于以下内容:

    ![Figure 6.45: Comparing predictions
    ](image/B15019_06_45.jpg)

图 6.45:比较预测

您可以看到，模型保存前的预测与模型保存并重新加载后的预测完全相同。可以得出结论，保存和加载模型不会影响它们的质量。

在本练习中，您学习了如何保存和加载模型。您还检查并确认了模型预测即使在保存和加载时也保持不变。

## 活动 6.01:训练三种不同的模型，并使用评估标准挑选出表现最佳的模型

你在一家银行担任数据科学家。该银行希望实施一个模型来预测客户购买定期存款的可能性。银行给你提供一个数据集，与*第三章*、*二元分类*中的数据集相同。您之前已经学习了如何为二元分类训练逻辑回归模型。您还听说过其他非参数建模技术，并且想要尝试决策树和随机森林，以查看它们在您一直在训练的逻辑回归模型中的表现如何。

在本活动中，您将训练一个逻辑回归模型并计算一个分类报告。然后，您将继续训练决策树分类器并计算分类报告。您将使用分类报告来比较这些模型。最后，您将训练一个随机森林分类器并生成分类报告。然后，使用分类报告将逻辑回归模型与随机森林进行比较，以确定应该将哪个模型投入生产。

完成这项任务的步骤是:

1.  打开 Colab 笔记本。
2.  加载必要的库。
3.  读入数据。
4.  探索数据。
5.  使用`pandas.get_dummies()`转换分类变量。
6.  准备`X`和`y`变量。
7.  将数据分成训练集和评估集。
8.  创建一个`LogisticRegression`的实例。
9.  将训练数据拟合到`LogisticRegression`模型。
10.  使用评估集进行预测。
11.  使用来自`LogisticRegression`模型的预测来计算分类报告。
12.  创建一个`DecisionTreeClassifier` :

    ```
    dt_model = DecisionTreeClassifier(max_depth= 6)
    ```

    的实例
13.  将训练数据拟合到`DecisionTreeClassifier`模型:

    ```
    dt_model.fit(train_X, train_y)
    ```

14.  使用`DecisionTreeClassifier`模型，对评估数据集进行预测:

    ```
    dt_preds = dt_model.predict(val_X)
    ```

15.  Use the prediction from the `DecisionTreeClassifier` model to compute the classification report:

    ```
    dt_report = classification_report(val_y, dt_preds)
    print(dt_report)
    ```

    注意

    我们将在*第 7 章，机器学习模型的推广*中详细研究决策树。

16.  比较线性回归模型的分类报告和决策树分类器的分类报告，以确定哪个模型更好。
17.  创建一个`RandomForestClassifier`的实例。
18.  将训练数据拟合到`RandomForestClassifier`模型。
19.  使用`RandomForestClassifier`模型，对评估数据集进行预测。
20.  使用来自随机森林分类器的预测，计算分类报告。
21.  将线性回归模型的分类报告与随机森林分类器的分类报告进行比较，以决定保留或改进哪个模型。
22.  比较所有三个模型的 R2 分数。输出应该类似于下面:![Figure 6.46: Comparing the R2 scores
    ](image/B15019_06_46.jpg)

图 6.46:比较 R2 分数

注意

这个活动的解决方案可以在以下地址找到:[https://packt.live/2GbJloz](https://packt.live/2GbJloz)。

# 总结

分类模型的一些评估指标需要二进制分类模型。如果你使用两个以上的类，你将需要使用一个对全部。一对一方法为每个类建立一个模型，并尝试预测输入属于特定类的概率。然后，您将预测该输入属于模型预测概率最高的类别。

ROC 和 ROC AUC 仅适用于二元分类。

如果您想知道为什么我们将评估数据集一分为二，这是因为`X_test`和`y_test`用于模型性能的最终评估。在将模型投入生产之前，您可以使用它们来查看模型在生产环境中的表现。

你已经学会了如何通过观察损失的变化来评估回归模型的质量。您看到了使用 MAE 的例子，也了解了 MSE 的存在。

您还学习了如何在活动中评估分类模型的质量。

在下一章中，您将学习如何使用交叉验证来训练多个模型，并实现正则化技术。