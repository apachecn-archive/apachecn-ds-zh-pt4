<title>C15019_04_Final_ePub_SW</title> <link href="css/epub.css" rel="stylesheet" type="text/css">

# 4。随机森林多类分类

概述

本章将向你展示如何使用随机森林算法训练一个多类分类器。您还将看到如何评估多类模型的性能。本章结束时，您将能够调整随机森林的关键超参数，并将数据分成训练/测试集。

# 简介

在前一章中，您看到了如何使用著名的**逻辑回归**算法构建二进制分类器。二元分类器的响应变量只能有两个不同的值，例如 0 和 1 或者是和否。多类分类任务只是一个扩展。它的响应变量可以有两个以上不同的值。

在数据科学行业，您经常会面临多类分类问题。例如，如果你在为网飞或任何其他流媒体平台工作，你必须建立一个模型，根据关键属性(如流派、时长或演员)预测电影的用户评级。一个潜在的评分值列表可能是:*讨厌它*，*不喜欢它*，*中立*，*喜欢* *it* ，*喜欢它*。该模型的目标是从这五个可能的值中预测正确的评级。

多类分类并不总是意味着响应变量将是文本。在一些数据集中，目标变量可以被编码成数字形式。以所讨论的同一个例子为例，评级可以从 1 到 5 编码:1 代表*讨厌它*，2 代表*不喜欢它*，3 代表*中立*，等等。所以，在得出这是一个回归问题的结论之前，先理解这个响应变量的含义是很重要的。

在下一节中，我们将着眼于训练我们的第一个随机森林分类器。

# 训练随机森林分类器

在本章中，我们将使用随机森林算法进行多类分类。市场上还有其他算法，但随机森林可能是此类项目中最受欢迎的算法之一。

随机森林方法最早是由 Tin Kam Ho 在 1995 年提出的，但最早是由 Leo Breiman 在 2001 年提出的。

所以随机森林本质上并不是一个新的算法。它已经使用了近 20 年。但由于其性能和简单性，它的受欢迎程度并没有减弱。

在本章中，我们将使用一个名为“基于多传感器数据的活动识别系统”的数据集最初由 *F. Palumbo，C. Gallicchio，r .普奇，A. Micheli 分享，使用基于水库计算的多传感器数据融合的人类活动识别，周围智能和智能环境杂志，2016，8 (2)，87-107 页*。

注意

完整的数据集可以在这里找到:[https://packt.live/3a5FI1s](https://packt.live/3a5FI1s)

让我们看看如何在这个数据集上训练一个随机森林分类器。

首先，我们需要使用`pandas`从 GitHub 存储库中加载数据，然后我们将打印它的前五行:

```
import pandas as pd
file_url = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter04/Dataset/activity.csv'
df = pd.read_csv(file_url)
df.head()
```

输出如下所示:

![Figure 4.1: First five rows of the dataset](image/B15019_04_01.jpg)

图 4.1:数据集的前五行

每行代表一个人执行的活动，活动的名称存储在`Activity`列中。这个变量中有七个不同的活动:`bending1`、`bending2`、`cycling`、`lying`、`sitting`、`standing`和`Walking`。其他六列是来自传感器数据的不同测量值。

在本例中，您将使用随机森林从特征(其他六列)中准确预测目标变量(`'Activity'`)。例如，对于前面示例的第一行，模型将接收以下特征作为输入，并将预测`'bending1'`类:

![Figure 4.2: Features for the first row of the dataset
](image/B15019_04_02.jpg)

图 4.2:数据集第一行的特征

但在此之前，我们需要做一点数据准备。`sklearn`包(我们将用它来训练随机森林模型)要求目标变量和特征分离。因此，我们需要使用`.pop()`方法从`pandas`中提取响应变量。`.pop()`方法提取指定的列并将其从 DataFrame 中删除:

```
target = df.pop('Activity')
```

现在，响应变量包含在名为`target`的变量中，所有特征都在名为`df`的数据帧中。

现在，我们将把数据集分成训练集和测试集。该模型使用训练集来学习预测响应变量的相关参数。测试集用于检查模型是否能够准确预测看不见的数据。当模型学习了仅与训练集相关的模式，并对测试集做出不正确的预测时，我们说模型过度拟合。在这种情况下，与测试集相比，训练集的模型性能要高得多。理想情况下，我们希望训练集和测试集具有非常相似的性能水平。这个话题将在*第 7 章*、*机器学习模型的泛化*中更深入的讨论。

`sklearn`包提供了一个名为`train_test_split()`的函数，将数据集随机分成两个不同的集合。我们需要为这个函数指定以下参数:特性和目标变量、测试集的比率(`test_size`)和`random_state`，以便在我们必须再次运行代码时获得可重现的结果:

```
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(df, target, test_size=0.33, random_state=42)
```

`train_test_split()`函数有四种不同的输出:训练集的特征、训练集的目标变量、测试集的特征及其目标变量。

既然我们已经有了训练和测试集，我们就可以开始建模了。让我们首先从`sklearn.ensemble`导入`RandomForestClassifier`类:

```
from sklearn.ensemble import RandomForestClassifier
```

现在我们可以用一些超参数实例化随机森林分类器。请记住*第 1 章，Python 中的数据科学简介*，超参数是一种模型无法学习的参数，但由数据科学家设置，以调整模型的学习过程。这个主题将在*第 8 章，超参数调整*中更深入地讨论。现在，我们将只指定`random_state`值。在以下几节中，我们将带您了解一些关键的超参数:

```
rf_model = RandomForestClassifier(random_state=1)
```

下一步是用训练数据训练(也称为拟合)模型。在此步骤中，模型将尝试学习响应变量和独立变量之间的关系，并保存学习到的参数。我们需要指定特性和目标变量作为参数:

```
rf_model.fit(X_train, y_train)
```

输出如下所示:

![Figure 4.3: Logs of the trained RandomForest
](image/B15019_04_03.jpg)

图 4.3:经过训练的随机森林的日志

既然模型已经完成了它的训练，我们可以使用它所学习的参数来对我们将提供的输入数据进行预测。在下面的示例中，我们使用训练集中的功能:

```
preds = rf_model.predict(X_train)
```

现在我们可以打印这些预测:

```
preds
```

输出如下所示:

![Figure 4.4: Predictions of the RandomForest algorithm on the training set
](image/B15019_04_04.jpg)

图 4.4:random forest 算法对训练集的预测

该输出向我们显示了模型预测值，分别是前三次观察的值`lying`、`bending1`和`cycling`，以及后三次观察的值`cycling`、`bending1`和`standing`。默认情况下，Python 会截断长值列表的输出。这就是为什么这里只显示了六个值。

这些基本上是训练随机森林分类器所需的关键步骤。这很简单，对吧？训练一个机器学习模型非常容易，但获得有意义和准确的结果是挑战所在。在下一节中，我们将学习如何评估一个经过训练的模型的性能。

# 评估模型的性能

现在我们知道了如何训练一个随机森林分类器，是时候检查我们是否做得很好了。我们想要的是得到一个能够做出极其准确预测的模型，所以我们需要使用某种度量来评估它的性能。

对于分类问题，可以使用多个指标来评估模型的预测能力，如 F1 得分、精确度、召回率或 ROC AUC。每一种都有自己的特点，根据项目和数据集，您可以使用其中的一种。

在这一章中，我们将使用一个叫做准确度分数的指标。它计算正确预测数与模型所做预测总数之间的比率:

![Figure 4.5: Formula for accuracy score
](image/B15019_04_05.jpg)

图 4.5:准确度分数的公式

例如，如果您的模型在 1，000 个案例中做出了 950 个正确的预测，那么准确性得分将是 950/1000 = 0.95。这意味着你的模型在数据集上有 95%的准确性。`sklearn`包提供了一个自动计算这个分数的函数，它被称为`accuracy_score()`。我们需要首先导入它:

```
from sklearn.metrics import accuracy_score
```

然后，我们只需要提供一些观测值的预测列表和目标变量对应的真值。使用前面的示例，我们将使用`y_train`和`preds`变量，它们分别包含训练集的响应变量(也称为目标)和随机森林模型做出的相应预测。我们将重用上一节的预测—`preds`:

```
accuracy_score(y_train, preds)
```

输出如下所示:

![Figure 4.6: Accuracy score on the training set
](image/B15019_04_06.jpg)

图 4.6:训练集的准确度得分

我们在训练数据上取得了 0.988 的准确率。这意味着我们准确预测了超过`98%`的病例。不幸的是，这并不意味着你能在新的、看不见的数据上获得如此高的分数。您的模型可能刚刚学习了只与该训练集相关的模式，在这种情况下，模型将会过度拟合。

如果我们打个比方，一个学生学习一门学科一个学期，他们可以记住所有课本上的练习，但当给他们一个类似的但看不见的练习时，他们将无法解决它。理想情况下，学生应该理解主题的基本概念，并能够将所学应用到任何类似的练习中。这对我们的模型来说是完全一样的:我们希望它学习通用模式，这将有助于它即使在看不见的数据上也能做出准确的预测。

但是，对于看不见的数据，我们如何评估模型的性能呢？有办法得到那种评估吗？这些问题的答案是肯定的。

请记住，在上一节中，我们将数据集分成了训练集和测试集。我们使用训练集来拟合模型，并评估其预测能力。但是它根本没有看到来自测试集的观察结果，所以我们可以用它来评估我们的模型是否能够概括看不见的数据。让我们计算测试集的准确度分数:

```
accuracy_score(y_test, test_preds)
```

输出如下所示:

![Figure 4.7: Accuracy score on the testing set
](image/B15019_04_07.jpg)

图 4.7:测试集的准确度分数

好的。现在精度已经急剧下降到`0.77`。训练集和测试集之间的差异相当大。这告诉我们，我们的模型实际上是过度拟合的，并且只学习了与训练集相关的模式。在理想情况下，这两个集合的模型性能应该相等或非常接近相等。

在下一节中，我们将研究如何调整一些随机森林超参数，以减少过度拟合。

## 练习 4.01:建立动物类型分类模型并评估其性能

在本练习中，我们将训练一个随机森林分类器来根据动物的属性预测其类型，并检查其准确性得分:

注意

我们将使用的数据集是 Richard S. Forsyth 共享的动物园数据集:

[https://packt.live/36DpRVK](https://packt.live/36DpRVK)。

此数据集的 CSV 版本可在此处找到:

[https://packt.live/37RWGhF](https://packt.live/37RWGhF)。

1.  打开新的 Colab 笔记本。
2.  导入`pandas`包:

    ```
    import pandas as pd
    ```

3.  创建一个名为`file_url`的变量，它包含数据集的 URL:

    ```
    file_url = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter04/Dataset/openml_phpZNNasq.csv'
    ```

4.  使用 pandas:

    ```
    df = pd.read_csv(file_url)
    ```

    中的`.read_csv()`方法将数据集加载到数据帧中
5.  Print the first five rows of the DataFrame:

    ```
    df.head()
    ```

    您应该得到以下输出:

    ![Figure 4.8: First five rows of the DataFrame
    ](image/B15019_04_08.jpg)

    图 4.8:数据帧的前五行

    我们将使用`type`列作为我们的目标变量。我们需要从数据帧中删除`animal`列，只使用剩余的列作为特性。

6.  使用`pandas`中的`.drop()`方法删除`'animal'`列，并指定`columns='animal'`和`inplace=True`参数(直接更新原始数据帧):

    ```
    df.drop(columns='animal', inplace=True)
    ```

7.  使用`.pop()`方法从`pandas` :

    ```
    y = df.pop('type')
    ```

    中提取`'type'`列
8.  Print the first five rows of the DataFrame:

    ```
    df.head()
    ```

    您应该得到以下输出:

    ![Figure 4.9: First five rows of the DataFrame
    ](image/B15019_04_09.jpg)

    图 4.9:数据帧的前五行

9.  从`sklearn.model_selection` :

    ```
    from sklearn.model_selection import train_test_split
    ```

    导入`train_test_split`函数
10.  用`df`、`y`、`test_size=0.4`和`random_state=188`参数将数据集分成训练集和测试集:

    ```
    X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.4, random_state=188)
    ```

11.  从`sklearn.ensemble` :

    ```
    from sklearn.ensemble import RandomForestClassifier
    ```

    导入`RandomForestClassifier`
12.  用`random_state`等于`42` :

    ```
    rf_model = RandomForestClassifier(random_state=42)
    ```

    实例化`RandomForestClassifier`对象
13.  Fit `RandomForestClassifier` with the training set:

    ```
    rf_model.fit(X_train, y_train)
    ```

    您应该得到以下输出:

    ![Figure 4.10: Logs of RandomForestClassifier
    ](image/B15019_04_10.jpg)

    图 4.10:RandomForestClassifier 的日志

14.  Predict the outcome of the training set with the `.fit()`method, save the results in a variable called '`train_preds`', and print its value:

    ```
    train_preds = rf_model.predict(X_train)
    train_preds
    ```

    您应该得到以下输出:

    ![Figure 4.11: Predictions on the training set
    ](image/B15019_04_11.jpg)

    图 4.11:对训练集的预测

15.  从`sklearn.metrics` :

    ```
    from sklearn.metrics import accuracy_score
    ```

    导入`accuracy_score`函数
16.  Calculate the accuracy score on the training set, save the result in a variable called `train_acc`, and print its value:

    ```
    train_acc = accuracy_score(y_train, train_preds)
    print(train_acc)
    ```

    您应该得到以下输出:

    ![Figure 4.12: Accuracy score on the training set
    ](image/B15019_04_12.jpg)

    图 4.12:训练集的准确度分数

    我们的模型在训练集上达到了`1`的准确度，这意味着它在所有这些观察值上完美地预测了目标变量。让我们检查一下测试设备的性能。

17.  用`.fit()`方法预测测试集的结果，并将结果保存到一个名为`test_preds` :

    ```
    test_preds = rf_model.predict(X_test)
    ```

    的变量中
18.  Calculate the accuracy score on the testing set, save the result in a variable called `test_acc`, and print its value:

    ```
    test_acc = accuracy_score(y_test, test_preds)
    print(test_acc)
    ```

    您应该得到以下输出:

    ![Figure 4.13: Accuracy score on the testing set 
    ](image/B15019_04_13.jpg)

图 4.13:测试集的准确度分数

在本练习中，我们训练了一个 RandomForest 来根据动物的关键属性预测它们的类型。我们的模型在训练集上取得了完美的准确度分数`1`，但是在测试集上只有`0.88`。这意味着我们的模型过度拟合，不够普遍。理想的情况是模型在训练集和测试集上都达到非常相似的高精度分数。

## Tr ees 估计数

既然我们知道了如何拟合随机森林分类器并评估其性能，那么是时候深入研究细节了。在接下来的部分中，我们将学习如何调优这个算法的一些最重要的超参数。在*第 1 章《Python 中的数据科学简介*中提到，超参数是机器学习算法不会自动学习的参数。它们的值必须由数据科学家设定。这些超参数会对模型的性能、对未知数据进行归纳的能力以及从数据中学习模式所需的时间产生巨大影响。

在本节中，您将看到的第一个超参数称为`n_estimators`。这个超参数负责定义将由`RandomForest`算法训练的树的数量。

在研究如何调优这个超参数之前，我们需要了解什么是树，以及为什么它对`RandomForest`算法如此重要。

树是一个逻辑图，它将决策及其结果映射到每个节点上。简单来说，就是一系列是/否(或真/假)的问题，导致不同的结果。

叶节点是一种特殊类型的节点，模型将在其中进行预测。一片叶子之后就不会有分裂了。树的单个节点拆分可能如下所示:

![Figure 4.14: Example of a single tree node
](image/B15019_04_14.jpg)

图 4.14:单个树节点的例子

树节点由一个问题和两个结果组成，具体取决于问题定义的条件是否满足。在前面的例子中，问题是`is avg_rss12 > 41?`如果答案是肯定的，结果是`bending_1`叶，如果不是，结果将是`sitting`叶。树只是一系列节点和叶子的组合:

![Figure 4.15: Example of a tree
](image/B15019_04_15.jpg)

图 4.15:一棵树的例子

在前面的示例中，树由三个带有不同问题的节点组成。现在，对于一个被预测为`sitting`的观测，它需要满足以下条件:`avg_rss13 <= 41`、`var_rss > 0.7`和`avg_rss13 <= 16.25`。

`RandomForest`算法会根据它看到的训练数据来构建这种树。我们不会讨论它如何为每个节点定义拆分的数学细节，但基本上，它会遍历数据集的每一列，并查看哪个拆分值最有助于将数据分成两组相似的类。以前面的例子为例，具有`avg_rss13 > 41`条件的第一个节点将有助于获得左侧的数据组，其中大部分是`bending_1`类。`RandomForest`算法通常会构建几棵这种树，这也是它被称为森林的原因。

您可能已经猜到了，`n_estimators`超参数用于指定`RandomForest`算法将要构建的树的数量。默认情况下，它将构建 10 棵树，对于给定的观察，它将要求每棵树进行预测。然后，它将对这些预测进行平均，并将结果用作该输入的最终预测。例如，如果 10 棵树中有 8 棵树预测了结果`sitting`，那么`RandomForest`算法将使用这个结果作为最终预测。

一般来说，树的数量越多，性能越好。让我们看看`n_estimators = 2`会发生什么:

```
rf_model2 = RandomForestClassifier(random_state=1, n_estimators=2)
rf_model2.fit(X_train, y_train)
preds2 = rf_model2.predict(X_train)
test_preds2 = rf_model2.predict(X_test)
print(accuracy_score(y_train, preds2))
print(accuracy_score(y_test, test_preds2))
```

输出如下所示:

![Figure 4.16: Accuracy of RandomForest with n_estimators = 2
](image/B15019_04_16.jpg)

图 4.16:n 估计值= 2 的随机森林的精确度

正如预期的那样，精度明显低于前面使用`n_estimators = 10`(默认值)的示例。现在让我们尝试使用`50`树:

```
rf_model3 = RandomForestClassifier(random_state=1, n_estimators=50)
rf_model3.fit(X_train, y_train)
preds3 = rf_model3.predict(X_train)
test_preds3 = rf_model3.predict(X_test)
print(accuracy_score(y_train, preds3))
print(accuracy_score(y_test, test_preds3))
```

输出如下所示:

![Figure 4.17: Accuracy of RandomForest with n_estimators = 50
](image/B15019_04_17.jpg)

图 4.17:n 估计值= 50 的随机森林的精确度

有了`n_estimators = 50`，我们在训练集和测试集的准确率上分别获得了`1%`和`2%`，这很棒。但是增加树的数量的主要缺点是它需要更多的计算能力。所以，训练一个模型要花更多的时间。在一个真实的项目中，你需要在绩效和培训持续时间之间找到合适的平衡。

## 练习 4.02: T 调整 n 估计器以减少过度拟合

在本练习中，我们将训练一个随机森林分类器来根据动物的属性预测动物的类型，并将尝试为`n_estimators`超参数设置两个不同的值:

我们将使用与上一个练习中相同的动物园数据集。

1.  打开新的 Colab 笔记本。
2.  从`sklearn` :

    ```
    import pandas as pd
    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.metrics import accuracy_score
    ```

    导入`pandas` 包、`train_test_split`、`RandomForestClassifier`、`accuracy_score`
3.  创建一个名为`file_url`的变量，包含数据集的 URL:

    ```
    file_url = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter04/Dataset/openml_phpZNNasq.csv'
    ```

4.  使用`pandas` :

    ```
    df = pd.read_csv(file_url)
    ```

    中的`.read_csv()`方法将数据集加载到数据帧中
5.  使用`.drop()`删除`animal`列，然后使用`.pop()` :

    ```
    df.drop(columns='animal', inplace=True)
    y = df.pop('type')
    ```

    将`type`目标变量提取到一个新变量`y`
6.  用`train_test_split()`和`test_size=0.4`和`random_state=188`参数

    ```
    X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.4, random_state=188)
    ```

    将数据分成训练集和测试集
7.  Instantiate `RandomForestClassifier` with `random_state=42` and `n_estimators=1`, and then fit the model with the training set:

    ```
    rf_model = RandomForestClassifier(random_state=42, n_estimators=1)
    rf_model.fit(X_train, y_train)
    ```

    您应该得到以下输出:

    ![Figure 4.18: Logs of RandomForestClassifier
    ](image/B15019_04_18.jpg)

    图 4.18:RandomForestClassifier 的日志

8.  用`.predict()`对训练集和测试集进行预测，并将结果保存到两个新变量中，称为`train_preds`和`test_preds` :

    ```
    train_preds = rf_model.predict(X_train)
    test_preds = rf_model.predict(X_test)
    ```

9.  计算训练集和测试集的准确度分数，并将结果保存在两个新变量中，称为`train_acc`和`test_acc` :

    ```
    train_acc = accuracy_score(y_train, train_preds)
    test_acc = accuracy_score(y_test, test_preds)
    ```

10.  Print the accuracy scores: `train_acc` and `test_acc`:

    ```
    print(train_acc)
    print(test_acc)
    ```

    您应该得到以下输出:

    ![Figure 4.19: Accuracy scores for the training and testing sets
    ](image/B15019_04_19.jpg)

    图 4.19:训练集和测试集的准确度分数

    训练集和测试集的准确度分数都下降了。但是现在，与来自*练习 4.01* 的结果相比，差异变小了。

11.  Instantiate another `RandomForestClassifier` with `random_state=42` and `n_estimators=30`, and then fit the model with the training set:

    ```
    rf_model2 = RandomForestClassifier(random_state=42, n_estimators=30)
    rf_model2.fit(X_train, y_train)
    ```

    您应该得到以下输出:

    ![Figure 4.20: Logs of RandomForest with n_estimators = 30
    ](image/B15019_04_20.jpg)

    图 4.20:n 估计值= 30 的随机森林的对数

12.  用`.predict()`对训练集和测试集进行预测，并将结果保存到两个新变量中，称为`train_preds2`和`test_preds2` :

    ```
    train_preds2 = rf_model2.predict(X_train)
    test_preds2 = rf_model2.predict(X_test)
    ```

13.  计算训练集和测试集的准确度分数，并将结果保存在两个新变量中，称为`train_acc2`和`test_acc2` :

    ```
    train_acc2 = accuracy_score(y_train, train_preds2)
    test_acc2 = accuracy_score(y_test, test_preds2)
    ```

14.  Print the accuracy scores: `train_acc` and `test_acc`:

    ```
    print(train_acc2)
    print(test_acc2)
    ```

    您应该得到以下输出:

    ![Figure 4.21: Accuracy scores for the training and testing sets
    ](image/B15019_04_21.jpg)

图 4.21:训练集和测试集的准确度分数

此输出向我们显示，与上一步的结果相比，该模型的过度拟合较少，并且对于训练集仍具有非常高的性能水平。

在之前的练习中，我们在训练集和测试集上分别获得了`1`和`0.88`的准确度分数。在这个练习中，我们用`n_estimators = 3`和`30`训练了另外两个随机森林模型。树数最少的模型准确率最低:`0.92`(训练)和`0.8`(测试)。另一方面，将树的数量增加到`30`，我们实现了更高的精度:`1`和`0.9`。我们的模型现在稍微有点过拟合。它并不完美，但它是一个好的开始。

# 最大深度

在前面的章节中，我们学习了随机森林如何构建多棵树来进行预测。增加树的数量确实可以提高模型的性能，但通常对降低过度拟合的风险没有太大帮助。在前面的例子中，我们的模型在训练集(它已经看到的数据)上的表现仍然比在测试集(看不见的数据)上的表现好得多。

因此，我们还没有足够的信心来说，该模型将在生产中表现良好。有不同的超参数可以帮助降低随机森林过度拟合的风险，其中之一称为`max_depth`。

这个超参数定义了随机森林建立的树的深度。基本上，它告诉随机森林模型，在进行预测之前，它可以创建多少个节点(问题)。但你可能会问，这如何有助于减少过度拟合。好吧，假设您构建了一个单独的树，并将`max_depth`超参数设置为`50`。这意味着在某些情况下，你可以在做出预测之前问 49 个不同的问题(值`c`包括最后一个叶节点)。所以，逻辑应该是`IF X1 > value1 AND X2 > value2 AND X1 <= value3 AND … AND X3 > value49 THEN predict class A`。

你可以想象，这是一个非常具体的规则。最后，它可能只适用于训练集中的少数观察值，这种情况很少出现。因此，您的模型会过度拟合。默认情况下，这个`max_depth`参数的值是`None`，这意味着对树的深度没有限制。

你真正想要的是找到一些足够通用的规则，以应用于更大的观察组。这就是为什么建议不要用随机森林创建深树。让我们在活动识别数据集上尝试这个超参数的几个值:`3`、`10`和`50`:

```
rf_model4 = RandomForestClassifier(random_state=1, n_estimators=50, max_depth=3)
rf_model4.fit(X_train, y_train)
preds4 = rf_model4.predict(X_train)
test_preds4 = rf_model4.predict(X_test)
print(accuracy_score(y_train, preds4))
print(accuracy_score(y_test, test_preds4))
rf_model4 = RandomForestClassifier(random_state=1, n_estimators=50, max_depth=3)
```

您应该得到以下输出:

![Figure 4.22: Accuracy scores for the training and testing sets and a max_depth of 3
](image/B15019_04_22.jpg)

图 4.22:训练集和测试集的准确度分数，max_depth 为 3

对于`3`中的`max_depth`，我们在训练集和测试集中得到了极其相似的结果，但是整体性能急剧下降到`0.61`。我们的模型不再过度拟合，但现在拟合不足；也就是说，它没有很好地预测目标变量(仅在`61%`的情况下)。让我们把`max_depth`增加到`10`:

```
rf_model5 = RandomForestClassifier(random_state=1, n_estimators=50, max_depth=10)
rf_model5.fit(X_train, y_train)
preds5 = rf_model5.predict(X_train)
test_preds5 = rf_model5.predict(X_test)
print(accuracy_score(y_train, preds5))
print(accuracy_score(y_test, test_preds5))
```

![Figure 4.23: Accuracy scores for the training and testing sets and a max_depth of 10
](image/B15019_04_23.jpg)

图 4.23:训练集和测试集的准确度分数，max_depth 为 10

训练集的准确度增加，并且相对接近测试集。我们开始得到一些好的结果，但是模型仍然有点过度拟合。现在我们将看到`max_depth = 50`的结果:

```
rf_model6 = RandomForestClassifier(random_state=1, n_estimators=50, max_depth=50)
rf_model6.fit(X_train, y_train)
preds6 = rf_model6.predict(X_train)
test_preds6 = rf_model6.predict(X_test)
print(accuracy_score(y_train, preds6))
print(accuracy_score(y_test, test_preds6))
```

输出如下所示:

![Figure 4.24: Accuracy scores for the training and testing sets and a max_depth of 50
](image/B15019_04_24.jpg)

图 4.24:训练集和测试集的准确度分数，max_depth 为 50

训练集的准确率提高到了`0.99`,但是测试集的准确率并没有提高多少。所以，模型与`max_depth = 50`过度拟合。对于这个数据集中的`max_depth`超参数来说，似乎获得良好预测并且没有太多过度拟合的最佳点在`10`附近。

## 练习 4.03:调整 m ax_depth 以减少过度拟合

在本练习中，我们将通过尝试`max_depth`超参数的两个不同值来不断调整预测动物类型的 RandomForest 分类器:

我们将使用与上一个练习中相同的动物园数据集。

1.  打开新的 Colab 笔记本。
2.  从`sklearn` :

    ```
    import pandas as pd
    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.metrics import accuracy_score
    ```

    导入`pandas`包、`train_test_split`、`RandomForestClassifier`、`accuracy_score`
3.  创建一个名为`file_url`的变量，包含数据集的 URL:

    ```
    file_url = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter04/Dataset/openml_phpZNNasq.csv'
    ```

4.  使用`pandas` :

    ```
    df = pd.read_csv(file_url)
    ```

    中的`.read_csv()`方法将数据集加载到数据帧中
5.  使用`.drop()`删除`animal`列，然后使用`.pop()` :

    ```
    df.drop(columns='animal', inplace=True)
    y = df.pop('type')
    ```

    将`type`目标变量提取到一个新变量`y`
6.  用`train_test_split()`和参数`test_size=0.4`和`random_state=188` :

    ```
    X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.4, random_state=188)
    ```

    将数据分成训练集和测试集
7.  Instantiate `RandomForestClassifier` with `random_state=42`, `n_estimators=30`, and `max_depth=5`, and then fit the model with the training set:

    ```
    rf_model = RandomForestClassifier(random_state=42, n_estimators=30, max_depth=5)
    rf_model.fit(X_train, y_train)
    ```

    您应该得到以下输出:

    ![Figure 4.25: Logs of RandomForest
    ](image/B15019_04_25.jpg)

    图 4.25:随机森林的日志

8.  用`.predict()`对训练集和测试集进行预测，并将结果保存到两个新变量中，称为`train_preds`和`test_preds` :

    ```
    train_preds = rf_model.predict(X_train)
    test_preds = rf_model.predict(X_test)
    ```

9.  计算训练集和测试集的准确度分数，并将结果保存在两个新变量中，称为`train_acc`和`test_acc` :

    ```
    train_acc = accuracy_score(y_train, train_preds)
    test_acc = accuracy_score(y_test, test_preds)
    ```

10.  Print the accuracy scores: `train_acc` and `test_acc`:

    ```
    print(train_acc)
    print(test_acc)
    ```

    您应该得到以下输出:

    ![Figure 4.26: Accuracy scores for the training and testing sets
    ](image/B15019_04_26.jpg)

    图 4.26:训练集和测试集的准确度分数

    我们获得了与之前练习中获得的最佳结果完全相同的准确度分数。`max_depth`超参数的这个值没有影响模型的性能。

11.  Instantiate another `RandomForestClassifier` with `random_state=42`, `n_estimators=30`, and `max_depth=2`, and then fit the model with the training set:

    ```
    rf_model2 = RandomForestClassifier(random_state=42, n_estimators=30, max_depth=2)
    rf_model2.fit(X_train, y_train)
    ```

    您应该得到以下输出:

    ![Figure 4.27: Logs of RandomForestClassifier with max_depth = 2
    ](image/B15019_04_27.jpg)

    图 4.27:max _ depth = 2 的 RandomForestClassifier 的日志

12.  用`.predict()`对训练集和测试集进行预测，并将结果保存到两个新变量中，称为`train_preds2` 和`test_preds2` :

    ```
    train_preds2 = rf_model2.predict(X_train)
    test_preds2 = rf_model2.predict(X_test)
    ```

13.  计算训练集和测试集的准确度分数，并将结果保存在两个新变量中，称为`train_acc2`和`test_acc2` :

    ```
    train_acc2 = accuracy_score(y_train, train_preds2)
    test_acc2 = accuracy_score(y_test, test_preds2)
    ```

14.  Print the accuracy scores: `train_acc` and `test_acc`:

    ```
    print(train_acc2)
    print(test_acc2)
    ```

    您应该得到以下输出:

    ![Figure 4.28: Accuracy scores for training and testing sets
    ](image/B15019_04_28.jpg)

图 4.28:训练集和测试集的准确度分数

在本练习中，您学习了如何调整`max_depth`超参数。将其值减少到`2`会将训练集的准确度分数减少到 0.9，但这也有助于减少训练和测试集的过拟合(0.83)，因此我们将保持该值为最佳值，并继续下一步。

# 叶子中的最小样本

之前，我们学习了如何减少或增加随机森林中树木的深度，并看到了它如何影响其性能和是否过度拟合的趋势。现在我们将通过另一个重要的超参数:`min_samples_leaf`。

顾名思义，这个超参数与树的叶节点有关。我们之前看到过,`RandomForest`算法构建的节点可以清楚地将观察结果分成两个不同的组。如果我们看一下*图 4.15* 中的树示例，顶部节点将数据分成两组:左边的组主要包含`bending_1`类的观察值，右边的组可以来自任何类。这听起来像是一个合理的分割，但是我们确定它没有增加过度拟合的风险吗？例如，如果这种分裂导致只有一个观察值落在左边，那该怎么办？这条规则非常具体(仅适用于一种情况)，我们不能说它对看不见的数据足够通用。这可能是训练集中永远不会再次发生的边缘情况。

如果我们能让模型知道不要创建这种很少发生的特定规则，那就太好了。幸运的是，`RandomForest`有这样一个超参数，你猜对了，它就是`min_samples_leaf`。该超参数将指定必须落在树中要考虑的叶节点下的最小观察值(或样本)数量。例如，如果我们将`min_samples_leaf`设置为`3`，那么`RandomForest`将只考虑在左右叶节点上导致至少三个观察的分裂。如果分割不满足此条件，模型将不会考虑它，并将它从树中排除。该超参数在`sklearn`中的默认值为`1`。让我们尝试为活动识别数据集找到`min_samples_leaf`的最佳值:

```
rf_model7 = RandomForestClassifier(random_state=1, n_estimators=50, max_depth=10, min_samples_leaf=3)
rf_model7.fit(X_train, y_train)
preds7 = rf_model7.predict(X_train)
test_preds7 = rf_model7.predict(X_test)
print(accuracy_score(y_train, preds7))
print(accuracy_score(y_test, test_preds7))
```

输出如下所示:

![Figure 4.29: Accuracy scores for the training and testing sets for min_samples_leaf=3
](image/B15019_04_29.jpg)

图 4.29:min _ samples _ leaf = 3 的训练集和测试集的准确度分数

使用`min_samples_leaf=3`，与我们在上一节中找到的最佳模型相比，训练集和测试集的准确性没有太大变化。让我们试着把它增加到`10`:

```
rf_model8 = RandomForestClassifier(random_state=1, n_estimators=50, max_depth=10, min_samples_leaf=10)
rf_model8.fit(X_train, y_train)
preds8 = rf_model8.predict(X_train)
test_preds8 = rf_model8.predict(X_test)
print(accuracy_score(y_train, preds8))
print(accuracy_score(y_test, test_preds8))
```

输出如下所示:

![Figure 4.30: Accuracy scores for the training and testing sets for min_samples_leaf=10
](image/B15019_04_30.jpg)

图 4.30:min _ samples _ leaf = 10 的训练集和测试集的准确度分数

现在，训练集的准确性有所下降，但测试集的准确性有所提高，它们的差异现在更小了。因此，我们的模型过度拟合较少。让我们尝试这个超参数的另一个值—`25`:

```
rf_model9 = RandomForestClassifier(random_state=1, n_estimators=50, max_depth=10, min_samples_leaf=25)
rf_model9.fit(X_train, y_train)
preds9 = rf_model9.predict(X_train)
test_preds9 = rf_model9.predict(X_test)
print(accuracy_score(y_train, preds9))
print(accuracy_score(y_test, test_preds9))
```

输出如下所示:

![Figure 4.31: Accuracy scores for the training and testing sets for min_samples_leaf=25
](image/B15019_04_31.jpg)

图 4.31:min _ samples _ leaf = 25 的训练集和测试集的准确度分数

训练集和测试集的准确度都降低了，但是现在它们彼此非常接近。因此，我们将保持这个值(`25`)作为这个数据集的最佳值，因为性能仍然可以，我们没有过度拟合。

在为这个超参数选择最佳值时，您需要小心:太低的值会增加模型过度拟合的机会，但另一方面，设置非常高的值会导致拟合不足(模型不会准确预测正确的结果)。

例如，如果您有一个包含`1000`行的数据集，如果您将`min_samples_leaf`设置为`400`，那么模型将无法找到良好的拆分来预测`5`不同的类。在这种情况下，模型只能创建一个单独的分割，并且模型只能预测两个不同的类别，而不是`5`。好的做法是先从低值开始，然后逐渐增加它们，直到达到满意的性能。

## 练习 4.04:调整 min_samp les_leaf

在本练习中，我们将通过尝试`min_samples_leaf`超参数的两个不同值来不断调整预测动物类型的随机森林分类器:

我们将使用与上一个练习中相同的动物园数据集。

1.  打开新的 Colab 笔记本。
2.  从`sklearn` :

    ```
    import pandas as pd
    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.metrics import accuracy_score
    ```

    导入`pandas`包、`train_test_split`、`RandomForestClassifier`、`accuracy_score`
3.  创建一个名为`file_url`的变量，包含数据集的 URL:

    ```
    file_url = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter04/Dataset/openml_phpZNNasq.csv'
    ```

4.  使用`pandas` :

    ```
    df = pd.read_csv(file_url)
    ```

    中的`.read_csv()`方法将数据集加载到数据帧中
5.  使用`.drop()`删除`animal`列，然后使用`.pop()` :

    ```
    df.drop(columns='animal', inplace=True)
    y = df.pop('type')
    ```

    将`type`目标变量提取到一个新变量`y`
6.  用`train_test_split()`和参数`test_size=0.4`和`random_state=188` :

    ```
    X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.4, random_state=188)
    ```

    将数据分成训练集和测试集
7.  Instantiate `RandomForestClassifier` with `random_state=42`, `n_estimators=30`, `max_depth=2`, and `min_samples_leaf=3`, and then fit the model with the training set:

    ```
    rf_model = RandomForestClassifier(random_state=42, n_estimators=30, max_depth=2, min_samples_leaf=3)
    rf_model.fit(X_train, y_train)
    ```

    您应该得到以下输出:

    ![Figure 4.32: Logs of RandomForest
    ](image/B15019_04_32.jpg)

    图 4.32:随机森林的日志

8.  用`.predict()`对训练集和测试集进行预测，并将结果保存到两个新变量中，称为`train_preds`和`test_preds` :

    ```
    train_preds = rf_model.predict(X_train)
    test_preds = rf_model.predict(X_test)
    ```

9.  计算训练集和测试集的准确度分数，并将结果保存在两个新变量中，称为`train_acc`和`test_acc` :

    ```
    train_acc = accuracy_score(y_train, train_preds)
    test_acc = accuracy_score(y_test, test_preds)
    ```

10.  Print the accuracy score – `train_acc` and `test_acc`:

    ```
    print(train_acc)
    print(test_acc)
    ```

    您应该得到以下输出:

    ![Figure 4.33: Accuracy scores for the training and testing sets
    ](image/B15019_04_33.jpg)

    图 4.33:训练集和测试集的准确度分数

    与我们在之前的练习中获得的最佳结果相比，训练集和测试集的准确性得分都有所下降。现在，训练集和测试集的准确度分数之间的差异小得多，因此我们的模型过拟合更少。

11.  Instantiate another `RandomForestClassifier` with `random_state=42`, `n_estimators=30`, `max_depth=2`, and `min_samples_leaf=7`, and then fit the model with the training set:

    ```
    rf_model2 = RandomForestClassifier(random_state=42, n_estimators=30, max_depth=2, min_samples_leaf=7)
    rf_model2.fit(X_train, y_train)
    ```

    您应该得到以下输出:

    ![Figure 4.34: Logs of RandomForest with max_depth=2
    ](image/B15019_04_34.jpg)

    图 4.34:max _ depth = 2 的随机森林的日志

12.  用`.predict()`对训练集和测试集进行预测，并将结果保存到两个新变量中，称为`train_preds2`和`test_preds2` :

    ```
    train_preds2 = rf_model2.predict(X_train)
    test_preds2 = rf_model2.predict(X_test)
    ```

13.  计算训练集和测试集的准确度分数，并将结果保存在两个新变量中，称为`train_acc2`和`test_acc2` :

    ```
    train_acc2 = accuracy_score(y_train, train_preds2)
    test_acc2 = accuracy_score(y_test, test_preds2)
    ```

14.  Print the accuracy scores: `train_acc` and `test_acc`:

    ```
    print(train_acc2)
    print(test_acc2)
    ```

    您应该得到以下输出:

    ![Figure 4.35: Accuracy scores for the training and testing sets
    ](image/B15019_04_35.jpg)

图 4.35:训练集和测试集的准确度分数

将`min_samples_leaf`的值增加到`7`会导致模型不再过度拟合。我们在训练和测试集上得到了非常相似的准确度分数，大约在`0.8`左右。对于这个数据集，我们将选择这个值作为`min_samples_leaf`的最佳值。

# 最大特性

这一章快结束了。您已经学习了如何调优 RandomForest 的几个最重要的超参数。在本节中，我们将为您呈现另一个极其重要的问题:`max_features`。

前面我们了解到`RandomForest`构建多棵树，取平均值进行预测。这就是为什么它被称为森林，但我们还没有真正讨论“随机”的部分。阅读本章时，您可能会问自己:构建多棵树如何有助于获得更好的预测，如果输入数据相同，所有的树不会看起来都一样吗？

在回答这些问题之前，我们先打个法庭审判的比方。在一些国家，审判的最终决定由法官或陪审团做出。法官是一个详细了解法律的人，可以决定一个人是否违反了法律。另一方面，陪审团由来自不同背景的人组成，他们彼此不认识，也不了解参与审判的任何一方，对法律体系的了解也有限。在这种情况下，我们要求随机的非法律专家来决定案件的结果。这一开始听起来风险很大。一个人做出错误决定的风险非常高。但事实上，10 个人或 20 个人全部做出错误决定的风险相对较低。

但要实现这一点，需要满足一个条件:随机性。如果陪审团中的所有人都来自相同的背景，从事相同的行业，或者生活在相同的地区，他们可能会有相同的思维方式，做出类似的决定。例如，如果一群人在一个早餐只喝热巧克力的社区长大，有一天你问他们早餐喝咖啡是否可以，他们都会说不可以。

另一方面，假设你有另一组来自不同背景、有不同习惯的人:一些人喝咖啡，一些人喝茶，一些人喝橙汁，等等。如果你问他们同样的问题，你会得到大多数人的肯定回答。因为我们随机挑选了这些人，他们作为一个群体有更少的偏见，因此这降低了他们做出错误决定的风险。

RandomForest 实际上应用了相同的逻辑:它通过随机采样数据来构建许多彼此独立的树。一棵树可以看到训练数据的`60%`，另一棵树可以看到`70%`，以此类推。通过这样做，很有可能这些树彼此完全不同，并且没有相同的偏好。这就是 RandomForest 的秘密:构建多个随机树导致更高的准确性。

但这不是 RandomForest 创造随机性的唯一方式。它也是通过对列进行随机采样来实现的。每个树只能看到部分特征，而不是全部特征。这正是`max_features`超参数的用途:它将设置一棵树允许看到的最大特征数。

在`sklearn`中，您可以将该超参数的值指定为:

*   以整数表示的最大要素数。
*   比率，以允许功能的百分比表示。
*   `sqrt`函数(`sklearn`中的默认值，代表平方根)，该函数将使用特征数量的平方根作为最大值。对于一个数据集，如果有`25`特征，它的平方根将是`5`，这将是`max_features`的值。
*   `log2`函数将使用特征数量的对数基数`2`作为最大值。如果一个数据集有八个特征，那么它的`log2`将是`3`，这将是`max_features`的值。
*   `None`值，这意味着随机森林将使用所有可用的特性。

让我们在活动数据集上尝试三个不同的值。首先，我们将功能的最大数量指定为两个:

```
rf_model10 = RandomForestClassifier(random_state=1, n_estimators=50, max_depth=10, min_samples_leaf=25, max_features=2)
rf_model10.fit(X_train, y_train)
preds10 = rf_model10.predict(X_train)
test_preds10 = rf_model10.predict(X_test)
print(accuracy_score(y_train, preds10))
print(accuracy_score(y_test, test_preds10))
```

输出如下所示:

![Figure 4.36: Accuracy scores for the training and testing sets for max_features=2
](image/B15019_04_36.jpg)

图 4.36:max _ features = 2 的训练集和测试集的准确度分数

我们得到的结果类似于我们在上一节中训练的最佳模型的结果。这并不奇怪，因为我们当时使用的是默认值`max_features`，即`sqrt`。`2`的平方根等于`1.45`，与`2`相当接近。这一次，我们来试试比率`0.7`:

```
rf_model11 = RandomForestClassifier(random_state=1, n_estimators=50, max_depth=10, min_samples_leaf=25, max_features=0.7)
rf_model11.fit(X_train, y_train)
preds11 = rf_model11.predict(X_train)
test_preds11 = rf_model11.predict(X_test)
print(accuracy_score(y_train, preds11))
print(accuracy_score(y_test, test_preds11))
```

输出如下所示:

![Figure 4.37: Accuracy scores for the training and testing sets for max_features=0.7
](image/B15019_04_37.jpg)

图 4.37:max _ features = 0.7 的训练集和测试集的准确度分数

有了这个比率，训练集和测试集的准确度分数都增加了，并且它们之间的差异变小了。我们的模型现在过度拟合更少，并且略微提高了它的预测能力。让我们用`log2`选项试一试:

```
rf_model12 = RandomForestClassifier(random_state=1, n_estimators=50, max_depth=10, min_samples_leaf=25, max_features='log2')
rf_model12.fit(X_train, y_train)
preds12 = rf_model12.predict(X_train)
test_preds12 = rf_model12.predict(X_test)
print(accuracy_score(y_train, preds12))
print(accuracy_score(y_test, test_preds12))
```

输出如下所示:

![Figure 4.38: Accuracy scores for the training and testing sets for max_features='log2'
](image/B15019_04_38.jpg)

图 4.38:max _ features = ' log2 '的训练集和测试集的准确度分数

对于默认值(`sqrt`)和`2`，我们得到了类似的结果。同样，这是正常的，因为`6`的`log2`等于`2.58`。因此，我们为这个数据集找到的`max_features`超参数的最佳值是`0.7`。

## 练习 4.05:调整 max_features

在这个练习中，我们将通过尝试`max_features`超参数的两个不同值来继续调整预测动物类型的 RandomForest 分类器:

我们将使用与上一个练习中相同的动物园数据集。

1.  打开新的 Colab 笔记本。
2.  从`sklearn` :

    ```
    import pandas as pd
    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.metrics import accuracy_score
    ```

    导入`pandas`包、`train_test_split`、`RandomForestClassifier`、`accuracy_score`
3.  创建一个名为`file_url`的变量，包含数据集的 URL:

    ```
    file_url = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter04/Dataset/openml_phpZNNasq.csv'
    ```

4.  使用`pandas` :

    ```
    df = pd.read_csv(file_url)
    ```

    中的`.read_csv()`方法将数据集加载到数据帧中
5.  使用`.drop()`删除`animal`列，然后使用`.pop()` :

    ```
    df.drop(columns='animal', inplace=True)
    y = df.pop('type')
    ```

    将`type`目标变量提取到一个新变量`y`
6.  用`train_test_split()`和参数`test_size=0.4`和`random_state=188` :

    ```
    X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.4, random_state=188)
    ```

    将数据分成训练集和测试集
7.  Instantiate `RandomForestClassifier` with `random_state=42`, `n_estimators=30`, `max_depth=2`, `min_samples_leaf=7`, and `max_features=10`, and then fit the model with the training set:

    ```
    rf_model = RandomForestClassifier(random_state=42, n_estimators=30, max_depth=2, min_samples_leaf=7, max_features=10)
    rf_model.fit(X_train, y_train)
    ```

    您应该得到以下输出:

    ![Figure 4.39: Logs of RandomForest
    ](image/B15019_04_39.jpg)

    图 4.39:随机森林的日志

8.  用`.predict()`对训练集和测试集进行预测，并将结果保存到两个新变量中，称为`train_preds`和`test_preds` :

    ```
    train_preds = rf_model.predict(X_train)
    test_preds = rf_model.predict(X_test)
    ```

9.  计算训练集和测试集的准确度分数，并将结果保存在两个新变量中，称为`train_acc`和`test_acc` :

    ```
    train_acc = accuracy_score(y_train, train_preds)
    test_acc = accuracy_score(y_test, test_preds)
    ```

10.  Print the accuracy scores: `train_acc` and `test_acc`:

    ```
    print(train_acc)
    print(test_acc)
    ```

    您应该得到以下输出:

    ![Figure 4.40: Accuracy scores for the training and testing sets
    ](image/B15019_04_40.jpg)

    图 4.40:训练集和测试集的准确度分数

11.  Instantiate another `RandomForestClassifier` with `random_state=42`, `n_estimators=30`, `max_depth=2`, `min_samples_leaf=7`, and `max_features=0.2`, and then fit the model with the training set:

    ```
    rf_model2 = RandomForestClassifier(random_state=42, n_estimators=30, max_depth=2, min_samples_leaf=7, max_features=0.2)
    rf_model2.fit(X_train, y_train)
    ```

    您应该得到以下输出:

    ![Figure 4.41: Logs of RandomForest with max_features = 0.2
    ](image/B15019_04_41.jpg)

    图 4.41:max _ features = 0.2 的随机森林的日志

12.  用`.predict()`对训练集和测试集进行预测，并将结果保存到两个新变量中，称为`train_preds2`和`test_preds2` :

    ```
    train_preds2 = rf_model2.predict(X_train)
    test_preds2 = rf_model2.predict(X_test)
    ```

13.  计算训练集和测试集的准确度分数，并将结果保存在两个新变量中，称为`train_acc2`和`test_acc2` :

    ```
    train_acc2 = accuracy_score(y_train, train_preds2)
    test_acc2 = accuracy_score(y_test, test_preds2)
    ```

14.  Print the accuracy scores: `train_acc` and `test_acc`:

    ```
    print(train_acc2)
    print(test_acc2)
    ```

    您应该得到以下输出:

    ![Figure 4.42: Accuracy scores for the training and testing sets
    ](image/B15019_04_42.jpg)

图 4.42:训练集和测试集的准确度分数

我们在本练习中为`max_features`超参数尝试的值`10`和`0.2`确实提高了训练集的准确性，但没有提高测试集的准确性。有了这些值，模型又开始过度拟合。`max_features`的最佳值是该数据集的默认值(`sqrt`)。最终，我们成功地建立了一个精确度分数为 0.8 的模型，这个分数并没有过度拟合。考虑到数据集并不大，这是一个相当好的结果:我们只有`6`个特征和`41759`个观察值。

## 活动 4.01:在等值线数据集上训练一个随机森林类 sifier

你在一家科技公司工作，他们计划推出一款新的语音助手产品。您的任务是构建一个分类模型，该模型将根据捕获的信号频率识别用户拼出的字母。每个声音都可以被捕捉并表示为由多个频率组成的信号。

注意

这是 ISOLET 数据集，取自以下链接的 UCI 机器学习知识库:[https://packt.live/2QFOawy](https://packt.live/2QFOawy)。

这个数据集的 CSV 版本可以在这里找到:[https://packt.live/36DWHpi](https://packt.live/36DWHpi)。

以下步骤将帮助您完成此活动:

1.  使用`pandas`中的`.read_csv()`下载并加载数据集。
2.  使用`pandas`中的`.pop()`提取响应变量。
3.  使用来自`sklearn.model_selection`的`train_test_split()`将数据集分成训练集和测试集。
4.  创建一个函数，该函数将使用来自`sklearn.ensemble`的`.fit()`实例化并拟合一个`RandomForestClassifier`。
5.  使用`.predict()`创建一个函数来预测训练和测试集的结果。
6.  创建一个函数，使用来自`sklearn.metrics`的`accuracy_score()`打印训练和测试集的准确度分数。
7.  训练并获得`n_estimators = 20`和`50`的准确度分数。
8.  训练并获得`max_depth = 5`和`10`的准确度分数。
9.  训练并获得`min_samples_leaf = 10`和`50`的准确度分数。
10.  训练并获得`max_features = 0.5`和`0.3`的准确度分数。
11.  选择最佳超参数值。

这些是我们训练的最佳模型的准确度分数:

![Figure 4.43: Accuracy scores for the Random Forest classifier
](image/B15019_04_43.jpg)

图 4.43:随机森林分类器的准确度分数

注意

活动的解决方案可以在这里找到:[https://packt.live/2GbJloz](https://packt.live/2GbJloz)。

# 总结

我们终于到达了这一章关于随机森林的多类分类的结尾。我们了解到多类分类是二元分类的扩展:目标变量可以有更多的值，而不是只预测两个类。我们看到了如何用几行代码训练一个随机森林模型，并通过计算训练集和测试集的准确性分数来评估其性能。最后，我们学习了如何调优它的一些最重要的超参数:`n_estimators`、`max_depth`、`min_samples_leaf`和`max_features`。我们还看到了它们的值如何对模型的预测能力以及对未知数据的归纳能力产生重大影响。

在实际项目中，选择一个有效的测试集是非常重要的。在将模型投入生产之前，这是您的最终代理，因此您真的希望它反映您认为它将来会收到的数据类型。例如，如果您的数据集有一个日期字段，您可以使用最近几周或几个月作为您的测试集，而将该日期之前的所有内容作为训练集。如果您没有正确地选择测试集，您可能最终得到一个非常好的模型，它看起来不会过度拟合，但是一旦投入生产，它将生成不正确的结果。问题不在于模型，而在于测试集选择不当。

在某些项目中，您可能会看到数据集被分成三个不同的集合:定型、验证和测试。验证集可用于调整超参数，一旦您足够自信，就可以在测试集上测试您的模型。如前所述，我们不希望模型看到太多的测试集，但是超参数调优要求您多次运行模型，直到找到最佳值。这就是为什么大多数数据科学家为此目的创建一个验证集，而只使用测试集很少几次的原因。这将在第 7 章*机器学习模型的推广*中进行更深入的解释。

在下一节中，将向您介绍无监督学习，并学习如何使用 k-means 算法构建聚类模型。