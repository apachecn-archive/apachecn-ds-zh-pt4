

# 16。机器学习管道

概观

本章结束时，您将能够使用 scikit-learn pipeline 实用程序自动化机器学习(ML)工作流；用管道处理和转换数据；使用管道自动化模型构建过程；并且使用网格搜索杠杆流水线来加速模型参数的选择。

在本章中，我们将使用在*第 15 章*、*集成学习*中使用的信用卡应用数据集，并且我们将研究使用管道实用程序执行预处理、降维和建模。

# 简介

在前一章中，我们学习了通过组合单个模型来生成集合模型的各种技术。你会注意到，构建理想的集成学习模型需要对不同的基础学习者和元学习者进行大量的实验。这不仅仅是集成学习的情况。ML 的整个领域都是关于执行各种实验，以找到参数和超参数的正确组合，并能够从模型中提取性能。

这是一个耗时的过程，在确定特定场景的理想组合之前，必须尝试许多不同的排列和组合。这就是 ML 管道发挥重要作用的地方。ML 管道有助于自动化 ML 工作流中的许多任务。在本章中，我们将探讨如何使用 ML 管道来实现 ML 工作流的自动化。

在下一节中，我们将在实现本章的管道练习之前定义业务环境。

# 管道

在您的数据科学之旅中，您将意识到在获得任何最终结果之前有各种过程要经历，包括数据清理、数据转换、建模等等。您会发现，当我们分别执行这些活动时，我们必须编写单独的步骤来执行它们。当我们必须为一个新数据集执行这些步骤时，即使它与我们之前处理过的另一个数据集相似，我们也必须再次重复这些步骤。正如您已经注意到的，这些步骤是冗长而重复的。

Pipeline 是 scikit-learn 库中的一个实用程序，它可以自动完成许多这样的任务。使用这个工具，我们可以将多个进程堆叠在一起，用于多个数据集。这有助于我们完成数据科学之旅中的许多手动步骤。

看看*图 16.1*；我们在多个不同的数据集上使用了流水线过程。然而，由于我们提供的管道流程，我们可以确保我们将获得预期的结果，即使正在处理不同的数据集:

![Figure 16.1: Working on ML pipelines
](image/B15019_16_01.jpg)

图 16.1:处理 ML 管道

在本章中，我们现在将定义一个可以应用 ML 管道的业务上下文。

## 业务背景

你在银行的信用卡部门工作。您已经对数据集进行了许多实验，以提高模型的性能。然而，你已经意识到这需要花费大量的时间，并且你必须交付期望结果的最后期限已经临近。为了加速这个过程，您决定使用 ML 管道来自动化和加速您的 ML 任务。

在以下练习中，您将准备数据集，这是您的组织向您提供原始数据集时您要做的第一步。您将使用管道来实现自动化。

## 练习 16.01:准备数据集以实现管道

在本练习中，我们将从 GitHub 存储库中下载数据集，将其加载到我们的 Colab 笔记本中，并进行一些基本的探索。此外，我们还将清理数据集。

这个练习将与*第 15 章*、*整体学习*中实施的练习相同。

以下步骤将帮助您完成本练习:

注意

本练习的数据集可从以下 GitHub 链接获得:[https://packt.live/35qUJHE](https://packt.live/35qUJHE)。

1.  打开新的 Colab 笔记本。
2.  现在，在你的 Colab 笔记本中导入`pandas`:

    ```
    import pandas as pd
    ```

3.  接下来，设置 GitHub 存储库的路径来上传数据，如下面的代码片段所示:

    ```
    #Loading data from the GitHub repository to Colab notebook
    filename = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter15/Dataset/crx.data'
    ```

4.  Read the file using the `pd.read_csv()` function from the `pandas` DataFrame:

    ```
    credData = pd.read_csv(filename,sep=",",header = None,na_values = "?")
    credData.head()
    ```

    在`pd.read_csv()`函数中使用的参数是字符串形式的文件名和`CSV`的限制分隔符，T1 是`","`。

    注意

    数据集中没有头，所以我们专门使用命令头`= None`。

    我们还使用参数`na_values = "?"`用`na`值替换数据集中表示为`?`的缺失值。进行这种替换是为了简化进一步的处理，例如输入缺失数据的平均值。

    读取文件后，使用`.head()`功能打印数据帧。

    您应该得到以下输出:

    ![Figure 16.2: Loading the data into the Colab notebook
    ](image/B15019_16_02.jpg)

    图 16.2:将数据加载到 Colab 笔记本中

    您会注意到，在数据集中，对于列`15`中表示的类，有一些特殊字符:`+`表示被批准使用信用卡的客户，`-`表示未被批准使用信用卡的客户。

5.  Change these to numerical values of `1` for approved and `0` for not approved, as shown in the following code snippet:

    ```
    # Changing the Classes to 1 & 0
    credData.loc[credData[15] == '+' , 15] = 1
    credData.loc[credData[15] == '-' , 15] = 0
    credData.head()
    ```

    您应该得到以下输出:

    ![Figure 16.3: DataFrame after replacing special characters
    ](image/B15019_16_03.jpg)

    图 16.3:替换特殊字符后的数据帧

    在前面的代码片段中，`.loc()`用于定位第 15 列，并将`+`或`-`值分别替换为`1`和`0`。

6.  Now, find the number of null values in each of the features using the `.isnull()` function. The `.sum()` function sums up all such null values across each of the columns in the dataset. This is done as shown in the following code snippet:

    ```
    # Finding number of null values in the data set
    credData.isnull().sum()
    ```

    您应该得到以下输出:

    ![Figure 16.4: Summarizing null values in the dataset
    ](image/B15019_16_04.jpg)

    图 16.4:汇总数据集中的空值

    从输出中可以看出，有许多列包含空值。接下来，我们继续清理这个数据集。

7.  使用带有以下代码片段的`.dropna()`函数删除所有带有`na`值的行:

    ```
    # Dropping all the rows with na values
    newcred = credData.dropna(axis = 0)
    ```

8.  Now, find the shape of the old and updated dataset using `.shape`:

    ```
    # Printing the shape of earlier data set and new data set
    print(credData.shape)
    print(newcred.shape)
    ```

    您应该得到以下输出:

    ```
    (690, 16)
    (653, 16)
    ```

    如您所见，大约 37 行带有`na`值的行被删除。在*步骤 7* 的代码片段中，我们定义了`axis = 0`来表示`na`值的删除应该沿着行进行。

9.  现在让我们从数据集中分离出`X`和`y`变量。这是通过使用`.loc()`功能:

    ```
    # Separating X and y variables
    X = newcred.loc[:,0:14]
    print(X.shape)
    y = newcred.loc[:,15]
    print(y.shape)
    ```

    实现的
10.  As the final step of data preparation, we will now split the dataset into training and testing sets using the `train_test_split()` function:

    ```
    from sklearn.model_selection import train_test_split
    # Splitting the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)
    print(X_train.shape)
    print(X_test.shape)
    ```

    您应该得到以下输出:

    ```
    (457, 15)
    (196, 15)
    ```

通过完成这个练习，我们现在已经在训练和测试集中准备好了所需的数据集，以供进一步处理。

在下一节中，我们将使用管道自动处理这个数据集。

# 使用管道实现 ML 工作流程自动化

现在我们已经准备好了数据，我们准备好实现管道工具来自动化我们的工作流。在接下来的章节中，我们将在 ML 工作流程中逐步构建管道。我们将采取的路径如*图 16.5* 所示:

![Figure 16.5: Path to take when automating ML using pipelines
](image/B15019_16_05.jpg)

图 16.5:使用管道实现 ML 自动化的途径

让我们来探索其中的每一步。

注意

如*图 16.5* 中所述，所有这些主题在之前的章节中都有涉及。在本章中，我们将使用管道来自动化这些过程。

## 使用管道自动化数据预处理

数据处理是任何 ML 工作流程的第一步。在*第 15 章中，集成学习*在*练习 15.01* 中，我们实现了数据处理步骤，例如分离分类数据和数值数据，从分类数据中创建虚拟变量，以及标准化数据。

在本章中，我们将使用 ML 管道执行所有这些步骤。

使用 scikit-learn 实现 ML 管道是通过一个名为`Sklearn.pipeline`的模块实现的。从这个模块中，我们导入`Pipeline()`函数来自动化工作流。作为自动化的一部分，将向您介绍 scikit-learn 中的一些新功能。

让我们逐一探索这些函数，从一个著名的函数`OneHotEncoder()`开始:

1.  Let's start with the `OneHotEncoder()` function. In the previous chapters, we transformed categorical variables to dummy variables as part of data processing. We used a function within `pandas` called `pd.create_dummies()`. However, the `OneHotEncoder()` function achieves the same purpose. It transforms categorical variables to a special format called one-hot encoded format. The one-hot encoded format represents the presence or absence of a variable using the values 1 and 0, respectively. Let's explore this concept with an example.

    假设我们有一个包含以下数据点的分类数据集。这是一个七行一列的数据集，如图*图 16.6* 所示。该数据集中有三个唯一值:A、B 和 C:

    ![Figure 16.6: Dataset of categorical values
    ](image/B15019_16_06.jpg)

    图 16.6:分类值数据集

    `OneHotEncoding()`函数将形状为(7 x 1)的前一个数据集转换为形状为(7 x 3)的数据集，其中一列对应于每个唯一数据点-A、B 和 c。

    每个像元的值将是`1`或`0`，这取决于原始数据集中是否存在唯一的数据点。新表单表示如下:

    ![Figure 16.7: DataFrame after one-hot encoding
    ](image/B15019_16_07.jpg)

    图 16.7:一键编码后的数据帧

    从新数据集，我们可以看到原始数据集的第一行有值 A，因此在新数据集中 A 列下有 1，其他两列是 0。所有其他行遵循类似的模式。

    使用`.fit()`方法和`.transform()`方法实现`OneHotEncoder()`功能。在实现`OneHotEncoder()`函数时，有一个名为`handle_unknown`的参数，它支持对用于拟合函数的数据集中不存在的值进行处理。

    例如，假设用于拟合函数的数据集中的唯一值是 A 和 b。我们应用了`.transform()`方法的新数据集具有唯一值 A 和 C。在这种情况下，新数据集具有 C 值，这在数据集拟合时不会遇到。通过定义参数`handle_unknown = ignore`，我们指示函数忽略这样的异常。遇到这种异常时，该函数会创建一个包含零的行。

2.  The `ColumnTransformer()` function is available in the `Sklearn.compose` package. This is a utility function for transforming columns. In *Chapter 15*, we performed data preprocessing where we separated the categorical and numerical variables to apply different transformations such as dummy variable creation and scaling. These transformed datasets were concatenated later to form the final DataFrame.

    `ColumnTransformer()`函数在一个函数中自动完成所有这些步骤。在这个函数中，我们使用一个名为 **transformers** 的参数来定义我们想要应用于数据集的转换类型。一旦定义了这些转换器，该函数就会执行必要的转换，然后创建一个新的数据集。

现在我们已经介绍了两个重要的函数，让我们看看在*练习 16.02* 中它们将如何用于特征提取。

## 练习 16.02:将用于特征提取的管道应用于数据集

本练习的目的是在建模阶段之前从分类变量和数值变量中提取新特征。在前面的章节中，我们应用了各种特征提取技术，例如将分类变量转换为虚拟变量和比例变量。本练习将演示如何使用 ML 管道自动完成这些任务:

1.  执行*练习 16.01* 、*的所有步骤，为实施管道*准备数据集，直到数据集被分割成训练集和测试集。
2.  Now, import the necessary packages, which are `Pipeline()`, `StandardScaler()`, and `OneHotEncoder()`:

    ```
    from sklearn.pipeline import Pipeline
    from sklearn.preprocessing import StandardScaler, OneHotEncoder
    ```

    既然您已经导入了重要的库，那么在下一步中，我们将创建第一个管道，用于将分类变量转换为一位热码编码变量。

3.  使用`Pipeline`函数中的`steps`参数定义不同的转换，如下面的代码片段所示:

    ```
    # Pipeline for transforming categorical variables
    catTransformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])
    ```

4.  我们现在将使用`StandardScaler()`函数标准化数值变量，该函数在*第 3 章* :

    ```
    # Pipeline for scaling numerical variables
    numTransformer = Pipeline(steps=[('scaler', StandardScaler())])
    ```

    中介绍
5.  Let's print the different data types for the independent variable, `X`:

    ```
    # Printing dtypes for X
    X.dtypes
    ```

    您应该得到以下输出:

    ![Figure 16.8: Output showing the different data types
    ](image/B15019_16_08.jpg)

    图 16.8:显示不同数据类型的输出

    我们可以看到，分类变量由类型`object`表示，数值数据由类型`float64`和`int64`表示。

6.  Select the numerical features based on the data types, `float64` and `int64`. You will now identify all the numerical columns using the `.columns` method. The selection of appropriate data types is implemented using the `.select_dtypes()` method, as shown in the following code snippet:

    ```
    # Selecting numerical features
    numFeatures = X.select_dtypes(include=['int64', 'float64']).columns
    numFeatures
    ```

    您应该得到以下输出:

    ![Figure 16.9: The numerical features based on the data types, float64 and int64
    ](image/B15019_16_09.jpg)

    图 16.9:基于数据类型 float64 和 int64 的数字特征

7.  Now, select the categorical features, which are of the `object` data type:

    ```
    # Selecting Categorical features
    catFeatures = X.select_dtypes(include=['object']).columns
    catFeatures
    ```

    您应该得到以下输出:

    ![Figure 16.10: The numerical features based on the data type object
    ](image/B15019_16_10.jpg)

    图 16.10:基于数据类型对象的数字特征

    为了了解我们下一步要做的事情，我们将创建一个文字*引擎*,它可以自动执行缩放数字特征和将分类变量转换为一键编码形式的任务。

    从前面的章节中，我们已经实现了分类变量的缩放和转换，我们知道这些任务涉及多个步骤。为了在新的数据集上执行这些步骤，我们必须再次重复代码。然而，通过构建这个引擎，我们将自动化这些转换任务。现在，我们所要做的就是将这个引擎应用到新的数据集，以更有效地实现缩放和一键编码的理想转换。

8.  Create a transformation engine using the `ColumnTransformer()` function, as shown in the following code snippet:

    ```
    # Creating the preprocessing engine
    from sklearn.compose import ColumnTransformer
    preprocessor = ColumnTransformer(
        transformers=[
            ('numeric', numTransformer, numFeatures),
            ('categoric', catTransformer, catFeatures)])
    ```

    从实现来看，我们通过`transformers`参数给出了必要的转换。第一个转换器是数字转换器，用字符串`numeric`表示。然后，我们将在*步骤 4* 中创建的`numTransformer`应用于在*步骤 6* 中识别的数字特征`numFeatures`。类似地，我们为分类变量定义适当的转换。

9.  Now that we have created an engine called `preprocessor`, we will apply this engine to transform training data. The transformation is done using the `fit_transform()` function:

    ```
    # Transforming the Training data
    Xtran_train = pd.DataFrame(preprocessor.fit_transform(X_train))
    print(Xtran_train.shape)
    Xtran_train.head()
    ```

    您应该会得到类似如下的输出:

    ![Figure 16.11: Transformation of the training data
    ](image/B15019_16_11.jpg)

    图 16.11:训练数据的转换

    注意

    这里只显示了总共 46 列中的前 15 列。

    转换函数的输出是一个数组。我们使用`pd.DataFrame()`函数将其转换成`pandas`数据帧。我们进行转换，使输出与我们的输入数据集一致，这是一个`pandas`数据框架。

10.  Now, transform the test set using the preprocessing engine as shown in the following code snippet:

    ```
    # Transforming Test data
    Xtran_test = pd.DataFrame(preprocessor.transform(X_test))
    print(Xtran_test.shape)
    Xtran_test.head()
    ```

    您应该会得到类似如下的输出:

![Figure 16.12: Transformation of the test set using the preprocessing engine
](image/B15019_16_12.jpg)

图 16.12:使用预处理引擎转换测试集

在这里，我们已经用我们在*步骤 8* 中创建的引擎完成了转换训练和测试集的任务。您会注意到，这是通过使用预处理引擎上的`.transform()`功能实现的。

在本练习中，我们使用管道和列转换方法实现了数据处理。您会注意到，一旦创建了一个引擎，就很容易将该引擎应用于多个数据集。这就是管道功能的本质:流程的自动化。

# 处理和降维的 ML 管道

上一个练习是我们对 ML 管道如何工作的介绍。在本节中，我们将建立在处理步骤的基础上，然后执行降维(在第 14 章*降维*中讨论)作为第二个转换步骤。我们将使用**主成分分析** (PCA)，它在*第 14 章*、*降维*中讨论过，是一个额外的转换步骤。

然而，在本节中，我们将在管道中引入一个新特性，称为**估计器**。估计器是一个实用程序，它可以顺序地将多个过程链接在一起，例如特征提取、特征归一化和维数减少。该引擎将有能力拟合和转换原始数据，以获得所需的功能。使用该实用程序的优点是，所有的过程可以在一个地方链接在一起，并应用于不同的数据集以获得类似的转换。

让我们在*练习 16.03* 中实现这一点。

## 练习 16.03:在特征提取流程中增加降维

在上一个练习中，我们使用 pipeline 实用程序构建了一个引擎，它从原始变量中提取特征。在本练习中，我们将向该引擎添加额外的功能。

我们将使用 pipeline 实用程序为该引擎添加降维功能。在本练习中，我们还将看到管道是如何将多个流程缝合在一起，从而实现 ML 工作流的自动化。

以下步骤将帮助您完成练习:

1.  执行*练习 16.02* 下的所有步骤，直到创建预处理引擎。
2.  导入`PCA`库:

    ```
    # Importing PCA library
    from sklearn.decomposition import PCA
    ```

3.  Now, add the new step, which is to reduce dimensions, to the pipeline. The new pipeline is then saved under the `estimator` variable, as shown in the following code snippet:

    ```
    # Creating an estimator with both preprocessor and dimensionality reduction
    estimator = Pipeline(steps=[('preprocessor', preprocessor),
                          ('dimred', PCA(10))])
    ```

    在此步骤中，PCA 用字符串`dimred`表示。我们将数据集缩减到`10`维。

4.  Let's now fit the training data using the new pipeline that has been created and transform the training set into a new DataFrame called `Xtran_train`:

    ```
    # Fitting and transforming Training set
    Xtran_train = pd.DataFrame(estimator.fit_transform(X_train))
    print(Xtran_train.shape)
    Xtran_train.head()
    ```

    您应该得到以下输出:

    ![Figure 16.13: Output showing that the dataset has been reduced to 10 features
    ](image/B15019_16_13.jpg)

    图 16.13:显示数据集已减少到 10 个要素的输出

    可以看到数据集已经缩减为`10`个特征。

5.  You will now transform the test set using the new pipeline:

    ```
    # Transforming test set
    Xtran_test = pd.DataFrame(estimator.transform(X_test))
    print(Xtran_test.shape)
    Xtran_test.head()
    ```

    您应该会得到类似如下的输出:

![Figure 16.14: Transformation of the test set
](image/B15019_16_14.jpg)

图 16.14:测试集的转换

从这些步骤中可以看出，转换训练集和测试集的任务是用同一个引擎完成的。

在本练习中，我们使用`Pipeline()`函数实现了数据预处理步骤，如缩放、一键编码和降维。正如我们已经看到的，使用`Pipeline()`函数实现新的步骤非常直观和简单。

# 用于建模和预测的 ML 管道

在上一节中，我们介绍了估计量的概念，它将不同的转换过程联系在一起，使特征提取更容易。我们还看到了我们构建的估算器的`fit`和`transform`函数的演示。估计器的功能远不止`fit`和`transform`。估计器也可用于将分类器(如逻辑回归、KNN 或随机森林分类器)与转换步骤链接在一起。

当分类器被引入估计器时，估计器也继承了分类器的许多功能，例如评分和预测。

因此，现在我们有了一个引擎，它能够执行非常多样的功能，否则这些功能将必须由单独的功能来执行。这就是管道实用程序的美妙之处，它使我们能够在单个引擎中构建无所不包的功能。

在下一个练习中，我们将演示由 ML 管道实现的无所不包的引擎。

## 练习 16.04:使用 ML 管道进行建模和预测

本练习旨在通过前面的练习，在估算器功能中建立已经内置的功能。

在前面的练习中，我们将缩放、一键编码和降维等功能整合到估计器中，以转换原始变量，从而提取新特征。在本练习中，我们将通过将逻辑回归分类器链接到估计器来进一步增强功能。我们还将对分类器进行评分，并根据测试集生成我们对哪些客户值得信赖的预测:

1.  执行*练习 16.03* 的所有步骤，直到预处理器引擎创建完成。
2.  Import the necessary libraries as shown in the following code snippet:

    ```
    # Importing necessary libraries
    from sklearn.decomposition import PCA
    from sklearn.linear_model import LogisticRegression
    ```

    在下一步中，您将创建 estimator 函数，包括模型构建部分。如前所述，所有附加流程都作为步骤添加到`Pipeline()`功能中。

3.  Now, create an `estimator` function:

    ```
    # Creating the estimator pipeline for model building
    estimator = Pipeline(steps=[('preprocessor', preprocessor),
                          ('dimred', PCA(10)),
                               ('clf',LogisticRegression(random_state=123))])
    ```

    在此步骤中，逻辑回归模型由字符串`clf`表示。

4.  Fit the model on the training set using the `.fit()` function:

    ```
    # Fitting the modelling pipeline on the training set
    estimator.fit(X_train,y_train)
    ```

    一旦模型拟合完成，管道中的每个步骤都将按顺序执行，最终创建模型。

5.  Now, print the accuracy score using the `.score()` function on the test set:

    ```
    # Creating the score on the test set
    estimator.score(X_test, y_test)
    ```

    您应该会得到类似如下的输出:

    ```
    0.8877551020408163
    ```

6.  现在，在测试集上生成您的预测:

    ```
    # Generating the predictions on test set
    pred = estimator.predict(X_test)
    ```

7.  Print the classification report:

    ```
    # Printing the classification report
    from sklearn.metrics import classification_report
    print(classification_report(pred,y_test))
    ```

    您应该会得到类似如下的输出:

    ![Figure 16.15: Classification report for the model
    ](image/B15019_16_15.jpg)

    图 16.15:模型的分类报告

8.  Now, print the confusion matrix as shown in the following code snippet:

    ```
    # Generating confusion matrix
    from sklearn.metrics import confusion_matrix
    confusionMatrix = confusion_matrix(y_test, pred)
    print(confusionMatrix)
    ```

    您应该会得到与下面类似的输出:

![Figure 16.16: Confusion matrix of the resulting metrics obtained
](image/B15019_16_16.jpg)

图 16.16:获得的结果度量的混淆矩阵

在本练习中，我们能够向估计函数添加建模、评分和预测功能。我们已经看到，所有这些步骤都整合到一个引擎中，这大大简化了流程。

让我们从商业角度仔细看看结果。我们看到我们得到了`89%`的准确率，这意味着测试集中的客户的`89%`(分类报告)被正确地分类为可信或不可信。让我们仔细看看每个类的召回值。我们可以看到，`0`类代表那些召回值为`90%`的不值得购买的客户。这意味着几乎 10% (100%-90%)的不值得的客户被错误地归类为值得的客户，这将是企业必须承担的风险。另一方面，有价值客户的召回值只有`88%`，这意味着企业错过了 12%的机会(100%-88%)。

# 用于抽查多个型号的 ML 管道

实施数据科学项目主要是一个迭代过程。数据科学生命周期中的一个关键决策点是确定在什么场景中尝试什么模型。这种在什么场景中使用什么模型的决定是在对多个模型进行不同的实验后得出的。这个过程称为抽查模型。

抽查模型是一个相当费力的过程。我们必须试验多个模型和不同的模型参数排列，直到找到最佳模型。模型的最终选择是基于它在测试集上的表现。当单独实施时，所有这些过程都相当耗时。

ML 管道可以用来使这个过程容易实现。我们将在下一个练习中看到这一过程的运行，我们将对四个不同的模型进行抽查。

## 练习 16.05:使用 ML 管道抽查模型

在前面的练习中，我们看到了估算器的创建，它用于预处理，然后拟合单个模型。

在本练习中，我们将使用估计量来抽查四个不同的模型-逻辑回归、KNN、随机森林和 Adaboost。这些模型将用于拟合由信用卡应用数据集生成的训练集，然后在测试集上生成预测。最佳模型将基于测试集的准确度分数来选择。

以下步骤将帮助您完成练习:

1.  执行*练习 16.04* 的所有步骤，直到预处理引擎创建完成。
2.  导入必要的库，如下面的代码片段所示:

    ```
    # Importing necessary libraries
    from sklearn.decomposition import PCA
    from sklearn.linear_model import LogisticRegression
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
    ```

3.  现在，创建一个分类器列表。该列表将在以下步骤中通过`for`循环执行:

    ```
    # Creating a list of the classifiers
    classifiers = [
        KNeighborsClassifier(5),     
        RandomForestClassifier(random_state=123),
        AdaBoostClassifier(random_state=123),
        LogisticRegression(random_state=123)
        ]
    ```

4.  Now, initiate a `for` loop over all the classifiers and then pass the respective classifiers into the estimator. The estimator here is the same as the one we created in *Exercise 16.04*. After the estimator is created, it is fit on the training data and the model scores are printed. These steps are implemented using the following code snippet:

    ```
    for classifier in classifiers:
        estimator = Pipeline(steps=[('preprocessor', preprocessor),
                          ('dimred', PCA(10)),
                               ('classifier',classifier)])
        estimator.fit(X_train, y_train)   
        print(classifier)
        print("model score: %.2f" % estimator.score(X_test, y_test))
    ```

    您应该得到以下输出:

![Figure 16.17: Report on the scores of each model
](image/B15019_16_17.jpg)

图 16.17:每个模型的分数报告

从输出中，我们可以观察每个模型在测试集上的得分。我们有精确度为`83%`的 KNN，精确度为`79%`的随机森林，精确度为`86%`的 Adaboost，精确度为`89%`的逻辑回归。从抽查过程来看，逻辑回归被认为是较好的模型。

从商业的角度来看，这个分数意味着 89%的客户被正确地归类为有信用或没有信用的银行。

# 用于确定模型最佳参数的 ML 管道

数据科学工作流程中的一个重要步骤是通过尝试模型的不同参数来微调模型。这一步对于提高性能指标(如模型的准确性或召回率)是必要的。然而，这一步非常耗时，因为它涉及到使用不同的参数组合来拟合模型，直到我们获得最佳性能。使用 ML 管道可以非常有效地实现所有这些任务。在下一个练习中，我们将对模型进行微调。

在此实现中，我们将使用我们在前几章中学到的两个重要概念:

*   交叉验证
*   网格搜索

## 交叉验证

正如我们在*第 7 章*中了解到的，交叉验证是这样一个步骤，我们将训练集分成多个部分，并在数据集的不同部分拟合一个模型，留出一部分用于验证结果。我们得到的结果将是所有遗漏部分所得结果的平均值。在此实施中，我们将使用 10 重交叉验证。

## 网格搜索

网格搜索是在第 8 章中介绍的一种方法。该方法包括定义模型参数网格，以在模型上进行试验。使用网格搜索，我们找到可以产生最佳结果的模型参数的最佳排列。

在这个实现中，我们将使用一种叫做`GridSearchCV()`的方法，它是网格搜索和交叉验证的结合。该方法将从`sklearn.model_selection`模块导入。通过创建将在模型中迭代的不同参数的字典来定义不同的参数。对于 PCA 的主成分，我们将用不同的成分数量值进行实验(`n_components`)。对于`AdaBoostClassifier`，我们将尝试的参数是模型的估计数(`n_estimators`)和学习率(`learning_rate`)。

让我们在下一个练习中看到这一点。

## 练习 16.06:使用 ML 管道进行网格搜索和交叉验证

使用 ML 管道可以使通过网格搜索找到最佳模型参数的过程变得更容易。

在本练习中，我们将使用`AdaBoostClassifier()`模型。我们将执行网格搜索，以找到 PCA 过程的最佳组件数量以及建模过程的最佳超参数，例如估计器的数量和学习速率。在网格搜索之后，最终的模型参数，例如学习率、组件数量和估计器数量，将用于在信用卡应用程序数据集上进行预测。

以下步骤将帮助您完成练习:

1.  执行*练习 16.05* 下的所有步骤，直到创建预处理引擎。
2.  导入必要的库，如下面的代码片段所示:

    ```
    # Importing necessary libraries
    from sklearn.decomposition import PCA
    from sklearn.ensemble import AdaBoostClassifier
    ```

3.  使用`AdaBoostClassifier`创建一个管道。这个步骤是使用下面的代码片段实现的:

    ```
    # Creating a pipeline with AdaBoostClassifier
    pipe = Pipeline(steps=[('preprocessor', preprocessor),
                          ('dimred', PCA()),
                               ('classifier',AdaBoostClassifier(random_state=123))])
    ```

4.  Define the parameters as a dictionary, as shown in the following code snippet:

    ```
    # Defining the parameters as a dictionary
    param_grid = {'dimred__n_components':[10,12,15],"classifier__n_estimators": [50, 100,200],"classifier__learning_rate":[0.7,0.6,1.0]}
    ```

    在这一步中，我们使用花括号`{ }`创建一个字典，然后定义每个参数。使用双下划线(`__`)将参数与管道关联起来。例如，`dimred__n_components`表示对于称为`dimred`的过程，即 PCA，要试验的参数是`n_components`。这种情况下要尝试的不同参数值以列表形式给出。

    在`n_components`的情况下，我们将尝试的不同值是`[10, 12, 15]`。这些是将要实验的不同的主要成分。类似地，其他参数与管道中的相应步骤相关联。

5.  现在，使用`GridSearchCv`函数创建估计函数。`GridSearchCV`函数的参数是我们之前定义的管道，即交叉验证折叠的数量，以及我们想要探索的参数字典。这在下面的代码片段中实现:

    ```
    from sklearn.model_selection import GridSearchCV
    # Fitting the grid search
    estimator = GridSearchCV(pipe, cv=10, param_grid=param_grid)
    ```

6.  接下来，拟合我们在训练集上创建的估计器。由于有多个参数需要迭代，这一步将是一个耗时的步骤:

    ```
    # Fitting the estimator on the training set
    estimator.fit(X_train,y_train)
    ```

7.  After the grid search is complete, we will print out the best parameters and the best score obtained using these parameters on the model. The best score is printed using the `estimator.best_score_` argument, and the best parameters are output using the `estimator.best_params_` argument:

    ```
    # Printing the best score and best parameters
    print("Best: %f using %s" % (estimator.best_score_, 
        estimator.best_params_))
    ```

    您应该得到以下输出:

    ![Figure 16.18: Best parameter and the best score of the parameter set
    ](image/B15019_16_18.jpg)

    图 16.18:最佳参数和参数集的最佳得分

    从输出可以看到，对于 Adaboost 模型，最佳学习率为`0.7`，估计器个数为`50`，主成分个数为`15`。

8.  现在您已经找到了最佳参数的值，您将使用该估计量对测试集进行预测:

    ```
    # Predicting with the best estimator
    pred = estimator.predict(X_test)
    ```

9.  Print the classification report:

    ```
    # Printing the classification report
    from sklearn.metrics import classification_report
    print(classification_report(pred,y_test))
    ```

    您应该得到以下输出:

![Figure 16.19: Classification report for the model
](image/B15019_16_19.jpg)

图 16.19:模型的分类报告

在这个练习中，我们使用 ML 管道实现了网格搜索。我们使用流水线尝试了三组不同的参数，组件的数量，Adaboost 模型的估计器的数量，最后是 Adaboost 模型的学习速率。对于这些参数中的每一个，我们尝试了三个值。网格搜索算法尝试了这九个参数(3 x 3)的不同排列，然后选择给我们最好结果的组合。从这个练习中，我们可以看到 ML 管道使得确定最佳模型参数的过程更加有效。我们还观察到，通过模型参数的组合，我们得到了 Adaboost 模型的精度`84%`。

从结果来看，该模型只能正确预测 84%的客户信用度。

# 对数据集应用管道

到目前为止，在这一章中，我们已经看到了如何逐步使用 ML 管道来自动化数据科学生命周期的不同例子。现在是时候将我们的学习应用到新的数据集了。

我们将使用心脏病预测数据集，该数据集由 UCI 机器学习库提供，最初可在以下链接找到:[https://packt.live/2Qq09OC](https://packt.live/2Qq09OC)。数据集被称为`processed.cleveland.data`。

该数据集包含大约 14 个与身体参数相关的属性，如胆固醇、血压、胸痛等，这些属性可能是心脏病的指标。除了这些身体参数之外，还有个人特定的细节，例如年龄和性别。问题陈述是预测是否有心脏病的可能性。要了解关于数据集属性的更多信息，您可以使用以下链接:[https://packt.live/36uG4fE](https://packt.live/36uG4fE)。

目标变量具有从`0`到`4`的不同类别。`0`级表示没有心脏病，而`1`到`4`级表示有心脏病。

在接下来的活动中，我们将把问题转化为一个二元分类问题，使问题陈述变得简单。所以，我们可以预测是否有心脏病。这需要将目标变量的类转换成仅仅是`0`和`1`。现有的`0`类将保持原样，而`1`到`4`类将被映射到`1`类。

到目前为止，本章还没有介绍两个功能:

*   使用`.columns`函数命名列
*   使用`.pop()`功能删除列

您将在这里的一个示例中看到这两种方法。

首先使用`np.arange()`函数创建一个`numpy`数组，然后使用`reshape()`函数对其进行整形。

一旦创建了`numpy`数组，就使用`pd.DataFrame()`函数将其转换为 pandas 数据帧:

```
# Creating a numpy array using np.arange and reshaping it
import pandas as pd
import numpy as np
df = pd.DataFrame(np.arange(20).reshape(5,4))
df
```

您应该得到以下输出:

![Figure 16.20: Conversion to a pandas DataFrame
](image/B15019_16_20.jpg)

图 16.20:转换成熊猫数据帧

通过提供一个名称列表来创建数据帧的列名，例如`A`、`B`、`C`和`D`:

```
# Creating column names
df.columns = ['A','B','C','D']
df
```

`.columns`方法用于获取数据帧的列名。将列名等同于名称列表会用新名称代替旧名称。

您应该得到以下输出:

![Figure 16.21: Using the .columns method on the DataFrame
](image/B15019_16_21.jpg)

图 16.21:使用。数据帧上的 columns 方法

从输出中可以看到，原来的列名[`0,1,2,3`]已经被替换为[`A,B,C,D`]。

通过使用`.pop()`函数从数据帧中删除列`D`来创建新的数据帧:

```
# Create a new df by removing one column
df1 = df.pop('D')
print('Printing new data frame')
print(df1)
print('Printing old data frame')
print(df)
```

`.pop()`函数用于从数据集中*弹出*一个特征。从代码中可以看出，特征`D`已从现有数据帧中移除。

您应该得到以下输出:

![Figure 16.22: Using the pop method on the DataFrame
](image/B15019_16_22.jpg)

图 16.22:在数据帧上使用 pop 方法

从*图 16.22* 中，我们观察到通过使用`.pop`函数，列`D`被移除。列`D`在第一个数据集`df1`中单独表示。

现在，让我们将本章中的所有知识应用到本练习中的新数据集。

## 活动 16.01:在管道中完成 ML 工作流程

你在一家心脏诊所担任数据科学家。你的任务是根据病人的身体参数，如胆固醇、血压、脉搏等，对他们进行初步筛查。

本练习的目的是让您使用患者参数数据集预测患者是否患有心脏病。为了简化数据科学的生命周期，您将在这个项目中使用 ML 管道，就像您在本章的其他地方所做的那样。

完成此活动的步骤如下:

1.  打开新的 Colab 笔记本。
2.  从 GitHub 资源库加载数据集:[https://packt.live/37DJcpO](https://packt.live/37DJcpO)。
3.  使用 pandas 读取数据，然后在缺少值或特殊字符(如`?`)的地方输入`NA`值。
4.  使用`.columns`函数定义列名。按照下面的列表指定名称:`['age','sex', 'cp', 'trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','label']`。
5.  将`label`列中除`0`之外的所有值的类更改为`1`，类似于本章中在信用卡数据集中所做的操作。
6.  使用`.dropna()`功能删除所有`NA`值。
7.  使用`.pop()`函数创建`Y`变量。
8.  从剩余的数据帧中创建`X`变量。
9.  使用`train_test_split`将数据集分成训练集和测试集。
10.  现在，创建处理引擎。
11.  导入`PCA`、`Logistic Regression`、`KNeighborsClassifier`、`RandomForestClassifier`、`AdaBoostClassifier`库抽查模型。
12.  创建分类器列表。
13.  使用预处理器、`PCA(10)`和分类器创建评估函数。为了获得分类器，使用一个`for`循环通过分类器列表形成一个迭代循环。
14.  选择生成最高准确度分数的模型。
15.  使用预处理器`PCA()`和给出最高准确度分数的分类器创建一个包含所有参数的新管道。
16.  Define the parameters of the selected model as in *Exercise 16.06*.

    如果所选模型是逻辑回归，请尝试以下参数:

    ```
    # Defining the parameters as a dictionary
    param_grid ={'dimred__n_components':[10,11,12,13],'classifier__penalty' : ['l1', 'l2'],'classifier__C' : [1,3, 5],'classifier__solver' : ['liblinear'] }
    ```

    如果选择的型号是`KNeighboursClassifier`，可以使用以下参数:

    ```
    # Defining the parameters as a dictionary
    param_grid ={'dimred__n_components':[10,11,12,13],'classifier__n_neighbors ' : [3,5,10,15]}
    ```

    如果选择的型号是`AdaBoostClassifier`，可以使用以下参数:

    ```
    # Defining the parameters as a dictionary
    param_grid ={'dimred__n_components':[10,11,12,13],"classifier__n_estimators": [50, 100,200],"classifier__learning_rate":[0.7,0.6,1.0]}
    ```

    如果选择的型号是`RandomForestClassifier`，可以使用以下参数:

    ```
    # Defining the parameters as a dictionary
    param_grid ={'dimred__n_components':[10,11,12,13],"classifier__n_estimators": [50, 100,200]}
    ```

17.  用`GridSearchCV`和`10`折叠定义估计量。
18.  使用`estimator.fit()`用训练集拟合估计器。
19.  打印最佳分数和最佳参数。
20.  使用`estimator.predict()`功能在测试集上生成预测。
21.  最后，打印分类报告。

**输出**:

您应该会得到类似如下的输出:

![Figure 16.23: Classification report for the model
](image/B15019_16_23.jpg)

图 16.23:模型的分类报告

注意

由于预测过程中的可变性，您将无法获得准确的输出值。

活动的解决方案可以在这里找到:[https://packt.live/2GbJloz](https://packt.live/2GbJloz)。

# 总结

在这一章中，我们介绍了 ML 管道。通过我们实施的无数练习，我们认识到，为了从我们的 ML 模型中挤出最佳性能，我们必须尝试各种特征、模型和模型参数的排列和组合。找到合适的组合确实是一个耗时的过程。使用 ML 管道是一种自动化这一过程的技术，可以省去我们大量的手工实验。

在本章中，我们逐步实现了 ML 工作流的不同部分。我们创建了一个处理引擎，并在处理引擎中增加了降维和建模。后来，我们对各种模型进行了抽查，还进行了网格搜索以找到最佳参数。在这个过程中，我们确定了 ML 管道是如何简化所有这些过程的。

本章的目的是让你能够使用一个非常强大的工具集在你的 ML 工作流程上进行不同的实验。读者可以发挥自己的聪明才智，在这里奠定的基础上进行扩展，并尝试使用管道进行不同的实验。如前所述，帮助你成为一名优秀数据科学家的秘诀是对不同技术、用例以及数据集进行严格的实验。

了解了一套旨在实现严格实验的工具后，我们将进入下一章，这将帮助你从实验中获得切实的成果。在接下来的几章中，我们将介绍在生产环境中部署模型的技术。这些概念是您数据科学之旅中非常重要的步骤。