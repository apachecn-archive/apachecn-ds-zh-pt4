<title>C15019_02_Final_ePub_RK</title> <link href="css/epub.css" rel="stylesheet" type="text/css">

# 2。回归

概观

本章结束时，你将能够识别和导入回归分析所需的 Python 模块；使用`pandas`模块加载数据集，并为回归分析做准备；创建一个二元数据散点图，并通过它拟合一条回归线；使用 Python `statsmodels`模块中可用的方法将回归模型拟合到数据集；解释简单和多元线性回归分析的结果；评估线性回归模型的拟合优度；并应用线性回归分析作为解决实际问题工具。

本章介绍线性回归分析及其在数据科学实际问题解决中的应用。您将学习如何使用 Python，一种通用的编程语言，来执行回归分析并检查结果。还将介绍如何使用对数函数来转换变量之间固有的非线性关系，以及如何应用线性回归分析方法。

# 简介

前一章提供了 Python 编程的入门知识和数据科学领域的概述。数据科学是一个相对年轻的多学科研究领域。它从传统的统计学、计算机科学和广泛的人工智能(AI)领域，尤其是称为机器学习的 AI 子领域中汲取概念和方法:

![Figure 2.1: The data science models
](image/B15019_02_01.jpg)

图 2.1:数据科学模型

正如您在*图 2.1* 中看到的，数据科学旨在利用**结构化**和**非结构化**数据，开发可有效使用的模型，进行预测，并获得决策洞察力。

结构化数据的松散描述是可以方便地排列到由行和列组成的表中的任何数据集。这种数据通常存储在数据库管理系统中。

然而，非结构化数据不能方便地以表格形式存储，例如文本文档。为了实现数据科学的目标，需要一种灵活的编程语言，将交互性与计算能力和速度有效地结合起来。这就是 Python 编程语言满足数据科学需求的地方，正如在第一章、*Python 中的数据科学介绍*中提到的，我们将在本书中使用 Python。

许多行业都需要开发模型来进行预测并获得决策洞察力。因此，数据科学在许多行业都有应用，包括医疗保健、制造和一般流程行业、银行和金融部门、营销和电子商务、政府和教育。

在本章中，我们将特别关注回归，这是数据科学中经常使用的关键方法之一，用于建模变量之间的关系，其中**目标变量**(即您正在寻找的值)是一个实数。

考虑这样一种情况，一家房地产公司想要了解一个城市的房地产价格之间的关系，如果可能的话，建模并了解这些房地产的关键属性。这是一个数据科学问题，可以通过回归来解决。

这是因为感兴趣的目标变量，即房产价格，是一个实数。可用于预测其价值的属性的关键属性示例如下:

*   财产的年龄
*   一处房产中卧室的数量
*   无论该物业是否有泳池
*   房产所覆盖的土地面积
*   物业距离火车站和学校等设施的距离

可以使用回归分析来研究这种情况，在这种情况下，您必须创建一个函数，将资产的关键属性映射到目标变量，在这种情况下，目标变量是资产的价格。

回归分析是称为**监督机器学习**的机器学习技术家族的一部分。它被称为有监督的，因为学习模型的机器学习算法提供了一种可以学习的*问题*和*答案*数据集。这里的*问题*是关键属性，而*答案*是研究中使用的每处房产的价格，如下图所示:

![Figure 2.2: Example of a supervised learning technique
](image/B15019_02_02.jpg)

图 2.2:监督学习技术的例子

一旦模型被算法学习，我们可以向模型提供一个问题(即，我们想要找到其价格的一个属性的集合)来告诉我们该属性的答案(即，价格)将是什么。

本章介绍了线性回归以及如何应用线性回归来解决实际问题，如前面在数据科学中描述的问题。Python 提供了一组丰富的模块(库),可用于进行各种严格的回归分析。在本章中，我们将使用以下 Python 模块，其中包括:`pandas`、`statsmodels`、`seaborn`、`matplotlib`和`scikit-learn`。

# 简单线性回归

在*图 2.3* 中，您可以看到波士顿市的人均犯罪率和自有住房的中值，波士顿是马萨诸塞州最大的城市。我们试图使用回归分析来深入了解是什么推动了这个城市的犯罪率。

这种分析对政策制定者和整个社会都是有用的，因为它有助于制定旨在降低犯罪率的决策，并有望根除整个社区的犯罪。这可以使社区更加安全，提高社会生活质量。

这是一个数据科学问题，属于监督机器学习类型。有一个因变量叫做`crime rate`(姑且称之为 *Y* )，它的变化我们寻求用一个自变量来理解，叫做`Median value of owner-occupied homes`(姑且称之为 *X* )。

换句话说，我们试图了解不同社区犯罪率的变化。

回归分析是在一组给定的假设下，找到一个函数，该函数最好地描述了因变量( *Y* )和自变量( *X* )之间的关系。

当自变量的个数只有一个，且因变量和自变量之间的关系假设为一条直线时，如图*图 2.3* 所示，这类回归分析称为**简单线性回归**。直线关系称为回归线或**最佳**拟合线:

![Figure 2.3: A scatter plot of the crime rate against the median value of owner-occupied homes
](image/B15019_02_03.jpg)

图 2.3:犯罪率与自有住房中值的散点图

在*图 2.3* 中，回归线显示为黑色实线。忽略回归线与图中数据的拟合质量差，我们可以看到，随着自有住房中值的增加，人均犯罪率下降。

从数据科学的角度来看，这种观察可能会提出许多问题。例如，随着自有住房价值中位数的增加，是什么推动了人均犯罪率的下降？富裕的郊区和城镇比不富裕的郊区和城镇获得更多的警力资源吗？不幸的是，这些问题无法用我们在*图 2.3* 中找到的如此简单的情节来回答。但是观察到的趋势可以作为讨论的起点，以审查警察和社区范围的安全资源的分配。

回到回归线与数据拟合程度的问题，很明显，几乎三分之一的回归线周围根本没有数据点。许多数据点简单地聚集在零(`0`)犯罪率标志周围的水平轴上。这不是你所期望的一条很好地拟合数据的好的回归线。一条很好地拟合数据的好的回归线必须位于数据点的*云*之中。

似乎人均犯罪率和自有住房中值之间的关系并不像你最初认为的那样是线性的。

在本章中，我们将学习如何使用对数函数(一种用于转换值的数学函数)来线性化人均犯罪率与自有住房中值之间的关系，以提高回归线与散点图上数据点的拟合度。

到目前为止，我们忽略了一个非常重要的问题。也就是说，*对于给定的一组数据，如何确定回归线？*

确定回归线的一种常用方法叫做最小二乘法，这将在下一节中介绍。

## 最小二乘法

简单线性回归线的形式一般如*式 2.1* 所示，其中β0 和β1 为未知常数，分别代表回归线的截距和斜率。

当自变量(X)的值为零(0)时，截距就是因变量(Y)的值。斜率是自变量(X)变化一(1)时因变量(Y)变化速率的量度。未知常数称为**模型系数**或**参数**。这种形式的回归线有时被称为人口回归线，作为一种概率模型，它大致符合数据集，因此在*等式 2.1* 中使用符号(`≈`)。该模型被称为概率模型，因为它没有模拟因变量(Y)的所有可变性:

![Figure 2.4: Simple linear regression equation
](image/B15019_02_04.jpg)

图 2.4:简单的线性回归方程

计算实际因变量值和预测因变量值之间的差值会产生一个误差，通常称为残差(ϵi).

对样本中的每个数据点重复这种计算，可以对每个数据点的残差(ϵi)求平方，以消除代数符号，并加在一起以获得**误差平方和** **(ESS)** 。

最小二乘法寻求最小化 ESS。

# 多元线性回归

在前面讨论的简单线性回归中，我们只有一个独立变量。如果我们在分析中包括多个独立变量，我们会得到一个多元线性回归模型。多元线性回归的表示方式类似于简单线性回归。

让我们考虑这样一种情况，我们想要拟合一个线性回归模型，该模型有三个独立变量，X1、X2 和 X3。多元线性回归方程的公式将类似于*方程 2.2* :

![Figure 2.5: Multiple linear regression equation
](image/B15019_02_05.jpg)

图 2.5:多元线性回归方程

每个自变量都会有自己的系数或参数(即β1 β2 或β3)。βs 系数告诉我们，如果所有其他自变量不变，它们各自自变量的变化如何影响因变量。

## 估计回归系数(β0、β1、β2 和β3)

*等式 2.2* 中的回归系数使用引入简单线性回归时讨论过的相同最小二乘法进行估算。为了满足最小二乘法，选择的系数必须使残差平方和最小。

在本章的后面，我们将利用 Python 编程语言来实际计算这些系数估计值。

## 变量的对数变换

正如已经提到的，有时因变量和自变量之间的关系不是线性的。这限制了线性回归的使用。为了解决这个问题，根据关系的性质，可以使用对数函数来转换感兴趣的变量。接下来发生的是，转换后的变量往往与其他未转换的变量具有线性关系，从而能够使用线性回归来拟合数据。这将在本书后面的练习中的数据集分析实践中加以说明。

## 相关矩阵

在*图 2.3* 中，我们看到了如何使用直线图分析两个变量之间的线性关系。将变量之间的线性关系可视化的另一种方式是使用相关矩阵。相关矩阵是一种数字交叉表，显示变量对之间的相关性，即两个变量的联系有多紧密(可以认为一个变量的变化会导致另一个变量的变化)。分析表格中的原始数据并不容易。因此，可以将相关矩阵转换成“热图”的形式，以便使用不同的颜色可以很容易地观察到变量之间的相关性。一个这样的例子显示在*练习 2.01* 中。

# 使用 Python 进行回归分析

讨论了回归分析的基础知识之后，现在是时候动手使用 Python 进行回归分析了。

为了开始我们的分析，我们需要在 Python 中启动一个会话，并加载所需的相关模块和数据集。

我们将在本章中进行的所有回归分析都将基于波士顿住房数据集。数据集有利于教学，适用于线性回归分析。它提出了一定程度的挑战，需要使用对数函数来转换变量，以实现更好的数据拟合模型。该数据集包含波士顿地区一组房产的信息，可用于确定特定房产的不同住房属性如何影响房产价值。

波士顿住房数据集 CSV 文件的列标题可以解释如下:

*   CRIM——城镇人均犯罪率
*   ZN——面积超过 25，000 平方英尺的住宅用地比例
*   印度河——每个城镇非零售商业英亩数的比例
*   CHAS–查尔斯河虚拟变量(= 1，如果区域边界为河流；否则为 0)
*   NOX——一氧化氮浓度(百万分之一)
*   RM——每个住宅的平均房间数
*   楼龄——1940 年之前建造的自住单元的比例
*   DIS 到五个波士顿就业中心的加权距离
*   RAD——放射状公路可达性指数
*   税收——每 10，000 美元的全价值财产税税率
*   pt ratio——按城镇划分的师生比率
*   LSTAT——较低社会地位人口的百分比
*   MEDV——以千美元计的自有住房中值

我们正在使用的数据集是原始数据集的一个略微修改的版本，来自 https://packt.live/39IN8Y6。

## 练习 2.01:加载和准备用于分析的数据

在本练习中，我们将学习如何将 Python 模块和分析所需的数据集加载到 Python 会话中，并为分析准备数据。

注意

我们将在本章中使用 Boston Housing 数据集，该数据集可以在我们位于 https://packt.live/2QCCbQB 的 GitHub 存储库中找到。

以下步骤将帮助您完成本练习:

1.  打开一个新的 Colab 笔记本文件。
2.  Load the necessary Python modules by entering the following code snippet into a single Colab notebook cell. Press the **Shift** and **Enter** keys together to run the block of code:

    ```
    %matplotlib inline
    import matplotlib as mpl
    import seaborn as sns
    import matplotlib.pyplot as plt
    import statsmodels.formula.api as smf
    import statsmodels.graphics.api as smg
    import pandas as pd
    import numpy as np
    import patsy
    from statsmodels.graphics.correlation import plot_corr
    from sklearn.model_selection import train_test_split
    plt.style.use('seaborn')
    ```

    前面代码的第一行使`matplotlib`能够在笔记本环境中显示代码的图形输出。接下来的代码行使用`import`关键字将各种 Python 模块加载到我们的编程环境中。这包括`patsy`，它是一个 Python 模块。为了便于参考，一些模块被赋予了别名，比如`seaborn`模块被赋予了别名`sns`。因此，每当我们在后续代码中引用`seaborn`时，我们都使用别名`sns`。`patsy`模块导入时没有别名。因此，我们在代码中需要的地方使用`patsy`模块的全名。

    `plot_corr`和`train_test_split`函数分别从`statsmodels.graphics.correlation`和`sklearn.model_selection`模块导入。最后一条语句用于将`matplotlib`生成的图形的美学外观设置为`seaborn`模块显示的类型。

3.  接下来，加载`Boston.CSV`文件，并通过运行下面的代码将变量名`rawBostonData`赋给它:

    ```
    rawBostonData = pd.read_csv('https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter02/Dataset/Boston.csv')
    ```

4.  Inspect the first five records in the DataFrame:

    ```
    rawBostonData.head() 
    ```

    您应该得到以下输出:

    ![Figure 2.6: First five rows of the dataset
    ](image/B15019_02_06.jpg)

    图 2.6:数据集的前五行

5.  检查数据帧中的缺失值( *null* 值)，然后删除它们，以获得干净的数据集:

    ```
    rawBostonData = rawBostonData.dropna()
    ```

6.  检查数据帧中的重复记录，然后删除它们以获得干净的数据集:

    ```
    rawBostonData = rawBostonData.drop_duplicates()
    ```

7.  List the column names of the DataFrame so that you can examine the fields in your dataset, and modify the names, if necessary, to names that are meaningful:

    ```
    list(rawBostonData.columns)
    ```

    您应该得到以下输出:

    ![Figure 2.7: Listing all the column names
    ](image/B15019_02_07.jpg)

    图 2.7:列出所有的列名

8.  Rename the DataFrame columns so that they are meaningful. Be mindful to match the column names exactly as leaving out even white spaces in the name strings will result in an error. For example, this string, `ZN`, has a white space before and after and it is different from `ZN`. After renaming, print the head of the new DataFrame as follows:

    ```
    renamedBostonData = rawBostonData.rename(columns = {'CRIM':'crimeRatePerCapita',
     ' ZN ':'landOver25K_sqft',
     'INDUS ':'non-retailLandProptn',
     'CHAS':'riverDummy',
     'NOX':'nitrixOxide_pp10m',
     'RM':'AvgNo.RoomsPerDwelling',
     'AGE':'ProptnOwnerOccupied',
     'DIS':'weightedDist',
     'RAD':'radialHighwaysAccess',
     'TAX':'propTaxRate_per10K',
     'PTRATIO':'pupilTeacherRatio',
     'LSTAT':'pctLowerStatus',
     'MEDV':'medianValue_Ks'})
    renamedBostonData.head()
    ```

    您应该得到以下输出:

    ![Figure 2.8: DataFrames  being renamed
    ](image/B15019_02_08.jpg)

    图 2.8:数据帧被重命名

    注意

    前面的输出被截断。请前往 GitHub 库查找完整的输出。

9.  Inspect the data types of the columns in your DataFrame using the `.info()` function:

    ```
    renamedBostonData.info()
    ```

    您应该得到以下输出:

    ![Figure 2.9: The different data types in the dataset
    ](image/B15019_02_09.jpg)

    图 2.9:数据集中不同的数据类型

    输出显示数据集中有`506`行(`Int64Index: 506 entries`)。总共还有`13`栏(`Data columns`)。没有一个`13`列有缺失值的行(所有的`506`行都是*非空的*)。其中 10 列有浮点(十进制)类型的数据，3 列有整数类型的数据。

10.  Now, calculate basic statistics for the numeric columns in the DataFrame:

    ```
    renamedBostonData.describe(include=[np.number]).T
    ```

    我们使用在数据帧上调用的 pandas 函数`describe`来计算数据帧中数值字段(包括任何具有`numpy`数字数据类型的字段)的简单统计数据。统计数据包括最小值、最大值、每列中的行数、每列的平均值、第 25 个百分点、第 50 个百分点和第 75 个百分点。我们转置(使用`.T`函数)函数`describe`的输出来得到一个更好的布局。

    您应该得到以下输出:

    ![Figure 2.10: Basic statistics of the numeric column
    ](image/B15019_02_10.jpg)

    图 2.10:数字列的基本统计数据

11.  Divide the DataFrame into training and test sets, as shown in the following code snippet:

    ```
    X = renamedBostonData.drop('crimeRatePerCapita', axis = 1)
    y = renamedBostonData[['crimeRatePerCapita']]
    seed = 10 
    test_data_size = 0.3 
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_data_size, random_state = seed)
    train_data = pd.concat([X_train, y_train], axis = 1)
    test_data = pd.concat([X_test, y_test], axis = 1)
    ```

    我们选择 30%的测试数据大小，也就是`0.3`。`train_test_split`功能用于实现这一点。我们设置随机数生成器的种子，这样每次运行这段代码时，我们都可以获得一个可重复的分割。这里使用了任意值`10`。将用于开发模型的数据集分成至少两部分是一种良好的模型构建实践。一部分用于开发模型，它被称为训练集(`X_train`和`y_train`的组合)。

    注意

    将您的数据分为训练和测试子集可让您使用一些数据来训练您的模型(也就是说，它让您构建一个学习变量之间关系的模型)，并使用其余的数据来测试您的模型(也就是说，查看在给定新数据的情况下，您的新模型可以做出多好的预测)。你将在本书中使用训练测试分割，这个概念将在*第 7 章，机器学习模型的一般化*中详细解释。

12.  Calculate and plot a correlation matrix for the `train_data` set:

    ```
    corrMatrix = train_data.corr(method = 'pearson')
    xnames=list(train_data.columns)
    ynames=list(train_data.columns)
    plot_corr(corrMatrix, xnames=xnames, ynames=ynames,\
              title=None, normcolor=False, cmap='RdYlBu_r')
    ```

    在前面的代码片段的第 4*行*中使用反斜杠字符`\`，是为了在 Python 中强制代码延续到新的一行。如果您将整行代码输入到笔记本的一行中，则不需要使用`\`字符。

    您应该得到以下输出:

![Figure 2.11: Output with the expected heatmap
](image/B15019_02_11.jpg)

图 2.11:带有预期热图的输出

在前面的热图中，我们可以看到具有橙色或红色方块的变量之间存在很强的正相关性(一个变量增加会导致另一个变量增加)。蓝色方块的变量之间有很强的负相关(一个增加导致另一个减少)。用浅色方块表示的变量之间很少或没有相关性。例如，在`nitrixOxide_pp10m`和`non-retailLandProptn`之间似乎有相对较强的相关性，但在`riverDummy`和任何其他变量之间相关性较低。

我们可以使用相关矩阵的发现作为进一步回归分析的起点。热图为我们提供了一个很好的数据关系概述，并可以显示我们的调查目标变量。

## 相关系数

在之前的练习中，我们已经了解了如何使用关联矩阵热图来可视化变量对之间的关系。我们也可以使用原始相关系数数字以数字形式看到这些相同的关系。这些值介于-1 和 1 之间，表示两个变量的联系有多紧密。

Pandas 提供了一个`corr`函数，当在 DataFrame 上调用该函数时，它提供了一个所有数字数据类型的相关性矩阵(表)。在我们的例子中，运行 Colab 笔记本中的代码`train_data.corr (method = 'pearson')`，结果如图 2.12 中的*所示。*

需要注意的是*图 2.12* 是沿左对角线对称的。左边的对角线值是特征相对于它们自身的相关系数(因此它们的值都是一(1))，因此与我们的分析无关。*图 2.12* 中的数据是在*练习 2.01* 中的*步骤 12* 的输出中以图表形式呈现的数据。

您应该得到以下输出:

![Figure 2.12: A correlation matrix of the training dataset 
](image/B15019_02_12.jpg)

图 2.12:训练数据集的相关矩阵

注意

前面的输出被截断。

数据科学家使用相关系数作为统计数据，以测量两个数值变量 X 和 y 之间的线性关系。二元数据样本的相关系数通常用 r 表示。在统计学中，测量两个数值变量之间相关性的常用方法是使用皮尔逊相关系数。因此，在本章中，对相关系数的任何引用都是指皮尔逊相关系数。

在本课程中，为了实际计算数据集中变量的相关系数统计数据，我们使用了 Python 函数。对这个讨论来说，重要的是我们计算的相关系数取值的意义。相关系数(r)取+1 和-1 之间的值。

当 r 等于+1 时，X 和 Y 之间的关系是这样的，X 和 Y 都在同一方向上完美地增加或减少。当 r 等于-1 时，X 和 Y 之间的关系是这样的，X 的增加与 Y 的减少完全相关，反之亦然。当 r 等于零(0)时，X 和 y 之间没有线性关系。

X 和 Y 之间没有线性关系，不代表 X 和 Y 没有关系；而是说，如果有什么关系，也不能用一条直线来描述。实际上，0.6 左右或更高(或-0.6 或更低)的相关系数值是两个变量 X 和 y 之间潜在令人兴奋的线性关系的标志。

*练习 2.01* 、*步骤 12* 输出的最后一列，提供了人均犯罪率相对于其他颜色阴影特征的 r 值。使用颜色条，很明显`radialHighwaysAccess`、`propTaxRate_per10K`、`nitrixOxide_pp10m`、`pctLowerStatus`与人均犯罪率的相关性最强。这表明，人均犯罪率和这些独立变量之间可能存在的线性关系值得研究。

## 练习 2.0 2:使用 Python 对线性关系进行图形化研究

拟合有回归线的散点图是一种快速的方法，数据科学家可以通过它来可视化因变量和自变量之间可能的相关性。

本练习的目的是使用这种技术来调查波士顿市城镇中人均犯罪率和自有住房中值之间可能存在的任何线性关系。

以下步骤将帮助您完成练习:

1.  打开一个新的 Colab 笔记本文件，执行*练习 2.01* 中的*步骤 11* 。
2.  使用`matplotlib`中的`subplots`函数在 Python 中定义一个 canvas(在下面的代码中被赋予变量名`fig`)和一个 graph 对象(在下面的代码中被赋予变量名`ax`)。您可以通过设置函数

    ```
    fig, ax = plt.subplots(figsize=(10, 6))
    ```

    的`figsize` (width = `10`，height = `6`)参数来设置图形的大小
3.  Use the `seaborn` function `regplot` to create the scatter plot:

    ```
    sns.regplot(x='medianValue_Ks', y='crimeRatePerCapita', ci=None, data=train_data, ax=ax, color='k', scatter_kws={"s": 20,"color":\ "royalblue", "alpha":1})
    ```

    注意

    下面代码中的反斜杠(`\`)是告诉 Python 该行代码在下一行继续。

    该函数接受自变量(`x`)、因变量(`y`)、回归参数的置信区间(`ci`)(取值范围为 0 到 100)、具有`x`和`y` ( `data`)的数据帧、matplotlib 图形对象(`ax`)以及其他参数，以控制图形上各点的美感。(在这种情况下，置信区间被设置为`None`——我们将在本章后面看到更多关于置信区间的内容。)

4.  Set the `x` and `y` labels, the `fontsize` and `name` labels, the `x` and `y` limits, and the `tick` parameters of the matplotlib graph object (`ax`). Also, set the layout of the canvas to `tight`:

    ```
    ax.set_ylabel('Crime rate per Capita', fontsize=15, fontname='DejaVu Sans')
    ax.set_xlabel("Median value of owner-occupied homes in $1000's",\ fontsize=15, fontname='DejaVu Sans')
    ax.set_xlim(left=None, right=None)
    ax.set_ylim(bottom=None, top=30)
    ax.tick_params(axis='both', which='major', labelsize=12)
    fig.tight_layout()
    ```

    您应该得到以下输出:

![Figure 2.13: Scatter graph with a regression line using Python
](image/B15019_02_13.jpg)

图 2.13:使用 Python 制作的带有回归线的散点图

如果练习正确，输出必须与图 2.3 中的图表相同。在*图 2.3* 中，该输出被呈现并用于引入线性回归，而没有显示它是如何被创建的。这个练习教会了我们如何使用 Python 创建散点图并拟合回归线。

## 练习 2.03:使用 Python 检查可能的对数线性关系

在这个练习中，我们将使用对数函数来转换变量，并研究这是否有助于提供更好的数据回归线拟合。我们还将通过在图上包含回归系数的 95%置信区间来了解如何使用置信区间。

以下步骤将帮助您完成本练习:

1.  打开一个新的 Colab 笔记本文件，执行从*练习 2.01* 的*步骤 11* 的所有步骤。
2.  使用`matplotlib`中的`subplots`函数在 Python:

    ```
    fig, ax = plt.subplots(figsize=(10, 6))
    ```

    中定义画布和图形对象
3.  使用`numpy` ( `np.log`)中的对数函数对因变量(`y`)进行变换。这实际上创建了一个新变量，`log(y)` :

    ```
    y = np.log(train_data['crimeRatePerCapita'])
    ```

4.  使用 seaborn `regplot`函数创建散点图。将`regplot`函数置信区间参数(`ci`)设置为`95%`。这将为回归系数计算一个`95%`置信区间，并将它们作为沿回归线的阴影区域绘制在图上。置信区间给出了一个估计范围，该范围可能包含您正在寻找的真实值。因此，`95%`置信区间表明我们可以`95%`确定真正的回归系数位于阴影区域。
5.  用我们在上一步中定义的新变量解析`y`参数。`x`参数是来自数据帧的原始变量，没有任何转换:

    ```
    sns.regplot(x='medianValue_Ks', y=y, ci=95, data=train_data, ax=ax, color='k', scatter_kws={"s": 20,"color": "royalblue", "alpha":1})
    ```

6.  Set the `x` and `y` labels, the `fontsize` and `name` labels, the `x` and `y` limits, and the `tick` parameters of the `matplotlib` graph object (`ax`). Also, set the layout of the canvas to `tight`:

    ```
    ax.set_ylabel('log of Crime rate per Capita', fontsize=15,\ fontname='DejaVu Sans')
    ax.set_xlabel("Median value of owner-occupied homes in $1000's",\ fontsize=15, fontname='DejaVu Sans')
    ax.set_xlim(left=None, right=None)
    ax.set_ylim(bottom=None, top=None)
    ax.tick_params(axis='both', which='major', labelsize=12)
    fig.tight_layout()
    ```

    输出如下所示:

![Figure 2.14: Expected scatter plot with an improved linear regression line
](image/B15019_02_14.jpg)

图 2.14:使用改进的线性回归线的预期散点图

通过完成这个练习，我们成功地改进了散点图。在本活动中创建的回归线比在*练习 2.02* 中创建的回归线更符合数据。通过比较这两个图，您可以看到对数图中的回归线更清楚地匹配了数据点的分布。我们已经解决了线的底部三分之一周围没有点聚集的问题。这是通过用对数函数转换因变量来实现的。转换后的因变量(人均犯罪率对数)与自有住房的中值的线性关系比未转换的变量有所改善。

## stats models 公式 API

在*图 2.3* 中，实线代表人均犯罪率和自有住房中值之间的关系。但是我们怎样才能得到描述这条线的方程呢？换句话说，怎样才能找到直线关系的截距和斜率呢？

Python 提供了丰富的**应用编程接口** **(API)** 来轻松做到这一点。statsmodels 公式 API 使数据科学家能够使用公式语言来定义回归模型，这些模型可以在统计文献和许多专用的统计计算机软件包中找到。

## 练习 2.04:使用 Statsmodels 公式 API 拟合简单的线性回归模型

在本练习中，我们检验了一个简单的线性回归模型，其中人均犯罪率是因变量，自有住房的中值是自变量。我们使用 statsmodels 公式 API 创建一个线性回归模型供 Python 分析。

以下步骤将帮助您完成本练习:

1.  打开一个新的 Colab 笔记本文件并导入所需的包。

    ```
    import pandas as pd
    import statsmodels.formula.api as smf
    from sklearn.model_selection import train_test_split
    ```

2.  执行*练习 2.01* 中的*步骤 2* 至 *11* 。
3.  Define a linear regression model and assign it to a variable named `linearModel`:

    ```
    linearModel = smf.ols(formula='crimeRatePerCapita ~ medianValue_Ks',\ data=train_data)
    ```

    如您所见，我们调用 statsmodels API 的`ols`函数，并通过定义一个`patsy`公式字符串来设置其公式参数，该公式字符串使用波浪号(`~`)符号将因变量与自变量相关联。通过将`ols`函数的数据参数分配给包含变量(`train_data`)的 DataFrame，告诉函数在字符串中何处找到指定的变量。

4.  打电话给。方法，并将该方法的结果赋给一个`linearModelResult`变量，如下面的代码片段所示:

    ```
    linearModelResult = linearModel.fit()
    ```

5.  Print a summary of the results stored the `linearModelResult` variable by running the following code:

    ```
    print(linearModelResult.summary())
    ```

    您应该得到以下输出:

![Figure 2.15: A summary of the simple linear regression analysis results
](image/B15019_02_15.jpg)

图 2.15:简单线性回归分析结果的总结

如果正确地遵循了练习，那么已经用 statsmodels 公式 API 创建了一个模型。模型对象的`fit`方法(`.fit()`)被调用以使线性回归模型适合数据。这里的拟合是指用普通的最小二乘法估计回归系数(参数)。

## 分析模型摘要

`.fit`方法提供了许多函数来探索它的输出。这些参数包括`conf_int()`、`pvalues`、`tvalues`和`summary()`参数。使用这些函数，可以从结果中检索模型的参数、置信区间以及用于分析的 p 值和 t 值。(p 值和 t 值的概念将在本章后面解释。)

语法简单地包括在包含结果的变量名后，加上相关的函数名——例如，`linearModelResult.conf_int()`将输出置信区间值。其中最方便的是`summary()`函数，它显示了分析的所有相关结果的表格。

在*图 2.15* 中，显示了*练习 2.04* 中使用的汇总函数的输出。使用双虚线将汇总函数的输出分成三个主要部分。

在*第九章*、*解读一个机器学习模型*中，将详细处理三个部分的结果。然而，在这里评论几点是很重要的。

在*图 2.15* 中*第 1 节*的左上角，我们找到了打印出来的模型中的因变量(`Dep. Variable`),`crimeRatePerCapita`是*练习 2.04* 的值。第 1 节中还提供了我们模型的一个名为 R 平方的统计量`0.144`。R 平方值由 Python 计算为分数(`0.144`)，但以百分比形式报告，因此我们模型的值为`14.4%`。R 平方统计量提供了因变量(`crimeRatePerCapita`)可变性的度量，我们模型能够解释。它可以被解释为衡量我们的模型与数据集的匹配程度。*第 2 节*中的*图 2.15* 中，报告了我们模型中的截距和自变量。我们模型中的自变量是自有住房的中位值(`medianValue_Ks`)。

在同一个*部分 2* 中，截距和自变量旁边是报告模型系数的列(`coef`)。在 Python 输出的摘要报告中，自变量的截距和系数打印在标签为`coef`的列下。截距的值为`11.2094`，自变量的系数为负`0.3502` ( `-0.3502`)。如果我们选择将模型中的因变量(`crimeRatePerCapita`)表示为 y，自变量(自有住房的中值)表示为 *x* ，我们就有了所有的要素来写出定义模型的方程。

因此，y ≈ 11.2094 - 0.3502 x 是我们模型的方程式。在*第九章*、*解读一个机器学习模型*中，这个模型是什么意思以及如何使用将会有完整的讨论。

## 模型公式语言

Python 是一种非常强大的语言，受到许多开发人员的喜爱。自从 stats models 0 . 5 . 0 版本发布以来，Python 现在为统计分析和建模提供了一个非常有竞争力的选项，可以与 R 和 SAS 相媲美。

这包括通常被称为 R 风格的公式语言，通过它可以很容易地定义统计模型。Statsmodels 通过在内部使用`Patsy` Python 库来将公式和数据转换为模型拟合中使用的矩阵，从而实现了 R 风格的公式语言。

*图 2.16* 总结了用于构建`Patsy`公式字符串的运算符及其含义:

![Figure 2.16: A summary of the Patsy formula syntax and examples
](image/B15019_02_16.jpg)

图 2.16:Patsy 公式语法和示例的摘要

## 拦截处理

在 patsy 公式字符串中，`string 1`用于定义模型的截距。因为大多数时候需要截距，`string 1`会自动包含在每个公式字符串定义中。您不必在字符串中包含它来指定截距。它是无形的。但是，如果您想从模型中删除截距，那么您可以从公式字符串中减去一(-1)，这将定义一个通过原点的模型。为了与其他统计软件兼容，`Patsy`还允许使用字符串零(0)和负一(-1)来从模型中排除截距。这意味着，如果您在公式字符串的右侧包含 0 或-1，您的模型将没有截距。

## 活动 2.01:使用 Statsmodels 公式 API 拟合对数线性模型

您已经看到了如何使用 statsmodels API 来拟合线性回归模型。在本练习中，要求您拟合一个对数线性模型。您的模型应该表示对数转换的因变量(人均犯罪率的对数)和自有住房的中值之间的关系。

完成此活动的步骤如下:

1.  定义线性回归模型，并将其分配给变量。记住使用`log`函数来转换公式字符串中的因变量。
2.  调用模型实例的`fit`方法，并将该方法的结果赋给一个变量。
3.  打印结果摘要并分析输出。

您的输出应该如下图所示:

![Figure 2.17: A log-linear regression of crime rate per capita on the median value of owner-occupied homes
](image/B15019_02_17.jpg)

图 2.17:人均犯罪率对自有住房中值的对数线性回归

注意

这个活动的解决方案可以在这里找到:[https://packt.live/2GbJloz](https://packt.live/2GbJloz)。

# 多元回归分析

在迄今为止的练习和活动中，我们在回归分析中仅使用了一个独立变量。在实践中，正如我们在波士顿住房数据集上看到的那样，具有分析意义的过程和现象很少会仅受一个要素的影响。因此，为了能够以更高的精确度模拟可变性，有必要调查所有可能对解释因变量可变性有显著贡献的自变量。多元回归分析是用来实现这一点的方法。

## 练习 2.05:使用 Statsmodels 公式 API 拟合多元线性回归模型

在本练习中，我们将在`patsy`公式字符串中使用加号运算符(`+`)来定义包含多个独立变量的线性回归模型。

要完成此活动，请在您的 Colab 笔记本中运行以下步骤中的代码:

1.  打开一个新的 Colab 笔记本文件并导入所需的包。

    ```
    import statsmodels.formula.api as smf
    import pandas as pd
    from sklearn.model_selection import train_test_split
    ```

2.  执行*练习 2.01* 中的*步骤 2* 至 *11* 。
3.  使用 Patsy 公式语言的加号运算符(`+`)定义一个线性模型，该模型在`pctLowerStatus`、`radialHighwaysAccess`、`medianValue_Ks`和`nitrixOxide_pp10m`上回归`crimeRatePerCapita`，并将其赋给一个名为`multiLinearModel`的变量。如果空间不足，使用 Python 行继续符(`\`)在新的一行上继续您的代码:

    ```
    multiLinearModel = smf.ols(formula=\
    'crimeRatePerCapita ~ pctLowerStatus + radialHighwaysAccess +\ medianValue_Ks + nitrixOxide_pp10m', data=train_data)
    ```

4.  调用模型实例的`fit`方法，并将该方法的结果赋给一个变量:

    ```
    multiLinearModResult = multiLinearModel.fit()
    ```

5.  Print a summary of the results stored the variable created in *Step 3*:

    ```
    print(multiLinearModResult.summary())
    ```

    输出如下所示:

![Figure 2.18: A summary of multiple linear regression results
](image/B15019_02_18.jpg)

图 2.18:多元线性回归结果汇总

如果正确遵循了该练习，*图 2.18* 将是分析的结果。在*活动 2.01* 中，R 平方统计用于评估模型的拟合优度。当涉及多个独立变量时，使用调整后的 R 平方统计量评估所创建模型的拟合优度。

调整后的 R 平方统计量考虑了模型中额外独立变量的存在，并校正了模型拟合优度测量值的膨胀，这种膨胀是由使用更多独立变量来创建模型这一事实引起的。

我们从这个练习中得到的教训是图 2.18 的*的*部分 1* 中调整后的 R 平方值的改进。当仅使用一个独立变量创建一个模型来解释*练习 2.04* 中`crimeRatePerCapita`的可变性时，计算出的 R 平方值仅为`14.4`百分比。在这个练习中，我们使用了四个独立变量。创建的模型将调整后的 R 平方统计提高到了`39.1`百分比，增加了`24.7`个百分比。*

我们了解到，与因变量相关的自变量的存在有助于解释模型中自变量的可变性。但是很明显，我们的模型仍然无法解释因变量中相当大的可变性，大约为百分之`60.9`。

如果我们想要一个能很好地解释我们在`crimeRatePerCapita`中看到的可变性的模型，仍然有改进的空间。在*图 2.18* 的第 2 节*中，截距和我们模型中的所有自变量连同它们的系数一起列出。如果我们用 x1 表示`pctLowerStatus`，用 x2 表示`radialHighwaysAccess`，用 x3 表示`medianValue_Ks`，用 x4 表示`nitrixOxide_pp10m`，那么所创建的模型的数学表达式可以写成 y≈0.8912+0.1028 x1+0.4948 x2-0.1103 x3-2.1039 x4*

刚刚陈述的表达式定义了在本练习中创建的模型，它与之前在*等式 2.2* 中提供的多元线性回归的表达式相当。

# 回归分析的假设

由于线性回归分析的参数性质，该方法对其分析的数据做出某些假设。当这些假设不满足时，回归分析的结果至少可以说是误导性的。因此，有必要检查任何分析工作，以确保不违反回归假设。

让我们回顾一下线性回归分析的主要假设，为了开发一个好的模型，我们必须确保满足这些假设:

1.  The relationship between the dependent and independent variables must be linear and additive.

    这意味着这种关系必须是直线型的，如果涉及到许多自变量，那么多元线性回归，这些自变量的加权和必须能够解释因变量的可变性。

2.  剩余项(ϵi)必须呈正态分布。这是为了正确计算估计的标准误差。这种估计统计的标准误差用于计算 t 值，而 t 值又用于做出统计显著性决策。因此，如果估计的标准误差是错误的，则 t 值也将是错误的，从 p 值得出的统计显著性决策也是错误的。使用估计的标准误差计算的 t 值也用于构建总体回归参数的置信区间。如果标准误差是错误的，那么置信区间也将是错误的。
3.  剩余项(ϵi)必须具有恒定的方差(同质性)。当情况不是这样时，我们就有了异方差问题。这一点指的是剩余项的方差。假设它是常数。我们假设回归分析中的每个数据点对我们试图建模的可变性有相同的解释。如果一些数据点比其他数据点提供更多的解释，我们的回归线将被拉向有更多信息的点。数据点不会平均分布在我们的回归线上。在这种情况下，回归线的误差(方差)将不是常数。
4.  剩余项(ϵi)不得相关。当剩余项存在相关性时，我们就有了自相关问题。知道一个剩余项，不能给我们任何关于下一个剩余项是什么的信息。自相关的剩余项不太可能具有正态分布。
5.  独立变量之间不能有相关性。当自变量之间相关时，我们就遇到了多重共线性问题。这将导致开发一个模型，其系数的值取决于其他独立变量的存在。换句话说，我们将会有一个模型，如果一个特定的自变量从模型中被删除，这个模型将会发生剧烈的变化。那样的模型是不准确的。

## 活动 2.02:拟合多重对数线性回归模型

你之前开发的对数线性回归模型能够解释转换后的人均犯罪率变量中约 24%的可变性。现在要求您开发一个对数线性多元回归模型，该模型可能解释转换后的因变量中 80%或更多的可变性。您应该使用波士顿住房数据集中相关系数为 0.4 或更高的独立变量。

我们也鼓励你在你的模型中加入这些变量的相互作用，从而得到二阶。您应该制作图表和数据来显示您的模型满足线性回归的假设。

步骤如下:

1.  定义线性回归模型，并将其分配给变量。记住使用`log`函数来转换公式字符串中的因变量，并且在您的分析中包含多个自变量。
2.  调用模型实例的`fit`方法，并将该方法的结果赋给一个新变量。
3.  Print a summary of the results and analyze your model.

    您的输出应该如下所示:

![Figure 2.19: Expected OLS results
](image/B15019_02_19.jpg)

图 2.19:预期的 OLS 结果

注意

这个活动的解决方案可以在这里找到:[https://packt.live/2GbJloz](https://packt.live/2GbJloz)。

# 解释回归分析的结果

回归分析的一个主要目的是找到一个模型来解释在感兴趣的因变量中观察到的可变性。因此，有一个数量来衡量回归模型解释这种可变性的程度是非常重要的。做到这一点的统计称为 R 平方(R2)。有时，它也被称为决定系数。为了理解它实际测量的是什么，我们需要看看其他一些定义。

第一个称为平方和(TSS)。TSS 为我们提供了从因变量的平均值中发现的总方差的度量。

下一个量称为回归平方和(RSS)。这给了我们模型解释的因变量变化量的度量。如果你想象我们创造了一个完美的模型，预测没有错误，那么 TSS 将等于 RSS。我们假设的完美模型将为我们看到的因变量相对于平均值的所有可变性提供解释。实际上，这种情况很少发生。而是创建不完美的模型，所以 RSS 比 TSS 少。RSS 未达到 TSS 的缺失量是我们的回归模型无法解释的因变量的可变性量。这个量就是误差平方和(ESS)，本质上是我们模型的残差项之和。

r 平方是 RSS 与 TSS 的比值。因此，这为我们提供了一个百分比，来衡量我们的回归模型相对于因变量相对于平均值的总可变性能够解释多少可变性。当 RSS 变小时，R2 也会变小，反之亦然。在自变量为 1 的简单线性回归的情况下，R2 足以决定模型对数据的总体拟合度。

然而，在多元线性回归中有一个问题。众所周知，R2 对模型中额外的独立变量非常敏感，即使独立变量与因变量之间的相关性很小。它的加入将增加 R2。仅依靠 R2 在为同一个因变量定义的模型之间做出决策，将导致追逐一个包含许多自变量的复杂模型。这种复杂性实际上没有帮助。事实上，它可能会导致一个称为过度拟合的建模问题。

为了克服这个问题，调整后的 R2(在 statsmodels 的输出上表示为 *Adj. R-Squared* )用于在为同一因变量定义的模型之间进行选择。只有在模型中加入自变量有助于以有意义的方式解释因变量的可变性时，调整后的 R2 才会增加。

在*活动 2.02* 中，我们的模型解释了转换后的因变量中 88%的可变性，这非常好。我们从简单的模型开始，并使用不同的技术改进模型的拟合度。本章所做的所有练习和活动都指出了回归分析工作流是迭代的。你从绘制一幅视觉图像开始，然后从那里开始，通过使用不同的技术来改进你最终开发的模型。一旦开发出一个好的模型，下一步就是在该模型可以用于进行预测或获得决策洞察力之前对其进行统计验证。接下来，让我们讨论从统计学角度验证模型意味着什么。

## 回归分析制衡

在前面的讨论中，我们使用了 R 平方和调整的 R 平方统计来评估模型的拟合优度。虽然 R 平方统计量提供了模型和因变量之间关系强度的估计值，但它并没有为这种关系提供正式的统计假设检验。

对于模型中因变量和一些自变量之间的关系，我们所说的正式统计假设检验是什么意思？

我们必须回忆一下，要说一个模型中的自变量与因变量有关系，回归模型中那个自变量的系数(β)必须*不是*为零(0)。使用我们的波士顿住房数据集进行回归分析，并在我们的模型中找到一个具有非零系数(β)的独立变量(比如业主自用住房的中值),这很好。

问题是，如果我们使用在不同地点或时间采集的波士顿住房数据集的不同样本重复这一分析，我们(或其他人)会发现自住住房的中值具有非零系数(β)吗？在我们的分析中发现的自有住房中值的非零系数是我们的样本数据集特有的吗？对于可能收集的任何其他波士顿住房数据样本，非零系数是零吗？我们是偶然发现自住房屋中值的非零系数的吗？这些问题是假设检验试图澄清的。我们不能百分之百确定一个自变量的非零系数(β)是偶然的还是非偶然的。但是假设检验给出了一个框架，通过这个框架我们可以计算出置信度，我们可以说在我们的分析中发现的非零系数(β)不是偶然的。这就是它的工作原理。

我们首先同意可能存在的风险水平(α值或α风险或 I 型误差),非零系数(β)可能是偶然发现的。这个想法是，我们乐于承受这种程度的风险，即声称系数(β)非零，而实际上它是零。

在大多数实际分析中，α值被设置为 0.05，以百分比表示为 5。当我们从 1(1-α)中减去α-风险时，我们就有了一个置信度的度量，即在我们的分析中发现的非零系数(β)不是偶然出现的。因此，我们的置信度为 95%，α值为 5%。

然后，我们继续计算概率值(通常称为 p 值)，这为我们提供了与模型中感兴趣的系数(β)相关的α风险的度量。我们将 p 值与我们选择的α风险进行比较，如果 p 值小于约定的α风险，我们拒绝非零系数(β)是偶然发现的想法。这是因为错误地声称系数(β)非零的风险在我们之前为自己设定的可接受的范围内。

说明非零系数(β)不是偶然发现的另一种方式是说系数(β)在统计上是显著的，或者我们拒绝零假设(零假设是指正在研究的变量之间没有关系)。我们分两个阶段将这些具有统计意义的想法应用到我们的模型中:

1.  在第一阶段，我们从统计学的角度对模型进行整体验证。
2.  在第二阶段，我们单独验证模型中的独立变量的统计显著性。

## f 检验

f 检验是验证模型与其因变量之间关系强度的总体统计显著性。如果 f 检验的 p 值小于选择的α水平(在我们的例子中是 0.05)，我们拒绝零假设，并得出结论，该模型总体上具有统计学意义。

当我们拟合回归模型时，我们生成 F 值。该值可用于确定测试是否具有统计显著性。一般来说，R2 的增加会增加 F 值。这意味着 F 值越大，模型的总体统计显著性越好。

一个好的 F 值应该比**大一个**。*图 2.19* 中的模型的 F 统计值为 261.5，大于 1，p 值(Prob (F 统计))约为零。犯错误和拒绝无效假设的风险(在假设检验中称为 I 型错误)小于我们在假设检验开始时选择的 5%的限制。因为 p 值小于 0.05，我们拒绝了关于图 2.19 中*模型的零假设。因此，我们声明该模型在选定的 95%置信水平下具有统计显著性。*

## t 检验

一旦一个模型被确定为具有全局统计显著性，我们就可以继续检查模型中各个独立变量的显著性。在*图 2.19* 中，提供了自变量的 p 值(在*第 2 节*中表示为`p>|t|`)。使用汇总结果中给出的 t 值计算 p 值。这个过程与刚才讨论的全球案例没有什么不同。我们将 p 值与 0.05 α水平进行比较。如果自变量的 p 值小于 0.05，则在解释因变量的可变性时，自变量在我们的模型中具有统计显著性。如果 p 值为 0.05 或更高，我们模型中的特定独立变量(或项)在统计上不显著。这意味着，在我们的模型中，这一项无助于从统计上解释因变量的可变性。仔细观察*图 2.19* 可以发现，有些项的 p 值大于 0.05。这些术语对解释我们转换后的因变量的可变性没有统计学意义。为了改进这个模型，这些术语将不得不被删除，并尝试一个新的模型。很明显，构建回归模型的过程是真正迭代的。

# 总结

本章介绍了使用 Python 进行线性回归分析的主题。我们了解到，回归分析通常是一个有监督的机器学习或数据科学问题。我们学习了线性回归分析的基础知识，包括最小二乘法背后的思想。我们还了解了如何使用 pandas Python 模块来加载和准备用于探索和分析的数据。

我们探索了如何创建二元数据的散点图，以及如何通过它们拟合最佳拟合线。在这个过程中，我们发现了 Python 中 statsmodels 模块的强大功能。我们探索了如何使用它来定义简单的线性回归模型并求解模型的相关参数。我们还学习了如何将它扩展到独立变量多于一个的情况，即多元线性回归。我们研究了可以转换因变量和自变量之间的非线性关系的方法，以便可以使用因转换而引入的线性回归来处理非线性问题。我们仔细研究了 statsmodels 公式语言。我们学习了如何使用它来定义各种线性模型，并求解它们各自的模型参数。

我们继续学习支持模型拟合优度的思想。我们讨论了 R 平方统计量作为回归模型拟合优度的度量。我们接着讨论了统计学意义的基本概念。我们学习了如何使用 Python 为我们计算的 F-statistic 来全局验证回归模型。我们还研究了如何使用 t 检验及其相关的 p 值来检查单个模型系数的统计显著性。我们回顾了线性回归分析的假设，以及它们如何影响任何回归分析工作的有效性。

我们现在将从回归分析开始，第三章、*二进制分类*和*第四章*、*随机森林多类分类*将分别讨论二进制和多标签分类。这些章节将介绍处理因变量为分类数据类型的监督数据科学问题所需的技术。

当模型性能改进和解释的重要主题在本书的后面给出一个更近的观察时，回归分析将被重新讨论。在*第八章*、*超参数调整*中，我们将看到如何使用 k-最近邻和作为另一种方法来进行回归分析。我们还将介绍岭回归，这是一种线性回归方法，适用于有大量参数的情况。