

# 七、机器学习模型的泛化

概观

本章将教你如何利用你所拥有的数据来训练更好的模型，如果数据足够的话，你可以拆分数据，如果数据不够的话，你可以利用交叉验证。本章结束时，您将知道如何将数据拆分为定型数据集、验证数据集和测试数据集。您将能够确定数据分割的比率，并在分割时考虑某些特征。您还将能够实现交叉验证，以使用有限的数据进行测试，并使用正则化来减少模型中的过度拟合。

# 简介

在前一章中，您学习了使用各种度量标准的模型评估，例如 R2 评分、MAE 和准确性。这些度量帮助您决定保留哪些模型，丢弃哪些模型。在这一章中，你将会学到更多训练更好模型的技巧。

泛化处理的是让您的模型在数据点上表现得足够好，而这些数据点是它们在过去(即在训练期间)没有遇到过的。我们将讨论两个具体领域:

*   如何利用尽可能多的数据来训练模型
*   如何减少模型中的过度拟合

# 过度拟合

当一个模型生成一个解释每个例子的假设时，它被认为是过度拟合了训练数据。这意味着它正确地预测了每个例子的结果。这种情况的问题是，模型方程变得极其复杂，并且已经观察到这种模型不能正确预测新的观察结果。

过度拟合发生在模型被过度设计时。发生这种情况的两种方式是:

*   模型在太多特征上被训练。
*   模型训练时间过长。

我们将在下面的小节中讨论这两点。

## 训练过多的功能

当一个模型训练了太多的特征时，假设就变得极其复杂。考虑这样一种情况，您有一列特征，您需要生成一个假设。这是一个简单的线性方程，如下所示:

![Figure 7.1: Equation for a hypothesis for a line
](image/B15019_07_01.jpg)

图 7.1:直线假设的方程式

现在，考虑这样一种情况，其中有两列，通过将它们相乘来交叉。假设变成如下:

![Figure 7.2: Equation for a hypothesis for a curve
](image/B15019_07_02.jpg)

图 7.2:曲线假设的方程式

第一个方程产生一条直线，第二个方程产生一条曲线，因为它现在是一个二次方程。但是同样的两个特性可能会变得更加复杂，这取决于你如何设计你的特性。考虑以下等式:

![Figure 7.3: Cubic equation for a hypothesis
](image/B15019_07_03.jpg)

图 7.3:假设的三次方程

同一套特征现在已经产生了一个三次方程。该等式具有大量权重的性质，例如:

*   简单的线性方程有一个权重和一个偏差。
*   二次方程有三个权重和一个偏差。
*   三次方程有五个权重和一个偏差。

解决由于过多特征而导致的过度拟合的一种方法是消除某些特征。这种技术被称为套索回归。

第二种解决由于太多特征导致的过度拟合的方法是为模型提供更多的数据。这可能并不总是一个可行的选择，但在可能的情况下，这样做总是一个好主意。

## 训练时间过长

该模型通过初始化权重向量来开始训练，使得所有值都等于零。在训练期间，根据梯度更新规则更新权重。这有系统地给每个权重加上或减去一个小值。随着训练的进行，重量会增加。如果模型训练时间过长，这些模型权重会变得过大。

对由于大权重而导致的过度拟合的解决方案是将权重的大小尽可能地减小到接近零。这种技术被称为岭回归。

# 欠拟合

考虑另一种情况，其中数据有 10 个特征，但您只利用了 1 个特征。您的模型假设仍然如下:

![Figure 7.4: Equation for a hypothesis for a line
](image/B15019_07_04.jpg)

图 7.4:直线假设的方程式

但是，那是一条直线的方程，但是你的模型很可能忽略了很多信息。该模型过于简化，据说数据不足。

解决拟合不足的方法是为模型提供更多的特征，或者相反，提供更少的数据进行训练；但是更多的功能是更好的方法。

# 数据

在机器学习的世界里，你所拥有的数据并不完全用于训练你的模型。相反，您需要将数据分成三组，如下所述:

*   训练数据集，用于训练您的模型并测量训练损失。
*   评估或验证数据集，用于测量模型的验证损失，以查看验证损失是否会像定型损失一样继续减少。
*   用于最终测试的测试数据集，用于在将模型投入生产之前查看模型的性能。

## 数据集分割的比率

评估数据集是从您的整个训练数据中分离出来的，永远不会用于训练。有各种各样的思想流派围绕着特定的比例，这是留给评估，但它通常范围从 30%的高到 10%的低。该评估数据集通常进一步分为在训练期间使用的验证数据集和在最后用于健全性检查的测试数据集。如果您使用 10%进行评估，您可以留出 5%用于验证，剩下的 5%用于测试。如果使用 30%，你可以留出 20%用于验证，10%用于测试。

总而言之，您可以将数据分成 70%用于定型，20%用于验证，10%用于测试，或者您可以将数据分成 80%用于定型，15%用于验证，5%用于测试。或者，最后，您可以将数据分成 90%用于训练，5%用于验证，5%用于测试。

使用何种比率取决于您拥有的数据量。例如，如果您正在处理 100，000 条记录，那么 20%的验证将得到 20，000 条记录。然而，如果您正在处理 100，000，000 条记录，那么 5%将为您提供 500 万条记录进行验证，这将绰绰有余。

## 创建数据集分割

在非常基本的层面上，拆分数据涉及随机抽样。假设你的碗里有 10 样东西。要得到 30%的物品，你可以伸手进去，随机拿走 3 件物品。

同样，因为您正在编写代码，所以您可以执行以下操作:

1.  创建一个 Python 列表。
2.  在列表中放置 10 个数字。
3.  生成 3 个从 0 到 9 的不重复的随机整数。
4.  选择其索引对应于先前生成的随机数的项目。

![Figure 7.5: Visualization of data splitting
](image/B15019_07_05.jpg)

图 7.5:数据分割的可视化

对于特定的数据集，这种操作只需做一次。你可以为它写一个函数。如果您需要重复做一些事情，并且您还需要处理高级功能，您可能需要为它编写一个类。

`sklearn`有一个名为`train_test_split`的类，它提供了拆分数据的功能。它被称为`sklearn.model_selection.train_test_split`。这个函数可以让你把一个数据帧分成两部分。

请看下面关于导入和拆分数据的练习。

## 练习 7.01:导入和拆分数据

本练习的目标是从存储库中导入数据，并将其分为训练集和评估集。

我们将使用 UCI 机器学习库中的 Cars 数据集。

注意

你可以在这里找到数据集:[https://packt.live/2RE5rWi](https://packt.live/2RE5rWi)

数据集也可以在我们的 GitHub 上找到，这里:[https://packt.live/36cvyc4](https://packt.live/36cvyc4)

您将在本章的所有练习中使用该数据集。

这个数据集是关于拥有具有某些属性的汽车的成本。该网站的摘要称:“*来源于简单的分层决策模型，该数据库可能对测试建设性归纳和结构发现方法*有用。”以下是该数据集的一些关键属性:

```py
CAR car acceptability
. PRICE overall price
. . buying buying price
. . maint price of the maintenance
. TECH technical characteristics
. . COMFORT comfort
. . . doors number of doors
. . . persons capacity in terms of persons to carry
. . . lug_boot the size of luggage boot
. . safety estimated safety of the car
```

以下步骤将帮助您完成练习:

1.  打开一个新的 Colab 笔记本文件。
2.  Import the necessary libraries:

    ```py
    # import libraries
    import pandas as pd
    from sklearn.model_selection import train_test_split
    ```

    在这一步中，您已经导入了`pandas`并将其别名为`pd`。你知道，`pandas`是文件中要求阅读的。您还从`sklearn.model_selection`导入`train_test_split`，将数据分成两部分。

3.  Before reading the file into your notebook, open and inspect the file with an editor. You should see an output similar to the following:![Figure 7.6: Car data
    ](image/B15019_07_06.jpg)

    图 7.6:汽车数据

    您将从前面的屏幕截图中注意到，该文件没有包含标题的第一行。

4.  创建一个 Python 列表来保存数据头:

    ```py
    # data doesn't have headers, so let's create headers
    _headers = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'car']
    ```

5.  Now, import the data as shown in the following code snippet:

    ```py
    # read in cars dataset
    df = pd.read_csv('https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/blob/master/Chapter07/Dataset/car.data', names=_headers, index_col=None)
    ```

    然后使用`pd.read_csv`将数据导入到一个名为`df`的变量中。您可以指定数据文件的位置以及列标题列表。您还指定数据没有列索引。

6.  Show the top five records:

    ```py
    df.info()
    ```

    为了获得关于数据中的列以及记录数量的信息，可以使用`info()`方法。您应该会得到类似如下的输出:

    ![Figure 7.7: The top five records of the DataFrame
    ](image/B15019_07_07.jpg)

    图 7.7:数据帧的前五条记录

    `RangeIndex`值显示记录的数量，即`1728`。

7.  Now, you need to split the data contained in `df` into a training dataset and an evaluation dataset:

    ```py
    #split the data into 80% for training and 20% for evaluation
    training_df, eval_df = train_test_split(df, train_size=0.8, random_state=0)
    ```

    在这一步中，您利用`train_test_split`创建两个新的数据帧，称为`training_df`和`eval_df`。

    您为`train_size`指定一个值`0.8`，以便将数据的`80%`分配给`training_df`。

    `random_state`确保您的实验具有可重复性。如果没有`random_state`，数据每次使用不同的随机数进行不同的分割。使用`random_state`，数据每次都以同样的方式分割。我们将在下一章深入研究`random_state`。

8.  Check the information of `training_df`:

    ```py
    training_df.info()
    ```

    在这一步中，您利用`.info()`来获得`training_df`的细节。这将打印出列名和记录数。

    您应该会得到类似如下的输出:

    ![Figure 7.8: Information on training_df
    ](image/B15019_07_08.jpg)

    图 7.8:关于培训 _df 的信息

    您应该注意到列名与`df`中的相匹配，但是您应该有在`df`中做的记录的`80%`，这是`1728`中的`1382`。

9.  Check the information on `eval_df`:

    ```py
    eval_df.info()
    ```

    在这一步中，您打印出关于`eval_df`的信息。这将为您提供列名和记录数。输出应该类似于以下内容:

![Figure 7.9: Information on eval_df
](image/B15019_07_09.jpg)

图 7.9:关于 eval_df 的信息

现在你知道如何分割你的数据。无论何时拆分数据，记录都会完全相同。您可以多次重复这个练习，并注意到`eval_df`的索引中的条目范围。

这意味着你不能重复你的实验。如果运行相同的代码，每次都会得到不同的结果。同样，如果你和你的同事分享你的代码，他们会得到不同的结果。这是因为编译器使用了随机数。

这些随机数实际上不是随机的，而是利用了一种叫做伪随机数发生器的东西。生成器使用一组预先确定的随机数，因此，您可以指定一个随机状态，使其使用一组特定的随机数。

# 随机状态

复制相同结果的关键叫做随机状态。您只需指定一个数字，无论何时使用该数字，都会产生相同的结果。这是因为计算机没有真正的随机数发生器。相反，他们有一个伪随机数发生器。这意味着如果你设置一个随机状态，你可以生成相同的随机数序列。

以下图为例。列是你的随机状态。如果你选择 0 作为随机状态，将产生以下数字:41，52，38，56…

但是，如果您选择 1 作为随机状态，将会生成一组不同的数字，以此类推。

![Figure 7.10: Numbers generated using random state
](image/B15019_07_10.jpg)

图 7.10:使用随机状态生成的数字

在上一个练习中，您将随机状态设置为 0，以便实验是可重复的。

## 练习 7.02:拆分数据时设置随机状态

本练习的目标是用一种可重现的方式分割您在*练习 7.01* 中导入的数据。

以下步骤将帮助您完成练习:

1.  从之前的*练习 7.01* 笔记本继续。
2.  Set the random state as `1` and split the data:

    ```py
    #split the data into 80% for training and 20% for evaluation #using a random state
    training_df, eval_df = train_test_split(df, train_size=0.8, random_state=1)
    ```

    在这一步中，您为`train_test_split`函数指定一个值为 1 的`random_state`。

3.  Now, view the top five records in `training_df`:

    ```py
    #view the head of training_eval
    training_df.head()
    ```

    在这一步中，您打印出`training_df`中的前五条记录。

    输出应该类似于以下内容:

    ![Figure 7.11: The top five rows for the training evaluation set
    ](image/B15019_07_11.jpg)

    图 7.11:训练评估集的前五行

4.  View the top five records in `eval_df`:

    ```py
    #view the top of eval_df
    eval_df.head()
    ```

    在这一步中，您打印出`eval_df`中的前五条记录。

    输出应该类似于以下内容:

![Figure 7.12: The top five rows of eval_df
](image/B15019_07_12.jpg)

图 7.12:eval _ df 的前五行

这个练习的目标是获得可重复的分割。如果您运行代码，您将在`training_df`和`eval_df`中获得相同的记录。您可以继续在每个系统上运行该代码几次，并验证您在两个数据集中获得了相同的记录。

每当你改变`random_state`，你会得到一组不同的训练和验证数据。

但是如何找到最佳的数据集分割来训练您的模型呢？当你没有很多数据时，推荐的方法是利用你所有的数据。

但是，如果您使用了所有的数据，您如何保留验证数据呢？

答案是将数据分成若干部分。这种方法被称为交叉验证，我们将在下一节中讨论。

# 交叉验证

考虑一个例子，你把数据分成五部分，每部分 20%。然后，您将利用四个部分进行培训，一个部分进行评估。因为您有五个部分，所以您可以使用数据五次，每次使用一个部分进行验证，其余的数据用于训练。

![Figure 7.13: Cross-validation
](image/B15019_07_13.jpg)

图 7.13:交叉验证

交叉验证是一种拆分数据的方法，您可以进行多次拆分，然后将其中一些用于训练，其余的用于验证。然后，您可以利用所有的数据组合来训练多个模型。

这种方法被称为 n 重交叉验证或 k 重交叉验证。

注意

有关 k 倍交叉验证的更多信息，请参考[https://packt.live/36eXyfi](https://packt.live/36eXyfi)。

## KFold

`sklearn.model_selection`中的`KFold`类返回一个生成器，该生成器提供一个具有两个索引的元组，一个用于训练，另一个用于测试或验证。生成器函数允许您声明一个行为类似迭代器的函数，从而允许您在循环中使用它。

## 练习 7.03:创建一个五重交叉验证数据集

本练习的目标是根据您在*练习 7.01* 中导入的数据创建一个五重交叉验证数据集。

以下步骤将帮助您完成练习:

1.  从*练习 7.01 的笔记本文件继续。*
2.  Import all the necessary libraries:

    ```py
    from sklearn.model_selection import KFold
    ```

    在这一步中，您从`sklearn.model_selection`导入`KFold`。

3.  Now create an instance of the class:

    ```py
    _kf = KFold(n_splits=5)
    ```

    在这一步中，您创建了一个`KFold`的实例，并将其分配给一个名为`_kf`的变量。您为`n_splits`参数指定一个值`5`,以便它将数据集分成五个部分。

4.  Now split the data as shown in the following code snippet:

    ```py
    indices = _kf.split(df)
    ```

    在这一步中，您调用`split`方法，它是`_kf`上的`.split()`。结果存储在一个名为`indices`的变量中。

5.  Find out what data type `indices` has:

    ```py
    print(type(indices))
    ```

    在此步骤中，您将检查分割输出返回的调用。

    输出应该是一个生成器，如下面的输出所示:

    ![Figure 7.14: Data type for indices
    ](image/B15019_07_14.jpg)

    图 7.14:索引的数据类型

    在前面的输出中，您可以看到输出是一个生成器。

6.  Get the first set of indices:

    ```py
    #first set
    train_indices, val_indices = next(indices)
    ```

    在这一步中，您将在生成器函数上使用`next()` Python 函数。使用`next()`是让生成器返回结果给你的方法。你要求五次拆分，所以你可以在这个特定的生成器上调用`next()`五次。第六次调用`next()`将导致 Python 运行时引发一个异常。

    对`next()`的调用产生了一个元组。在这种情况下，它是一对指数。第一个包含您的训练指数，第二个包含您的验证指数。你把这些分配给`train_indices`和`val_indices`。

7.  Create a training dataset as shown in the following code snippet:

    ```py
    train_df = df.drop(val_indices)
    train_df.info()
    ```

    在这一步中，通过从包含所有数据的数据帧`df`中删除验证索引，创建一个名为`train_df`的新数据帧。这是一种减法运算，类似于集合论中的运算。`df`集是`train`和`val`的结合。一旦你知道`val`是什么，你就可以通过从`df`中减去`val`来确定`train`。如果你认为`df`是一个名为`A`的集合，`val`是一个名为`B`的集合，而 train 是一个名为`C`的集合，那么以下成立:

    ![Figure 7.15: Dataframe A
    ](image/B15019_07_15.jpg)

    图 7.15:数据帧 A

    类似地，集合`C`可以是集合`A`和集合`B`之间的差，如下所示:

    ![Figure 7.16: Dataframe C
    ](image/B15019_07_16.jpg)

    图 7.16:数据帧 C

    使用 pandas DataFrame 实现这一点的方法是从`A`中删除带有`B`元素索引的行，这就是您在前面的代码片段中看到的。

    您可以通过在新的数据帧上调用`info()`方法来查看结果。

    该调用的结果应该类似于下面的屏幕截图:

    ![Figure 7.17: Information on the new dataframe
    ](image/B15019_07_17.jpg)

    图 7.17:新数据帧上的信息

8.  Create a validation dataset:

    ```py
    val_df = df.drop(train_indices)
    val_df.info()
    ```

    在这一步中，您通过从`df`数据帧中删除训练索引来创建`val_df`验证数据集。同样，您可以通过调用`info()`方法来查看这个新数据帧的细节。

    输出应该类似于以下内容:

![Figure 7.18: Information for the validation dataset
](image/B15019_07_18.jpg)

图 7.18:验证数据集的信息

您可以在一个循环中对上述所有内容进行编程，这样就不需要手动调用`next()`五次。这是我们在下一个练习中要做的。

## 练习 7.04:使用调用循环创建五重交叉验证数据集

本练习的目标是根据您在*练习 7.01* 中导入的数据创建一个五重交叉验证数据集。您将利用一个循环来调用生成器函数。

以下步骤将帮助您完成本练习:

1.  打开一个新的 Colab 笔记本，重复您在*练习 7.01* 中用于导入数据的步骤。
2.  Define the number of splits you would like:

    ```py
    from sklearn.model_selection import KFold
    #define number of splits
    n_splits = 5
    ```

    在这一步中，您将分割数设置为`5`。您将它存储在一个名为`n_splits`的变量中。

3.  Create an instance of `Kfold`:

    ```py
    #create an instance of KFold
    _kf = KFold(n_splits=n_splits)
    ```

    在这一步中，您创建了一个`Kfold`的实例。您将这个实例分配给一个名为`_kf`的变量。

4.  Generate the split indices:

    ```py
    #create splits as _indices
    _indices = _kf.split(df)
    ```

    在这一步中，您在`_kf`上调用`split()`方法，这是您之前定义的`KFold`的实例。您提供`df`作为参数，以便对包含在名为`df`的数据帧中的数据执行分割。生成的生成器存储为`_indices`。

5.  Create two Python lists:

    ```py
    _t, _v = [], []
    ```

    在这一步中，您将创建两个 Python 列表。第一个称为`_t`，保存训练数据帧，第二个称为`_v`，保存验证数据帧。

6.  Iterate over the generator and create DataFrames called `train_idx`, `val_idx`, `_train_df` and `_val_df`:

    ```py
    #iterate over _indices
    for i in range(n_splits):
        train_idx, val_idx = next(_indices)
        _train_df = df.drop(val_idx)
        _t.append(_train_df)
        _val_df = df.drop(train_idx)
        _v.append(_val_df)
    ```

    在这一步中，您使用`range`创建一个循环来确定迭代次数。您通过将`n_splits`作为参数提供给`range()`来指定迭代次数。在每次迭代中，在`_indices`生成器上执行`next()`，并将结果存储在`train_idx`和`val_idx`中。然后，通过从`df`中删除验证索引`val_idx`，继续创建`_train_df`。您还可以通过从`df`中删除训练索引来创建`_val_df`。

7.  Iterate over the training list:

    ```py
    for d in _t:
        print(d.info())
    ```

    在这一步中，您将验证编译器是否创建了数据帧。您可以通过遍历列表并使用`.info()`方法打印出每个元素的细节来做到这一点。输出类似于下面的截图，由于输出的大小，它是不完整的。列表中的每个元素都是具有 1，382 个条目的数据帧:

    ![Figure 7.19: Iterating over the training list
    ](image/B15019_07_19.jpg)

    图 7.19:迭代训练列表

8.  Iterate over the validation list:

    ```py
    for d in _v:
        print(d.info())
    ```

    在这一步中，迭代验证列表，并利用`.info()`打印出每个元素的细节。输出类似于下面的截图，由于大小原因不完整。每个元素是具有 346 个条目的数据帧:

![Figure 7.20: Iterating over the validation list
](image/B15019_07_20.jpg)

图 7.20:迭代验证列表

在本练习中，您学习了如何使用 k 重交叉验证循环来提取训练和验证数据集。您可以利用这些数据集来训练和评估多个模型。

创建交叉验证数据集的本质是您可以训练和评估多个模型。如果不用循环训练那些模型会怎么样？

好消息是，您可以避免在一个循环中训练多个模型，因为如果您这样做，您将需要数组来跟踪大量指标。

# 交叉值分数

`cross_val_score()`功能在`sklearn.model_selection`中可用。到目前为止，您已经学习了如何在循环中创建交叉验证数据集。如果您使用这种方法，您将需要跟踪您在该循环中训练和评估的所有模型。

`cross_val_score`负责以下事项:

*   创建交叉验证数据集
*   通过使模型符合训练数据来训练模型
*   根据验证数据评估模型
*   返回被训练的每个模型的 R2 分数的列表

要执行上述所有操作，您需要提供以下输入:

*   估计量的实例(例如，`LinearRegression`)
*   原始数据集
*   要创建的拆分数量(也是将被定型和评估的模型数量)

## 练习 7.05:从五重交叉验证中获得分数

本练习的目标是根据您在*练习 7.01* 中导入的数据创建一个五重交叉验证数据集。然后，您将使用`cross_val_score`来获得在这些数据集上训练的模型的分数。

以下步骤将帮助您完成练习:

1.  打开一个新的 Colab 笔记本，重复在*练习 7.01* 中导入数据的步骤。
2.  Encode the categorical variables in the dataset:

    ```py
    # encode categorical variables
    _df = pd.get_dummies(df, columns=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'])
    _df.head()
    ```

    在这一步中，您利用`pd.get_dummies()`将分类变量转换成编码。您将结果存储在一个名为`_df`的新 DataFrame 变量中。然后，您继续查看前五条记录。

    结果应该类似于以下内容:

    ![Figure 7.21: Encoding categorical variables
    ](image/B15019_07_21.jpg)

    图 7.21:编码分类变量

3.  Split the data into features and labels:

    ```py
    # separate features and labels DataFrames
    features = _df.drop(['car'], axis=1).values
    labels = _df[['car']].values
    ```

    在这一步中，您通过从`_df`中拖放`car`来创建一个`features`数据帧。您还可以通过在新的数据帧中只选择`car`来创建`labels`。这里，汽车数据集中的要素和标注是相似的。

4.  Create an instance of the `LogisticRegression` class to be used later:

    ```py
    from sklearn.linear_model import LogisticRegression
    # create an instance of LogisticRegression
    _lr = LogisticRegression()
    ```

    在这一步中，您从`sklearn.linear_model`导入`LogisticRegression`。我们使用`LogisticRegression`，因为它让我们创建一个分类模型，正如你在*第 3 章，二元分类*中所学的。然后继续创建一个实例，并将其存储为`_lr`。

5.  Import the `cross_val_score` function:

    ```py
    from sklearn.model_selection import cross_val_score
    ```

    在这一步中，您将导入`cross_val_score`，您将利用它来计算模型的分数。

6.  Compute the cross-validation scores:

    ```py
    _scores = cross_val_score(_lr, features, labels, cv=5)
    ```

    在这一步中，您将计算交叉验证分数，并将结果存储在一个 Python 列表中，您称之为`_scores`。您可以使用`cross_cal_score`来完成这项工作。该函数需要以下四个参数:要使用的模型(在我们的例子中，它被称为`_lr`)；数据集的特征；数据集的标签；以及要创建的交叉验证拆分的数量(在我们的例子中是五个)。

7.  Now, display the scores as shown in the following code snippet:

    ```py
    print(_scores)
    ```

    在这一步中，您使用`print()`显示分数。

    输出应该类似于以下内容:

![Figure 7.22: Printing the cross-validation scores
](image/B15019_07_22.jpg)

图 7.22:打印交叉验证分数

在前面的输出中，您可以看到存储在`variable _scores`中的 Python 列表包含五个结果。每个结果都是一个`LogisticRegression`模型的 R2 分数。如练习前所述，数据将被分成五组，这五组数据的每个组合将用于训练和评估模型，然后计算 R2 分数。

您应该从前面的示例中观察到，在五个不同的数据集上训练的同一个模型产生了不同的分数。这意味着数据的重要性以及数据是如何分割的。

通过完成这个练习，我们看到最好成绩是 **0.832** ，属于秒劈。这是我们的结论。

您已经看到交叉验证会产生不同的模型。

但是你如何找到最好的工作模式呢？有一些带有内置交叉验证的模型或估计量。让我们解释一下。

## 理解实现 CV 的评估者

使用交叉验证的目的是使用您拥有的数据找到性能最佳的模型。其流程如下:

1.  使用类似于`Kfold()`的东西分割数据。
2.  迭代分裂数并创建一个估计量。
3.  培训和评估每个评估员。
4.  选择具有最佳指标的评估者来使用。您已经看到了实现这一目标的各种方法。

交叉验证是一种流行的技术，因此存在用于交叉验证的估计量。例如，`LogisticRegressionCV`是作为一个在`LogisticRegression`内部实现交叉验证的类存在的。当您使用`LogisticRegressionCV`时，它会返回一个`LogisticRegression`的实例。它返回的实例是性能最好的实例。

当您创建一个`LogisticRegressionCV`的实例时，您将需要指定您想要的`cv`部件的数量。例如，如果您将`cv`设置为`3` , `LogisticRegressionCV`将训练三个`LogisticRegression`实例，然后对它们进行评估并返回性能最佳的实例。

你不必使用`LogisticRegressionCV`。您可以通过`Kfold`和迭代继续使用`LogisticRegression`。`LogisticRegressionCV`只是为了方便而存在。

以类似的方式，`LinearRegressionCV`是一种使用`LinearRegression`实现交叉验证的便捷方式。

所以，要明确的是，你不必使用像`LogisticRegressionCV`这样的便利方法。此外，它们不能替代它们的主要实现，比如`LogisticRegression`。相反，当您需要实现交叉验证，但想省去前面的四个步骤时，您可以使用方便的方法。

# 物流损耗 CV

`LogisticRegressionCV`是一个在内部实现交叉验证的类。这个班会训练多个`LogisticRegression`模型，返回最好的一个。

## 练习 7.06:使用交叉验证训练逻辑回归模型

本练习的目标是使用交叉验证训练逻辑回归模型，并获得最佳 R2 结果。我们将利用您之前使用的汽车数据集。

以下步骤将帮助您完成练习:

1.  打开新的 Colab 笔记本。
2.  Import the necessary libraries:

    ```py
    # import libraries
    import pandas as pd
    ```

    在这一步中，您导入`pandas`并将其别名为`pd`。您将使用 pandas 来读取您将使用的文件。

3.  Create headers for the data:

    ```py
    # data doesn't have headers, so let's create headers
    _headers = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'car']
    ```

    在这一步中，首先创建一个 Python 列表来保存您将使用的文件的`headers`列。您将这个列表存储为`_headers`。

4.  Read the data:

    ```py
    # read in cars dataset
    df = pd.read_csv('https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter07/Dataset/car.data', names=_headers, index_col=None)
    ```

    然后，您继续读入文件，并将其存储为`df`。这是一个数据帧。

5.  Print out the top five records:

    ```py
    df.info()
    ```

    最后，使用`.info()`查看数据帧的摘要。

    输出如下所示:

    ![Figure 7.23: The top five records of the dataframe
    ](image/B15019_07_23.jpg)

    图 7.23:数据帧的前五条记录

6.  Encode the categorical variables as shown in the following code snippet:

    ```py
    # encode categorical variables
    _df = pd.get_dummies(df, columns=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'])
    _df.head()
    ```

    在这一步中，您使用 pandas 的`get_dummies()`方法将分类变量转换成编码。您提供原始数据帧作为参数，并指定您想要编码的列。

    最后，您瞥一眼最上面的五行。输出如下所示:

    ![Figure 7.24: Encoding categorical variables
    ](image/B15019_07_24.jpg)

    图 7.24:编码分类变量

7.  Split the DataFrame into features and labels:

    ```py
    # separate features and labels DataFrames
    features = _df.drop(['car'], axis=1).values
    labels = _df[['car']].values
    ```

    在这一步中，您将创建两个 NumPy 数组。第一个称为`features`，包含独立变量。第二个称为`labels`，包含模型学习预测的值。这些也被称为`targets`。

8.  Import logistic regression with cross-validation:

    ```py
    from sklearn.linear_model import LogisticRegressionCV
    ```

    在这一步中，您导入了`LogisticRegressionCV`类。

9.  Instantiate `LogisticRegressionCV` as shown in the following code snippet:

    ```py
    model = LogisticRegressionCV(max_iter=2000, multi_class='auto', cv=5)
    ```

    在这一步中，您创建了一个`LogisticRegressionCV`的实例。您需要指定以下参数:

    `max_iter`:你把这个设置为`2000`，这样训练者继续训练`2000`迭代，找到更好的重量。

    `multi_class`:您将它设置为`auto`，以便模型自动检测您的数据有两个以上的类。

    `cv`:您将此设置为`5`，这是您想要训练的交叉验证集的数量。

10.  Now fit the model:

    ```py
    model.fit(features, labels.ravel())
    ```

    在此步骤中，您将训练模型。你传入`features`和`labels`。因为`labels`是一个 2D 数组，所以使用`ravel()`将其转换成 1D 数组或向量。

    解释器产生如下所示的输出:

    ![Figure 7.25: Fitting the model
    ](image/B15019_07_25.jpg)

    图 7.25:拟合模型

    在前面的输出中，您可以看到模型符合定型数据。输出显示了培训中使用的参数，因此您不会感到惊讶。注意，例如，`max_iter`是`2000`，这是您设置的值。您没有设置的其他参数使用默认值，您可以从文档中找到更多信息。

11.  Evaluate the training R2:

    ```py
    print(model.score(features, labels.ravel()))
    ```

    在这一步中，我们利用训练数据集来计算 R2 分数。虽然我们没有留出特定的验证数据集，但需要注意的是，该模型只看到了我们 80%的训练数据，因此它仍然有新的数据可用于此次评估。

    输出如下所示:

![Figure 7.26: Computing the R2 score
](image/B15019_07_26.jpg)

图 7.26:计算 R2 分数

在前面的输出中，您可以看到最终模型的`R2`分数为`0.95`，这是一个不错的分数。

此时，您应该会看到一个比之前遇到的好得多的`R2`分数。

如果您使用的是没有内置交叉验证的其他类型的模型，会怎么样呢？你能利用交叉验证来训练模型并找到最好的吗？让我们找出答案。

# 使用 GridSearchCV 调整超参数

`GridSearchCV`将获取一个模型和参数，并为每个参数排列训练一个模型。在培训结束时，它将提供对参数和模型分数的访问。这被称为超参数调优，你将在*第 8 章，超参数调优*中更深入地了解这一点。

通常的做法是利用一个小的训练集，通过超参数调整找到最佳参数，然后用所有数据训练一个最终模型。

在下一个练习之前，让我们简要地看一下决策树，它是一种模型或估计器。

## 决策树

决策树通过为数据中的特征生成分离超平面或阈值来工作。它通过考虑每个特征并找到该特征中值的分布与您试图预测的标签之间的相关性来实现这一点。

考虑以下关于气球的数据。你需要预测的标签叫做`inflated`。该数据集用于预测给定特征下气球是膨胀还是收缩。其特点是:

*   `color`
*   `size`
*   `act`
*   `age`

下表显示了功能的分布:

![Figure 7.27: Tabular data for balloon features
](image/B15019_07_27.jpg)

图 7.27:气球特征的表格数据

现在考虑以下图表，这些图表根据特征相对于标签的分布情况进行可视化:

*   如果考虑`Color`特征，值为`PURPLE`和`YELLOW`，但观测次数相同，所以不能根据颜色推断气球是否充气，如下图所示:

![Figure 7.28: Barplot for the color feature
](image/B15019_07_28.jpg)

图 7.28:颜色特征的条形图

*   `Size`特性有两个值:`LARGE`和`SMALL`。这些是平均分布的，所以我们不能根据颜色来推断气球是否膨胀，如下图所示:

![Figure 7.29: Barplot for the size feature
](image/B15019_07_29.jpg)

图 7.29:尺寸特征的条形图

*   `Act`特性有两个值:`DIP`和`STRETCH`。从图表中可以看出，大多数`STRETCH`值都被夸大了。如果你必须做一个猜测，你可以很容易地说，如果`Act`是`STRETCH`，那么气球是膨胀的。请考虑下图:

![Figure 7.30: Barplot for the act feature
](image/B15019_07_30.jpg)

图 7.30:act 特性的条形图

*   最后，`Age`特性也有两个值:`ADULT`和`CHILD`。从图表中还可以看出，`ADULT`值构成了膨胀气球的大部分:

![Figure 7.31: Barplot for the age feature
](image/B15019_07_31.jpg)

图 7.31:年龄特征的条形图

对决策树有用的两个特征是`Act`和`Age`。该树可以从考虑`Act`是否是`STRETCH`开始。如果是的话，预测将是真实的。该树看起来如下图所示:

![Figure 7.32: Decision tree with depth=1
](image/B15019_07_32.jpg)

图 7.32:深度=1 的决策树

左侧评估条件为假，右侧评估条件为真。这棵树的深度为 1。f 表示预测为假，T 表示预测为真。

为了得到更好的结果，决策树可以引入第二个层次。第二级将利用`Age`特性并评估值是否为`ADULT`。它看起来如下图所示:

![Figure 7.33: Decision tree with depth=2
](image/B15019_07_33.jpg)

图 7.33:深度=2 的决策树

这棵树的深度为 2。在第一层，如果`Act`为`STRETCH`，则预测为真。如果`Act`不是`STRETCH`，则检查`Age`是否是`ADULT`。如果是，它预测真，否则，它预测假。

决策树可以有任意多的层次，但是在某一点上开始过度适应。与数据科学中的一切一样，最佳深度取决于数据，并且是一个超参数，这意味着您需要尝试不同的值来找到最佳值。

在下面的练习中，我们将利用交叉验证的网格搜索来寻找决策树估计器的最佳参数。

## 练习 7.07:使用交叉验证的网格搜索找到模型的最佳参数

本练习的目标是利用网格搜索为`DecisionTree`分类器找到最佳参数。我们将利用您之前使用的汽车数据集。

以下步骤将帮助您完成练习:

1.  打开 Colab 笔记本文件。
2.  Import `pandas`:

    ```py
    import pandas as pd
    ```

    在这一步中，您导入`pandas`。你把它别名为`pd`。`Pandas`用于读入您随后将使用的数据。

3.  创建`headers` :

    ```py
    _headers = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'car']
    ```

4.  读入`headers` :

    ```py
    # read in cars dataset
    df = pd.read_csv('https://github.com/PacktWorkshops/The-Data-Science-Workshop/blob/master/Chapter07/Dataset/car.data', names=_headers, index_col=None)
    ```

5.  Inspect the top five records:

    ```py
    df.info()
    ```

    输出如下所示:

    ![Figure 7.34: The top five records of the dataframe
    ](image/B15019_07_34.jpg)

    图 7.34:数据帧的前五条记录

6.  Encode the categorical variables:

    ```py
    _df = pd.get_dummies(df, columns=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'])
    _df.head()
    ```

    在这一步中，您利用`.get_dummies()`将分类变量转换成编码。`.head()`方法指示 Python 解释器输出前五列。

    输出类似于以下内容:

    ![Figure 7.35: Encoding categorical variables
    ](image/B15019_07_35.jpg)

    图 7.35:编码分类变量

7.  Separate `features` and `labels`:

    ```py
    features = _df.drop(['car'], axis=1).values
    labels = _df[['car']].values
    ```

    在这一步，您创建两个`numpy`数组，`features`和`labels`，第一个包含自变量或预测值，第二个包含因变量或目标值。

8.  Import more libraries – `numpy`, `DecisionTreeClassifier`, and `GridSearchCV`:

    ```py
    import numpy as np
    from sklearn.tree import DecisionTreeClassifier
    from sklearn.model_selection import GridSearchCV
    ```

    在这一步中，您导入`numpy`。NumPy 是一个数值计算库。你把它别名为`np`。您还导入了用于创建决策树的`DecisionTreeClassifier`。最后，您导入`GridSearchCV`，它将使用交叉验证来训练多个模型。

9.  Instantiate the decision tree:

    ```py
    clf = DecisionTreeClassifier()
    ```

    在这一步中，您将创建一个作为`clf`的`DecisionTreeClassifier`实例。网格搜索将重复使用该实例。

10.  Create parameters – `max_depth`:

    ```py
    params = {'max_depth': np.arange(1, 8)}
    ```

    在这一步中，您将创建一个参数字典。这本词典有两部分:

    字典的关键字是传递给模型的参数。在这种情况下，`max_depth`是`DecisionTreeClassifier`取的一个参数。

    该值是一个 Python 列表，grid search 对其进行迭代并传递给模型。在这种情况下，我们创建一个从 1 开始到 7 结束的数组。

11.  Instantiate the grid search as shown in the following code snippet:

    ```py
    clf_cv = GridSearchCV(clf, param_grid=params, cv=5)
    ```

    在这一步中，您创建了一个`GridSearchCV`的实例。第一个参数是要训练的模型。第二个参数是要搜索的参数。第三个参数是要创建的交叉验证拆分的数量。

12.  Now train the models:

    ```py
    clf_cv.fit(features, labels)
    ```

    在此步骤中，您将使用要素和标签来训练模型。根据型号的类型，这可能需要一段时间。因为我们用的是决策树，所以训练很快。

    输出类似于以下内容:

    ![Figure 7.36: Training the model
    ](image/B15019_07_36.jpg)

    图 7.36:训练模型

    通过阅读输出可以了解到很多东西，比如创建的交叉验证数据集的数量(称为`cv`，等于`5`)，使用的估计量(`DecisionTreeClassifier`)，参数搜索空间(称为`param_grid`)。

13.  Print the best parameter:

    ```py
    print("Tuned Decision Tree Parameters: {}".format(clf_cv.best_params_))
    ```

    在这一步中，您将打印出最佳参数。在这种情况下，我们寻找的是最好的`max_depth`。输出如下所示:

    ![Figure 7.37: Printing the best parameter
    ](image/B15019_07_37.jpg)

    图 7.37:打印最佳参数

    在前面的输出中，您可以看到性能最好的模型是`max_depth`为`2`的模型。

    访问`best_params_`允许您使用更大的训练数据集，用最著名的参数训练另一个模型。

14.  Print the best `R2`:

    ```py
    print("Best score is {}".format(clf_cv.best_score_))
    ```

    在这一步中，您将打印出表现最佳的模型的`R2`分数。

    输出类似于以下内容:

    ```py
    Best score is 0.7777777777777776
    ```

    在前面的输出中，您可以看到表现最好的模型的`R2`得分为`0.778`。

15.  Access the best model:

    ```py
    model = clf_cv.best_estimator_
    ```

    在这一步中，您使用`best_estimator_`来访问最佳模型(或估计器)。这将允许您分析模型，或者有选择地使用它来进行预测和查找其他指标。指示 Python 解释器打印最佳估计值将产生类似如下的输出:

![Figure 7.38: Accessing the model
](image/B15019_07_38.jpg)

图 7.38:访问模型

在前面的输出中，您可以看到最佳模型是`DecisionTreeClassifier`，其`max_depth`为`2`。

网格搜索是超参数调优的第一批技术之一。然而，随着搜索空间的增大，它很快变得昂贵。随着参数选项的增加，搜索空间也会增加，因为参数选项的每种可能组合都会被考虑。

考虑模型(或估计量)采用多个参数的情况。搜索空间变成参数数量的倍数。例如，如果我们想要训练一个随机的森林分类器，我们将需要指定森林中的树的数量，以及最大深度。如果我们指定最大深度为 1、2 和 3，一个森林有 1，000、2，000 和 3，000 棵树，我们将需要训练 9 个不同的估计器。如果我们添加更多的参数(或超参数)，我们的搜索空间将呈几何级数增长。

# 使用随机搜索进行超参数调整

网格搜索遍历整个搜索空间，并为每个参数组合训练模型或估计器。随机搜索只检查一些组合。这是一种更优化的资源利用方式，并且仍然具有超参数调整和交叉验证的优势。您将在*第 8 章，超参数调整*中深入了解这一点。

看看下面的练习。

## 练习 7.08:使用随机搜索进行超参数调整

本练习的目标是使用随机搜索和交叉验证来执行超参数调整。

以下步骤将帮助您完成本练习:

1.  打开一个新的 Colab 笔记本文件。
2.  Import `pandas`:

    ```py
    import pandas as pd
    ```

    在这一步中，您导入`pandas`。您将在下一步中使用它。

3.  创建`headers` :

    ```py
    _headers = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'car']
    ```

4.  读入数据:

    ```py
    # read in cars dataset
    df = pd.read_csv('https://github.com/PacktWorkshops/The-Data-Science-Workshop/blob/master/Chapter07/Dataset/car.data', names=_headers, index_col=None)
    ```

5.  Check the first five rows:

    ```py
    df.info()
    ```

    您需要提供列标题的 Python 列表，因为数据不包含列标题。您还将检查您创建的数据帧。

    输出类似于以下内容:

    ![Figure 7.39: The top five rows of the DataFrame
    ](image/B15019_07_39.jpg)

    图 7.39:数据框的前五行

6.  Encode categorical variables as shown in the following code snippet:

    ```py
    _df = pd.get_dummies(df, columns=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'])
    _df.head()
    ```

    在这一步中，您将使用一键编码找到文本数据的数字表示。该操作产生新的数据帧。您将看到生成的数据结构如下所示:

    ![Figure 7.40: Encoding categorical variables
    ](image/B15019_07_40.jpg)

    图 7.40:编码分类变量

7.  Separate the data into independent and dependent variables, which are the `features` and `labels`:

    ```py
    features = _df.drop(['car'], axis=1).values
    labels = _df[['car']].values
    ```

    在这一步中，您将数据帧分成两个名为`features`和`labels`的`numpy`数组。`Features`包含自变量，而`labels`包含目标或因变量。

8.  Import additional libraries – `numpy`, `RandomForestClassifier`, and `RandomizedSearchCV`:

    ```py
    import numpy as np
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.model_selection import RandomizedSearchCV
    ```

    在这一步中，您导入`numpy`进行数值计算，导入`RandomForestClassifier`创建一个估计器集合，导入`RandomizedSearchCV`进行带有交叉验证的随机搜索。

9.  Create an instance of `RandomForestClassifier`:

    ```py
    clf = RandomForestClassifier()
    ```

    在这一步中，您实例化了`RandomForestClassifier`。随机森林分类器是投票分类器。它利用了多个决策树，这些决策树根据不同的数据子集进行训练。通过使用投票机制，来自树的结果有助于随机森林的输出。

10.  Specify the parameters:

    ```py
    params = {'n_estimators':[500, 1000, 2000], 'max_depth': np.arange(1, 8)}
    ```

    `RandomForestClassifier`接受许多参数，但是我们指定了两个:森林中的树的数量，称为`n_estimators`，以及每棵树中节点的深度，称为`max_depth`。

11.  Instantiate a randomized search:

    ```py
    clf_cv = RandomizedSearchCV(clf, param_distributions=params, cv=5)
    ```

    在这一步中，当实例化`clf`类、估计器或要使用的模型时，指定三个参数，即随机森林分类器、`param_distributions`、参数搜索空间和`cv`,即要创建的交叉验证数据集的数量。

12.  Perform the search:

    ```py
    clf_cv.fit(features, labels.ravel())
    ```

    在这一步中，您通过调用`fit()`来执行搜索。该操作使用交叉验证数据集和超参数的各种组合来训练不同的模型。此操作的输出类似于以下内容:

    ![Figure 7.41: Output of the search operation
    ](image/B15019_07_41.jpg)

    图 7.41:搜索操作的输出

    在前面的输出中，您可以看到随机搜索将使用五次分割的交叉验证(`cv=5`)来执行。要使用的估计器是`RandomForestClassifier`。

13.  Print the best parameter combination:

    ```py
    print("Tuned Random Forest Parameters: {}".format(clf_cv.best_params_))
    ```

    在这一步中，您将打印出最佳的超参数。

    输出类似于以下内容:

    ![Figure 7.42: Printing the best parameter combination
    ](image/B15019_07_42.jpg)

    图 7.42:打印最佳参数组合

    在前面的输出中，您可以看到最佳估计器是一个随机森林分类器，有 1000 棵树(`n_estimators=1000`)和`max_depth=5`。

14.  Inspect the best model:

    ```py
    model = clf_cv.best_estimator_
    model
    ```

    在这一步中，您将找到性能最佳的估算器(或模型),并打印出其详细信息。输出类似于以下内容:

![Figure 7.43:  Inspecting the model
](image/B15019_07_43.jpg)

图 7.43:检查模型

在前面的输出中，您可以看到最佳估计器是带有`n_estimators=1000`和`max_depth=5`的`RandomForestClassifier`。

在本练习中，您学习了如何利用交叉验证和随机搜索，通过组合超参数来找到最佳模型。这个过程称为超参数调整，在这个过程中，您可以找到最佳的超参数组合来训练您将投入生产的模型。

# 使用 Lasso 回归的模型正则化

正如本章开始时提到的，模型可能会过度拟合训练数据。其中一个原因是有太多系数大的要素(也称为权重)。解决这种过拟合问题的关键是降低系数的大小。

您可能还记得，权重是在模型训练期间优化的。一种优化权重的方法叫做梯度下降。梯度更新规则利用了可微分的损失函数。可微分损失函数的例子有:

*   平均绝对误差
*   均方误差

对于套索回归，损失函数中引入了一个惩罚。这个实现的技术细节被类隐藏了。惩罚也称为正则化参数。

考虑以下练习，在该练习中，您过度设计模型以引入过度拟合，然后使用套索回归来获得更好的结果。

## 练习 7.09:使用套索回归修正模型过度拟合

本练习的目标是教您如何识别模型何时开始过度拟合，并使用套索回归来修复模型中的过度拟合。

注意

您将使用的数据是来自 UCI 机器学习资料库的联合循环电厂数据集。它包含从联合循环发电厂收集的 9568 个数据点。特性包括温度、压力、湿度和排气真空。这些用于预测电厂每小时的净电能输出。请看以下链接:[https://packt.live/2v9ohwK](https://packt.live/2v9ohwK)。

属性信息声明“特征由每小时平均环境变量组成:

*   温度(T)在 1.81℃和 37.11℃之间，
*   环境压力(AP)在 992.89-1033.30 毫巴范围内，
*   相对湿度(RH)在 25.56%至 100.16%的范围内
*   排气真空(V)在 25.36-81.56 厘米汞柱的范围内
*   每小时净电能输出(EP) 420.26-495.76 兆瓦

平均值取自位于工厂周围的各种传感器，这些传感器每秒记录环境变量。给定的变量没有规格化。"

以下步骤将帮助您完成练习:

1.  打开 Colab 笔记本。
2.  导入所需的库:

    ```py
    import pandas as pd
    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import LinearRegression, Lasso
    from sklearn.metrics import mean_squared_error
    from sklearn.pipeline import Pipeline
    from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures
    ```

3.  读入数据:

    ```py
    _df = pd.read_csv('https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter07/Dataset/ccpp.csv')
    ```

4.  Inspect the DataFrame:

    ```py
    _df.info()
    ```

    `.info()`方法打印出数据帧的摘要，包括列名和记录数。输出可能类似于以下内容:

    ![Figure 7.44: Inspecting the dataframe
    ](image/B15019_07_44.jpg)

    图 7.44:检查数据帧

    从上图中可以看出，DataFrame 有 5 列和 9，568 条记录。您可以看到所有列都包含数字数据，并且这些列有以下名称:`AT`、`V`、`AP`、`RH`和`PE`。

5.  将特征提取到名为`X` :

    ```py
    X = _df.drop(['PE'], axis=1).values
    ```

    的列中
6.  将标签提取到名为`y` :

    ```py
    y = _df['PE'].values
    ```

    的列中
7.  将数据分成训练集和评估集:

    ```py
    train_X, eval_X, train_y, eval_y = train_test_split(X, y, train_size=0.8, random_state=0)
    ```

8.  创建一个`LinearRegression`模型的实例:

    ```py
    lr_model_1 = LinearRegression()
    ```

9.  Fit the model on the training data:

    ```py
    lr_model_1.fit(train_X, train_y)
    ```

    此步骤的输出应该类似于以下内容:

    ![Figure 7.45: Fitting the model on training data
    ](image/B15019_07_45.jpg)

    图 7.45:根据训练数据拟合模型

10.  使用模型对评估数据集进行预测:

    ```py
    lr_model_1_preds = lr_model_1.predict(eval_X)
    ```

11.  Print out the `R2` score of the model:

    ```py
    print('lr_model_1 R2 Score: {}'.format(lr_model_1.score(eval_X, eval_y)))
    ```

    此步骤的输出应该类似于以下内容:

    ![Figure 7.46: Printing the R2 score
    ](image/B15019_07_46.jpg)

    图 7.46:打印 R2 分数

    你会注意到这个模型的`R2`分数是`0.926`。您将利用这个数字与您培训的下一个模型进行比较。请记住，这是一个评估指标。

12.  Print out the Mean Squared Error (MSE) of this model:

    ```py
    print('lr_model_1 MSE: {}'.format(mean_squared_error(eval_y, lr_model_1_preds)))
    ```

    此步骤的输出应该类似于以下内容:

    ![Figure 7.47: Printing the MSE
    ](image/B15019_07_47.jpg)

    图 7.47:打印 MSE

    你会注意到 MSE 是`21.675`。这是一个评估指标，您将使用它将此模型与后续模型进行比较。

    第一个模型在四个特征上被训练。现在，您将在四个立方体要素上训练一个新模型。

13.  Create a list of tuples to serve as a pipeline:

    ```py
    steps = [
        ('scaler', MinMaxScaler()),
        ('poly', PolynomialFeatures(degree=3)),
        ('lr', LinearRegression())
    ]
    ```

    在这一步中，您将创建一个包含三个元组的列表。第一个元组表示利用`MinMaxScaler`的缩放操作。第二个元组代表一个特征工程步骤，并利用了`PolynomialFeatures`。第三个元组表示一个`LinearRegression`模型。

    元组的第一个元素表示步骤的名称，而第二个元素表示执行转换或估计器的类。

14.  创建管道实例:

    ```py
    lr_model_2 = Pipeline(steps)
    ```

15.  Train the instance of the pipeline:

    ```py
    lr_model_2.fit(train_X, train_y)
    ```

    管道实现了一个`.fit()`方法，该方法也在转换器和估计器的所有实例中实现。`.fit()`方法导致`.fit_transform()`在变压器上被调用，导致`.fit()`在估算器上被调用。此步骤的输出类似于以下内容:

    ![Figure 7.48: Training the instance of the pipeline
    ](image/B15019_07_48.jpg)

    图 7.48:训练管道实例

    您可以从输出中看到一个管道被训练。你可以看到步骤是由`MinMaxScaler`和`PolynomialFeatures`组成的，最后一步是由`LinearRegression`组成的。

16.  Print out the `R2` score of the model:

    ```py
    print('lr_model_2 R2 Score: {}'.format(lr_model_2.score(eval_X, eval_y)))
    ```

    输出类似于以下内容:

    ![Figure 7.49: The R2 score of the model
    ](image/B15019_07_49.jpg)

    图 7.49:模型的 R2 分数

    从前面可以看出，`R2`的分数是`0.937`，比第一款车型的`R2`分数`0.926`要好。您可以开始观察到指标表明这个模型比第一个模型更好。

17.  使用模型对评估数据进行预测:

    ```py
    lr_model_2_preds = lr_model_2.predict(eval_X)
    ```

18.  Print the MSE of the second model:

    ```py
    print('lr_model_2 MSE: {}'.format(mean_squared_error(eval_y, lr_model_2_preds)))
    ```

    输出类似于以下内容:

    ![Figure 7.50: The MSE of the second model
    ](image/B15019_07_50.jpg)

    图 7.50:第二个模型的 MSE

    从输出可以看到，第二个模型的 MSE 是`18.503`。这小于第一个模型的 MSE，也就是`21.675`。你可以有把握地断定第二种型号比第一种好。

19.  Inspect the model coefficients (also called weights):

    ```py
    print(lr_model_2[-1].coef_)
    ```

    在这一步，你会注意到`lr_model_2`是一个管道。这个管道中的最后一个对象是模型，所以通过将列表元素的索引设置为`-1`，可以利用列表寻址来访问它。

    一旦有了模型，也就是管道中的最后一个元素，就可以利用`.coef_`来获得模型系数。输出类似于以下内容:

    ![Figure 7.51: Print the model coefficients
    ](image/B15019_07_51.jpg)

    图 7.51:打印模型系数

    您将从前面的输出中注意到，大多数值都是十进制的，有些值是数百进制的，还有一个值的大小非常小。

20.  Check for the number of coefficients in this model:

    ```py
    print(len(lr_model_2[-1].coef_))
    ```

    此步骤的输出类似于以下内容:

    ```py
    35
    ```

    从前面的截图可以看出，第二个模型有`35`系数。

21.  用`10`的`PolynomialFeatures`:

    ```py
    steps = [
        ('scaler', MinMaxScaler()),
        ('poly', PolynomialFeatures(degree=10)),
        ('lr', LinearRegression())
    ]
    ```

    创建一个`steps`列表
22.  根据前面的步骤创建第三个模型:

    ```py
    lr_model_3 = Pipeline(steps)
    ```

23.  Fit the third model on the training data:

    ```py
    lr_model_3.fit(train_X, train_y)
    ```

    此步骤的输出类似于以下内容:

    ![Figure 7.52: Fitting the third model on the data
    ](image/B15019_07_52.jpg)

    图 7.52:根据数据拟合第三个模型

    从输出中可以看到，管道利用了度为`10`的`PolynomialFeatures`。你这样做是希望得到更好的模式。

24.  Print out the `R2` score of this model:

    ```py
    print('lr_model_3 R2 Score: {}'.format(lr_model_3.score(eval_X, eval_y)))
    ```

    此模型的输出类似于以下内容:

    ![Figure 7.53: R2 score of the model
    ](image/B15019_07_53.jpg)

    图 7.53:模型的 R2 分数

    从上图可以看出，R2 的分数现在是`-0.29`。之前的型号有一个`0.937`的`R2`分数。该型号的 R2 分数比先前型号`lr_model_2`的分数差得多。当您的模型过度拟合时会发生这种情况。

25.  使用`lr_model_3`对评估数据进行预测:

    ```py
    lr_model_3_preds = lr_model_3.predict(eval_X)
    ```

26.  Print out the MSE for `lr_model_3`:

    ```py
    print('lr_model_3 MSE: {}'.format(mean_squared_error(eval_y, lr_model_3_preds)))
    ```

    此步骤的输出可能类似于以下内容:

    ![Figure 7.54: The MSE of the model
    ](image/B15019_07_54.jpg)

    图 7.54:模型的均方误差

    从上图中可以看出，MSE 也相当糟糕。与之前型号的`18.503`相比，MSE 为`378.756`。

27.  Print out the number of coefficients (also called weights) in this model:

    ```py
    print(len(lr_model_3[-1].coef_))
    ```

    输出可能如下所示:

    ![Figure 7.55: Printing the number of coefficients
    ](image/B15019_07_55.jpg)

    图 7.55:打印系数的数量

    你可以看到这个模型有 1001 个系数。

28.  Inspect the first 35 coefficients to get a sense of the individual magnitudes:

    ```py
    print(lr_model_3[-1].coef_[:35])
    ```

    输出可能类似于以下内容:

    ![Figure 7.56: Inspecting the first 35 coefficients
    ](image/B15019_07_56.jpg)

    图 7.56:检查前 35 个系数

    您可以从输出中看到，系数的幅度明显大于`lr_model_2`中的系数。

    在接下来的步骤中，您将对同一组要素训练套索回归模型以减少过度拟合。

29.  Create a list of steps for the pipeline you will create later on:

    ```py
    steps = [
        ('scaler', MinMaxScaler()),
        ('poly', PolynomialFeatures(degree=10)),
        ('lr', Lasso(alpha=0.01))
    ]
    ```

    为将要创建的管线创建一个步骤列表。请注意，此列表中的第三步是 lasso 的实例。在对`Lasso()`的调用中被称为`alpha`的参数是正则化参数。您可以使用 0 到 1 之间的任何值，查看它如何影响您训练的模型的性能。

30.  创建管道实例:

    ```py
    lasso_model = Pipeline(steps)
    ```

31.  Fit the pipeline on the training data:

    ```py
    lasso_model.fit(train_X, train_y)
    ```

    此操作的输出可能类似于以下内容:

    ![Figure 7.57: Fitting the pipeline on the training data
    ](image/B15019_07_57.jpg)

    图 7.57:根据训练数据拟合管道

    从输出中可以看到，管道在最后一步训练了一个套索模型。正则化参数为`0.01`，模型最多训练 1000 次迭代。

32.  Print the `R2` score of `lasso_model`:

    ```py
    print('lasso_model R2 Score: {}'.format(lasso_model.score(eval_X, eval_y)))
    ```

    此步骤的输出可能类似于以下内容:

    ![Figure 7.58: R2 score
    ](image/B15019_07_58.jpg)

    图 7.58: R2 得分

    你可以看到`R2`的分数已经回升到了`0.934`，比`lr_model_3`的`-0.291`分数好了很多。这已经看起来像一个更好的模型。

33.  使用`lasso_model`对评估数据进行预测:

    ```py
    lasso_preds = lasso_model.predict(eval_X)
    ```

34.  Print the MSE of `lasso_model`:

    ```py
    print('lasso_model MSE: {}'.format(mean_squared_error(eval_y, lasso_preds)))
    ```

    输出可能类似于以下内容:

    ![Figure 7.59: MSE of lasso model
    ](image/B15019_07_59.jpg)

    图 7.59:套索模型的均方误差

    从输出中可以看到，MSE 是`19.279`，比`lr_model_3`的 MSE 值`378.756`低很多。你可以有把握地断定这是一个好得多的模型。

35.  Print out the number of coefficients in `lasso_model`:

    ```py
    print(len(lasso_model[-1].coef_))
    ```

    输出可能类似于以下内容:

    ```py
    1001
    ```

    您可以看到这个模型有 1001 个系数，这与`lr_model_3`的系数数量相同。

36.  Print out the values of the first 35 coefficients:

    ```py
    print(lasso_model[-1].coef_[:35])
    ```

    输出可能类似于以下内容:

![Figure 7.60: Printing the values of 35 coefficients
](image/B15019_07_60.jpg)

图 7.60:打印 35 个系数的值

从前面的输出可以看出，一些系数被设置为`0`。这将忽略输入中相应的数据列。您还可以看到，其余系数的幅度小于 100。这表明模型不再过度拟合。

这个练习教你如何通过使用`LassoRegression`训练一个新模型来修复过度拟合。

在下一节中，您将了解如何使用岭回归来解决模型中的过度拟合问题。

# 岭回归

您刚刚学习了 lasso 回归，它引入了一种惩罚并试图从数据中消除某些要素。岭回归采用另一种方法，引入惩罚大权重的惩罚。因此，优化过程试图降低系数的幅度，而不是完全消除它们。

## 练习 7.10:使用岭回归修正模型过度拟合

本练习的目标是教您如何识别模型何时开始过度拟合，并使用岭回归来修复模型中的过度拟合。

注意

您将使用与*练习 7.09* 中相同的数据集

以下步骤将帮助您完成练习:

1.  打开 Colab 笔记本。
2.  导入所需的库:

    ```py
    import pandas as pd
    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import LinearRegression, Ridge
    from sklearn.metrics import mean_squared_error
    from sklearn.pipeline import Pipeline
    from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures
    ```

3.  读入数据:

    ```py
    _df = pd.read_csv('https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter07/Dataset/ccpp.csv')
    ```

4.  Inspect the DataFrame:

    ```py
    _df.info()
    ```

    `.info()`方法打印出数据帧的摘要，包括列名和记录数。输出可能类似于以下内容:

    ![Figure 7.61: Inspecting the dataframe
    ](image/B15019_07_61.jpg)

    图 7.61:检查数据帧

    从上图中可以看出，DataFrame 有 5 列和 9，568 条记录。您可以看到所有的列都包含数字数据，并且这些列的名称是:`AT`、`V`、`AP`、`RH`和`PE`。

5.  将特征提取到名为`X` :

    ```py
    X = _df.drop(['PE'], axis=1).values
    ```

    的列中
6.  将标签提取到名为`y` :

    ```py
    y = _df['PE'].values
    ```

    的列中
7.  将数据分成训练集和评估集:

    ```py
    train_X, eval_X, train_y, eval_y = train_test_split(X, y, train_size=0.8, random_state=0)
    ```

8.  创建一个`LinearRegression`模型的实例:

    ```py
    lr_model_1 = LinearRegression()
    ```

9.  Fit the model on the training data:

    ```py
    lr_model_1.fit(train_X, train_y)
    ```

    此步骤的输出应该类似于以下内容:

    ![Figure 7.62: Fitting the model on data
    ](image/B15019_07_62.jpg)

    图 7.62:根据数据拟合模型

10.  使用模型对评估数据集进行预测:

    ```py
    lr_model_1_preds = lr_model_1.predict(eval_X)
    ```

11.  Print out the `R2` score of the model:

    ```py
    print('lr_model_1 R2 Score: {}'.format(lr_model_1.score(eval_X, eval_y)))
    ```

    此步骤的输出应该类似于以下内容:

    ![Figure 7.63: R2 score
    ](image/B15019_07_63.jpg)

    图 7.63: R2 得分

    你会注意到这个模型的 R2 分数是`0.933`。您将利用这个数字与您训练的下一个模型进行比较。请记住，这是一个评估指标。

12.  Print out the MSE of this model:

    ```py
    print('lr_model_1 MSE: {}'.format(mean_squared_error(eval_y, lr_model_1_preds)))
    ```

    此步骤的输出应该类似于以下内容:

    ![Figure 7.64: The MSE of the model
    ](image/B15019_07_64.jpg)

    图 7.64:模型的均方误差

    你会注意到 MSE 是`19.734`。这是一个评估指标，您将使用它将此模型与后续模型进行比较。

    第一个模型在四个特征上被训练。现在，您将在四个立方体要素上训练一个新模型。

13.  Create a list of tuples to serve as a pipeline:

    ```py
    steps = [
        ('scaler', MinMaxScaler()),
        ('poly', PolynomialFeatures(degree=3)),
        ('lr', LinearRegression())
    ]
    ```

    在这一步中，您将创建一个包含三个元组的列表。第一个元组表示利用`MinMaxScaler`的缩放操作。第二个元组代表一个特征工程步骤，并利用了`PolynomialFeatures`。第三个元组表示一个`LinearRegression`模型。

    元组的第一个元素表示步骤的名称，而第二个元素表示执行转换或估计的类。

14.  创建管道实例:

    ```py
    lr_model_2 = Pipeline(steps)
    ```

15.  Train the instance of the pipeline:

    ```py
    lr_model_2.fit(train_X, train_y)
    ```

    管道实现了一个`.fit()`方法，该方法也在转换器和估计器的所有实例中实现。`.fit()`方法导致`.fit_transform()`在变压器上被调用，导致`.fit()`在估算器上被调用。此步骤的输出类似于以下内容:

    ![Figure 7.65: Training the instance of a pipeline
    ](image/B15019_07_65.jpg)

    图 7.65:训练管道实例

    您可以从输出中看到一个管道被训练。你可以看到步骤是由`MinMaxScaler`和`PolynomialFeatures`组成的，最后一步是由`LinearRegression`组成的。

16.  Print out the `R2` score of the model:

    ```py
    print('lr_model_2 R2 Score: {}'.format(lr_model_2.score(eval_X, eval_y)))
    ```

    输出类似于以下内容:

    ![Figure 7.66: R2 score
    ](image/B15019_07_66.jpg)

    图 7.66: R2 得分

    从前面可以看出，R2 得分为`0.944`，比第一款车型的 R2 得分`0.933`要好。您可以开始观察到指标表明这个模型比第一个模型更好。

17.  使用模型对评估数据进行预测:

    ```py
    lr_model_2_preds = lr_model_2.predict(eval_X)
    ```

18.  Print the MSE of the second model:

    ```py
    print('lr_model_2 MSE: {}'.format(mean_squared_error(eval_y, lr_model_2_preds)))
    ```

    输出类似于以下内容:

    ![Figure 7.67: The MSE of the model
    ](image/B15019_07_67.jpg)

    图 7.67:模型的均方误差

    从输出可以看到，第二个模型的 MSE 是`16.272`。这小于第一个模型的 MSE，也就是`19.734`。你可以有把握地断定第二种型号比第一种好。

19.  Inspect the model coefficients (also called weights):

    ```py
    print(lr_model_2[-1].coef_)
    ```

    在这一步，你会注意到`lr_model_2`是一个管道。这个管道中的最后一个对象是模型，所以通过将列表元素的索引设置为`-1`，可以利用列表寻址来访问它。

    一旦有了模型，也就是管道中的最后一个元素，就可以利用`.coef_`来获得模型系数。输出类似于以下内容:

    ![Figure 7.68: Printing model coefficients
    ](image/B15019_07_68.jpg)

    图 7.68:打印模型系数

    您将从前面的输出中注意到，大多数值都是十进制的，有些值是数百进制的，还有一个值的大小非常小。

20.  Check the number of coefficients in this model:

    ```py
    print(len(lr_model_2[-1].coef_))
    ```

    此步骤的输出类似于以下内容:

    ![Figure 7.69: Checking the number of coefficients
    ](image/B15019_07_69.jpg)

    图 7.69:检查系数的数量

    从前面可以看出，第二个模型有 35 个系数。

21.  用`10`的`PolynomialFeatures`:

    ```py
    steps = [
        ('scaler', MinMaxScaler()),
        ('poly', PolynomialFeatures(degree=10)),
        ('lr', LinearRegression())
    ]
    ```

    创建一个`steps`列表
22.  根据前面的步骤创建第三个模型:

    ```py
    lr_model_3 = Pipeline(steps)
    ```

23.  Fit the third model on the training data:

    ```py
    lr_model_3.fit(train_X, train_y)
    ```

    此步骤的输出类似于以下内容:

    ![Figure 7.70: Fitting lr_model_3 on the training data
    ](image/B15019_07_70.jpg)

    图 7.70:根据训练数据拟合 lr_model_3

    从输出中可以看到，管道利用了度为`10`的`PolynomialFeatures`。你这样做是希望得到更好的模式。

24.  Print out the `R2` score of this model:

    ```py
    print('lr_model_3 R2 Score: {}'.format(lr_model_3.score(eval_X, eval_y)))
    ```

    此模型的输出类似于以下内容:

    ![Figure 7.71: R2 score
    ](image/B15019_07_71.jpg)

    图 7.71: R2 分数

    从上图中可以看出，`R2`的分数现在是`0.568`，之前的型号的`R2`分数是`0.944`。这款车型的`R2`评分比之前的`lr_model_2`差。当您的模型过度拟合时会发生这种情况。

25.  使用`lr_model_3`对评估数据进行预测:

    ```py
    lr_model_3_preds = lr_model_3.predict(eval_X)
    ```

26.  Print out the MSE for `lr_model_3`:

    ```py
    print('lr_model_3 MSE: {}'.format(mean_squared_error(eval_y, lr_model_3_preds)))
    ```

    此步骤的输出可能类似于以下内容:

    ![Figure 7.72: The MSE of lr_model_3
    ](image/B15019_07_72.jpg)

    图 7.72:lr _ model _ 3 的均方误差

    从上图可以看出，MSE 也更差。与之前型号的`16.271`相比，MSE 为`126.254`。

27.  Print out the number of coefficients (also called weights) in this model:

    ```py
    print(len(lr_model_3[-1].coef_))
    ```

    输出可能如下所示:

    ```py
    1001
    ```

    可以看到模型有`1,001`个系数。

28.  Inspect the first `35` coefficients to get a sense of the individual magnitudes:

    ```py
    print(lr_model_3[-1].coef_[:35])
    ```

    输出可能类似于以下内容:

    ![Figure 7.73: Inspecting 35 coefficients
    ](image/B15019_07_73.jpg)

    图 7.73:检查 35 个系数

    您可以从输出中看到，系数的幅度明显大于`lr_model_2`中的系数。

    在接下来的步骤中，您将对同一组要素训练岭回归模型以减少过度拟合。

29.  Create a list of steps for the pipeline you will create later on:

    ```py
    steps = [
        ('scaler', MinMaxScaler()),
        ('poly', PolynomialFeatures(degree=10)),
        ('lr', Ridge(alpha=0.9))
    ]
    ```

    为将要创建的管线创建一个步骤列表。注意，这个列表中的第三步是`Ridge`的一个实例。在对`Ridge()`的调用中被称为`alpha`的参数是正则化参数。您可以使用 0 到 1 之间的任何值，查看它如何影响您训练的模型的性能。

30.  创建管道实例:

    ```py
    ridge_model = Pipeline(steps)
    ```

31.  Fit the pipeline on the training data:

    ```py
    ridge_model.fit(train_X, train_y)
    ```

    此操作的输出可能类似于以下内容:

    ![Figure 7.74: Fitting the pipeline on training data
    ](image/B15019_07_74.jpg)

    图 7.74:根据训练数据拟合管道

    从输出中可以看到，管道在最后一步中训练了一个山脊模型。正则化参数为`0`。

32.  Print the R2 score of `ridge_model`:

    ```py
    print('ridge_model R2 Score: {}'.format(ridge_model.score(eval_X, eval_y)))
    ```

    此步骤的输出可能类似于以下内容:

    ![Figure 7.75: R2 score
    ](image/B15019_07_75.jpg)

    图 7.75: R2 分数

    你可以看到 R2 的分数已经回升到了`0.945`，这比`lr_model_3`的`0.568`分数要好得多。这已经看起来像一个更好的模型。

33.  使用`ridge_model`对评估数据进行预测:

    ```py
    ridge_model_preds = ridge_model.predict(eval_X)
    ```

34.  Print the MSE of `ridge_model`:

    ```py
    print('ridge_model MSE: {}'.format(mean_squared_error(eval_y, ridge_model_preds)))
    ```

    输出可能类似于以下内容:

    ![Figure 7.76: The MSE of ridge_model
    ](image/B15019_07_76.jpg)

    图 7.76:岭模型的均方误差

    从输出中可以看到，MSE 为`16.030`，低于`lr_model_3`的 MSE 值`126.254`。你可以有把握地断定这是一个好得多的模型。

35.  Print out the number of coefficients in `ridge_model`:

    ```py
    print(len(ridge_model[-1].coef_))
    ```

    输出可能类似于以下内容:

    ![Figure 7.77: The number of coefficients in the ridge model
    ](image/B15019_07_77.jpg)

    图 7.77:岭模型中系数的数量

    您可以看到这个模型有`1001`个系数，这与`lr_model_3`的系数数量相同。

36.  Print out the values of the first 35 coefficients:

    ```py
    print(ridge_model[-1].coef_[:35])
    ```

    输出可能类似于以下内容:

![Figure 7.78: The values of the first 35 coefficients
](image/B15019_07_78.jpg)

图 7.78:前 35 个系数的值

从前面的输出中可以看出，系数值不再有很大的幅度。许多系数的大小都小于 10，没有一个超过 100。这表明模型不再过度拟合。

这个练习教你如何通过使用`RidgeRegression`训练一个新模型来修复过度拟合。

## 活动 7.01:找到一个预测超导体临界温度的最佳模型

你是一家电缆制造商的数据科学家。管理层决定开始向世界各地的客户运送低电阻电缆。为了确保将正确的电缆运送到正确的国家，他们希望根据某些观察到的读数来预测各种电缆的临界温度。

在本活动中，您将训练一个线性回归模型，并计算 R2 分数和 MSE。您将继续使用 3 次多项式要素设计新要素。将这个新模型的 R2 分数和 MSE 与第一个模型进行比较，以确定过度拟合。然后，您将使用正则化来训练一个模型，该模型将对以前未见过的数据进行归纳。

注意

您将在这里找到活动所需的数据集:[https://packt.live/2tJFVqu](https://packt.live/2tJFVqu)。

原始数据集可以在这里找到:[https://packt.live/3ay3aoe](https://packt.live/3ay3aoe)。

引用:

Hamidieh，Kam，预测超导体临界温度的数据驱动统计模型，计算材料科学，第 154 卷，2018 年 11 月，第 346-354 页。

完成这项任务的步骤是:

1.  打开 Colab 笔记本。
2.  加载必要的库。
3.  从`superconduct`文件夹中读入数据。
4.  准备`X`和`y`变量。
5.  将数据分成训练集和评估集。
6.  创建基线线性回归模型。
7.  打印出模型的 R2 分数和均方差。
8.  创建管道以设计多项式要素并训练线性回归模型。
9.  打印出 R2 分数和均方差。
10.  确定这个新模型是过度拟合的。
11.  创建管线以设计多项式特征并训练山脊或套索模型。
12.  Print out the R2 score and MSE.

    输出如下所示:

    ![Figure 7.79: The R2 score and MSE of the ridge model
    ](image/B15019_07_79.jpg)

    图 7.79:岭模型的 R2 分数和均方误差

13.  Determine that this model is no longer overfitting. This is the model to put into production.

    岭模型的系数如下图所示:

![Figure 7.80: The coefficients for the ridge model
](image/B15019_07_80.jpg)

图 7.80:山脊模型的系数

注意

这个活动的解决方案可以在以下地址找到:[https://packt.live/2GbJloz](https://packt.live/2GbJloz)。

# 总结

在这一章中，我们研究了保留一些可用数据来评估模型的重要性。我们还学习了如何使用一种叫做交叉验证的技术来利用所有可用的数据，以便从您正在训练的一组模型中找到性能最佳的模型。我们还利用评估指标来确定模型何时开始过度拟合，并利用岭和套索回归来修复过度拟合的模型。

在下一章，我们将深入探讨超参数调优。您将了解到寻找最佳超参数来训练模型的各种技术。