<title>Chapter 4. Data Visualization</title><link href="epub.css" rel="stylesheet" type="text/css"> 

# 第四章。数据可视化

在本章中，我们将介绍以下配方:

*   使用 Zeppelin 可视化
*   使用散景缩放创建散点图
*   用散景标量创建时间序列多点图

# 简介

老实说，与其他成熟的数据分析语言(如 R 或 Python)相比，Scala 中的免费/开源数据可视化工具并不丰富。我们可能会将这部分归因于 Java 中缺乏丰富的图表框架，而可视化从来都不是大数据分析的强项。

也就是说，Scala(或者更具体地说是 Hadoop 世界，包括 Spark)正在赶上 Apache 孵化器 project Zeppelin 和高度活跃的 Scala 绑定([https://github.com/bokeh/bokeh-scala](https://github.com/bokeh/bokeh-scala))用于 Bokeh 项目([http://bokeh.pydata.org/en/latest/](http://bokeh.pydata.org/en/latest/))。随着 R 成为 Spark 中的一等公民——从 1.4 版本开始，Spark 数据帧开始可用——Spark 从 R 获得了除现有 Python APIs 之外的额外可视化。

顺便提一下，所有现有的 Java 库都可以从 Scala 中访问。因此，我们可以自由地从 Java 借用任何可视化库。

<title>Visualizing using Zeppelin</title><link href="epub.css" rel="stylesheet" type="text/css"> 

# 使用齐柏林飞艇进行可视化

Apache Zeppelin 是一个漂亮的基于网络的工具，帮助我们可视化和探索大型数据集。从技术角度来看，Apache Zeppelin 是一个强大的 web 应用程序。我们的目标是使用这个应用程序来呈现一些简洁的、交互式的、可共享的图形和图表。

Zeppelin 有趣的部分是它有一堆内置的解释器——可以解释和调用 Spark(用一个`SparkContext`)和 Spark SQL(用一个`SQLContext`)中的所有 API 函数。其他内置的解释器是针对 Hive、Flink、Markdown 和 Scala 的。它还能够通过 Thrift 运行远程解释器(在 Zeppelin 自己的 JVM 之外)。要查看内置解释器的列表，可以通过`zeppelin`安装目录中的`conf/interpreter.json`。或者，一旦启动了`zeppelin`守护进程，您可以从`http://localhost:8080/#/interpreter`查看和定制解释器。

## 怎么做...

在这个菜谱中，我们将使用 Zeppelin 内部的内置`SparkContext`和`SQLContext`并使用 Spark 转换数据。最后，我们将把转换后的数据注册为一个表，并使用 Spark SQL 查询数据并将其可视化。

本节中的子副本列表如下:

*   安装齐柏林飞艇
*   定制 Zeppelin 的服务器和 websocket 端口
*   可视化 HDFS 数据–参数化输入
*   在可视化过程中使用自定义函数
*   向 Zeppelin 添加外部依赖项
*   指向一个外部火花簇

### 安装齐柏林飞艇

齐柏林飞艇([http://zeppelin-project.org/](http://zeppelin-project.org/))还没有的二进制包。然而，正如其项目网站声称的那样，从源代码开始构建非常容易。我们只需要运行一个命令就可以在本地机器上安装它。在本食谱的最后，我们将看看如何将我们的齐柏林飞艇指向外部火花主控器:

```

git clone https://github.com/apache/incubator-zeppelin.git

cd incubator-zeppelin

mvn clean package -Pspark-1.4 -Dhadoop.version=2.2.0 -Phadoop-2.2 -DskipTests

```

![Installing Zeppelin](graphics/B03812_04_01.jpg)

构建完成后，我们可以使用以下命令启动 Zeppelin 守护进程:

```

bin/zeppelin-daemon.sh start

```

![Installing Zeppelin](graphics/B03812_04_02.jpg)

要停止守护进程，我们可以使用以下命令:

```

bin/zeppelin-daemon.sh stop

```

### 注意

如果你遇到以下错误，你可以用`rat.txt`检查，却发现它抱怨你的数据文件:

**无法执行 goal org . Apache . rat:Apache-rat-plugin:0.11:检查(verify . rat)zeppelin 项目:太多文件带有未批准的许可证:3**

只需将数据文件移动到不同的位置，然后再次启动构建。

### 定制 Zeppelin 的服务器和 websocket 端口

Zeppelin 默认运行在端口 `8080`上，默认在端口+1(`8081`)上启用 websocket 端口。如果需要，我们可以通过将`conf/zeppelin-site.xml.template`复制到`conf/zeppelin-site.xml`并更改端口和其他各种属性来定制端口。由于 Spark standalone cluster master web UI 也在`8080`上运行，当我们在 Spark master 的同一台机器上运行 Zeppelin 时，我们必须更改端口以避免冲突。

![Customizing Zeppelin's server and websocket port](graphics/B03812_04_03.jpg)

1.  现在，让我们将端口改为`8180`。为了让它生效，让我们使用`bin/zeppelin-daemon restart`重启 Zeppelin

### 可视化 HDFS 数据–参数化输入

一旦我们启动守护进程，我们可以将浏览器指向`http://localhost:8080`(根据您修改的端口配置更改端口)来查看 Zeppelin UI。Zeppelin 将其内容组织为笔记和段落。注释只是一个网页上所有段落的列表。

使用来自 HDFS 的数据仅仅意味着我们指向 HDFS 位置，而不是本地文件系统位置。

在我们使用来自 HDFS 的文件之前，让我们快速检查一下 Zeppelin 使用的 Spark 版本。这可以通过在一个段落上发出`sc.version`来实现。`sc`是一个隐式变量，代表 Zeppelin 内部的`SparkContext`，这仅仅意味着我们不需要通过编程在 Zeppelin 内部创建一个`SparkContext`。

![Visualizing data on HDFS – parameterizing inputs](graphics/B03812_04_04.jpg)

接下来，让我们加载`profiles.json`示例数据文件，将其转换成 DataFrame，并打印模式和前 20 行(show)以供验证。最后，让我们将数据帧注册为一个表。就像`SparkContext`的隐式变量一样，`SQLContext`由 Zeppelin 内部的`sqlc`隐式变量表示:

```

val profilesJsonRdd = sqlc.jsonFile("hdfs://localhost:9000/data/scalada/profiles.json")

val profileDF=profilesJsonRdd.toDF()

profileDF.printSchema()

profileDF.show()

profileDF.registerTempTable("profiles")

```

![Visualizing data on HDFS – parameterizing inputs](graphics/B03812_04_05.jpg)

输出看起来像这样:

![Visualizing data on HDFS – parameterizing inputs](graphics/B03812_04_06.jpg)

### 注意

注意不要让显式创建`SQLContext`或`SparkContext`。如果我们显式地创建一个`SQLContext`，并向其注册我们的临时表，那么我们执行的 SQL 查询将无法访问它。我们会得到这个错误:

**没有这样的表列表(【您的临时表名称】)**

现在，让我们运行一个简单的查询来了解眼睛的颜色以及在数据集中男性的数量:

```

 %sql select eyeColor, count(eyeColor) as count from profiles where gender='male' group by eyeColor

```

段落开头的`%sql`向 Zeppelin 表明，我们将在该段落中执行 Spark SQL 查询。

![Visualizing data on HDFS – parameterizing inputs](graphics/B03812_04_07.jpg)

现在，如果我们希望与他人分享此图表或将其链接到外部网站，我们可以通过单击此段落中的齿轮图标，然后单击**链接此段落**，如以下截图所示:

![Visualizing data on HDFS – parameterizing inputs](graphics/B03812_04_08.jpg)

我们实际上可以为性别参数化输入，而不是每次都改变我们的查询。这是通过使用`${PARAMETER PLACEHOLDER}`实现的:

```

%sql select eyeColor, count(eyeColor) as count from profiles where gender="${gender}" group by eyeColor

```

![Visualizing data on HDFS – parameterizing inputs](graphics/B03812_04_09.jpg)

最后，如果使用自由格式的文本进行参数化还不够，我们可以使用下拉菜单:

```

%sql select eyeColor, count(eyeColor) as count from profiles where gender="${gender=male,male|female}" group by eyeColor

```

![Visualizing data on HDFS – parameterizing inputs](graphics/B03812_04_10.jpg)

### 运行自定义功能

虽然 Spark SQL 不像 ANSI SQL 那样支持广泛的函数，但它有一个简单而强大的机制来注册一个普通的 Scala 函数，并在 SQL 上下文中使用它。

比方说，我们想找出每个年龄组下有多少个人资料。我们有一个简单的函数叫做`ageGroup`。给定一个年龄，它返回一个表示年龄组的字符串:

```

def ageGroup(age: Long) = {

 val buckets = Array("0-10", "11-20", "20-30", "31-40", "41-50", "51-60", "61-70", "71-80", "81-90", "91-100", ">100")

 buckets(math.min((age.toInt - 1) / 10, buckets.length - 1))

 }

```

现在，为了注册这个函数以便在 Spark SQL 中使用，我们需要做的就是给它一个名称，并调用 SQLContext 的用户定义函数对象的 register 方法:

```

 sqlc.udf.register("ageGroup", (age:Long)=>ageGroup(age.toInt))

```

让我们启动我们的查询，看看该函数的实际使用情况:

```

%sql select ageGroup(age) as group,

 count(1) as total

from profiles

where gender='${gender=male,male|female}' group by ageGroup(age)

order by group

```

以下是输出:

![Running custom functions](graphics/B03812_04_11.jpg)

### 向 Zeppelin 添加外部依赖项

迟早，我们会依赖外部库，而不是 Zeppelin 附带的库，比如高效的 CSV 导入或 RDBMS 数据导入。让我们看看如何加载 MySQL 数据库驱动程序并可视化表中的数据。

为了加载一个`mysql`连接器`java`驱动程序，我们只需要指定组 ID、工件 ID 和版本号，然后从`maven`仓库下载 JAR。`%dep`表示段落添加了依赖关系，`z`隐式变量代表 Zeppelin 上下文:

```

%dep

z.load("mysql:mysql-connector-java:5.1.35")

```

如果我们想指向我们的 enterprise Maven 存储库或其他自定义存储库，我们可以通过调用 Zeppelin 上下文的`addRepo`方法来添加它们，该方法可通过同一个`z`隐式变量获得:

```

%dep

z.addRepo("RepoName").url("RepoURL")

```

或者，我们可以使用重载的`load`方法从本地文件系统加载`jar`:

```

%dep

z.load("/path/to.jar")

```

在使用`%dep`时，我们唯一需要注意的是，在使用正在加载的库之前，应该使用依赖段。所以，一般建议在笔记本顶部加载依赖项。

让我们看看它的实际用途:

*   Loading the dependency:![Adding external dependencies to Zeppelin](graphics/B03812_04_12.jpg)

    加载完依赖项后，我们需要构建连接 MySQL 数据库所需的选项:

    ```

    val props = scala.collection.mutable.Map[String,String]();

     props+=("driver" -> "com.mysql.jdbc.Driver")

     props+=("url" -> "jdbc:mysql://localhost/scalada?user=root&password=orange123")

     props+=("dbtable" -> "(select id, name, phone, email, gender from scalada.student) as students")

     props+=("partitionColumn" -> "id")

     props+=("lowerBound" -> "0")

     props+=("upperBound" -> "100")

     props+=("numPartitions" -> "2")

    ```

*   使用连接创建一个数据帧:![Adding external dependencies to Zeppelin](graphics/B03812_04_13.jpg)

    ```

    import scala.collection.JavaConverters._

     val studentDf = sqlContext.load("jdbc", props.asJava)

     studentDf.printSchema()

     studentDf.show()

     studentDf.registerTempTable("students")

    ```

*   可视化数据:![Adding external dependencies to Zeppelin](graphics/B03812_04_14.jpg)

### 指向外部火花簇

运行带有内置 Spark 的 Zeppelin 是很好的，但是在大多数情况下，我们将在一个集群上执行由 Zeppelin 发起的 Spark 作业。实现这一点非常简单；我们需要配置 Zeppelin 将其 Spark `master`属性指向一个外部 Spark 主 URL。我们将在后面的章节([第 6 章](ch20.html "Chapter 6. Scaling Up")、*纵向扩展*)中，研究如何在 AWS 上安装和运行 Spark 集群，或者真正的分布式集群，但是对于这个例子，我在本地机器上运行了一个简单独立的外部 Spark 集群。请注意，我们将不得不在不同的端口上运行 Zeppelin，因为 Zeppelin UI 端口与 Spark standalone cluster master web UI 通过`8080`发生冲突:

对于这个例子，让我们为 1.4.1 下载 Spark 源代码，并为 Hadoop 版本 2.2 构建它:

```

build/mvn -Pyarn -Phadoop-2.2 -Dhadoop.version=2.2.0 -DskipTests clean package

```

同样，让我们下载`zeppelin`孵化器并构建它，指定 Hadoop 版本为 2.2:

```

mvn clean install -Pspark-1.4 -Dhadoop.version=2.2.0 -Phadoop-2.2 -DskipTests -Pyarn

```

让我们调出火花簇。从你的火花源内部，执行这个:

```

sbin/start-all.sh

```

最后，让我们修改`conf/interpreter.json`和`conf/zeppelin-env.sh`，将`master`属性指向运行 Spark VM 的主机。在这种情况下，它将是我的`localhost`，端口是`7077`，这是默认的主端口。

1.  `conf/interpreter.json`文件:![Pointing to an external Spark cluster](graphics/B03812_04_15.jpg)
2.  `conf/zeppelin-env.sh`文件:![Pointing to an external Spark cluster](graphics/B03812_04_16.jpg)

现在，当我们从 Zeppelin 重新运行 Spark SQL 时，我们可以看到作业在外部 Spark 实例上运行，如下所示:

![Pointing to an external Spark cluster](graphics/B03812_04_17.jpg)<title>Creating scatter plots with Bokeh-Scala</title><link href="epub.css" rel="stylesheet" type="text/css"> 

# 使用散景-Scala 创建散点图

虽然 Zeppelin 足够强大，可以快速执行我们的 Spark SQLs 并可视化数据，但它仍然是一个不断发展的平台。在这一节中，我们将简要介绍 Python 中最流行的可视化框架 Bokeh，并使用它(也是快速发展的)Scala 绑定到框架。Breeze 还有一个名为 **breeze-viz** 的可视化 API，它是基于 JFreeChart 构建的。不幸的是，在写这本书的时候，这个 API 还没有得到积极的维护，因此我们在这里不讨论它。

Zeppelin 的强大之处在于能够在浏览器上共享和查看图形。这是由 D3.js JavaScript 可视化库的支持带来的。Bokeh 还受到另一个 JavaScript 可视化库 BokehJS 的支持。Scala bindings 库(`bokeh-scala`)不仅提供了一种更简单的方法来构造 Scala 对象的字形(线、圆等等)，还将字形翻译成 BokehJS JavaScript 组件可以理解的格式。

这里有一个警告:Bokeh-Scala 绑定仍然在发展，并且在较低的水平上运行。有时，这比它的 Python 对应物更麻烦。也就是说，我仍然相信我们都能够欣赏到我们可以直接从 Scala 中创建的令人惊叹的图形。

## 怎么做...

在这个食谱中，我们将使用虹膜数据([https://archive.ics.uci.edu/ml/datasets/Iris](https://archive.ics.uci.edu/ml/datasets/Iris))创建一个散点图，它具有属于同一植物的三个不同物种的花的长度和宽度属性。在这个数据集上绘制散点图涉及一系列有趣的子步骤。

为了在 Breeze 矩阵中表示 iris 数据，我简单地将物种类别转换为数字:

*   *丝状虹膜* : 0
*   *杂色鸢尾* : 1
*   *北美鸢尾* : 2

这个在`irisNumeric.csv`里有。稍后，我们将了解如何将原始 iris 数据(`iris.data`)加载到 Spark 数据帧中，并将其用作绘图源。

为了清楚起见，让我们来定义散景中各种术语的实际含义:

*   **字形**:我们能想到的所有几何形状——圆形、正方形、直线等等——都是字形。这只是 UI 表示，不包含任何数据。所有与这个对象相关的属性只是帮助我们修改 UI 属性:`color`、`x`、`y`、`width`等等。
*   **Plot**:Plot 就像一块画布，我们在上面安排各种与可视化相关的对象，比如图例、 *x* 和 *y* 轴、网格、工具，显然还有图形的核心——数据本身。我们构造各种附件对象，最后将它们添加到 plot 对象的渲染器列表中。
*   **文档**:文档是进行实际渲染的组件。它接受 plot 作为参数，当我们在文档中调用`save`方法时，它使用 plot 对象中的所有子渲染器，并从包装的元素中构造一个 JSON。这个 JSON 最终被 BokehJS 小部件读取，以一种视觉愉悦的方式呈现数据。通过将一个以上的图添加到网格图中，可以在文档中呈现多个图(我们将在下一个菜谱中查看如何完成这个操作，*使用 Bokeh-Scala* 创建时间序列多图)。

一个图由多个小部件/符号组成。

这包括一系列步骤:

1.  准备我们的数据。
2.  创建打印和文档对象。
3.  创建一个点(标记对象)和一个渲染器。
4.  设置绘图的 x 轴和 y 轴数据范围。
5.  画出 x 轴和 y 轴。
6.  查看不同颜色的标记对象。
7.  添加网格线。
8.  向图中添加图例。

### 准备数据

散景图要求我们的数据采用它能理解的格式，但这真的很容易做到。我们需要做的就是创建一个继承自`ColumnDataSource`的新的源对象。其他选项是`AjaxDataSource`和`RemoteDataSource`。

因此，让我们将 Breeze 数据源覆盖在`ColumnDataSource`上:

```
import breeze.linalg._

object IrisSource extends ColumnDataSource {

  private val colormap = Map[Int, Color](0 -> Color.Red, 1 -> Color.Green, 2 -> Color.Blue)

  private val iris = csvread(file = new File("irisNumeric.csv"), separator = ',')

  val sepalLength = column(iris(::, 0))

  val sepalWidth = column(iris(::, 1))

  val petalLength = column(iris(::, 2))

  val petalWidth = column(iris(::, 3))

  val species = column(iris(::, 4))

}
```

第一行使用 Breeze 库的`csvread`函数读取`irisNumeric.csv`。彩色地图是我们稍后在绘图时会用到的东西。这张地图的目的是将每一种花翻译成不同的颜色。最后一部分是我们将微风矩阵转换成`ColumnDataSource`。根据`ColumnDataSource`的要求，我们选择 Breeze 矩阵中的特定列并将其映射到相应的列。

### 创建绘图和文档对象

让我们将图像的标题设为`Iris Petal Length vs Width`，并创建一个文档对象，这样我们就可以用名称`IrisBokehBreeze.html`保存最终的 HTML。由于我们没有在`save`方法中指定目标文件的完整路径，文件将保存在与项目本身相同的目录中:

```

val plot = new Plot().title("Iris Petal Length vs Width")

val document = new Document(plot)

val file = document.save("IrisBokehBreeze.html")

println(s"Saved the chart as ${file.url}")

```

### 创建标记对象

我们的图既没有数据也没有任何符号。让我们首先创建一个标记数据点的标记对象。有多种标记对象可供选择:`Asterisk`、`Circle`、`CircleCross`、`CircleX`、`Cross`、`Diamond`、`DiamondCross`、`InvertedTriangle`、`PlainX`、`Square`、`SquareCross`、`SquareX`和`Triangle`。

为了我们的目的，让我们选择`Diamond`:

```

val diamond = new Diamond()

 .x(petalLength)

 .y(petalWidth)

 .fill_color(Color.Blue)

 .fill_alpha(0.5)

 .size(5)

val dataPointRenderer = new GlyphRenderer().data_source(IrisSource).glyph(diamond)

```

当构造标记对象时，除了 UI 属性，我们还说它的 *x* 和 *y* 坐标是什么。注意，我们也提到过这个标记的颜色是蓝色的。我们一会儿会用彩色地图来改变它。

### 设置绘图的 X 轴和 Y 轴数据范围

绘图在渲染之前需要知道绘图的`x`和`y`数据范围是什么。让我们通过创建两个`DataRange`对象并将它们设置到情节中来实现:

```

val xRange = new DataRange1d().sources(petal_length :: Nil)

val yRange = new DataRange1d().sources(petal_width :: Nil)

plot.x_range(xRange).y_range(yRange)

```

让我们试着运行这个程序的第一部分。

以下是输出:

![Setting the X and Y axes' data range for the plot](graphics/B03812_04_18.jpg)

我们看到这个需要做很多工作。让我们一点一点地做它。

### 绘制 x 轴和 y 轴

现在让我们绘制轴，设置它们的边界，并将它们添加到绘图的渲染器中。我们还需要让绘图知道每个轴属于哪个位置:

```

//X and Y Axis

 val xAxis = new LinearAxis().plot(plot).axis_label("Petal Length").bounds((1.0, 7.0))

 val yAxis = new LinearAxis().plot(plot).axis_label("Petal Width").bounds((0.0, 2.5))

 plot.below <<= (listRenderer => (xAxis :: listRenderer))

 plot.left <<= (listRenderer => (yAxis :: listRenderer))

 //Add the renderer to the plot

 plot.renderers := List(xAxis, yAxis, dataPointRenderer)

```

以下是输出:

![Drawing the x and the y axes](graphics/B03812_04_19.jpg)

### 观赏色彩各异的花卉

到目前为止，所有的数据点都用蓝色标记，但是我们真的想在视觉上区分物种。这是一个简单的两步过程:

1.  Add new derived data (`speciesColor`) into our `ColumnDataSource` to hold colors that represent the species:

    ```
    object IrisSource extends ColumnDataSource {

      private val colormap = Map[Int, Color](0 -> Color.Red, 1 -> Color.Green, 2 -> Color.Blue)

      private val iris = csvread(file = new File("irisNumeric.csv"), separator = ',')

      val sepalLength = column(iris(::, 0))

      val sepalWidth = column(iris(::, 1))

      val petalLength = column(iris(::, 2))

      val petalWidth = column(iris(::, 3))

    val speciesColor = column(species.value.map(v => colormap(v.round.toInt)))

    }
    ```

    因此，我们将红色分配给刚毛鸢尾，绿色分配给杂色鸢尾，蓝色分配给海滨鸢尾。

2.  修改`diamond`标记，将其作为输入，而不是接受静态蓝色:

    ```

    val diamond = new Diamond()

     .x(petalLength)

     .y(petalWidth)

     .fill_color(speciesColor)

     .fill_alpha(0.5)

     .size(10)

    ```

输出如下所示:

![Viewing flower species with varying colors](graphics/B03812_04_20.jpg)

现在看起来还不错。让我们给图像添加一些工具。散景有一些很好看的工具可以贴在图像上:`BoxSelectTool`、`BoxZoomTool`、`CrosshairTool`、`HoverTool`、`LassoSelectTool`、`PanTool`、`PolySelectTool`、`PreviewSaveTool`、`ResetTool`、`ResizeTool`、`SelectTool`、`TapTool`、`TransientSelectTool`、`WheelZoomTool`。

下面我们来添加几个来看看好玩的:

```

val panTool = new PanTool().plot(plot)

 val wheelZoomTool = new WheelZoomTool().plot(plot)

 val previewSaveTool = new PreviewSaveTool().plot(plot)

 val resetTool = new ResetTool().plot(plot)

 val resizeTool = new ResizeTool().plot(plot)

 val crosshairTool = new CrosshairTool().plot(plot)

plot.tools := List(panTool, wheelZoomTool, previewSaveTool, resetTool, resizeTool, crosshairTool)

```

![Viewing flower species with varying colors](graphics/B03812_04_21.jpg)

### 添加网格线

虽然我们有十字准线工具，它可以帮助我们定位特定数据点的精确 x 和 y 值，但如果有一个数据网格就更好了。让我们添加两个数据网格，一个用于 *x* 轴，一个用于 *y* 轴:

```

 val xAxis = new LinearAxis().plot(plot).axis_label("Petal Length").bounds((1.0, 7.0))

 val yAxis = new LinearAxis().plot(plot).axis_label("Petal Width").bounds((0.0, 2.5))

 val xgrid = new Grid().plot(plot).axis(xAxis).dimension(0)

 val ygrid = new Grid().plot(plot).axis(yAxis).dimension(1)

```

接下来，让我们也将网格添加到绘图渲染器列表中:

```

 plot.renderers := List(xAxis, yAxis, dataPointRenderer, xgrid, ygrid)

```

![Adding grid lines](graphics/B03812_04_22.jpg)

### 将图例添加到情节中

这一步在 Bokeh 的 Scala 绑定中有点棘手，因为缺少高级图形对象，比如`scatter`。现在，让我们创造自己的传奇。`Legend`对象的 `legends`属性接受元组列表——一个标签和一个`GlyphRenderer`对。让我们显式地创建三个`GlyphRenderer`包裹三种颜色的钻石，它们代表这个物种。然后我们将它们添加到绘图中:

```

val setosa = new Diamond().fill_color(Color.Red).size(10).fill_alpha(0.5)

 val setosaGlyphRnd=new GlyphRenderer().glyph(setosa)

 val versicolor = new Diamond().fill_color(Color.Green).size(10).fill_alpha(0.5)

 val versicolorGlyphRnd=new GlyphRenderer().glyph(versicolor)

 val virginica = new Diamond().fill_color(Color.Blue).size(10).fill_alpha(0.5)

 val virginicaGlyphRnd=new GlyphRenderer().glyph(virginica)

 val legends = List("setosa" -> List(setosaGlyphRnd),

 "versicolor" -> List(versicolorGlyphRnd),

 "virginica" -> List(virginicaGlyphRnd))

 val legend = new Legend().orientation(LegendOrientation.TopLeft).plot(plot).legends(legends)

plot.renderers := List(xAxis, yAxis, dataPointRenderer, xgrid, ygrid, legend, setosaGlyphRnd, virginicaGlyphRnd, versicolorGlyphRnd)

```

![Adding a legend to the plot](graphics/B03812_04_23.jpg)

### 注意

这个食谱的代码可以在[https://github . com/arun ma/scaladata analysis cookbook/blob/master/chapter 4-visualization/src/main/Scala/com/packt/Scala da/viz/breeze](https://github.com/arunma/ScalaDataAnalysisCookbook/blob/master/chapter4-visualization/src/main/scala/com/packt/scalada/viz/breeze)找到。

<title>Creating a time series MultiPlot with Bokeh-Scala</title><link href="epub.css" rel="stylesheet" type="text/css"> 

# 用散景-Scala 创建时间序列多点图

在这个使用散景绘图的第二个方法中，我们将看到如何使用从[https://archive.ics.uci.edu/ml/datasets/Dow+Jones+Index](https://archive.ics.uci.edu/ml/datasets/Dow+Jones+Index)借来的数据集绘制时间系列图。我们还将了解如何在一个文档中绘制多个图表。

## 怎么做...

我们将只使用数据集中的两个字段:股票在周末的收盘价，以及第周的最后一个工作日。我们的数据集用逗号分隔。让我们来看一些样本，如下所示:

![How to do it...](graphics/B03812_04_24.jpg)

### 准备数据

与之前的食谱相反，我们使用 Breeze 矩阵来构建散景`ColumnDataSource`，这次我们将使用 Spark 数据帧来构建源。`getSource`方法接受一个股票代码(MSFT-微软和卡特彼勒)和一个`SQLContext`。它运行 Spark SQL，从表中获取数据，并从中构造一个`ColumnDataSource`:

```
import org.joda.time.format.DateTimeFormat

object StockSource {

  val formatter = DateTimeFormat.forPattern("MM/dd/yyyy");

  def getSource(ticker: String, sqlContext: SQLContext) = {

    val stockDf = sqlContext.sql(s"select stock, date, close from stocks where stock= '$ticker'")

    stockDf.cache()

    val dateData: Array[Double] = stockDf.select("date").collect.map(eachRow => formatter.parseDateTime(eachRow.getString(0)).getMillis().toDouble)

    val closeData: Array[Double] = stockDf.select("close").collect.map(eachRow => eachRow.getString(0).drop(1).toDouble)

    object source extends ColumnDataSource {

      val date = column(dateData)

      val close = column(closeData)

    }

    source

  }

}
```

之前，我们构造了`SQLContext`并将数据集注册为一个表，如下所示:

```

val conf = new SparkConf().setAppName("csvDataFrame").setMaster("local[2]")

val sc = new SparkContext(conf)

val sqlContext = new SQLContext(sc)

val stocks = sqlContext.csvFile(filePath = "dow_jones_index.data", useHeader = true, delimiter = ',')

stocks.registerTempTable("stocks")

```

我们在这里做的唯一棘手的事情是将日期值转换成毫秒。这是因为`Plot`点需要双精度。我们使用 **Joda-Time** API 来实现这一点。

### 创造情节

让我们继续,从源代码创建`Plot`对象:

```

//Create Plot

val plot = new Plot().title(ticker).x_range(xdr).y_range(ydr).width(800).height(400)

```

让我们将图片的标题作为股票的代号，并创建一个`Document`对象，这样我们就可以用名称`ClosingPrices.html`保存最终的 HTML:

```
val msDocument = new Document(microsoftPlot)

val msHtml = msDocument.save("ClosingPrices.html")
```

### 创建一条连接所有数据点的线

正如我们前面看到的带有`Diamond`标记的，我们必须传递数据点的`x`和`y`位置。此外，我们需要将`Line`字形包装成渲染器，这样我们就可以将它添加到`Plot`:

```

val line = new Line().x(date).y(close).line_color(color).line_width(2)

val lineGlyph = new GlyphRenderer().data_source(source).glyph(line)

```

### 设置绘图的 x 轴和 y 轴数据范围

绘图在渲染之前需要知道绘图的`x`和`y`数据范围是什么。让我们通过创建两个`DataRange`对象并将它们设置到情节中来实现:

```

val xdr = new DataRange1d().sources(List(date))

val ydr = new DataRange1d().sources(List(close))

plot.x_range(xdr).y_range(ydr)

```

### 绘制轴和网格

绘制轴和网格是和以前一样的。我们向轴添加了一些标签，格式化了 *x* 轴的显示，然后将它们添加到`Plot`:

```

val xformatter = new DatetimeTickFormatter().formats(Map(DatetimeUnits.Months -> List("%b %Y")))

val xaxis = new DatetimeAxis().plot(plot).formatter(xformatter).axis_label("Month")

val yaxis = new LinearAxis().plot(plot).axis_label("Price")

plot.below <<= (xaxis :: _)

plot.left <<= (yaxis :: _)

val xgrid = new Grid().plot(plot).dimension(0).axis(xaxis)

val ygrid = new Grid().plot(plot).dimension(1).axis(yaxis)

```

### 添加工具

像以前一样，让我们添加一些工具到图像——和添加到`plot`:

```
//Tools

val panTool = new PanTool().plot(plot)

val wheelZoomTool = new WheelZoomTool().plot(plot)

val previewSaveTool = new PreviewSaveTool().plot(plot)

val resetTool = new ResetTool().plot(plot)

val resizeTool = new ResizeTool().plot(plot)

val crosshairTool = new CrosshairTool().plot(plot)

plot.tools := List(panTool, wheelZoomTool, previewSaveTool, resetTool, resizeTool, crosshairTool)
```

### 将图例添加到情节中

因为我们已经有了`line`的`Glyph`渲染器，我们需要做的就是将它添加到图例中。线条的属性会自动传播到图例:

```

//Legend

 val legends = List(ticker -> List(lineGlyph))

 val legend = new Legend().plot(plot).legends(legends)

```

接下来，让我们将之前创建的所有渲染器添加到绘图中:

```

plot.renderers <<= (xaxis :: yaxis :: xgrid :: ygrid :: lineGlyph :: legend :: _)

```

![Adding a legend to the plot](graphics/B03812_04_25.jpg)

最后一步，让我们尝试在同一个文档中绘制多个图。

### 文档中有多个图

在同一个文档中创建多个图是轻而易举的事情。我们需要做的就是创建所有的图，然后将它们添加到网格中。最后，我们没有将单个的绘图对象传入文档，而是传入了`GridPlot`:

```

val children = List(List(microsoftPlot, bofaPlot), List(caterPillarPlot, mmmPlot))

val grid = new GridPlot().children(children)

val document = new Document(grid)

val html = document.save("DJClosingPrices.html")

```

![Multiple plots in the document](graphics/B03812_04_26.jpg)

### 注意

这个食谱的代码可以在[https://github . com/arun ma/scaladata analysis cookbook/blob/master/chapter 4-visualization/src/main/Scala/com/packt/Scala da/viz/breeze](https://github.com/arunma/ScalaDataAnalysisCookbook/blob/master/chapter4-visualization/src/main/scala/com/packt/scalada/viz/breeze)找到。

在这一章中，我们探索了两种可视化方法，并用 Scala 构建了一些基本的图形和图表。正如我前面提到的，Scala 中的可视化库正在积极开发中，无法与使用 R 或 Tableau 生成的高级可视化相提并论。