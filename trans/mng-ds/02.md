<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 你能用数据科学做什么

我曾经告诉一位软件开发人员朋友，欧洲最大的数据科学会议之一。他表现出真正的兴趣，并问我们是否可以一起去。当然，我说。让我们一起拓宽知识面。和你讨论机器学习会很棒。几天后，我们坐在一个大会议厅的中央。第一位演讲者上台向我们讲述了他用来赢得几场数据科学竞赛的一些技术技巧。当下一个演讲者谈到张量代数时，我注意到我朋友眼中的疲惫。

— *怎么了？*我问。

我只是在想他们什么时候会给我们展示机器人。

为了避免不正确的期望，我们需要告诉自己。在盖房子之前，你最好知道锤子是如何工作的。对你所管理的领域有基本的了解对于任何类型的管理者都是至关重要的。软件开发经理需要了解计算机编程。工厂经理需要了解制造过程。数据科学经理也不例外。这本书的第一部分简单解释了数据科学背后的主要概念。我们会一点一点的解剖探索。

数据科学已经变得很受欢迎，许多业务人员和技术专业人员对了解数据科学并应用它来解决他们的问题越来越感兴趣。人们通常从他们通过后台收集的信息中形成对数据科学的第一印象:新闻网站、社交网络等等。不幸的是，这些来源中的大多数都误导了人们，而不是给出数据科学和机器学习的真实图景。

媒体没有解释，而是描述了轻松解决我们所有问题的终极神奇工具。技术奇点即将到来。普遍收入经济即将到来。除非机器能像人类一样学习和思考。事实上，我们还远远没有创造出通用的、自我学习和自我改进的算法。

本章探讨数据科学主要工具的当前可能性和现代应用:**机器** **学习**和**深度** **学习**。

在本章中，我们将讨论以下主题:

*   定义人工智能
*   机器学习导论
*   深度学习简介
*   深度学习用例
*   因果推理导论

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 定义人工智能

媒体和新闻将 AI 作为任何与数据分析相关的技术的替代术语。其实 AI 是计算机科学和数学的一个子领域。这一切都始于 20 世纪 50 年代，当时几名研究人员开始询问计算机是否可以学习、思考和推理。70 年后，我们仍然不知道答案。然而，我们在一种特定类型的人工智能方面取得了重大进展，这种人工智能彻底解决了指定的狭窄任务:**弱人工智能**。

科幻小说讲述了可以像人类一样推理和思考的机器。在科学语言中，他们被描述为**强 AI** 。强 AI 可以像人类一样思考，它的智力能力可能要先进得多。创造强大的人工智能仍然是科学界的主要长期梦想。但是，实际应用都是关于弱 AI 的。强人工智能试图解决一般智能的问题，而弱人工智能则专注于解决一个狭隘的认知任务，如视觉、语音或听力。弱人工智能任务的例子多种多样:语音识别、图像分类和客户流失预测。弱人工智能在我们的生活中扮演着重要的角色，改变着我们的工作、思考和生活方式。我们可以在生活的各个领域找到弱 AI 的成功应用。医药、机器人、营销、物流、艺术和音乐都受益于弱人工智能的最新进展。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 定义数据科学

人工智能与机器学习有什么关系？什么是深度学习？我们如何定义数据科学？这些流行的问题最好用图形来回答:

![](Images/445e79b1-dc2d-4e5e-9319-380208624e70.png)

该图表包括本书将讨论的所有技术主题:

*   人工智能是一个广义的科学领域，涵盖了与弱人工智能和强人工智能相关的一切。我们不会过多地关注人工智能，因为大多数实际应用来自它的子领域，我们将在第一部分 *的剩余部分定义和讨论什么是数据科学？*
*   机器学习是人工智能的一个子领域，它研究的算法可以根据输入的数据调整自己的行为，而无需程序员的明确指示。
*   深度学习是机器学习的一个子领域，它研究一种特定的机器学习模型，称为深度神经网络。
*   数据科学是一个多学科领域，它使用一套工具从数据中提取知识并支持决策制定。机器学习和深度学习是数据科学的主要工具之一。

数据科学的最终目标是通过从数据中提取知识并为复杂的决策提供支持来解决问题。解决问题的第一步是很好地理解它的领域。在使用数据科学进行风险分析之前，您需要了解保险业务。在设计自动化质量保证流程之前，您需要了解产品制造流程的细节。首先，你了解领域。然后，你发现一个问题。如果你跳过这一部分，你很有可能会解错题。

在想出一个好的问题定义后，你寻求一个解决方案。假设您已经创建了一个解决任务的模型。任何人都不会对真空中的机器学习模型感兴趣。所以，它没有用。为了使它有用，我们需要把我们的模型包装成可以被看到和操作的东西。换句话说，我们需要围绕模型创建软件。数据科学总是与创建软件系统携手并进。任何机器学习模型都需要软件。如果没有软件，模型只会存在于计算机内存中，对任何人都没有帮助。

所以，数据科学从来不仅仅是科学。商业知识和软件开发也很重要。没有它们，任何解决方案都不会完整。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 数据科学的影响

数据科学有巨大的潜力。它已经影响了我们的日常生活。医疗保健公司正在学习诊断和预测主要的健康问题。企业使用它来寻找赢得新客户的新策略，并个性化他们的服务。我们在遗传学和粒子物理学中使用大数据分析。由于数据科学的进步，无人驾驶汽车现在已经成为现实。

由于互联网和全球计算机化，我们每天都在创造大量的数据。不断增长的数据量使我们能够自动化人类劳动。

可悲的是，对于每一个改善我们生活的用例，我们很容易找到两个使它们变得更糟的用例。给你一个令人不安的例子，我们来看看中国。中国政府正在试验一种新的社会信用体系。它使用监控摄像头大规模地跟踪其公民的日常生活。计算机视觉系统可以识别并记录你在上下班途中、在政府办公室排队等候或聚会后回家时的每一个动作。一个特殊的社会评分，然后根据你的监测行动计算。这个分数影响着现实中人的生活。特别是公共交通费用可以根据你的分数而变化；低分会阻止你参加一系列政府工作的面试。

另一方面，同样的技术可以用来帮助人们。例如，它可以用来在人群中追踪罪犯。你应用这种新技术的方式可以让世界更接近乔治·奥威尔的《1984 年的 T1》，或者让它成为一个更安全的地方。公众必须更加意识到这些选择，因为它们可能会对他们的生活产生持久的影响。

机器学习的一些令人不安的用途的另一个例子是使用基于机器学习的招聘算法的企业。几个月后，他们发现算法引入了对女性的偏见。越来越明显的是，我们没有对数据科学的伦理给予足够的重视。虽然谷歌等公司建立了内部道德委员会，但政府仍无法控制现代技术的不道德使用。在这样的程序到来之前，我强烈建议你考虑使用数据科学的伦理含义。我们都希望生活在一个更美好的世界。我们的未来，以及我们孩子的未来，取决于我们每天做出的小决定。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 数据科学的局限性

像任何一套工具一样，数据科学也有其局限性。在开始一个雄心勃勃的项目之前，重要的是要考虑当前的可能性极限。看似容易解决的任务实际上可能无法解决。

对数据科学技术方面的理解不足会导致您的项目出现严重问题。你可以开始一个项目，却发现你根本无法解决这个任务。更糟糕的是，您会发现只有在部署之后，一切才按预期运行。根据您的使用情况，它可以影响真实的人。理解数据科学背后的主要原理将使您摆脱许多技术风险，这些风险甚至在项目开始之前就预先决定了项目的命运。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 机器学习导论

机器学习是迄今为止数据科学家最重要的工具。它使我们能够创建算法，发现具有数千个变量的数据中的模式。我们现在将探索不同类型和功能的机器学习算法。

机器学习是一个研究算法的科学领域，这些算法可以在没有特定指令的情况下，依靠数据中发现的模式来学习执行任务。例如，我们可以使用算法来预测疾病的可能性或评估复杂制造设备的故障风险。每个机器学习算法都遵循一个简单的公式。在下图中，您可以看到基于机器学习算法的高级决策流程。每种机器学习模型都消耗数据来产生可以支持人类决策或完全自动化决策的信息:

![](Images/68df27d0-e558-47ea-86f0-44b82e38d008.png)

我们现在将在下一节中更详细地探讨每个块的含义。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 机器学习模型提供的决策和见解

当使用机器学习解决一项任务时，您通常希望自动化决策过程或获得支持您决策的见解。例如，在给定患者的病史和当前状况的情况下，您可能希望算法输出可能的疾病列表。如果机器学习完全解决了你的任务，或者说端到端，这意味着算法的输出可以用来做最终的决定，而不需要进一步思考；在我们的例子中，确定患者所患的疾病并自动开出合适的药物处方。这个决定的执行可以是手动的或自动的。我们说像这样的机器学习应用是端到端的。它们为这项任务提供了完整的解决方案。让我们以数字广告为例。一个算法可以预测你是否会点击一个广告。如果我们的目标是最大化点击，我们可以自动和个性化地决定向每个用户显示哪个特定广告，从而端到端地解决点击率最大化问题。

另一个选择是创建一个算法，为您提供洞察力。你可以将这种洞察力作为决策过程的一部分。这样，许多机器学习算法的输出可以参与复杂的决策制定。为了说明这一点，我们来看一个仓库安全监控系统。它监控所有的监控摄像头并从视频中识别员工。如果系统没有将某个人识别为员工，它会发出警报。这种设置使用两种机器学习模型:人脸检测和人脸识别。首先，人脸检测模型在视频的每一帧中搜索人脸。接下来，人脸识别模型通过搜索人脸数据库将一个人识别为雇员。每个模型都不能单独解决员工识别任务。然而，每个模型都提供了作为决策过程一部分的洞察力。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 机器学习模型的数据

您可能已经注意到，我们示例中的算法适用于不同的数据类型。在数字广告的例子中，我们使用了结构化的客户数据。监控示例使用来自摄像机的视频。事实上，机器学习算法可以处理不同的数据类型。

我们可以将整个世界的数据分为两类:结构化和非结构化。大多数数据是非结构化的。图像、录音、文档、书籍和文章都代表非结构化数据。非结构化数据是我们当今生活的自然副产品。智能手机和社交网络促进了无尽数据流的产生。如今，你几乎不需要拍照片或拍视频。分析非结构化数据非常困难，直到 2010 年我们才拿出一个实用的解决方案。

结构化数据很难收集和维护，但却是最容易分析的。原因是我们经常收集它就是为了这个确切的目的。结构化数据通常存储在计算机数据库和文件中。在数字广告中，广告网络尽最大努力收集尽可能多的数据。数据是广告公司的黄金。他们收集你的浏览历史，链接点击，花在网站页面上的时间，以及每个用户的许多其他功能。大量的数据允许创建精确的点击概率模型，可以个性化您的广告浏览体验。个性化增加了点击概率，从而增加了广告商的利润。

为了增加数据供应，现代企业构建业务流程的方式是生成尽可能多的结构化数据。例如，银行记录你的每一笔金融交易。这些信息是管理帐户所必需的，但他们也将其作为信用评分模型的主要数据源。这些模型使用客户的财务状况来估计他们的信用违约风险概率。

分析非结构化数据的难度来自于其高维性。为了解释这一点，我们拿一个有两列数字的数据表来说: **x** 和 **y** 。我们可以说这个数据有两个维度。

该数据集中的每个值都显示在以下图上:

![](Images/6a728c43-3f0c-414f-945b-38649df03ff2.png)

正如你所看到的，我们可以准确的猜测出给定 **x** 时 **y** 的值是多少。要做到这一点，我们可以看看线上相应的点。例如，对于 **x** = **10** ， **y** 将等于 **8** ，这与描绘为蓝点的真实数据点相匹配。

现在，让我们转到用 iPhone 制作的照片。该图像的分辨率为 4，032 x 3，024 像素。每个像素将有三个颜色通道:红色、绿色和蓝色。如果我们用数字来表示图像中的像素，那么每张照片中的像素将超过 1200 万个。换句话说，我们的数据有 1200 万个维度。

在下面的屏幕截图中，您可以看到用一组数字表示的图像:

![](Images/e739e9f2-3538-4dad-81f9-d11e772129db.png)

对高维数据使用机器学习算法可能会出现问题。许多机器学习算法都存在一个叫做维数灾难的问题。要创建一个好的模型来识别照片中的对象，你需要一个比简单的线条复杂得多的模型。模型的复杂性增加了模型的**数据饥饿**，因此在非结构化数据上工作良好的模型通常需要大量的训练数据样本。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 机器学习的起源

在数据科学、机器学习、深度学习出现之前，有统计学。所有与数据分析相关的领域都以统计学为核心。从一开始，统计学就是许多领域的混合体。这是因为统计学过去和现在都是为了解决实际问题。在 17 世纪，统计学家将数学应用于数据，以做出推论并支持有关经济和人口统计的决策。这听起来不像数据科学吗？这里有一个有趣的事实:第一个机器学习算法，线性回归，是 200 多年前由卡尔·弗里德里希·高斯发明的。我们今天仍在使用它，它的实现存在于所有主要的机器学习和统计软件包中。

高斯发明的最小二乘算法是线性回归的基本形式。线性模型的一般形式是在很久以后才介绍的。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 机器学习剖析

让我们看看机器学习的常见用例。可以说最常见的是预测。预测算法告诉我们什么时候会发生，但不一定是为什么会发生。预测任务的一些例子是:*这个用户在下个月会流失吗？* *这个人患老年痴呆症的风险高吗？* *接下来一个小时会不会堵车？通常，我们想要的是解释而不是预测。解决推理任务意味着通过询问*为什么在数据中找到支持某些主张的证据？*提问。*这个人为什么会赢得选举？* *为什么这药有效，另一种无效？*统计推断帮助我们找到解释或证明我们行动的效率。当我们进行推理时，我们寻求现在或过去的答案。当我们试图展望未来时，预测开始发挥作用。*

有时候，我们对预测未来或寻找证据不感兴趣。我们希望机器能够识别数据中的复杂模式，例如图像中的对象，或者分析短信的情感。这组任务叫做识别。

机器学习涵盖了许多类型和风格的模型。但是为什么我们需要如此多样的不同算法呢？原因在于一个叫做**没有免费的午餐定理**的定理。它指出，对于每个数据集的每个任务，没有一个最佳模型能够始终如一地为您提供最佳结果。每种算法都有自己的优点和缺点。它可能在一项任务上完美无缺，但在另一项任务上却惨败。数据科学家最重要的目标之一是找到解决手头问题的最佳模型。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 您可以通过机器学习解决的主要任务类型

没有免费的午餐定理表明，不存在能很好地解决所有任务的最佳模型。这样做的后果是，我们有许多专门解决特定任务的算法。

例如，让我们看看时尚零售仓库需求预测。零售商在他们的店里出售一套固定的衣服。一件商品在上架之前，必须从制造商那里购买并转移到仓库。我们假设他们的物流周期需要两周。我们如何知道每个项目的最佳订购数量？我们很可能有每个商店的商品销售数据。我们可以用它来创建一个预测模型，估计未来两周客户对我们仓库目录中每种商品的平均需求。也就是说，我们预测了未来两周的平均购买数量。最简单的模型是将过去两周每种商品的平均需求作为未来平均需求的估计值。像这样简单的统计模型在真实的零售店中经常使用，所以我们不要过于简化。更一般地说，让我们把我们想要预测的东西叫做`target`变量。在前一种情况下，`target`变量是需求。为了建立预测模型，我们将使用前两周的历史数据来计算每个项目的算术平均值。然后，我们使用这些平均值作为未来值的估计。在某种程度上，历史数据被用来教导我们的模型应该如何预测`target`变量。当模型使用输入/输出示例学习执行给定的任务时，我们将该过程称为监督学习。将我们的平均计算器命名为监督学习算法有点言过其实，但没有什么能阻止我们这样做(至少在技术上)。

监督学习不限于简单的模型。一般来说，模型越复杂，需要训练的数据就越多。你的训练数据越多，你的模型就越好。为了说明这一点，我们来看看信息安全领域。我们假想的客户是一家大型电信公司。多年来，他们的网络经历了许多安全漏洞。值得庆幸的是，专家已经记录并彻底调查了网络上的所有欺诈活动。安全专家在网络日志中标记了每个欺诈活动。有了大量带有标签的训练样本的数据，我们可以训练一个监督学习模型来区分正常和欺诈活动。该模型将从大量传入数据中识别可疑行为。然而，这只有在专家正确标记数据的情况下才会发生。如果他们不这样做，我们的模型不会纠正他们。这个原理叫做**垃圾进**，**垃圾出**。你的模型只能和你的数据一样好。

零售和安全示例都使用监督学习，但让我们更仔细地看看`target`变量。预测算法使用需求作为`target`变量。需求是一个从 0 到无穷大的连续数字。另一方面，安全模型有固定数量的结果。

网络活动要么是正常的，要么是欺诈性的。我们称第一种类型的`target`变量为连续变量，第二种类型为分类变量。`target`变量类型强烈表明我们可以解决哪种任务。具有连续`target`变量的预测任务称为回归问题。当结果的总数有限时，我们说我们解决了一个分类问题。分类模型将数据点分配给类别，而回归模型估计数量。

以下是一些例子:

*   房价估计是一个回归任务。
*   预测用户广告点击是一项分类任务。
*   预测云存储服务中的 HDD 利用率是一项回归任务。
*   识别信用违约风险是一项分类任务。

如果你找到了一个好的标注数据集，你可以认为自己是幸运的。如果数据集很大，不包含丢失的标签，并且是问题的端到端解决方案的良好匹配，那就更幸运了。我们用于监督学习的标签是一种稀缺资源。完全没有标注比完全标注的数据集更常见。这意味着，通常，我们不能使用监督学习。但是没有标签并不意味着我们注定要失败。一种解决方案是手工标记数据。如果数据不能在公司外部共享，您可以将此任务分配给员工。否则，更简单快捷的解决方案是使用亚马逊 Mechanical Turk 等众筹服务。在那里，你可以将数据标注外包给很多人，为每个数据点支付少量费用。

虽然很方便，但标注数据并不总是负担得起的，而且可能是不可能的。一个`target`变量缺失或者可以从数据本身推导出来的学习过程叫做无监督学习。虽然监督学习意味着数据被标记，但无监督学习消除了这一限制，允许算法在没有指导的情况下从数据中学习。

例如，营销部门可能希望发现具有相似购买习惯的新客户群。这些见解可用于定制营销活动，并增加每个细分市场的收入。发现数据集中隐藏结构的一种方法是使用聚类分析算法。许多聚类算法可以处理未标记的数据。这个特点让他们特别有意思。

有时，标签隐藏在原始数据中。看音乐创作的任务。假设我们想创建一个算法来创作新的音乐。在这种情况下，我们可以使用无显式标记的监督学习。序列中的下一个音符是这项任务的绝佳标签。从一个音符开始，模型预测下一个音符。取前两个，输出第三个。这样，我们可以根据需要添加任意多的新笔记。

现在，让我们看看能否将机器学习应用到游戏中。如果我们拿单个游戏来说，可能会标注一些数据，使用监督学习。但在实践中，将这种方法推广到所有游戏是不可能的。在典型的游戏控制台上，您使用同一个控制器来玩不同的游戏。试着回忆一下你人生中第一次打球是什么时候。我猜是马里奥。很可能你不确定该做什么。你可能试着按下几个按钮，看着一个跳跃的角色。一块一块的，你一定是搞清楚了游戏规则，开始玩了。如果你有信心玩游戏，并且在几个小时的经验后就能完成第一关，我不会感到惊讶。

利用我们目前所获得的知识，我们是否可以设计一种机器学习算法，它将学习如何玩游戏？使用监督学习可能很有诱惑力，但是先想想。你人生第一次拿控制器的时候没有训练数据。但是我们能创造出能自己计算出游戏规则的算法吗？

如果我们事先知道规则，就很容易为特定的电脑游戏编写一个好的机器人。几乎所有现代电脑游戏都有基于规则的人工智能或非玩家角色，可以与玩家互动。一些游戏甚至有如此先进的人工智能，以至于所有的游戏都是围绕这个特性来构建的。有兴趣的话，看看 2014 年上映的*外星人* : *隔离*。那些算法的最大限制是它们是特定于游戏的。他们不能根据经验学习和行动。

直到 2015 年，深度学习研究人员发现了一种训练机器学习模型像人类一样玩雅达利游戏的方法:看着屏幕，通过使用游戏控制器来执行动作。唯一的区别是，该算法不是用眼睛或手来玩游戏。它通过 RAM 接收游戏的每一帧，并通过虚拟控制器进行操作。最重要的是，模型在每个输入帧中接收当前的游戏分数。开始时，模型执行随机动作。一些行动导致得分增加，并被视为积极的反馈。随着时间的推移，该模型学习了与较高分数相对应的输入/输出或帧/动作对。结果令人震惊。经过 75 个小时的训练，模特打出了业余水平的*突围*。它没有任何游戏的先验知识。它看到的都是原始像素。一段时间后，该算法已经学会如何比人类更好地玩*突围*。完全相同的模型可以被训练来玩不同的游戏。用于训练这种模型的学习框架被称为强化学习。在强化学习中，一个代理(玩家)学习一种策略(一种基于输入执行动作的特定方式)，在未知环境(一种计算机游戏)中使奖励(游戏分数)最大化。

当然也有局限性。记住，机器学习餐厅没有免费的午餐。虽然这种算法在大量游戏中表现良好，但在其他游戏中却完全失败。特别是，一款名为*蒙特祖马的复仇*的游戏在 2018 年之前一直困扰着所有模特。这个游戏的问题是，你需要在很长时间内执行一系列特定的动作，才能获得哪怕是很小的奖励信号。

为了解决复杂环境中的任务，强化学习算法需要极其大量的数据。你可能已经看到了关于 OpenAI Five 模型在一个名为 *Dota 2* 的复杂多人网络体育游戏中击败职业选手的新闻。为了让您有所了解，OpenAI 团队使用了一个由 256 个 GPU 和 128，000 个 CPU 核心组成的集群来训练他们的代理。每天，这个模型都在和自己玩 180 年的游戏。这个过程是在一个大型计算集群上并行发生的，所以实际上花费的时间要少得多。

强化学习的另一个重大胜利当然是 *Go* 游戏。在*围棋*中的动作总数比我们宇宙中的原子总数还要多，这使得这个游戏很难用计算机来处理。1997 年，计算机科学家在国际象棋上击败了最优秀的人类。对于*围棋*，他们又花了 18 年。如果你感兴趣，谷歌拍摄了一部关于 AlphaGo 的纪录片，alpha Go 是一种在围棋比赛中战胜世界冠军的算法。

当你可以完全模拟你的环境，也就是说，你事先知道游戏规则时，强化学习就能很好地发挥作用。这个先有鸡还是先有蛋的问题使得应用强化学习变得很棘手。尽管如此，强化学习仍然可以用来解决现实世界中的问题。一组科学家利用强化学习来寻找火箭发动机的最佳参数。由于发动机内部工作的完整物理模型，这成为可能。他们使用这些模型创建了一个模拟，其中强化学习算法改变了发动机的参数和设计，以找到最佳设置。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 深度学习简介

在写这一节之前，我在思考我们可以在机器学习和深度学习之间划清界限的许多方法。他们每个人在某种程度上都是矛盾的。事实上，你无法将深度学习与机器学习分开，因为深度学习是机器学习的一个子领域。深度学习研究一组称为神经网络的特定模型。第一次提到神经网络的数学基础可以追溯到 20 世纪 80 年代，现代神经网络背后的理论起源于 1958 年。尽管如此，他们直到 2010 年才显示出好的结果。为什么？

答案很简单:硬件。训练大型神经网络需要大量的计算能力。但是任何计算能力都不够。原来神经网络在引擎盖下做了很多矩阵运算。奇怪的是，渲染计算机图形还涉及许多矩阵运算，实际上如此之多，以至于每台计算机内部都有一个专用电路:GPU。Nvidia 知道快速矩阵运算的科学需求，因此他们开发了一个名为 **CUDA** 的特殊编程框架。CUDA 允许你不仅为计算机图形，而且为一般的计算任务驾驭你的 GPU 的力量。GPU 可以进行大量的并行矩阵运算。现代显卡有几千个核心，你可以并行执行几千次运算。并且所有单独操作也工作迅速。现代 GPU 可以执行数千次并行浮点计算。GPU 专门解决一个特定的任务，比通用 CPU 快得多。

所有这些意味着科学家可以训练更大的神经网络。训练大型神经网络的艺术和科学被称为深度学习。名称中的单词 **deep** 的来源来自于神经网络的特定结构，这种结构使它们能够高效而准确地进行预测。我们将在[第二章](20c52af6-9bb7-4578-9db2-6d74ac656248.xhtml)、*测试你的模型*中更多地了解神经网络的内部。

深度学习在解决非结构化数据集的任务方面非常出色。为了说明这一点，我们来看一个名为 **ImageNet** 的机器学习竞赛。它包含超过 1400 万张图片，分为 22，000 个不同的类别。为了解决 ImageNet，算法应该学会识别照片中的对象。虽然人类在这项任务上的表现约为 95%的准确率，但最好的神经网络模型在 2015 年超过了这一水平。

传统的机器学习算法不太擅长处理非结构化数据。然而，它们同样重要，因为在结构化数据集的领域中，传统机器学习模型和深度学习模型之间的性能差距不是那么大。大多数结构化数据集数据科学竞赛的获胜者都没有使用深度神经网络。他们使用更简单的模型，因为它们在结构化数据集上显示出更好的结果。这些模型训练速度更快，不需要专门的硬件，并且使用更少的计算能力。

更简单的模型并不更容易应用。深度学习也可以在结构化数据上显示出良好的结果。尽管如此，在现实世界的场景中，您可能会花费更多的时间、金钱和计算能力。简单性指的是内部模型的结构和模型内部变化参数的数量。

为了区分其他机器学习算法和深度学习，专业人士通常将深度学习称为研究神经网络的领域，机器学习用于每一个其他模型。在机器学习和深度学习之间划清界限是不正确的，但由于缺乏更好的术语，社区已经同意了模糊的定义。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 潜入自然语言处理

我们每天都在写作，无论是文档、推文、电子信息、书籍还是电子邮件。这个清单可以一直列下去。使用算法来理解自然语言是困难的，因为我们的语言是模糊的，复杂的，并且包含许多例外和角落情况。自然语言处理的最初尝试是关于建立基于规则的系统。语言学家精心设计了成千上万条规则来执行看似简单的任务，比如词性标注。

从这一节的标题，你大概能猜到这一切都随着深度学习而改变了。深度学习模型可以执行更多的文本处理任务，而不需要显式地陈述复杂的语法规则和解析器。深度学习模型席卷了 NLP 世界。它们可以执行各种各样的 NLP 任务，并且质量比前一代 NLP 模型好得多。深度神经网络以接近人类的准确度将文本翻译成另一种语言。他们在词性标注方面也相当准确。

神经网络在解决理解问题方面也做得很好:问题回答和文本摘要。在问答中，模型得到一段文本和一个关于其内容的问题。例如，给定本节的介绍，*深度学习介绍*，问答模型可以正确回答以下查询:

*   现代桌面 CPU 有几个核心？(少于 10)
*   神经网络起源于何时？(1980 年代)

文本摘要试图从源中提取要点。如果我们将本节的前几段输入到文本摘要模型中，我们将得到以下结果:

现在是时候在机器学习和深度学习之间划清界限了。事实上，我们不能这样做，因为深度学习是机器学习的一个子领域。从形式上来说，深度学习研究一组称为神经网络的特定模型。神经网络背后的理论起源于 20 世纪 80 年代。你可以在[http://textsummarization.net/](http://textsummarization.net/)在线试用一个文本摘要模型。

另一个交叉的 NLP 问题是文本分类。通过将许多文本标记为情绪积极或消极，我们可以创建一个情绪分析模型。正如你已经知道的，我们可以使用监督学习来训练这种模型。当用于衡量对新闻的反应或围绕 Twitter 标签的总体情绪时，情绪分析模型可以提供强大的洞察力。

文本分类也用于解决自动电子邮件和文档标记。我们可以使用神经网络来处理大量的电子邮件，并给它们分配适当的标签。

实用 NLP 的顶峰是对话系统或聊天机器人的创建。聊天机器人可用于自动化 IT 支持部门和呼叫中心的常见场景。然而，创建一个能够可靠且一致地解决其任务的机器人并不是一件容易的事情。客户倾向于以意想不到的方式与机器人交流，因此您将有许多棘手的问题需要解决。NLP 研究并没有提供一个端到端的对话模型来解决这个问题。

一般聊天机器人使用几种模型来理解用户的请求并准备答案:

*   意图分类模型决定了用户的请求。
*   实体识别模型从用户的消息中提取所有命名的实体。
*   响应生成器模型从意图分类和实体识别模型获取输入，并生成响应。响应生成器还可以使用知识数据库来查找额外的信息，以丰富响应。
*   有时，响应生成器会创建几个响应。然后，单独的响应排序模型选择最合适的一个。

NLP 模型还可以基于初始输入生成任意长度的文本。最先进的模型输出的结果可以说与人类书写的文本没有什么区别。

你可以在 OpenAI 关于 GPT-2 模型的博客文章中查看模型输出样本:[https://openai.com/blog/better-language-models/#sample1](https://openai.com/blog/better-language-models/#sample1)。

虽然结果非常引人注目，但我们还没有找到文本生成模型的有用和实际的应用。虽然作者和内容创作者可以通过使用这些模型将关键点列表扩展到连贯的文本中来潜在地受益于这些模型，但不幸的是，这些模型缺乏控制其输出的手段，使得它们难以在实践中使用。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 探索计算机视觉

我们已经探索了深度学习如何理解文本。现在，让我们来探索一下深度学习模型能看到什么。2010 年，举办了第一届 ImageNet 大规模视觉识别挑战赛。任务是创建一个分类模型，解决在图像中识别对象的雄心勃勃的任务。总共有大约 22，000 个类别可供选择。该数据集包含超过 1400 万张带标签的图像。如果有人坐下来为每张图片选择前 5 个物体，他们的错误率大约为 5%。

2015 年，一个深度神经网络在 ImageNet 上超过了人类的表现。从那以后，许多计算机视觉算法已经过时了。深度学习不仅可以让我们对图像进行分类，还可以进行对象检测和实例分割。

下面两张图片有助于描述对象检测和实例分割之间的区别:

![](Images/d7168b4f-b805-40db-88ef-f88e6ef6978e.png)

前面的照片向我们展示了对象检测模型识别对象并在它们周围放置边界框。

在下图中，从[https://github.com/matterport/Mask_RCNN](https://github.com/matterport/Mask_RCNN)，我们可以看到实例分割模型找到了物体的精确轮廓:

![](Images/fd56c7a5-7fd3-48d9-8ed3-38ddfcfb2d2b.png)

因此，深度学习在计算机视觉中的主要实际用途本质上是不同分辨率级别的相同任务:

*   **图像分类**:从预定的一组类别中确定图像的类别
*   **对象检测**:寻找图像内对象的边界框，并为每个边界框分配一个类别概率
*   I **实例分割**:对图像进行逐像素分割，从预定的类别列表中勾勒出每个对象

计算机视觉算法已经在癌症筛查、手写识别、人脸识别、机器人、自动驾驶汽车和许多其他领域得到了应用。

计算机视觉中另一个有趣的方向是生成模型。虽然我们已经检查过的模型执行识别任务，但是生成模型改变图像，甚至创建全新的图像。风格转换模型可以改变图像的风格外观，使其看起来更像另一个图像。这种模型可用于将照片转换成看起来和感觉上都像艺术家作品的绘画，如下所示:

![](Images/37256eaa-0c38-4e8d-9a5c-4139bdf35c1f.png)

另一种训练生成模型的有前途的方法叫做**生成对抗网络** ( **GANs** )。您使用两个模型来训练 GANs:生成器和鉴别器。生成器创建图像。鉴别器试图将数据集的真实图像与生成的图像区分开来。随着时间的推移，生成器学习创建更真实的图像，而鉴别器学习识别图像生成过程中更细微的错误。这种方法的结果不言自明。最先进的模型可以生成逼真的人脸，正如你在 Nvidia 的论文第 3 页看到的那样，【https://arxiv.org/pdf/1812.04948.pdf[。看看下面的图片。这些照片不是真的。一个深度神经网络生成了这些图像:](https://arxiv.org/pdf/1812.04948.pdf)

![](Images/fbf690d0-8e36-4a24-ac62-bd608a3585cc.png)

我们也可以使用 GANs 来执行条件图像生成。*条件*这个词的意思是我们可以为生成器指定一些参数。特别是，我们可以指定正在生成的对象或纹理的类型。例如，Nvidia 的 landscape generator 软件可以将简单的彩色编码图像(其中特定的颜色代表土壤、天空、水和其他物体)转换为逼真的照片。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 深度学习用例

为了展示深度学习在实际环境中可能如何工作，我们将探索产品匹配。

对于大型互联网零售商来说，最新的定价非常重要。当你的竞争对手降低一种受欢迎产品的价格时，反应迟缓会导致巨大的利润损失。如果你知道你的产品目录正确的市场价格分布，你就能永远领先你的竞争对手一步。要为单个产品创建这样的发行版，您首先需要在竞争对手的网站上找到该产品的描述。虽然自动收集产品描述很容易，但产品匹配却很难。

一旦我们有了大量的非结构化文本，我们需要从中提取产品属性。为此，我们首先需要判断两个描述是否指的是同一个产品。假设我们已经收集了一个类似产品描述的大型数据集。如果我们打乱数据中的所有配对，我们将得到另一个非相似产品描述的数据集。使用大量相似和不相似产品描述的例子，我们可以训练一个能够识别相似产品描述的 NLP 模型。我们也可以考虑比较零售商网站上的照片来寻找相似的产品。为此，我们可以应用计算机视觉模型来进行匹配。即使有这两个模型，总的匹配精度也可能不足以满足我们的要求。另一种方法是从文本描述中提取产品属性。我们可以训练单词标注模型或开发一套匹配规则来完成这项任务。随着我们使用的数据源的多样性和可描述性，匹配的准确性将会提高。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 因果推理导论

至此，我们已经讨论了预测模型。预测模型的主要目的是识别和预测。模型推理背后的解释是次要的。相反，因果推理试图解释数据中的关系，而不是对未来事件做出预测。在因果推理中，我们检查某种行为的结果是否不是由所谓的混杂变量*引起的。*这些变量可以通过结果间接影响行动。让我们通过几个有助于回答的问题来比较因果推理和预测模型:

*   预测模型:
    *   我们的销售额什么时候会翻倍？
    *   这个客户购买某个产品的概率有多大？
*   因果推理模型:
    *   这种癌症治疗有效吗？或者这种影响仅仅是因为数据中变量之间的复杂关系才显现出来的？
    *   我们推荐模型的新版本比另一个更好吗？如果是的话，与旧型号相比，它使我们的销售增加了多少？
    *   哪些因素导致一些书成为畅销书？
    *   什么因素导致老年痴呆症？

统计学家们有一句口头禅:相关性并不意味着因果关系。如果一些变量一起改变或具有相似的值，并不意味着它们以某种逻辑方式连接。在[http://www.tylervigen.com/spurious-correlations](http://www.tylervigen.com/spurious-correlations)的真实世界数据中，有许多非理性荒谬关联的伟大例子。

请看下面截图中的例子:

![](Images/f342eb94-9c08-416c-acde-69587cdfe689.png)

一些发现既有趣又令人困惑:

![](Images/066df39c-d9f3-4f4f-8cbf-edf7d273c56f.png)

当数据驱动的决策影响人们的生活时，寻求解释和衡量效果很重要。具体来说，当发明一种新药时，我们需要检查它是否真的有效。为了做到这一点，我们需要收集数据，并衡量使用新药与不使用新药的统计效果。

因果推理以一种相当大胆的方式提出了这个问题:衡量某种治疗效果的最简单方法是将我们的宇宙分成两部分。在第一部分，我们不进行治疗，并表现得好像这种药物从未被发现过。在第二部分，我们应用新的处理方法。不幸的是，创造新的宇宙远远超出了统计学家的能力。但他们已经提出了一个推理框架，允许你设计实验和收集数据，就好像它来自两个独立的宇宙。

最简单的方法是进行随机实验:

1.  首先，我们将从全球范围内随机抽取一组测试人员。
2.  然后，每个人将被分配新药或糖丸(安慰剂)，概率为 50%。
3.  一段时间后，我们可以衡量两组的治疗效果。

像这样的研究执行起来可能非常复杂。想象一下，每次你需要测试一种新药时，从全世界人口中随机选择一个样本。此外，你不能将所有人运送到一个地方，因为环境或气候的突然变化可能会影响治疗结果。这项实验也可能被认为是不道德的，尤其是如果治疗有死亡的危险。因果推理允许你设计更复杂的实验设计，在某些条件下仍然等同于随机实验。通过这种方式，你可以创建一个符合伦理的、现实的、具有统计严谨性的研究。

因果推断的另一个重要特征是一套对观察数据起作用的方法。进行假设检验的实验并不总是可行的。因果推断可用于应用预测模型来衡量对不是专门为此目的收集的观察数据的影响。例如，我们可以使用客户数据来衡量和量化营销活动的效率。观察研究便于实施，因为它们不需要实验装置。然而，他们只能给你一个关于真正因果关系的有力的有根据的猜测。在做出数据驱动的决策之前，总是建议设计并进行适当的实验。

将治疗应用于测试组的框架是非常通用的。它不局限于医学研究，可以测量和解释任何变化的影响。问题— *使用机器学习模型是否比完全不使用要好？*如果是的话，*它能带来多少好处？*经常占据数据科学家的头脑。多亏了因果推理，我们才能找到解决办法。在这个问题中，你可以用机器学习模型来代替治疗。

衡量真实效果的唯一方法是在真实用户身上检查这两种方法。虽然在现实世界中很难进行，但纯粹的随机实验在互联网上很容易进行。如果你在一家拥有大量客户的大型互联网公司使用机器学习模型，设计一个随机实验似乎很容易。您可以为每个用户随机分配两个不同版本的软件，并等待收集到足够多的数据样本。

但是，您应该警惕许多可能扭曲结果的事情:

*   数据中隐藏的偏差被称为混杂因素。客户生活方式、社会因素或环境暴露会影响你看似随机的用户样本。
*   测试组选择中的一个缺陷叫做选择偏差。例如，从一个地区随机选择测试参与者可能会影响研究。
*   测量误差:错误或不一致的数据收集会导致误导性的结果

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 摘要

在这一章中，我们探讨了人工智能、数据科学、机器学习、深度学习和因果推理的实际应用。我们已经将机器学习定义为一个研究算法的领域，这些算法使用数据来支持决策，并在没有特定指令的情况下给出见解。有三种主要的机器学习方法:监督、非监督和强化学习。在实践中，我们使用机器学习解决的最常见的任务类型是回归和分类。接下来，我们将深度学习描述为致力于研究神经网络算法的机器学习的子集。深度学习的主要应用领域是计算机视觉和自然语言处理。我们还触及了因果推理的重要主题:研究一套方法来发现数据中的因果关系的领域。您现在对一般数据科学能力有了很多了解。但是机器学习模型能成功解决你特定的一组问题吗？

在下一章，我们将学习通过模型测试来区分好的和坏的解决方案。