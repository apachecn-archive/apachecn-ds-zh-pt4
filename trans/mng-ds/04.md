<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 理解人工智能

您现在已经很好地理解了数据科学可以做什么，以及我们如何检查它是否有效。我们已经涵盖了数据科学的主要领域，包括机器学习和深度学习，但仍然很难透过迷雾辨别算法的内部工作方式。在这一章中，我们将研究算法。你会对学习过程是如何用数学和统计学定义的有一个直观的理解。深度神经网络将不再那么神秘，常见的机器学习术语不会吓到你，而是提供理解和想法，以完成不断增长的潜在项目列表。

你不是唯一一个从阅读本章中受益的人。你的新知识将简化与同事的沟通，使会议简短而有目的，团队合作更有效率。我们将从每个机器学习问题的核心开始:定义学习过程。为此，我们将从数据科学的两个基础学科开始:数学和统计学。

在本章中，我们将讨论以下主题:

*   了解数学优化
*   用统计数据思考
*   机器是如何学习的？
*   探索机器学习
*   探索深度学习

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 了解数学优化

首先，我们将探讨数学优化的概念。优化是机器学习问题的核心组成部分。事实证明，学习过程只不过是一个简单的数学优化问题。诀窍是正确地定义它。为了给出一个好的定义，我们首先需要了解数学优化是如何工作的，以及它可以解决哪些问题。

如果你在商业领域工作，我打赌你一天会听到好几次优化这个词。优化意味着提高效率、削减成本、增加收入和降低风险。优化包括采取一系列行动，衡量结果，并决定你是否已经在一个更好的地方结束。

例如，为了优化你每天上班的路线，你可以最大限度地减少从家开车到办公室的总时间。让我们假设在你的情况下，唯一重要的是时间。因此，优化意味着时间的最小化。你可以尝试不同的选择，如使用另一条道路或乘坐公共交通工具，而不是开车。要选择最佳方案，您将使用相同的数量评估所有路线，即从家到办公室的总时间。

为了更好地理解优化问题的定义，让我们考虑另一个例子。我们的朋友乔纳森厌倦了他在银行的日常工作，所以他开办了一个兔子农场。原来兔子繁殖快。一开始，他买了四只兔子，过了一会儿，他有了 16 只。一个月后，他们有 256 人。所有这些新的兔子导致额外的费用。乔纳森的兔子销售率低于兔子繁殖的速度。乔纳森的聪明的农民朋友阿伦对他的兔子生产率印象深刻，所以他提议以折扣价购买所有多余的兔子。现在，乔纳森需要弄清楚有多少兔子要卖给阿伦，这样他就可以保持在以下范围内:

*   他不会陷入无法把兔子卖给迫切想要兔子的人的境地。兔子繁殖率不应低于兔子销售预测。
*   他照顾兔子的总费用保持在预算之内。

你可以看到，我们已经定义了另一个优化问题，兔场开始提醒乔纳森之前离开的银行工作。这个优化任务非常不同，看起来更难。在第一个问题中，我们试图最小化通勤时间。在这个问题中，我们需要寻找出售兔子的最小数量，这样就不会违反其他条件。我们称这样的问题为**约束优化**。额外的约束允许我们在复杂的环境中模拟更真实的场景。举几个例子，约束优化可以解决计划、预算和路由问题。最终，乔纳森对自己的养兔场感到失望，把它卖给了阿伦。然后，他继续寻找一份完美的职业，不会像他的银行工作那样结束。

有一个地方，利润和亏损不会让你发疯；那是一所技术大学的数学系。为了得到一个职位，他们要求你通过考试。第一个任务是找到函数的最小值![](Images/bddf2c16-f3e3-4ee5-a413-152095024615.png)。

下面是这个函数的绘图:

![](Images/911bbd48-87ee-4d8d-b9b9-d7fb2b90ba24.png)

在检查该图时，您注意到该函数的值不小于 0，因此答案显然是 0。下一个问题看起来与前一个问题相似，但有所不同— *找到函数* ![](Images/d94e8a03-ff14-400a-8131-1bd7086194e4.png)，*的最小值，其中![](Images/1def254f-e730-4c92-aaf4-e592208ef0ec.png)是任意数字*。为了求解，你画了一堆图，发现最小值总是 *a* 。

最后一个问题把它发挥到了极致。上面说不会给你一个![](Images/65cb02ad-8d7e-4ab8-ae3d-3a0fb57d2388.png)的公式，但是你可以去找你的老师，问一些![](Images/d9035d65-10fa-4f72-ace4-b66d9f566858.png)的![](Images/93434734-953b-4790-86f1-da915f2d31de.png)的值，次数不限。不可能画出剧情。在其他地块中，最小值总是最低点。不看剧情怎么找到那个点？为了解决这个问题，我们将首先想象我们有一个这个函数的图。

首先，我们将在函数的任意两点之间画一条线，如下图所示:

![](Images/ffd06268-af3c-47f9-aca4-fa7b27087a62.png)

我们将这些点之间的距离称为![](Images/15e681ce-db67-4f73-8d4b-505deea6e04e.png)。如果我们让![](Images/6a7e6175-b05f-4c10-9d92-f13938a7ba93.png)变得越来越小，那么两个点将会如此接近，以至于它们将会在视觉上汇聚成一个点:

![](Images/d40fa9e2-4e3f-49a0-a572-563935a309c9.png)

前面图中的直线称为切线。它有一个非常方便的性质，这条线的斜率可以帮助我们找到一个函数的最小值或最大值。如果直线是平的，那么我们就找到了函数的最小值或最大值。如果附近所有的点都更高，那么它应该是一个最大值。如果附近所有的点都更低，那么这就是最小值。

下图显示了一个函数(以蓝色绘制)及其最大值，以及切线(以橙色绘制):

![](Images/8205186f-79a2-4ac6-8a63-695d7ce6c7ae.png)

画一堆线和点过一段时间就变得平淡无奇了。幸运的是，有一个简单的方法可以计算出![](Images/b41a95fb-d14c-4d8a-bdbc-4740c20405e3.png)和![](Images/da500071-60c5-4e9f-a9f1-bcbff0c8c5c0.png)之间这条线的斜率。如果你回忆一下勾股定理，你会很快找到答案: [![](Images/429f9755-80d6-431a-b87d-9a7467ec2461.png)] 。利用这个公式，我们可以很容易地求出斜率。

恭喜，我们刚刚发明了我们的第一个数学优化算法，梯度下降。一如既往，名字很吓人，但直觉很简单。为了更好地理解函数优化，想象你站在一个大山丘上。你需要闭着眼睛从上面下来。你可能会通过移动你的脚来测试你周围的区域。当你感觉到一个下降的方向时，你会在那里迈一步，然后重复。在数学术语中，山是一个函数。每次计算一个斜率，就要计算函数![](Images/e17eff6c-1b96-4465-8ce1-da2bc478e56a.png)的梯度。你可以沿着这个梯度找到一个函数的最小值或最大值。这就是为什么它被称为梯度下降。

您可以通过使用梯度下降来解决最终任务。可以选择一个起点， [![](Images/c10f822a-4c2a-4f53-be28-925894d94bf8.png)] ，求 [![](Images/20764d2d-3746-443c-a6f9-55212c8b176d.png)] 的值，用小数字，![](Images/212858db-b721-4543-bc1c-b54c9fb0ec9f.png)计算斜率。通过观察斜率，你可以决定你的下一次选择， [![](Images/77706a78-632d-40df-87dc-d753b3fa43b4.png)] ，应该大于还是小于 [![](Images/c8400b52-92cc-463f-94a7-17ff7f8bf387.png)] 。当斜率变为零时，可以通过查看附近的几个值来测试你当前的 [![](Images/51db79c8-9fd4-4570-97ca-bcf1fa28f884.png)] 值是最小值还是最大值。如果每个值都小于 [![](Images/afff9b66-3b6c-46b2-abb6-4fb90cc6c18e.png)] ，那么 [![](Images/8e4a7548-7761-46f4-9756-099ce8f2a4d7.png)] 就是最大值。否则，它是一个最小值。

一如既往，有一个警告。让我们来看看这个函数:

![](Images/cf871086-e906-4a3e-9e7e-59c38b9ca861.png)

如果我们在点 **A** 开始梯度下降，我们会以一个真正的最小值结束。但是如果我们从点 **B** 开始，我们将会陷入局部最小值。当你使用梯度下降时，你永远也不会知道你是处于局部最小值还是全局最小值。检查的一个方法是从彼此远离的不同点重复下降。另一种避免局部极小的方法是增加步长，![](Images/04a9240d-d9ff-430a-818d-c2b77eb5ee44.png)。但是要小心；如果![](Images/60e0e937-c4e9-4c72-b04b-5af0ef22adf6.png)太大，你只会一次又一次地跳过最小值，永远达不到你真正的目标，全局最小值。

就像在机器学习中，有许多数学优化算法，有不同的权衡。梯度下降是最简单和最容易开始的方法之一。尽管简单，梯度下降通常用于训练机器学习模型。

在继续之前，让我们回顾几个要点:

*   数学优化是机器学习的核心组成部分。
*   最优化问题有两种:有约束和无约束。
*   梯度下降法是一种简单且应用广泛的优化算法。为了理解梯度下降背后的直觉，回想一下希尔下降类比。

现在你已经很好地掌握了你的工具箱中的数学优化的主要原则，我们可以研究统计学领域——机器学习的祖父。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 用统计数据思考

统计学处理与数据有关的所有事情，即收集、分析、解释、推断和呈现。这是一个广阔的领域，包含了许多分析数据的方法。涵盖这一切超出了本书的范围，但我们将研究机器学习核心的一个概念，即**最大似然估计** ( **MLE** )。和往常一样，不要害怕术语，因为潜在的概念是简单和直观的。为了理解最大似然估计，我们需要深入概率论，统计学的基石。

首先，让我们看看为什么我们需要概率，当我们已经有了这么好的数学工具。我们用微积分处理无穷小尺度上的函数，并测量它们如何变化。我们发展了代数来解方程，我们还有几十个其他的数学领域来帮助我们解决我们能想到的几乎任何类型的难题。我们甚至提出了范畴理论，为几乎没有人(包括 Haskell 程序员)能理解的所有数学提供了一种通用语言。

难的是，我们都生活在一个混沌的宇宙中，事物无法精确测量。当我们研究现实世界的过程时，我们希望了解许多扭曲我们实验的随机事件。不确定性无处不在，我们必须驯服并利用它来满足我们的需求。这就是概率论和统计学发挥作用的时候。概率允许我们量化和测量不确定的事件，这样我们就可以做出正确的决定。丹尼尔·卡内曼在他广为人知的书《思考，快与慢》中指出，我们的直觉在解决统计问题时是出了名的糟糕。概率思维帮助我们避免偏见，理性行动。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 常客概率

想象一下，一个陌生人建议你玩一个游戏:他给你一枚硬币。你扔了它。如果是正面朝上，你会得到 100 美元。如果是反面，你输 75 美元。在玩游戏之前，你肯定会想检查它是否公平。如果硬币偏向反面，你会很快输钱。我们如何解决这个问题？让我们做一个实验，如果正面朝上，我们将记录 1，如果我们看到反面，我们将记录 0。有趣的是，我们需要投掷 1000 次来确保我们的计算是正确的。假设我们得到了以下结果:600 个正面(1)，400 个反面(0)。如果我们接着计算正面或反面在过去出现的频率，我们将分别得到 60%和 40%。我们可以把这些频率解释为硬币正面朝上或反面朝上的概率。我们称之为对概率的频繁主义观点。原来我们的硬币其实是偏向正面的。这个游戏的期望值可以通过将概率与它们的值相乘并求和来计算(下面公式中的值是负的，因为 40 美元是潜在的损失，而不是收益):

![](Images/c9ef427c-e4dd-4b65-ac08-e900e07fa5b0.png)

玩的越多，收获越多。即使在连续几次不走运的抛出后，你也可以肯定回报很快会达到平均水平。因此，频繁事件概率衡量某一事件与所有其他可能事件的比例。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 条件概率

已知一个事件发生的概率，知道另一个事件发生的概率是很方便的。我们把给定事件![](Images/0550de15-ba34-43f1-89cb-7092ac03c448.png)的事件![](Images/9f4edf0c-02f4-4f5d-b327-e42b6dcc3a16.png)的条件概率写成![](Images/a2f7111c-68ab-4eff-80fb-67c0fb20a134.png)。以雨为例:

*   如果我们听到雷声，下雨的可能性有多大？
*   假设天气晴朗，下雨的可能性有多大？

在下图中，您可以看到不同事件同时发生的概率:

![](Images/481bc35d-6f6e-46b7-897d-ad0651b4d5d5.png)

从这张欧拉图中，我们可以看到![](Images/28e92085-79d8-4c5a-872b-cc0c512fb639.png)，意思是当我们听到打雷的时候，总会有雨(是的，不完全是这样，但为了简单起见，我们会把这当成是真的)。

那![](Images/43ee27c6-2ae9-48ce-a87b-33bfbef3869d.png)呢？从视觉上看，这个概率很小，但是我们如何用数学公式来进行精确的计算呢？条件概率定义如下:

![](Images/a4c54506-0805-410b-aad6-05bd8cf1501f.png)

换句话说，我们将*下雨*和*晴朗*的联合概率除以晴朗天气的概率。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 从属和独立事件

如果一个事件的概率不影响另一个事件，我们称一对事件是独立的。例如，以连续两次掷骰子得到 2 的概率为例。这些事件是独立的。我们可以这样表述:

![](Images/4da71ad8-0de3-4f03-84b2-5f4d26d8111e.png)

但是为什么这个公式有效呢？首先，让我们将第一次和第二次投掷的事件重命名为 A 和 B，以消除符号混乱，然后将掷骰子的概率显式地重写为我们到目前为止看到的两次掷骰子的联合概率:

![](Images/50559135-6ee9-4325-b8dc-956b27439e7b.png)

而现在把![](Images/44c56de8-4513-4459-a57c-53b0054b58a1.png)乘以![](Images/1d94f705-b256-4be6-97c3-906f2cd98549.png)(没什么变化，可以抵消)，回想一下条件概率的定义:

![](Images/b54ec1b2-12c0-4a51-8eb7-4e828a1b8480.png)

如果我们从右向左阅读前面的表达式，我们会发现![](Images/f9030a42-ae3c-4599-8d4b-b2fcf30b9b2c.png)。基本上，这意味着 A 独立于 B！同样的道理也适用于![](Images/0213653a-f971-423a-9b01-2ec9716cb496.png)。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 贝叶斯概率观

在这之前，我们总是用频率来衡量概率。频率主义者的方法并不是定义概率的唯一方法。虽然常客认为概率是比例，但贝叶斯方法考虑了先验信息。贝叶斯理论以一个简单的定理为中心，该定理允许我们基于先验知识计算条件概率:

![](Images/044af8c0-e62f-4e60-9fa5-d9d23981ca19.png)

在这个例子中，先验值是![](Images/77bcd102-059d-4827-8e48-ebb7ebe62e33.png)。如果我们不知道真实的先验值，我们可以用一个基于我们经验的估计来代替，进行一个近似的计算。这就是贝叶斯定理的妙处。你可以用简单的成分计算复杂的条件概率。

贝叶斯定理具有巨大的价值和广阔的应用领域。贝叶斯理论甚至有自己的统计和推理方法分支。许多人认为贝叶斯观点更接近我们人类理解不确定性的方式，特别是先前的经验如何影响我们做出的决定。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 分布

概率与一系列结果或事件有关。我们用概率描述的许多问题都有共同的性质。在下图中，您可以看到钟形曲线:

![](Images/e75f1b9f-bef0-4888-96d2-2268f20267be.png)

钟形曲线或高斯分布以最可能的结果为中心，两端的尾部代表最不可能的结果。由于其数学特性，钟形曲线出现在我们世界的每一个地方。测量很多随机人群的身高，你会看到一条钟形曲线；看看你家草坪上所有草叶的高度，你就又看到了。计算一下你所在城市的人有一定收入的概率，又来了。

高斯分布是最常见的分布之一，但还有更多。概率分布是一种数学定律，它告诉我们事件不同可能结果的概率，以数学函数的形式表达。

当我们测量抛硬币事件的相对频率时，我们计算了所谓的经验概率分布。掷硬币也可以用伯努利分布来表示。如果我们想计算 n 次试验后正面朝上的概率，我们可以使用二项分布。

引入一个类似于在概率环境中使用的变量——随机变量——的概念是很方便的。随机变量是统计学的基本组成部分。每个随机变量都有一个分配给它的分布。按照惯例，随机变量用大写字母书写，我们使用~符号来指定分配给变量的分布:

![](Images/32946440-4404-446d-bd28-815b1df0db25.png)

这意味着随机变量 *X* 根据伯努利定律分布，成功概率(正面)等于 0.6。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 从数据样本计算统计数据

假设你正在做人类身高的研究，渴望发表一篇令人瞠目结舌的科学论文。为了完成你的研究，你需要测量你所在地区普通人的身高。有两种方法可以做到这一点:

*   收集你所在城市每个人的身高，并计算平均值
*   应用统计数据

统计学允许我们对人口的不同属性进行推理，而无需收集人口中每个人的完整数据集。从真实总体中随机选择数据子集的过程称为抽样。统计数据是使用样本中的值来汇总数据的任何函数。几乎每个人每天都在使用的无处不在的统计数据是样本平均值或算术平均值:

![](Images/6cfed050-984c-4092-b7ca-c64ae9932998.png)

我们随机抽取了 16 个人来计算平均身高。在下表中，我们可以看到四天内的高度:

| **日** | **高度** | **平均值** |
| 星期一 | 162 厘米，155 厘米，160 厘米，171 厘米 | 162.00 厘米 |
| 星期二 | 180 厘米，200 厘米，210 厘米，179 厘米 | 192.25 厘米 |
| 星期三 | 160 厘米，170 厘米，158 厘米，176 厘米 | 166.00 厘米 |
| 星期四 | 178 厘米，169 厘米，157 厘米，165 厘米 | 167.25 厘米 |
| 总数 |  | 171.88 厘米 |

我们每天收集四个高度的样本，总共 16 个高度。你的统计学家朋友弗雷德周五告诉你，他已经收集了 2000 人的样本，该地区的平均身高约为 170 厘米。

为了进行研究，我们可以看看您的样本平均值如何随着每个新数据点而变化:

![](Images/00996332-e5a5-406b-96ab-6d4f476833d9.png)

请注意，在第 2 天，平均值出乎意料地高。我们偶然发现了四个高个子，这可能只是碰巧。数据中的随机波动称为方差。

我们可以使用以下公式来测量样本方差:

![](Images/634c6613-06d9-452d-959d-2541f3dc820c.png)

样本方差总结了我们的数据，所以我们可以把它当作另一个统计量。方差越大，在计算出准确的平均值之前需要收集的样本量就越多，这样就会接近真实值。这种现象有一个名字——大数定律。你做的测量越多，你的估计就越准确。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 统计建模

统计不仅仅是简单地计算汇总数字。统计学最有趣的一个方面是建模。统计建模研究对数据做出一组统计假设的数学模型。为了更清楚，让我们回到天气的例子。我们收集了一个数据集，其中包含描述当前天气的随机变量:

*   平均风速
*   气湿
*   空气温度
*   在当地天空中看到的鸟类总数
*   统计学家的心情

利用这些数据，我们想推断哪些变量与降雨有关。为此，我们将建立一个统计模型。除了前面的数据，我们还记录了一个二元 rain 变量，如果下雨，它的值为 1，否则为 0。

现在，我们提出一组与数据相关的假设:

*   降雨概率服从伯努利分布。
*   下雨的可能性取决于我们收集的数据。换句话说，数据和下雨概率是有关系的。

你可能会觉得从概率的角度考虑下雨很奇怪。说上周三下雨概率 45%是什么意思？上周三是过去的一天，所以我们可以检查数据并检查是否有雨。诀窍是要明白，在我们的数据集中，有很多类似于星期三的日子。假设我们已经收集了以下值:

| **星期几** | **风速** | **湿度** | **温度** | **结果** |
| 星期一 | 5 米/秒 | 50% | 30 摄氏度 | 没有雨 |
| 星期二 | 10 米/秒 | 80% | 25 摄氏度 | 雨 |
| 星期三 | 5 米/秒 | 52% | 28 摄氏度 | 雨 |
| 星期四 | 3 米/秒 | thirty percent | 23 摄氏度 | 没有雨 |
| 星期五 | 8 米/秒 | 35% | 27 摄氏度 | 没有雨 |

在这个例子中，星期一和星期三非常相似，但是它们的降雨结果不同。在足够大的数据集中，我们可以找到完全匹配但结果不同的两行。为什么会这样？首先，我们的数据集不包括所有可能描述降雨的变量。收集这样的数据集是不可能的，所以我们假设我们的数据与雨有关，但没有完全描述它。测量误差、事件的随机性和不完整的数据使得降雨具有概率性。你可能想知道雨在本质上是否是概率性的？还是每一段雨都是预先定好的？为了检查降雨事件是否是确定性的，我们必须收集宇宙完整状态的每日快照，这是不可能的。统计和概率论帮助我们理解我们的世界，即使我们有不完善的信息。例如，假设我们的数据集中有 10 天与上周三相似。所谓相似，我的意思是我们收集的所有变量只有很小的差异。在这 10 天中，有 8 天是雨天，2 天是晴天。我们可以说，在上周三典型的一天，有 80%的可能性下雨。这是我们利用这些数据能够给出的最准确的答案。

有了关于数据的假设，我们就可以开始建模了。我们可以做出另一个假设，即存在某种数学模型 **M** ，它使用数据来估计下雨的概率。也就是说，模型 **M** 使用数据 **d** 来学习数据和降雨概率之间的关系。该模型将通过指定最接近我们数据集中真实结果的降雨概率来推断这种关系。

模型 **M** 的主要目标不是做出准确的预测，而是发现和解释关系。这是我们可以在统计学和机器学习之间划清界限的地方。机器学习寻求找到准确的预测模型，而统计学使用模型找到解释和诠释。目标不同，但允许模型从数据中学习的基本概念是相同的。现在，我们终于可以揭开这个模型 **M** 如何从数据中学习。我们将解开魔法，留下对机器学习背后的数学的直接理解。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 机器是如何学习的？

算法是如何学习的？我们如何定义学习？作为人类，我们一生中学到了很多。这对我们来说是一项自然的任务。在我们生命的最初几年，我们学习如何控制我们的身体，走路，说话，以及识别不同的物体。我们不断获得新的体验，这些体验改变了我们思考、行为和行动的方式。一段计算机代码能像我们一样学习吗？要接近机器学习，我们首先需要想出一种方法，将经验直接传输给算法。

在实际案例中，我们感兴趣的是教会算法更快、更好、更可靠地执行我们自己可以完成的各种特定任务。现在，我们将专注于预测和识别任务。因此，我们希望建立能够识别模式和预测未来结果的算法。下表显示了识别和预测任务的一些示例:

| 识别任务 | 这是高薪客户吗？这房子在目前的市场上值多少钱？图像中的那些对象是什么？ |
| 预测任务 | 该客户有可能在未来 6 个月内归还债务吗？下一季度我们会卖出多少？这项投资的风险有多大？ |

第一个想法可能是像人类一样进行学习，并通过语音、图像和示例集提供解释和示例。不幸的是，在以这种方式学习的同时，我们执行许多复杂的认知任务，如听、写和说。计算机算法本身无法像我们这样收集新的经验。相反，如果我们以数字数据的形式对我们的世界进行简化，会怎么样呢？例如，预测 Acme Co 的客户流失只能使用关于客户购买和产品评级的数据来完成。数据集越完整和充分，客户流失模型就可能越准确。

让我们看另一个例子。我们将建立一个机器学习项目成本估算器。该模型将使用项目的属性来计算成本估算。假设我们已经为我们公司的每个项目收集了以下数据属性:

| **属性名** | **属性类型** | **属性描述** | **可能值** |
| 属性数量 | 整数 | 项目数据集中数据属性的数量 | 0 到∞之间 |
| 数据科学家的数量 | 整数 | 客户要求的项目实施数据科学家的数量 | 0 到∞之间 |
| 综合 | 整数 | 与客户要求的客户软件系统集成 | 0 表示项目范围内没有集成1 用于项目范围内的集成 |
| 是一家大公司 | 整数 | 指明客户是否有大量员工 | 0 =客户的公司员工数大于 1001 =客户的公司员工数小于或等于 100 |
| 项目总成本 | 整数 | 总成本(美元) | 0 到∞之间 |

下表提供了包含这些属性的示例数据集:

| **属性数量** | **数据科学家的数量** | **整合** | **是一家大公司** | **项目总成本** |
| Ten | one | one | Zero | One hundred and thirty-five thousand |
| Twenty | one | Zero | one | One hundred and forty thousand |
| five | Two | one | Zero | One hundred and seventy-three thousand two hundred |
| One hundred | three | one | one | Three hundred thousand |

我们能想象的最简单的模型就是所谓的线性模型。它将乘以可变系数的数据属性相加，以计算项目成本估计值:

![](Images/4e5bca27-1c7f-4532-ac51-06629d71190b.png)

在这个简化的场景中，我们不知道成本变量的真实值。但是，我们可以使用统计方法，从数据中进行估计。让我们从一组随机参数开始:

*   基本成本= 50，000
*   每个数据属性的成本= 115
*   每位数据科学家的成本= 40，000 英镑
*   集成成本= 50，000
*   客户关系复杂性成本= 5，000

如果我们对数据集中的每个项目都使用这些参数，我们将得到以下结果:

***项目 1 总费用= 5 万+115×10+4 万×1+5 万×1+5 万×0 = 14.115 万***

***项目二总费用= 5 万+115×20+4 万×1+5 万×0+5 万×1 = 14.23 万***

***项目三总费用= 5 万+115×5+4 万×2+5 万×1+5 万×0 = 180575***

***项目 4 总造价= 5 万+115×100+4 万×3+5 万×1+5 万×1 = 28.15 万***

您可能已经注意到，这些值与我们数据集中的实际项目成本不同。这意味着，如果我们在任何实际项目中使用这个模型，我们的估计将是错误的。我们可以用多种方法来衡量这一误差，但让我们坚持最受欢迎的选择之一:

![](Images/8a0ef489-b139-450a-b4af-da5d63b5b94c.png)

有许多方法可以量化预测误差。它们都引入了不同的权衡和限制。误差度量选择是建立机器学习模型的最重要的技术方面之一。

对于总体误差，我们取所有项目的个别误差的算术平均值。我们计算出来的数字叫做**均方根误差** ( **RMSE** )。

这个度量的精确数学形式不是一个结果。RMSE 背后的逻辑很简单。虽然我们可以使用线性模型上的几个技术约束来推导 RMSE 公式，但数学证明超出了本书的范围。

事实证明，我们可以使用优化算法来调整我们的成本参数，使 RMSE 最小化。换句话说，我们可以找到使数据集中所有行的误差最小化的最佳成本参数。我们称这个过程为 MLE。

MLE 给出了一种在给定数据下估计统计模型参数的方法。它寻求最大化给定数据的参数概率。这听起来可能很难，但如果我们将定义重新表述为一个问题，这个概念就变得非常直观:我们应该设置什么参数，以便我们得到的结果将最接近数据？MLE 帮助我们找到了这个问题的答案。

让我们关注另一个例子来得到一个更一般的方法。假设我们已经开始了咖啡订阅服务。顾客在我们的移动应用程序中选择她最喜欢的咖啡口味，并填写地址和支付信息。之后，我们的快递员每天早上都会送来一杯热咖啡。app 内置了反馈系统。我们通过推送通知向客户推广季节性产品和折扣。去年用户数量大幅增长:已经有近 2000 人在使用这项服务，每月还有 100 多人在订阅。然而，我们的客户流失率正以令人不安的速度增长。营销优惠似乎不会产生很大的影响。为了解决这个问题，我们决定建立一个机器学习模型，提前预测客户流失。知道一个客户会流失，我们可以定制一个个性化的服务，让他们再次成为活跃用户。

这一次，我们将在定义上更加严谨和抽象。我们将定义一个模型 **M** ，该模型接受客户数据 **X** 和历史客户流失结果 **Y** 。我们称目标变量为 **Y** 。

下表描述了数据集的属性:

| **属性名** | **属性类型** | **属性描述** | **可能值** |
| 订阅月数 | 整数 | 用户订阅我们服务的月数 | 0 到∞之间 |
| 特别优惠已激活 | 整数 | 用户上个月激活的特别优惠的数量 | 0 到∞之间 |
| 工作日的杯数 | 浮动 | 上个月用户在工作日订购的平均杯数 | 1.0 到 5.0 |
| 周末的杯数 | 浮动 | 上个月用户在周末订购的平均杯数 | 1.0 到 2.0 |

这种表叫做数据字典。我们可以使用它来理解进出模型的数据，而无需查看代码或数据库。每个数据科学项目都必须有一个最新的数据字典。在本书的后面将会展示更多完整的数据字典的例子。

我们的目标变量 **Y** 可以用以下方式描述:

| **目标变量名** | **目标变量类型** | **目标变量描述** | **目标变量可能值** |
| 搅拌 | 整数 | 指示用户上个月是否停止使用我们的服务 | 0 或 1 |

给定客户描述![](Images/47db3c92-704a-4938-a88d-aededf2bbb93.png)，模型输出流失概率![](Images/0afcd35b-e59e-4f4d-93c6-8d4a7542ad7f.png)。给![](Images/e52dbafb-bbd9-49d6-b4b2-c433dcdc1282.png)戴上帽子意味着![](Images/0afcd35b-e59e-4f4d-93c6-8d4a7542ad7f.png)不是一个真实的流失概率，而只是一个可以包含误差的估计。该值不会严格为零或一。相反，模型将输出 0%到 100%之间的概率。例如，对于一些客户![](Images/47db3c92-704a-4938-a88d-aededf2bbb93.png)，我们得到了 76%的![](Images/0afcd35b-e59e-4f4d-93c6-8d4a7542ad7f.png)。我们可以这样解释这个值:根据历史数据，这个客户的流失率预期是 76%。或者说，100 个像客户![](Images/30287e69-02b1-4fbb-9a6d-527793dd6d66.png)这样的客户，会有 76 个流失。

机器学习模型必须有一些可变参数，这些参数可以改变以更好地匹配客户流失结果。既然我们已经使用了公式，我们就不能在不引入至少一个希腊字母的情况下继续。我们模型的所有参数将由![](Images/3457eb94-12b2-4edd-ab4e-622dec683370.png)表示。

现在，我们一切就绪:

*   历史客户数据![](Images/e5c22cd2-7bee-4f0f-9ab5-4a14b5f72c4a.png)和流失结果![](Images/b9742446-b92d-4048-988c-bd56185c6a35.png)，我们称之为训练数据集![](Images/03798ff0-0bc9-462d-acdc-7444803b369b.png)
*   机器学习算法![](Images/5b08d2dd-01fb-4d28-90dd-af668b42920d.png)接受客户描述![](Images/747c1c74-c079-4d1c-b27c-f584b284b30c.png)并输出客户流失概率![](Images/80513bf6-2166-4fb5-b16d-ba7c898db5cb.png)
*   可以使用 MLE 调整的模型参数![](Images/667c9f2f-7ffa-4be7-9f9e-9b705773a02e.png)

我们将使用训练数据集![](Images/8d37f0bc-1c35-40e5-9b5c-e2533fdc2bcd.png)上的 MLE 来估计我们的模型![](Images/0c1721ef-3faa-45cd-98a4-77a06950ed10.png)的参数![](Images/25e1af35-cbdd-413b-9e89-de80eadc420a.png)。我在![](Images/2ceb9466-e565-4ecc-8ac6-eeef6dc17921.png)上放了一顶帽子，表示理论上可能有最佳参数集![](Images/2ceb9466-e565-4ecc-8ac6-eeef6dc17921.png)，但实际上我们的数据有限。因此，我们所能得到的最佳参数集只是一个可能包含误差的真值估计。

现在，我们终于可以使用我们的模型来预测客户流失
概率![](Images/b8b4a596-2252-4c58-9284-940b53d5864b.png):

![](Images/af320444-5ea3-465c-b4ac-ac4cefe58fe4.png)

概率的精确解释很大程度上取决于我们用来估计这个概率的模型。一些模型可以用来给出概率性的解释，而另一些则不具备这样的品质。

注意，我们没有明确定义我们使用的机器学习模型的种类。我们已经定义了一个从数据中学习的抽象框架，它不依赖于特定的数据或它使用的具体算法。这就是数学的美妙之处，它开启了无限的实际应用。有了这个抽象的框架，我们可以想出许多具有不同权衡和能力的模型 **M** 。机器就是这样学习的。

**如何选择型号**

There are many different types of machine learning models and many estimation methods. Linear regression and MLE are among the simplest examples that show the underlying principles that lie beneath many machine learning models. A theorem called the **no free lunch theorem** says that there is no model that will give you the best results for each task for every dataset. Our machine learning framework is abstract, but this does not mean it can yield a perfect algorithm. Some models are best for one task, but are terrible for another. One model may classify images better than humans do, but it will fail at credit scoring. The process of choosing the best model for a given task requires deep knowledge of several disciplines, such as machine learning, statistics, and software engineering. It depends on many factors, such as statistical data properties, the type of task we are trying to solve, business constraints, and risks. That is why only a professional data scientist can handle the selection and training machine of learning models. This process has many intricacies and explaining all of them is beyond the scope of this book. An interested reader may refer to the book list at the end of this book. There you can find free books that explain the technical side of machine learning in great depth.<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 探索机器学习

现在你已经理解了如何使用数学和统计学定义学习过程的一般思路，我们可以探索机器学习的内部工作方式了。机器学习研究能够在没有明确指示的情况下学习和执行特定任务的算法和统计模型。由于每个软件开发经理都应该在计算机编程方面有一些专业知识，数据科学项目经理应该了解机器学习。掌握任何机器学习算法之间的基本概念将允许您更好地理解您项目的限制和要求。这将有助于您和团队中的数据科学家之间的沟通，增进相互理解。基本机器学习术语的知识会让你用数据科学的语言说话。

我们现在将深入流行的机器学习算法背后的主要直觉，为了只见树木不见森林，我们省略了技术细节。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 定义机器学习的目标

当我们谈论机器学习时，我们谈论的是准确的预测和识别。统计学家经常使用简单但可解释的模型，并有严格的数学基础来解释数据和证明观点。机器学习专家建立更复杂的模型，这些模型更难解释，通常像黑盒一样工作。因此，许多机器学习算法更适合预测质量，而不是模型可解释性。趋势变化缓慢，尽管越来越多的研究人员研究模型解释和预测解释的主题，但机器学习的主要目标仍然是创建更快、更准确的模型。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 使用生命周期来构建机器学习模型

当创建机器学习模型时，我们通常遵循一组固定的阶段:

*   **探索性数据分析师** : 在这个阶段，数据科学家使用一套统计和可视化技术来更好地理解数据。
*   **数据准备**:在这一部分，数据科学家将数据转换成适合应用机器学习算法的格式。
*   **数据预处理**:在这里，我们清理准备好的数据，并对其进行转换，以便机器学习算法可以正确地使用数据的每一部分。
*   **建模**:在这一部分，一名数据科学家训练机器学习模型。
*   **测试**:在这个阶段，我们使用一组度量其性能的指标来评估模型。

在我们取得足够好的结果之前，这个过程要重复很多次。您可以应用生命周期来训练多种机器学习模型，我们将在接下来进行探索。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 线性模型

机器学习模型的最基本类型是线性模型。在前一节中，我们已经看到了一个线性模型的详细例子。线性模型的预测可以通过查看模型的系数来解释。系数越大，它对最终预测的贡献就越大。虽然简单，但这些模型往往不是最准确的。线性模型速度快，计算效率高，这使得它们在具有大量数据和有限计算资源的环境中很有价值。

线性模型快速、高效、简单且易于解释。它们可以解决分类和回归问题。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 分类和回归树

**分类和回归树** ( **推车**)采用非常直观的方法进行预测。基于训练数据构建决策树。如果我们使用 CART 进行信用违约风险任务，我们可能会看到这样一个模型:

![](Images/5bd3570c-9d49-4528-8331-e3d564709153.png)

为了进行预测，算法从树的顶部开始，并根据数据中的值进行连续选择。对于二元分类，在树的底部，您将获得相似客户的肯定案例的比例。

虽然简单，但手推车模型有两个缺点:

*   预测准确率低。
*   单个数据集有许多可能的树。一棵树可能比另一棵树具有更好的预测准确性。

但是 CART 如何为拆分选择列和值呢？我们将探索 CART 在二进制分类上的一般逻辑:

1.  首先，它取一个单独的列，并针对该列的每个值将数据分成两部分。
2.  然后，它计算每次拆分的阳性案例的比例。
3.  对于数据中的每一列，重复*步骤 1* 和*步骤 2* 。
4.  我们根据数据分割的好坏对每个分割进行排名。如果分割完美地分割了数据集，那么正例将适用于低于阈值的所有值，而负例将位于另一侧。举例来说，如果**年龄> 25** 是一个完美的分裂，那么所有小于 25 岁的客户将有信用违约，而所有大于 25 岁的客户将有一个完美的信用记录。
5.  根据*步骤 4* ，为树的当前级别选择最佳分割。数据集根据分割值分为两部分。
6.  对于每个新的数据集部分，重复步骤 1 到 *5* 。
7.  该过程在算法满足停止标准之前继续。例如，我们可以通过查看决策树的深度或下一次拆分可用的最小数据点数来停止构建树。

我们也可以将 CART 应用于回归问题，尽管算法会稍微复杂一些。CART 简单且可解释，但它产生的模型很弱，很少在实践中应用。但是，算法的性质和实现技巧允许我们将它们的最弱点作为它们的主要优势。我们将在下一节学习如何利用这些属性。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 集合模型

假设你拥有一家零售店的特许经营权。业务正在增长，你准备建立一个新的商店。问题是，你应该把它建在哪里？建筑位置的选择极其重要，因为它是永久性的，它定义了将进入你的商店的当地客户群。

你有几个选择来做这个决定:

1.  自己决定。
2.  征求最有能力的员工的意见。
3.  询问许多经验稍少的员工的意见。

*选项 1* 和 *2* 包含一个和两个做出决定的人。*选项 3* 包含多位专家的意见。从统计上来看，选项 3 可能会产生更好的决策。即使是世界级的专家也会犯错误。几个专业人士，互相分享信息，更有可能成功。这就是为什么在大社区生活和在大机构工作会有好结果的原因。

在机器学习中，这个原理也适用。许多模型有助于在集合中做出单一决策。模型集合往往比单一模型更准确，包括最先进的模型。不过，要小心；你需要建立许多模型来创造一个合奏。大量的模型会非常快速地增加计算资源需求，从而在预测精度和速度之间进行权衡。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 基于树的集成

一个特别有用的集成模型是决策树。有一整类机器学习模型致力于创建树集合的不同方式。这种类型的模型是 Kaggle 结构化数据竞赛中最常见的赢家，因此理解它是如何工作的非常重要。

树是构建集成的良好候选者，因为它们具有高方差。由于树构建算法的随机性，即使数据集没有变化，每个决策树都与前一个不同。每次我们建立一个决策树，我们可能会得出一些与以前不同的东西。因此，每棵树都会犯不同的错误。回想一下下图:

![](Images/d148d81a-041f-4c10-ac00-aee5b322721b.png)

原来决策树的偏差极低，方差很高。想象一下，许多不同的树为每个个体做出数百个预测，形成一个整体。如果我们平均所有的预测会发生什么？我们会离真正的答案更近一步。当在集成中使用时，决策树可以以高预测精度处理复杂数据集。

在下图中，您可以看到多棵树如何创建集合:

![](Images/9686fcd0-4f5a-4686-89e7-53a94528923b.png)

如果您正在处理结构化数据，请确保在进入机器学习的其他领域(包括深度学习)之前尝试决策树集成。十有八九，结果会让你和你的客户都满意。媒体往往忽略了这个算法的价值。对集成模型的赞美很少发现，但它可以说是解决实际应用的机器学习问题最常用的算法家族。一定要给树合奏一个机会。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 聚类模型

机器学习的另一个有用的应用是聚类。与我们在本节中研究的其他机器学习问题相比，聚类是一个无监督的学习问题。这意味着聚类算法可以处理未标记的数据。为了说明这一点，让我们来看看营销部门的核心任务——客户细分。为每个客户提供营销优惠可能是不可能的。例如，如果您拥有一个大型零售商店网络，您希望根据客户的兴趣在商店应用不同的折扣来促进销售。为了做到这一点，营销部门创建客户细分市场，并为每个特定的细分市场定制营销公司。

在下图中，您可以看到六个客户被分配到两个不同的细分市场:

![](Images/455c6dc0-8c82-42f8-b509-634317dc759e.png)

我们可以通过获取所有客户的所有购买历史，并应用聚类算法将相似的客户分组在一起，来实现客户细分的自动化。该算法会将每个客户分配到一个单独的细分市场，从而允许您进一步分析这些细分市场。在探索每个细分市场的数据时，您可能会发现有趣的模式，这些模式将为针对这一特定客户细分市场的新营销方案提供见解。

我们可以以特别的方式将聚类算法应用于数据，因为它们不需要预先标记。然而，情况可能会变得复杂，因为许多算法受到维数灾难的困扰，无法处理数据中的许多列。

最流行的聚类算法是 K-means。该算法最简单的形式只有一个参数:要在数据中查找的聚类数。K-means 从几何的角度处理聚类。将每个数据行想象成空间中的一个点。对我们来说，这种想法对于具有两个或三个点的数据集来说很容易，但它在三维之外也很有效。在几何空间中布置了数据集后，我们现在可以看到一些点彼此更加靠近。K-means 查找中心点，其他点围绕这些中心点聚集。

它迭代地这样做，如下所示:

1.  它采用当前的聚类中心(对于第一次迭代，它采用随机点)。
2.  它遍历所有数据行，并将它们分配到最近的聚类中心点。
3.  它通过对来自*步骤 2* 的所有点的位置进行平均来更新聚类中心。

下图解释了该算法:

![](Images/47842a77-e1b1-48d7-a5e7-af9423a38a22.png)

至此，我们结束了对机器学习的介绍。虽然还有很多机器学习算法需要研究，但描述它们已经超出了本书的范围。我确信你会发现关于回归、决策树、集合模型和聚类的知识涵盖了实际应用的惊人的大部分，并将很好地为你服务。现在我们已经准备好进入深度学习了。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 探索深度学习

对图像进行分类的深度神经网络比我们做得更好，创造了一种极其复杂的模型的印象，其内部结构受到我们自己大脑结构的启发。事实上，神经网络背后的中心思想很容易理解。虽然第一个神经网络确实受到了我们大脑物理结构的启发，但这种类比不再成立，人类大脑内部物理过程的关系主要是历史的。

为了揭开神经网络的神秘面纱，我们将从基本构件开始:人工神经元。一个人工神经元无非是两个数学函数。第一种方法将一串数字作为输入，并通过使用其内部状态(权重)来组合它们。第二个函数是激活函数，它接受第一个函数的输出并应用特殊的转换。激活函数告诉我们这个神经元对特定的输入组合有多活跃。在下图中，您可以看到人工神经元如何将输入转换为输出:

![](Images/9c3f5af2-af84-4bb6-9cc6-68693be66f4a.png)

在下图中，我们可以看到最流行的激活函数的曲线图:

![](Images/5077ba7a-3bcb-48b0-9387-9512feaad043.png)

如果输出小于 0，该函数将输出 0。如果它更大，它将回显它的输入。很简单，不是吗？试着想出这个函数的名字。我知道，命名很难。名字应该简单，同时传达关于你所命名的事物的核心概念的深刻见解。当然，数学家们知道这一点，正如我们之前多次目睹的那样，他们想出了一个完美而清晰的名字——**整流线性单位** ( **ReLU** )。一个有趣的事实是，ReLU 并不符合激活函数的基本要求，但仍然给出了比其他替代方案更好的结果。在特定的情况下，其他激活函数可能更好，但在作为一个明智的默认设置方面，它们都不如 ReLU。

你需要知道的另一个重要的激活函数是 sigmoid。你可以在下面的截图中看到:

![](Images/262339b8-8361-415e-9196-6a9a8132fd08.png)

在 ReLU 登上王位之前，sigmoid 作为激活功能是一个受欢迎的选择。虽然它作为激活功能的价值已经消退，但由于另一个原因，乙状结肠仍然很重要。它经常出现在二元分类问题中。如果你仔细观察这个图，你会发现它可以将任何数字映射到 0 到 1 之间的范围。这一特性使得 sigmoid 在对二元分类问题建模时非常有用。

请注意，我们在二进制分类问题中使用 sigmoid，并不是因为它可以方便地将任何数字映射到 0 到 1 之间。这一有用特性背后的原因是 sigmoid(也称为逻辑函数)与伯努利概率分布密切相关。这种分布描述了以 0 到 1 之间的概率 ***、p*** 发生的事件。例如，伯努利分布可以用 ***p = 0.5*** 或 50%来描述抛硬币。正如你所看到的，任何二元分类问题都可以用伯努利分布来自然地描述。要了解如何，请看下面的问题:*客户点击广告的概率有多大？* *客户在负债的情况下声明违约的概率有多大？*我们可以将这些情况建模为伯努利分布。

现在，我们知道了人工神经元的主要组成部分:权重和激活函数。为了让神经元工作，我们需要获取它的输入，并将其与神经元权重相结合。为此，我们可以回忆一下线性回归。线性回归模型通过将每个属性乘以一个权重，然后求和来组合数据属性。然后，应用一个激活函数，你就会得到一个人工神经元。如果我们的数据行有两个名为 *a* 和 *b* 的列，那么神经元将有两个权重![](Images/99978480-9cf3-4eea-aaaf-8ea1d21db412.png)和![](Images/9fa78070-be91-46b4-8591-9efde6594188.png)。ReLU 激活神经元的公式如下所示:

![](Images/126417e1-835a-47ee-9965-2ca8eae45ded.png)

请注意，![](Images/ccfa7b45-6039-45f6-a898-d338ee0a57aa.png)是一个称为偏差的特殊权重，它不依赖于任何输入。

所以，人工神经元只是一堆乘法和加法:

![](Images/e7aa98f4-39cf-4175-8f6a-edebbe2efc87.png)

或者，给你一个实际计算的更具体的例子，看看下面的例子:

![](Images/4b19e3f6-cd57-4c7f-93e9-0ea1b7d8ec5c.png)

通过将每一项乘以一个常数并将结果相加来组合数字的操作在机器学习和统计中无所不在。它被称为两个向量的线性组合。你可以把向量想象成一组固定的数字。在我们的示例中，第一个向量是一个数据行，第二个向量包含每个数据属性的权重。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 构建神经网络

我们准备建立我们的第一个神经网络。我们先来举个例子:我们公司正在努力留住客户。我们非常了解我们的客户，我们可以创造一个让他们愿意留下来的优惠。问题是，我们无法确定哪些客户会流失。因此，我们的老板 Jane 要求我们建立一个客户流失预测模型。该模型将获取客户数据，并预测下个月的搅动概率。有了这个概率估计，Jane 可以决定她是否需要为这个客户创建一个个性化的营销提议。

我们已经决定使用神经网络来解决这个流失预测问题。我们的网络将由多层神经元组成。每一层中的神经元将连接到下一层中的神经元:

![](Images/f6042a5e-ca74-4211-8ab6-71fc811bb9e3.png)

那是许多箭，不是吗？两个神经元之间的连接意味着一个神经元会将其输出传递给下一个神经元。如果一个神经元接收到多个输入，它们都被累加。这种类型的网络被称为**全连接神经网络** ( **FCNN** )。

我们看到了如何使用神经网络进行预测，但是我们如何学习进行什么预测呢？如果你仔细观察，神经网络只不过是一个具有许多权重的大函数。通过使用权重和通过神经元输入传入的信息来确定模型预测。因此，要有一个精确的神经网络，你必须设置正确的权重。我们已经知道，我们可以使用数学优化和统计学，通过改变函数的参数来最小化预测误差。神经网络只不过是一个具有可变权重的大型复杂数学函数。因此，我们可以使用最大似然法和梯度下降法来进行优化。我将用粗体给出每个阶段的正式名称，然后是每个阶段的直观解释:

1.  **网络初始化**:首先我们可以用随机值初始化我们的权重。
2.  **向前传递**:我们可以从我们的训练数据集中取一个例子，并使用我们当前的一组权重进行预测。
3.  **损失函数计算**:我们测量我们的预测和地面实况之间的差异。我们希望这种差异尽可能接近 0。也就是说，我们希望最小化损失函数。
4.  **后向传递**:我们可以使用优化算法来调整权重，这样预测会更准确。一种称为反向传播的特殊算法可以计算每层神经元的更新，从最后一层到第一层。
5.  *重复步骤 1* 到 *4* ，直到达到所需的精度水平，或者直到网络停止学习:

![](Images/831809c3-879a-425f-817f-e9794f8d8d9a.png)

反向传播是训练神经网络最广泛使用的学习算法。它采用预测误差，并计算我们应该改变网络中每个权重的多少，以使预测更接近实际情况。反向传播这个名称来自于算法更新权重的特定方式:它从最后一层开始，将变化传播到每个神经元，直到它到达网络输入。当输入通过网络计算输出预测时，我们称之为前向传递。当我们通过传播误差来改变权重时，我们称之为反向传递。

现在，有许多不同类型的构建模块可以用来组成神经网络。一些特定的神经元类型更好地处理图像数据，而另一些则可以利用文本的顺序性质。发明了许多专门的层来提高训练速度和对抗过度配合。专用于解决特定任务的神经网络中的层的特定组合被称为神经网络架构。所有的神经网络架构，不管有多复杂多深入，仍然符合反向传播的基本规律。接下来，我们将探索深度学习的特定领域应用。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 计算机视觉导论

首先，我们将看看计算机视觉。先说个例子。我们的客户乔喜欢动物。他是六只猫和三只狗的快乐主人。作为一个快乐的主人，他也喜欢给他的宠物拍照。多年来，他的电脑上积累了大量的照片档案。乔已经决定，他需要把他那可怕的照片文件夹整理一下，里面有 50，000 张宠物照片。为了帮助乔，我们决定创建一个神经网络，它可以拍摄图像，并判断照片上是猫还是狗。下图显示了神经网络分类器如何处理猫照片:

![](Images/9b1832d8-40c9-4ec3-9fc2-139563cc4f82.png)

首先，我们将一幅图像转换成三个数字表，每个像素的红色、绿色和蓝色通道各有一个。如果我们像以前一样试图使用一个普通的 FCNN，我们将看到不起眼的结果。深度神经网络在计算机视觉任务中表现出色，因为有一种特定的神经元类型，称为卷积滤波器或卷积。**卷积神经网络**(**CNN**)是由法国机器学习研究者 Yann LeCun 发明的。在 CNN 中，单个神经元可以查看图像的一小块，比如说 16×16 像素，而不是将整个像素集作为输入。这种神经元可以遍历图像的每个 16×16 的区域，检测它通过反向传播学习到的图像的一些特征。然后，这个神经元可以将信息传递到更远的层。在下图中，您可以看到单个卷积神经元穿过小图像块，并试图检测类似毛皮的图案:

![](Images/f2936bd0-cc7e-4adb-b9ed-c5b1c69afbd5.png)

CNN 的显著成就在于，单个神经元可以重复使用少量的权重，但仍然可以覆盖整个图像。这个特性使得 CNN 比普通的神经网络更快更轻。这个想法直到 21 世纪 10 年代才得以实现，当时 CNN 在 ImageNet 比赛中击败了所有其他计算机视觉方法，其中一种算法必须学会在 21，000 种可能的类别之间对照片进行分类。CNN 的开发花了这么长时间，因为我们缺乏在大数据集上用大量参数训练深度神经网络的计算能力。为了获得良好的准确性，CNN 需要大量的数据。例如，ImageNet 竞赛包括 1，200，000 幅训练图像。

在第一层，CNN 倾向于检测简单的模式，例如图像中的边缘和轮廓。随着层深度的增加，卷积滤波器变得更加复杂，可以检测眼睛、鼻子等特征。

在以下可视化中，您可以看到神经网络不同层的卷积滤波器的示例可视化:

![](Images/2a479028-5b00-4e7d-a173-4cc0daff5cdf.png)

许多神经元学会识别对任何计算机视觉任务都有用的简单模式。这一观察让我们想到了一个非常重要的想法:一个被训练得能很好地执行一项任务的神经网络，可以被重新训练来执行另一项任务。此外，第二个任务需要的训练数据要少得多，因为网络已经从之前的训练数据集中学习了许多有用的特征。特别是，如果你想从零开始训练两个类别的 CNN 分类器，你将需要标记数万张图像才能达到良好的性能水平。但是，如果您使用的网络是在 ImageNet 上预先训练的，那么您可能只需要 1，000 到 2，000 个图像就可以获得良好的效果。这种方法被称为迁移学习。迁移学习不仅限于计算机视觉任务。近年来，研究人员在将它用于其他领域方面取得了重大进展:自然语言处理、强化学习和声音处理。

现在你已经了解了深度 CNN 是如何工作的，我们将进入语言领域，在那里深度学习改变了一切。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 自然语言处理导论

在深度学习革命之前，**自然语言处理** ( **NLP** )系统几乎完全基于规则。语言学家创造了复杂的解析规则，并试图定义我们语言的语法来自动完成诸如词性标注或命名实体识别等任务。不同语言之间的人工翻译和自由形式的问题回答属于科幻小说的范畴。NLP 系统很难维护，并且需要很长时间来开发。

与计算机视觉一样，深度学习席卷了 NLP 世界。基于深度学习的 NLP 算法成功地在不同语言之间进行接近人类水平的翻译，可以测量文本的情感情绪，可以学习从文本中检索信息，并可以生成自由形式问题的答案。深度学习的另一个巨大好处是统一的方法。单一的词性标注模型架构将适用于法语、英语、俄语、德语和其他语言。您将需要所有这些语言的训练数据，但是底层模型将是相同的。有了深度学习，我们不需要试图硬编码我们模糊语言的规则。虽然许多任务，如长格式写作和人机对话，对于深度学习来说仍然是不可征服的，但 NLP 算法在商业和日常生活中是一个很大的帮助。

对于 NLP 深度学习来说，一切都始于一个想法:一个词的意义是由其邻居定义的。也就是说，要学习一门语言和单词的意思，你所需要的就是理解课文中每个单词的上下文。这个想法可能看起来太简单而不真实。为了检查其有效性，我们可以创建一个神经网络，通过接收周围的单词作为输入来预测一个单词。为了创建训练数据集，我们可以使用任何语言的任何文本。

如果我们取两个单词的上下文窗口，那么我们可以为这个句子生成以下训练样本:

如果，我们，拿，a →会

我们，可以，跟随，训练→生成

跟踪，培训，用于，这→样本

诸如此类…

接下来，我们需要想出一个将所有单词转换成数字的方法，因为神经网络只理解数字。一种方法是将文本中所有唯一的单词分配给一个数字:

跟随→ 0

培训→ 1

样本→ 2

For → 3

这→ 4

…

然后，我们用神经网络中的一组权重来表示每个单词。具体来说，我们从 0 和 1 之间的两个随机数开始每个单词。

我们将所有数字放入一个表中，如下所示:

| **单词标识符** | **词向量** |
| Zero | 0.63, 0.26 |
| one | 0.52, 0.51 |
| Two | 0.72, 0.16 |
| three | 0.28, 0.93 |
| four | 0.27, 0.71 |
| … | … |
| 普通 | 0.37, 0.34 |

现在我们有办法把文本中的每个单词都转换成一对数字。我们将把我们生成的所有数字作为神经网络的权重。它将获得四个单词作为输入，将它们转换成八个数字，并使用它们来预测中间单词的标识符。

例如，对于跟随的训练样本**，**训练**，**对于**，**这个** → **样本**:**

输入:

跟随→ 0 → 0.63，0.26

训练→ 1 → 0.52，0.51

For → 3 → 0.28，0.93

这个→ 4 → 0.27，0.71

输出:

2 →样品

我们称每一对与一个单词相关的数字为单词向量。我们的神经网络会输出一个从 0 到 1 的概率向量。这个向量的长度将与数据集中唯一单词的总数相匹配。然后，概率最大的数字将代表根据模型最有可能完成我们输入的单词。

在这种设置中，我们可以应用反向传播算法来调整单词向量，直到模型将正确的单词匹配到它们的上下文。在我们的例子中，你可以想象每个单词都存在于一个坐标网格中。单词 vector 的元素可以表示 *X* 和 *Y* 坐标。如果你以这种几何方式思考单词，你可能会得出结论，你可以加上或减去单词向量来得到另一个单词向量。在现实世界中，这样的向量包含不是两个而是 100 到 300 个元素，但是直觉是一样的。经过多次训练迭代，你会看到显著的效果。

尝试使用单词向量计算以下内容:

国王-男人+女人=？

你会得到一个单词 Queen 的向量。通过学习将单词放入其周围的上下文，该模型学习不同的单词如何相互关联。

我们建立的模型叫做 Word2Vec。我们可以通过两种方式训练 Word2Vec 模型:

*   通过周围的上下文来预测一个单词。这种设置被称为**连续的单词包** ( **CBOW** )。
*   通过单词预测周围的上下文。这种设置称为**skip program**。

除了模型输入和输出规范之外，这两种方法没有任何不同。

单词向量也称为单词嵌入。嵌入比简单的数字标识符包含更多的单词信息，NLP 模型可以使用它们来获得更好的准确性。例如，您可以通过以下步骤来训练情感分类模型:

1.  创建包含用户评论及其观点的训练数据集，将 0 标记为负面，将 1 标记为正面。
2.  将用户评论嵌入到多组词向量中。
3.  使用该数据集训练深度学习分类器。

当前最先进的模型很少使用通过训练单独的模型而创建的单词嵌入。较新的架构允许动态学习特定任务的单词嵌入，而不需要使用 Word2Vec。尽管如此，我们已经在这一章中讨论了单词嵌入，因为它们让我们了解了计算机如何理解文本的意思。尽管现代模型更复杂、更稳健，但这一理念仍保持不变。

嵌入的概念起源于自然语言处理，现在已经应用于推荐系统、人脸识别、具有大量分类数据的分类问题等许多领域。

要训练使用单词嵌入的分类器，可以使用 CNN。在 CNN 中，每个神经元在单词窗口中逐步扫描输入文本。卷积神经元学习权重，这些权重将邻近单词的单词向量组合成更紧凑的表示，输出层使用这些表示来估计句子情感。

在下面的截图中，您可以看到单个卷积神经元如何处理单个句子:

![](Images/646d01d6-47ca-4bfb-90a4-4fe58f5377c2.png)

CNNs 在一个固定的窗口中处理文本，这是一个过于简化的过程。事实上，句子开头的一个词会影响它的结尾，反之亦然。另一种称为**递归神经网络** ( **RNNs** )的架构可以处理任意长度的序列，从头到尾传递信息。这是可能的，因为所有的复发性神经元都与其自身相连:

![](Images/22883415-c01e-4a97-a129-683dfaea54c0.png)

自连接允许神经元循环通过其输入，在每次迭代中拉动其内部状态:

![](Images/4d0fd715-8483-4a27-bf57-9285aa83c472.png)

前面的屏幕截图描述了一个单独的循环神经元的展开。随着每个新单词的出现，一个循环神经元会改变其先前的状态。当最后一个字被处理时，它返回其内部状态作为输出。这是最基本的递归架构。实践中使用的神经网络具有更复杂的内部结构，但是循环连接的思想仍然成立。说到循环网络，你可能会听说**长短期记忆网络** ( **LSTMs** )。虽然它们在细节上有所不同，但对于 rnn 和 LSTMs 来说，思路是相同的。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 摘要

在这一章中，我们揭示了机器学习和深度学习的内部工作原理。我们学习了数学优化和统计学的主要概念。我们将它们与机器学习联系起来，最后，了解了机器如何学习，以及我们如何使用优化算法来定义学习。最后，我们讨论了流行的机器学习和深度学习算法，包括线性回归、树集成、CNN、单词嵌入和递归神经网络。本章结束了我们对数据科学的介绍。

在下一章中，我们将学习如何建立和维持一个能够交付复杂的跨职能项目的数据科学团队。