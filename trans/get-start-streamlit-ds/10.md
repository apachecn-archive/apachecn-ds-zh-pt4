

# *第八章*:用 Heroku 和 AWS 部署 Streamlit 应用

在 [*第 5 章*](B16864_05_Final_VK_ePub.xhtml#_idTextAnchor056) 、*部署具有 Streamlit 共享的 Streamlit*中，我们学习了如何部署具有 Streamlit 共享的 Streamlit 应用。Streamlit 共享对于大多数应用程序来说快速、简单且非常有效，但也有一些缺点，主要是我们受到一次只能托管三个免费应用程序的限制，并且我们也受到手头计算能力的限制。以下节选自 Streamlit 分享页面:

在共享执行环境中，应用程序可以获得多达 1 个 CPU、800 MB RAM 和 800 MB 专用存储。

如果您希望一次部署三个以上的应用程序，或者在运行时需要更多的计算，例如，更复杂的 ML 模型将受益于 GPU 或更多的 RAM，那么本章就是为您准备的！我们将介绍如何在 AWS 和 Heroku 上建立帐户，以及如何在那里完全部署您的 Streamlit 应用程序。

在本章中，我们将讨论以下主题:

*   在 AWS、Streamlit 共享和 Heroku 之间选择
*   使用 Heroku 部署 Streamlit
*   使用 AWS 部署 Streamlit

# 技术要求

以下是本章所需的分期付款列表:

*   **Heroku account** : Heroku 是一个受欢迎的平台，数据科学家和软件工程师使用它来托管他们的应用程序、模型和 API(应用程序编程接口)，由 Salesforce 所有。要获得 Heroku 帐户，请前往 https://signup.heroku.com 的创建您的免费帐户。
*   Heroku 命令行界面 ( **CLI** ):为了有效地使用 Heroku，我们需要下载 Heroku CLI，这将允许我们运行 Heroku 命令。要下载这个，请按照这里列出的说明:【https://devcenter.heroku.com/articles/heroku-cli】T4。
*   **亚马逊网络服务** ( **AWS** ) **账号**:在我们可以使用 AWS 之前，我们首先需要注册我们自己的亚马逊账号，你可以在[https://aws.amazon.com/free](https://aws.amazon.com/free)进行注册。谢天谢地，有一个慷慨的免费层提供给学生。初创企业创始人和企业家以及非营利组织都有 edu 账户。一旦你做到了这一点，我强烈建议在你的账户上设置账单提醒(更多细节见[https://console.aws.amazon.com/billing/home?#preferences](https://console.aws.amazon.com/billing/home?#preferences)以确保你不会超出你的免费等级，当你部署了自己的应用程序时，确保你不会花费超过预期。
*   **PuTTy** (仅限 Windows):如果你使用的是 Windows，你需要下载并安装 PuTTy 程序，它允许 Windows 操作系统使用一种叫做**安全外壳** ( **SSH** )的协议。要下载腻子，前往[https://www.putty.org/](https://www.putty.org/)并按照安装说明。然后，无论我们在本章的什么地方使用 SSH，打开 PuTTY 并像平常一样按照指示操作！

既然有了要求，那就开始吧！

# 在 AWS、Streamlit Sharing 和 Heroku 之间做出选择

在一个高的层面上，每当我们正在尝试部署我们的 Streamlit 应用程序，以便互联网上的用户可以看到我们的应用程序，我们真正做的是租用别人(如亚马逊)拥有的计算机，并给那台计算机一套启动我们的应用程序的指令。如果没有部署系统的背景或者没有首先尝试每个选项，很难知道选择使用哪个平台，但是有一些启发应该可以帮助您。做出这一决定的两个最重要的因素是系统的灵活性和启动并运行所需的时间。请注意，这两个因素直接相互抵消。如果你正在使用 Streamlit 共享，你不能说“我想让它在 macOS 上运行，我想给这个应用程序添加两个 GPU，”等等，但作为回报，你会得到一个非常简单的过程，你可以简单地将 Streamlit 共享指向你的 GitHub 存储库，它会负责所有其他需要做出的小决定。

另一方面，AWS 和 Heroku 给你更多的灵活性，但需要时间来设置(你会发现！).两者之间最大的区别是 Heroku 是一个作为服务产品的平台，而 Amazon 是一个作为服务产品的基础设施，这意味着，实际上，Heroku 通过允许你做一些事情，比如提供更多的计算资源，比 AWS 更快地部署，Heroku 给了你更多的灵活性。

![Figure 8.1 – Heroku versus AWS versus Sharing
](image/B16864_08_1.jpg)

图 8.1–Heroku 对比 AWS 对比共享

然而，AWS 的优势在于它的高度灵活性。AWS 将让你在 Ubuntu、macOS、Windows 和 Red Hat Linux 之间进行选择，在几十种不同的数据库类型之间进行选择，并且看起来是无限可定制的。当你制作你的 Streamlit 应用程序时，如果你想得到一个快速的原型来测试一个想法，Streamlit 共享对你来说是完美的。对于需要更多计算的成熟的公共应用程序，Heroku 可能是最好的选择。如果您需要一个复杂的 ML 应用程序的终极灵活性，或者如果您完全在 Streamlit 上运行业务，那么 AWS 可能是最好的选择。在这一章的剩余部分，我们将深入探讨如何在 AWS 和 Heroku 上部署自己的应用，因为我们已经在 [*第 5 章*](B16864_05_Final_VK_ePub.xhtml#_idTextAnchor056) 、*部署 Streamlit 和 Streamlit 共享*中直接介绍了 Streamlit 共享。让我们从 Heroku 开始吧！

# 使用 Heroku 部署 Streamlit

Heroku 比 AWS 略快且简单，比 Streamlit 共享更麻烦。但是，如果您已经用完了您的 Streamlit 共享库，或者需要比共享所提供的更多的计算，但需要比 AWS 提供的无限配置选项更少的配置选项，那么 Heroku 就是您的理想之选。另一个好处是，你可以用 Heroku 为你的应用程序定制 URL，这是 Streamlit Sharing 不支持的。).要在 Heroku 上部署我们的 Streamlit 应用，我们需要做以下工作:

1.  设置并登录 Heroku。
2.  克隆并配置我们的本地存储库。
3.  部署到 Heroku。

让我们详细看一下这些步骤！

## 设置并登录 Heroku

在本章的*技术要求*一节中，我们介绍了如何下载 Heroku 并创建账户。现在，我们需要通过运行以下命令并在出现提示时登录，从我们的命令行登录 Heroku:

```
heroku login
```

这将把我们带到 Heroku 页面，一旦我们登录，我们就可以开始了。这个命令将使你无限期地保持在你的机器上，除非你的密码改变或者你故意退出 Heroku。

## 克隆和配置我们的本地存储库

接下来，我们需要将我们的目录更改为企鹅机器学习应用所在的位置。我的应用程序文件夹在我的`Documents`文件夹中，所以以下命令会带我到那里，但你的文件夹可能不同:

```
cd ~/Documents/penguin_ml
```

如果您还没有在 GitHub 上本地下载相应的存储库，请继续并在 [*第 5 章*](B16864_05_Final_VK_ePub.xhtml#_idTextAnchor056) 、*部署 Streamlit 并共享 Streamlit*处停下来，看看如何开始使用 GitHub。相反，您也可以运行以下命令从我的个人 GitHub 本地下载存储库，就像我们从 AWS 部署一样:

```
git clone https://github.com/tylerjrichards/penguin_ml.git
```

强烈建议您使用自己的 GitHub 库进行练习，因为这比从我这里克隆一个应用程序来部署到 Heroku 要好得多。

现在，我们需要使用下一个命令为我们的应用程序创建一个具有唯一名称的 Heroku 应用程序(该应用程序将被部署为这个名称，在其末尾附加有`.heroku.com`)。我的将是`penguin-machine-learning`，但是继续挑选你自己的吧！

```
heroku create penguin-machine-learning
```

一旦我们有了这些，我们需要明确地在我们的 Git 存储库和我们刚刚创建的 Heroku 应用程序之间建立连接，这可以用下面的命令来完成:

```
heroku git:remote -a penguin-machine-learning
```

最后，我们将添加两个文件到我们的存储库中，它们是启动 Heroku 所需要的，分别是`Procfile`文件和`streamlit_setup.sh`文件。Heroku 使用一种叫做 **Procfile** 的来声明应用程序在启动时应该执行哪些命令，并告诉 Heroku 这是什么类型的应用程序。对于我们的 Heroku 应用程序，我们还需要这个 Procfile 来配置我们的应用程序的一些特定设置(如端口配置)，然后还需要运行`streamlit run`命令来启动我们的应用程序。让我们从使用以下命令创建`streamlit_setup.sh`文件开始:

```
touch streamlit_setup.sh
```

我们可以用我们的文本编辑器打开这个文件，并在其中输入下面几行，这将在基本目录中创建我们熟悉的`config.toml`文件:

```
mkdir -p ~/.streamlit
echo "[server]
headless = true
port = $PORT
enableCORS = false
" > ~/.streamlit/config.toml
```

一旦我们保存了这个文件，我们需要创建一个 Procfile 来运行这个`streamlit_setup.sh`文件，然后运行我们的 Streamlit 应用程序:

```
touch Procfile
```

在我们刚刚创建的`Procfile`文件中，我们接下来将添加以下行:

```
web: sh streamlit_setup.sh && streamlit run penguins_streamlit.py
```

现在我们已经设置好了我们的 Streamlit 应用程序，我们的最后一步是部署到 Heroku！

## 部署到 Heroku

在我们部署之前，我们的应用程序上有几个新文件，所以我们需要使用以下命令将它们添加到我们的 Git 存储库中:

```
git add .
git commit -m 'added heroku files'
git push
```

现在，我们在这一章的最后一步是推进 Heroku，我们可以通过下一个命令来完成:

```
git push heroku main
```

这将启动 Heroku 的构建，很快我们将看到我们的企鹅应用程序部署到 Heroku 上，供任何人访问和查看。我们一直在开发和刚刚部署的应用程序可以在下面的链接中找到(附上截图！)、https://penguin-machine-learning.herokuapp.com/[，该 app 的 GitHub 库可以在 https://github.com/tylerjrichards/penguin_ml](https://penguin-machine-learning.herokuapp.com/)的[找到。它与我们在本章前面部署在 AWS 上的应用程序相同，如下图所示:](https://github.com/tylerjrichards/penguin_ml)

![Figure 8.2 – Heroku App deployment
](image/B16864_08_2.jpg)

图 8.2–Heroku 应用程序部署

我们现在已经在 Heroku 平台上成功部署了我们的 Streamlit 应用程序之一，但是如果我们需要对我们应用程序背后的服务器类型进行更多的控制，我们需要直接在 AWS 上构建，如下一节所示！

# 使用 AWS 部署 Streamlit

与使用 Heroku 部署相比，在 AWS 上部署应用程序要麻烦得多，但似乎有无限的选择。使用 AWS 部署您自己的应用程序需要几个步骤，其中包括:

1.  选择并启动虚拟机
2.  安装必要的软件
3.  克隆和运行您的应用
4.  长期 AWS 部署

我们将按顺序运行！

## 选择并启动虚拟机

AWS 有数百个服务选项，从部署 ML 模型到计算资源，再到两者之间的一切。在本书中，到目前为止，我们已经提到了下面截图中在中心名称 *AWS* 下列出的服务，但更准确地说，我们将使用**亚马逊弹性计算云**，或简称为**亚马逊 EC2** 。下一个屏幕截图显示了仅适用于计算资源的服务范围，其中不包括适用于机器学习、业务应用或存储的任何服务:

![Figure 8.3 – AWS Compute
](image/B16864_08_3.jpg)

图 8.3–AWS 计算

Amazon EC2 是一个动态的现收现付服务，将根据使用情况自动扩展。如果您的 Streamlit 应用程序有 10、100 或 10，000 个并发用户，EC2 将更改分配给应用程序的计算资源以适应这些用户。你为你使用的东西付费！

首先，进入[https://console.aws.amazon.com/ec2/v2/home](https://console.aws.amazon.com/ec2/v2/home)，点击按钮**启动实例**，如下图所示。您的默认地区可能与我的不同，这完全没问题！AWS 区域允许您选择您希望计算物理位于何处，以防您的应用程序需要低延迟，或者由于监管原因，您的数据托管在何处(例如，由于**通用数据隐私法规** ( **GDPR** )，在欧盟)。绝大多数时候，AWS 给你设置的默认区域是非常好的:

![Figure 8.4 – EC2 launch
](image/B16864_08_4.jpg)

图 8.4–EC2 发布

启动实例后，有七个选项卡:

*   **选择 AMI** (Amazon 机器映像)或虚拟机使用的操作系统
*   **选择实例类型**(选择虚拟机的计算/内存/存储)
*   **配置实例**
*   **添加存储器**
*   **添加标签**
*   **配置安全组**
*   **回顾**

当我提到灵活性与速度的对比时，你可能开始明白我刚才在说什么了！幸运的是，我们只需要从其中的几个开始，从从选项列表中选择 AMI 开始。当我们单击 **Launch instance** 按钮时，我们将看到包括但不限于以下选项:

*   Amazon Linux 2 AMI

    这个选项是 Amazon 自己的选项，是免费的，设计用于 EC2。

*   Red Hat Enterprise Linux

    这个选项是由红帽基金会创建的 Linux 的企业版本，该基金会创建了开源企业解决方案(【https://www.redhat.com/en】T2)。根据版本和卷类型，有多种选项。

*   Ubuntu Server

    Ubuntu 是另一个构建在 Linux 上的开源 OS，类似于 Red Hat。他们也有各种免费和付费选项，和红帽一样。

我建议选择你已经最熟悉的操作系统。如果您已经使用了 Ubuntu 服务器，请尝试最新的 Ubuntu 选项，在本例中是 Ubuntu Server 20.04。最常用的 AMI 选项都是基于 Linux 的，Linux 是一个开源的 OS，有很多风格，包括 Red Hat、Debian 和 Ubuntu。

按照本章，选择默认的 Amazon 选项， **Amazon Linux 2** 。当您选中此选项并转到**选择实例类型**页面时，选择任何符合自由层条件的类型，如下图所示。当然，如果您想购买更多内存或 vCPUs，您完全可以，但目前没有必要:

![Figure 8.5 – AWS AMI options
](image/B16864_08_5.jpg)

图 8.5–AWS AMI 选项

接下来，我们可以跳过接下来的几个选项，直到您看到标题为**配置安全组**的第六个选项卡。这里我们需要做一些编辑:

*   TCP Rule

    我们需要设置我们的**安全**设置，以允许其他在线用户通过添加新的**传输控制协议** ( **TCP** )规则，通过点击**添加规则**并将端口范围列设置为自定义 Streamlit 端口`8501`，来与我们的 web 应用程序交互。

*   Access Source

    我们还需要允许任何人访问我们的应用程序，因此我们也将 source 设置为 **Anywhere** ，如下面的截图所示:

![Figure 8.6 – Security settings 
](image/B16864_08_6.jpg)

图 8.6–安全设置

现在，我们准备发射了！前往第七个标签，**查看**，如果一切正常，点击**启动**按钮。接下来将弹出的是创建公钥和私钥的方法，一个由 AWS 持有，另一个由您持有，允许您从命令行访问这台新的虚拟计算机，如下面的截图所示:

![ Figure 8.7 – Key-value pairs
](image/B16864_08_7.jpg)

图 8.7-键值对

可以把它想象成一个独特的密码，作为自己的文件下载。您可以将该文件保存在任何对您来说最容易和最安全的地方，但是请确保不要将该文件上传到公共位置，例如 GitHub 存储库，否则，其他人可能会访问您的虚拟机！现在我们已经启动了 EC2 实例，我们可以从命令行访问它并下载我们的应用程序。

## 安装必要的软件

对于这个示例，我们将尝试部署我们在 [*第 4 章*](B16864_04_Final_VK_ePub.xhtml#_idTextAnchor049) 、*中使用机器学习和 Streamlit* 创建的企鹅 ML 应用程序，并在 Streamlit 共享上的 [*第 5 章*](B16864_05_Final_VK_ePub.xhtml#_idTextAnchor056) 、*部署 Streamlit 和 Streamlit 共享*。现在我们有了虚拟机和目标，我们需要从命令行访问虚拟机。首先，我们需要首先找出 AWS 实例的公共 DNS。使用这个链接找到您的 AWS 实例，[https://console.aws.amazon.com/ec2/v2/home#Instances](https://console.aws.amazon.com/ec2/v2/home#Instances)，并查找**公共 DNS** ，其格式为`ec2-10-857-84-485.compute-1.amazonaws.com`。那些数字是我编的，但你的应该接近这个。

现在，我们可以使用 SSH 访问我们的虚拟机，SSH 是一种安全的 Shell 协议，使用下面的命令，它结合了我们的密码和我们的公共 DNS:

```
ssh -i "path_to_private_key.pem" ec2-user@<insert_Public_DNS>
```

通常，AWS 命令感觉像是魔法咒语，尤其是当您第一次开始使用时。有了一些经验之后，你肯定会对此更加适应。此时，AWS 可能会在命令行上询问您一些关于允许特定类型访问的问题，具体取决于您在本地计算机上的安全设置，在您确认要连接后，如果您看到类似于以下屏幕截图的内容，您将知道您已连接:

![Figure 8.8 – AWS login 
](image/B16864_08_8.jpg)

图 8.8–AWS 登录

这是你自己的新虚拟电脑！这台计算机上没有程序、文件夹或其他任何东西。它是全新的，刚从亚马逊盒子里拿出来。我们用`ec2`租出去的每台电脑一开始几乎什么都没有，所以我们必须下载这个项目需要的所有东西。有很多方法可以做到这一点。我们可以做到以下几点:

*   手动安装一切。
*   安装预打包的安装程序，如 Anaconda 或 Miniconda。
*   使用 Docker 创建一组安装说明。

对于大多数用例，我建议选择第二个选项，因为 Anaconda 或 Miniconda 被设计用来处理安装 Python、处理我们的路径以及安装各种 Python 和 R 包时遇到的所有困难。Anaconda 和它的引导(也就是更小的)版本 Miniconda，因为在你的计算机环境之外很难安装而臭名昭著。如果您需要在您的虚拟机或本地机器上安装 Python，我会推荐选择*选项 1* 或*选项 3* 。

为了在我们的虚拟机上安装和设置 Miniconda，我们可以运行以下命令，这些命令使用`wget`将 Miniconda 下载到文件位置`~/miniconda.sh`，然后使用`bash`运行安装文件，然后更改我们的路径，以便我们可以更容易地使用`conda`下载包:

```
wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh
bash ~/miniconda.sh -b -p ~/miniconda
export PATH="$HOME/miniconda/bin":$PATH
```

太好了！现在我们有了最新版本的`python`、`pip`，以及一大堆 Python 包。然而，Miniconda 没有附带 Streamlit，因此我们将使用下一个命令来下载、安装和测试 Streamlit 的安装，方法是启动 Streamlit 演示应用程序:

```
pip install Streamlit
streamlit hello
```

当我们运行这个命令时，我们应该在终端中看到以下内容(尽管使用不同的网络和外部 URL):

![Figure 8.9 – First Streamlit command
](image/B16864_08_9.jpg)

图 8.9–第一个 Streamlit 命令

当您从任何浏览器前往外部 URL 时，您将会看到 Streamlit 演示应用程序，如以下截图中的所示:

![Figure 8.10 – Streamlit demo
](image/B16864_08_10.jpg)

图 8.10–简化演示

我们现在已经部署了来自 AWS 的首个 Streamlit 应用程序。现在，部署我们已经构建的 Streamlit 应用程序。

## 克隆和运行您的应用

我们现在有了一个可以运行 Streamlit 的虚拟机，我们的下一步是将我们自己的应用程序下载到我们的机器上。最直接的方法是使用 Git 并克隆存放企鹅机器学习应用的存储库。如果你还没有在第五章 、*使用 Streamlit 共享部署 Streamlit*中这样做，请随意使用我在[https://github.com/tylerjrichards/penguin_ml.git](https://github.com/tylerjrichards/penguin_ml.git)的 GitHub 库。下面的代码下载`git`，然后从 GitHub 下载我们的应用:

```
conda install git
git clone https://github.com/tylerjrichards/penguin_ml.git
```

这将在我们当前的目录中创建一个名为`penguin_ml`的新文件夹，其中包含 Streamlit 应用程序的所有文件。这个应用程序需要比来自 Miniconda 更多的库，如 Seaborn 和 scikit-learn，所以我们需要在运行我们的应用程序之前下载它们。我们已经将这些库的名称放入一个名为`requirements.txt`的文件中，所以我们需要使用下一组命令将`pip`指向该文件:

```
cd penguin_ml
pip install -r penguin_ml/requirements.txt
```

现在，我们的最后一步是运行我们的 Streamlit 应用程序:

```
streamlit run penguins_streamlit.py
```

当我们转到 AWS 终端中的外部 URL 时，我们将看到我们的 Streamlit 应用程序在那里完全运行，如下面的屏幕截图所示:

![Figure 8.11 – AWS Penguin app 
](image/B16864_08_11.jpg)

图 8.11–AWS 企鹅应用程序

我们开始吧！我们现在在 AWS 上运行我们的应用程序，全世界都可以看到。从这一点上，我们可以从你可能已经有的个人网站链接到我们的应用程序，或者将其发送给可能对自己的企鹅集分类感兴趣的其他人。

## 长期 AWS 部署

我们的最后一个问题是，为了让 Streamlit 应用程序保持运行，我们运行的将本地机器连接到 AWS 的 SSH 会话需要运行。对于大多数用例来说，这不会起作用，因为如果您的本地计算机与 AWS 断开连接，您会希望用户与您的 Streamlit 应用程序进行交互。输入`tmux`，或者终端多路复用器，它可以保持终端会话继续进行，而不管我们与它的本地连接。要下载`tmux`，我们可以在连接到 AWS 虚拟机时运行以下命令:

```
sudo yum install tmux
```

现在，我们可以开始新的`tmux`会话，并通过运行以下命令启动我们的 Streamlit 应用程序:

```
tmux 
streamlit run penguins_streamlit.py
```

如果我们与 AWS 的连接断开，`tmux`将保持我们的应用程序运行。我们可以通过按下 *Ctrl + D* 随时离开`tmux`会话，并可以通过运行`tmux attach`重新进入会话。

这包括使用 AWS 部署 Streamlit！如你所见，Streamlit 共享解决了大多数现成的困难，所以我会尽可能地让 Streamlit 共享发挥作用。然而，本课程应该会让您对我们使用 AWS 时所面临的选项和配置控制的真正广度有所了解，这在未来可能会派上用场。

摘要

到目前为止，这是我们章节中技术含量最高的一章，所以恭喜你通过了！众所周知，部署应用程序既困难又耗时，并且需要软件工程和开发运维方面的技能，还经常需要版本控制软件(如 Git)和 Unix 风格的命令和系统方面的经验。这是为什么 Streamlit 共享是如此重要的创新的部分原因，但在本章中，我们已经了解了如何通过租赁我们自己的虚拟机并将这些虚拟机部署在 AWS 和 Heroku 上来推动 Streamlit 部署的发展。我们还学会了如何在开始之前找出正确的部署策略，这将节省数小时或数天的工作(没有什么比完成一个应用程序的部署后发现需要使用另一个平台更糟糕的了！).

接下来，我们将进入本书的第三部分，也是最后一部分，这一部分将重点介绍 Streamlit 的各种应用，从使用 Streamlit 改进工作应用开始。下一章将重点介绍如何用 Streamlit 应用程序给招聘经理和招聘人员留下深刻印象，如何在实际的工作申请部分使用 Streamlit 应用程序，例如许多面试中臭名昭著的带回家的部分，以及如何改进数据科学简历的技能证明数据项目。