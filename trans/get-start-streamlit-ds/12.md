

# 九、使用 Streamlit 改进工作应用

至此，您应该已经是一名经验丰富的 Streamlit 用户了。从Streamlit设计到部署，再到数据可视化，以及两者之间的一切，您都掌握得很好。本章旨在以应用为中心；它将向您展示 Streamlit 应用的一些伟大用例，这样您就可以受到启发来创建自己的应用！我们将从演示如何使用 Streamlit 进行*技能数据项目的证明*开始。然后，我们将继续讨论如何在工作应用的*带回家*部分使用 Streamlit。

在本章中，我们将讨论以下主题:

*   使用 Streamlit 验证技能数据项目
*   改善细流中的工作应用

# 技术要求

以下是本章所需的软件和硬件安装列表:

*   `streamlit-lottie`: To download this library, run the following code in your Terminal:

    ```
    pip install streamlit-lottie
    ```

    有趣的是，`streamlit-lottie`使用了`lottie`开源库，它允许我们将网络原生动画(如 GIF)添加到我们的 Streamlit 应用中。坦率地说，这是一个很棒的库，你可以用它来美化 Streamlit 应用，它是由多产的 Streamlit 应用创作者 Andy Fanilo 创建的。

*   工作应用示例文件夹:这本书的中央存储库可以在[https://github . com/tylerjrichards/Getting-Started-with-Streamlit-for-Data-Science](https://github.com/tylerjrichards/Getting-Started-with-Streamlit-for-Data-Science)找到。在这个存储库中，`job_application_example`文件夹将包含本章第二部分(涵盖工作应用)所需的一些文件。如果您还没有下载这个主存储库，那么在您的终端中使用下面的代码来克隆它:

    ```
    git clone https://github.com/tylerjrichards/Getting-Started-with-Streamlit-for-Data-Science
    ```

既然我们已经设置好了一切，让我们开始吧！

# 使用 Streamlit 进行技能数据项目证明

众所周知，向他人证明你是一名熟练的数据科学家是非常困难的。任何人都可以将 Python 或机器学习放在简历上，甚至可以在一所大学的研究小组工作，该小组可能会进行一些机器学习。但通常情况下，招聘人员、你想与之共事的教授和数据科学经理依赖于你简历中代表能力的东西，比如上过“正确的”大学，或者已经有了一份不错的数据科学实习或工作。

在 Streamlit 之前，对于这个问题没有多少有效的解决方案。如果你把一个 Python 文件或者 Jupyter 笔记本放在你的 GitHub 个人资料上，人们需要花时间去理解这个作品是否令人印象深刻，这个风险太大了。如果招聘人员不得不点击你的 GitHub 个人资料中的正确存储库，然后点击大量文件，直到他们发现 Jupyter 笔记本上有不可读的代码(没有注释)，那么你已经失去了他们。如果招聘人员在你的简历上看到了“机器学习”,但是点击五次才能看到你写的任何机器学习产品或代码，那么你已经失去它们了。大多数感兴趣的人会在你的简历上花很少的时间；平均来说，我的个人投资组合网站(www.tylerjrichards.com)的访问者在转到其他地方之前会在网站上停留大约 2 分钟。

这个问题的一个解决方案是尝试创建和分享 Streamlit 应用，这些应用专门针对你希望最广泛展示的技能。例如，如果你在基础统计方面有很多经验，你可以创建一个 Streamlit 应用来证明或说明一个基础统计定理，比如中心极限定理——就像我们在本书前面所做的那样。相反，如果你有自然语言处理方面的经验，你可以创建一个应用，展示你创建的一个新的文本生成神经网络。这里的要点是最大限度地减少某人需要点击的次数，直到他们证明你在某个领域的能力。

我们已经创建的许多 Streamlit 应用确实服务于这一目的。让我们看几个例子。

## 机器学习——企鹅应用

在 [*第四章*](B16864_04_Final_VK_ePub.xhtml#_idTextAnchor049)*中，我们使用 Streamlit* 的机器学习，创建了一个随机森林模型，该模型在我们的帕尔默企鹅数据集上进行训练，根据体重、居住岛屿和喙长等特征预测企鹅的种类。然后，我们保存了该模型，以便在我们的 Streamlit 应用中使用它。

为了生成我们的 Streamlit 应用，我们需要(在第一次迭代中)运行以下代码。这将创建要部署的模型:

```
import pandas as pd
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import pickle
penguin_df = pd.read_csv('penguins.csv')
penguin_df.dropna(inplace=True)
output = penguin_df['species']
features = penguin_df[['island', 'bill_length_mm', 'bill_depth_mm',
                       'flipper_length_mm', 'body_mass_g', 'sex']]
features = pd.get_dummies(features)
output, uniques = pd.factorize(output)
x_train, x_test, y_train, y_test = train_test_split(
    features, output, test_size=.8)
rfc = RandomForestClassifier(random_state=15)
rfc.fit(x_train, y_train)
y_pred = rfc.predict(x_test)
score = accuracy_score(y_pred, y_test)
print('Our accuracy score for this model is {}'.format(score))
```

在第一部分中，我们导入我们的库，加载我们的数据，训练/评估我们的模型，同时打印出评估结果。然后，我们使用以下代码将模型结果保存到`pickle`文件中:

```
rf_pickle = open('random_forest_penguin.pickle', 'wb')
pickle.dump(rfc, rf_pickle)
rf_pickle.close()
output_pickle = open('output_penguin.pickle', 'wb')
pickle.dump(uniques, output_pickle)
output_pickle.close()
```

回想一下，在本章的最后，我们添加了一个新功能，这样如果用户上传了他们自己的数据集，他们就可以使用我们的模型训练脚本完全根据他们的数据来训练模型(前提是数据是相同的格式；它带有一些先决条件)。

这个应用，在其最终形式中，表明我们至少有一些关于数据清理的知识，如何对我们的变量进行一次性编码，我们如何考虑根据测试数据评估我们的模型，以及最后，如何在应用中部署我们预先训练的模型。光是这一点就比仅仅在简历上写“机器学习”要好得多，而且它显示了我们所拥有的一些技能的证据。没有这种技能证明，看我们申请的招聘人员或招聘经理将不得不要么相信我们在简历上是完全诚实的(根据多年来阅读的数百份简历，这是一个糟糕的假设)，要么使用大学学位等信心的替代物(这也是一个评估能力的糟糕替代物)。

除此之外，当我们在 [*第五章*](B16864_05_Final_VK_ePub.xhtml#_idTextAnchor056) 、*部署具有 Streamlit 共享的 Streamlit*中部署这个应用以实现 Streamlit 共享时，我们讨论了一个 Streamlit 共享免费提供的自动功能:**查看应用源**按钮。正如您在下面的截图中看到的，当我们部署我们的应用时，Streamlit 在用户的**设置**下拉菜单中添加了一个按钮，允许他们查看应用背后的源代码:

![Figure 9.1 – The View app source option
](image/B16864_09_1.jpg)

图 9.1–查看应用源选项

通过这种方式，用户可以随时检查以确保恶意代码(例如，研究人员的企鹅数据是否没有被应用存储)没有被 Streamlit Sharing 部署。作为第二个功能，用户还可以查看您编写的构建应用的代码，这提高了我们使用 Streamlit 作为*技能证明*工具的能力。

## 可视化——漂亮的树应用

在 [*第六章*](B16864_06_Final_VK_ePub.xhtml#_idTextAnchor065) 、*美化 Streamlit 应用*中，我们开发了一个 Streamlit 应用，可以创建美丽的和动态可视化的三藩市的树木，这就产生了下面的应用:

![Figure 9.2 – Mapping a web app
](image/B16864_09_2.jpg)

图 9.2–映射 web 应用

在这个应用中，我们必须创建多个不同的可视化效果(即两个直方图和一个地图),这些可视化效果可以根据右侧的用户输入进行动态更新。有了这样的应用，我们能够展示我们的数据操作技能，我们对 pandas、Matplotlib 和 Seaborn 库的熟悉程度，甚至我们知道如何用 Python 处理日期时间。让我们来看看应用代码中专注于可视化的部分:

```
#define multiple columns, add two graphs
col1, col2 = st.beta_columns(2)
with col1:
     st.write('Trees by Width')
     fig_1, ax_1 = plt.subplots()
     ax_1 = sns.histplot(trees_df['dbh'], 
          color=graph_color)
     plt.xlabel('Tree Width')
     st.pyplot(fig_1)
with col2:
     st.write('Trees by Age')
     fig_2, ax_2 = plt.subplots()
     ax_2 = sns.histplot(trees_df['age'],
          color=graph_color)
     plt.xlabel('Age (Days)')
     st.pyplot(fig_2)
st.write('Trees by Location')
trees_df = trees_df.dropna(subset=['longitude', 'latitude'])
trees_df = trees_df.sample(n = 1000, replace=True)
st.map(trees_df)
```

对于熟悉 Python 或其他脚本语言的人来说，这段代码非常容易阅读，这比简单地在简历上写“数据可视化”或“熊猫”要好得多。

在这一点上，我希望你相信。Streamlit 应用是向招聘人员、潜在的招聘经理或任何你需要向其证明你的技能的人展示你的工作的绝佳方式。在下一节中，我们将更详细地介绍这一过程，并演示如何使用 Streamlit 来支持您可能希望为之工作的公司的应用。

# 改善 Streamlit 中的工作应用

通常，数据科学和机器学习工作应用依靠带回家的数据科学挑战来判断候选人。坦率地说，由于求职者和雇主之间的互动，这是公司可能要求的一种残酷而恼人的经历。例如，候选人可能需要 5-10 个小时才能完全完成一项数据科学挑战，但雇主可能只需要 10 分钟就可以评估它。此外，对于雇主来说，单独的虚拟或电话面试可能需要 30-45 分钟，加上额外的 15 分钟来写反馈，相比之下，申请人同样需要 30-45 分钟。因为获得 5-10 个小时的工作时间给了他们每分钟员工时间非常高的信号，雇主们倾向于在他们的工作应用中包括这些挑战。

您可以利用这里的机会，通过创建一个功能齐全的应用，而不是向公司发送一个 Jupyter 笔记本、Word 文档或 PowerPoint 幻灯片，来使用 Streamlit 从人群中脱颖而出。

## 问题

让我们来看一个虚构的例子，一名求职者正在申请一家主要的美国航空公司。他们需要解决两个主要问题，其中一个包含数据集:

*   **Question 1**: **Airport distance**

    第一个练习要求，“给定包含的机场和位置数据集(以纬度和经度表示)，编写一个函数，将机场代码作为输入，并返回从离输入机场最近到最远列出的机场。”

*   **Question 2**: **Representation**

    第二个问题是，“如何将搜索集合转换成表示旅行的数字向量？假设我们有成千上万的用户，我们希望以这种方式表示他们所有的旅行。理想情况下，我们希望这是一个通用的表示，我们可以在多个不同的建模项目中使用，但我们肯定关心找到类似的旅行。准确地说，你如何比较两次旅行，看它们有多相似？你觉得前面的数据可能遗漏了哪些信息，有助于提高你的表现？”

    注意

    不用担心在这一节写代码；您可以简单地描述您将执行的任何数据转换。您的描述应该足够清晰，以便数据科学家在阅读时知道如何在必要时实现您的解决方案。

现在我们已经有了个必需的问题，我们可以开始一个新的 Streamlit 应用了。为了做到这一点，我经历了迄今为止我们在每一章中使用的相同过程。我们在中心文件夹(`streamlit_apps`)中为我们的应用创建一个新文件夹，称为`job_application_example`。在这个文件夹中，我们可以在终端中使用以下命令创建一个名为`job_streamlit.py`的 Python 文件:

```
touch job_streamlit.py
```

## 回答问题 1

对于你来说，确切地理解如何回答手头的问题并不是非常重要，但是总体框架是非常重要的。我们创建的 Streamlit 应用读起来应该像一个令人难以置信的动态文档，以独特的方式回答问题，这取决于 Streamlit 的能力，使申请人无法通过 Word 文档轻松复制申请。

首先，我们可以创建一个标题来介绍我们，并开始整个应用的格式。这里的一个改进是使用我们在 [*第 7 章*](B16864_07_Final_VK_ePub.xhtml#_idTextAnchor074) 、*探索 Streamlit 组件*中了解到的`streamlit-lottie`库在应用顶部添加一个可选动画，如以下代码所示:

```
import streamlit as st
from streamlit_lottie import st_lottie
import pandas as pd
import requests
def load_lottieurl(url: str):
    r = requests.get(url)
    if r.status_code != 200:
        return None
    return r.json()
lottie_airplane = load_lottieurl('https://assets4.lottiefiles.com/packages/lf20_jhu1lqdz.json')
st_lottie(lottie_airplane, speed=1, height=200, key="initial")
st.title('Major US Airline Job Application')
st.write('by Tyler Richards')
st.subheader('Question 1: Airport Distance')
```

前面的代码将创建一个顶部带有漂亮的飞机动画的应用，如下面的屏幕截图所示:

![Figure 9.3 – An airplane GIF 
](image/B16864_09_3.jpg)

图 9.3-飞机 GIF

接下来，我们需要将问题复制并粘贴到副标题下方。Streamlit 有许多将文本放入应用的选项。我们还没有使用的一个选项是将我们的文本放在三个撇号内，这告诉 Streamlit 使用 markdown 语言编写这个文本。这对于大块文本非常有用，例如下面的文本，它开始回答第一个问题:

```
'''
The first exercise asks us 'Given the table of airports and 
locations (in latitude and longitude) below, 
write a function that takes an airport code as input and 
returns the airports listed from nearest to furthest from 
the input airport.' There are three steps here:
1\. Load Data
2\. Implement Distance Algorithm
3\. Apply distance formula across all airports other than the input
4\. Return sorted list of airports Distance
'''
```

如本章*技术要求*一节所述，需要两个文件来完成该应用。第一个是机场位置的数据集(称为`airport_location.csv`)，第二个是显示哈弗线距离(即球体上两点之间的距离；该文件被恰当地命名为`haversine.png`。请将这些文件复制到与 Streamlit 应用 Python 文件相同的文件夹中。

现在，我们需要完成第一步:加载数据。我们既需要在 Streamlit 中完成这一步，也需要向用户展示代码。这与其他 Streamlit 应用不同，后者的代码隐藏在后台。然而，因为用户肯定希望看到我们的代码，因为他们会对我们进行评估，所以我们需要两者都做。我们可以使用之前用过的`st.echo()`函数，将代码块打印到我们的应用中。我们可以用下面的代码做到这一点:

```
airport_distance_df = pd.read_csv('airport_location.csv')
with st.echo():
     #load necessary data
     airport_distance_df = pd.read_csv('airport_location.csv')
```

我想在这里指出，我们已经在代码的顶部放置了一个注释。这不是为了给你(读者)注释代码，而是为了应用读者。偶尔对您在代码内部以及代码前后的文本块中编写的代码的目的进行评论是一种很好的做法；这是为了让读者理解你试图采取的方法。这在工作应用中尤其重要，但对于协作式简化应用也是很好的实践。

我们的下一步是解释哈弗辛公式，并在我们的 Streamlit 应用中显示图像，这是我们在下面的代码块中完成的。在你的文本块中采用叙事格式是完全可以接受的。简单地想象一下，作为一名招聘经理，你想读什么，并尽可能地复制它:

```
'''
From some quick googling, I found that the haversine distance is 
a good approximation for distance. At least good enough to get the 
distance between airports! Haversine distances can be off by up to .5%, 
because the earth is not actually a sphere. It looks like the latitudes 
and longitudes are in degrees, so I'll make sure to have a way to account 
for that as well. The haversine distance formula is labeled below, 
followed by an implementation in python
'''
st.image('haversine.png')
```

现在，我们的应用应该类似于下面的屏幕截图:

![Figure 9.4 – Loading the data for Question 1
](image/B16864_09_4.jpg)

图 9.4-加载问题 1 的数据

我们有需要处理的条目列表、动画、哈弗线距离公式和读取数据的基本代码。此时，我们需要用 Python 实现哈弗辛距离公式，并展示我们的实现:

```
with st.echo():
     from math import radians, sin, cos, atan2, sqrt
     def haversine_distance(long1, lat1, long2, lat2, degrees=False):
         #degrees vs radians
         if degrees == True:
             long1 = radians(long1)
             lat1 = radians(lat1)
             long2 = radians(long2)
             lat2 = radians(lat2)

         #implementing haversine
         a = sin((lat2-lat1) / 2)**2 + cos(lat1) * cos(lat2) * sin((long2-long1) / 2)**2
         c = 2*atan2(sqrt(a), sqrt(1-a))
         distance = 6371 * c #radius of earth in kilometers
         return(distance)
```

我们代码的第一部分没有创建我们的函数，而是打印出我们将创建到 Streamlit 应用的函数。这是为了让应用的读者可以查看我们编写的两段重要代码，并与代码本身进行交互。如果我们只是创建一个函数来实现哈弗线距离，我们的应用的读者将不会真正知道我们是如何解决手头的问题的！下面的代码块创建了这个函数:

```
#execute haversine function definition
from math import radians, sin, cos, atan2, sqrt
def haversine_distance(long1, lat1, long2, lat2, degrees=False):
    #degrees vs radians
    if degrees == True:
        long1 = radians(long1)
        lat1 = radians(lat1)
        long2 = radians(long2)
        lat2 = radians(lat2)

    #implementing haversine
    a = sin((lat2-lat1) / 2)**2 + cos(lat1) * cos(lat2) * sin((long2-long1) / 2)**2
    c = 2*atan2(sqrt(a), sqrt(1-a))
    distance = 6371 * c #radius of earth in kilometers
    return(distance)
```

我们已经完成了我们的哈弗辛实现！每当我们想要找出两个位置之间的距离时，我们可以调用我们的公式，输入经度和纬度，并以公里为单位获得距离。这个 app 有用；但是，目前来看，比 Word 文档好不了多少。我们的下一步是允许用户输入自己的点来检查和查看哈弗线距离是否有效。几乎没有人知道地球上的两个点相距多少公里，所以我包括了默认点并检查了它们之间的实际距离:

```
'''
Now, we need to test out our function! The 
distance between the default points is 
18,986 kilometers, but feel free to try out
your own points of interest. 
'''
long1 = st.number_input('Longitude 1', value = 2.55)
long2 = st.number_input('Longitude 2', value = 172.00)
lat1 = st.number_input('Latitude 1', value = 49.01)
lat2 = st.number_input('Latitude 2', value = -43.48)
test_distance = haversine_distance(long1 = long1, long2 = long2,
          lat1 = lat1, lat2 = lat2, degrees=True)
st.write('Your distance is: {} kilometers'.format(int(test_distance)))
```

当我们输入我们的默认值时，应用返回大约 2 公里的距离，如下面的截图所示:

![Figure 9.5 – Implementing the Haversine distance 
](image/B16864_09_5.jpg)

图 9.5-实现哈弗线距离

在这一点上，我们的下一步是通过在我们给定的数据集上使用实现的哈弗线距离计算器来组合所有的片段。这在下面的截图中有简要的显示:

![Figure 9.6 – The airport distances that have been given
](image/B16864_09_6.jpg)

图 9.6-给出的机场距离

该数据集具有机场代码及其相应的`lat`和`long`值。下面的代码块引入了一个解决方案，它结合了两个距离并省略了完整的`get_distance_list`函数，因为它只是我们已经实现了两次的函数的副本:

```
'''
We have the Haversine distance implemented, and we also have
proven to ourselves that it works reasonably well.
Our next step is to implement this in a function!
'''
def get_distance_list(airport_dataframe, airport_code):
    df = airport_dataframe.copy() 
    row = df[df.loc[:,'Airport Code'] == airport_code] 
    lat = row['Lat'] 
    long = row['Long'] 
    df = df[df['Airport Code'] != airport_code] 
    df['Distance'] = df.apply(lambda x: haversine_distance(lat1=lat, long1=long, 
         lat2 = x.Lat, long2 = x.Long, degrees=True), axis=1)
    return(df.sort_values(by='Distance').reset_index()['Airport Code']) 
with st.echo():
     def get_distance_list(airport_dataframe, airport_code):
          *copy of function above with comments*
```

最后，我们可以在给定的数据帧上实现这个距离公式。我们可以允许用户从我们拥有数据的选项中输入他们自己的机场代码，并返回正确值:

```
'''
To use this function, select an airport from the airports provided in the dataframe
and this application will find the distance between each one, and 
return a list of the airports closest to furthest.
'''
selected_airport = st.selectbox('Airport Code', airport_distance_df['Airport Code'])
distance_airports = get_distance_list(
     airport_dataframe=airport_distance_df, airport_code=selected_airport)
st.write('Your closest airports in order are {}'.format(list(distance_airports)))
```

我们第一个问题到此结束。我们可以在最后添加一个可选的部分，如果我们有更多的时间来解决这个问题，我们将如何改变我们的实现。如果你知道你只想在整个应用上花几个小时，这总是一个好主意，但是你也想证明如果你有更多的时间，你知道如何改进它。下面的代码块显示了这样一个例子，它将直接放在前面的代码块之后:

```
'''
This all seems to work just fine! There are a few ways I would improve this if I was working on 
this for a longer period of time.  
1\. I would implement the [Vincenty Distance](https://en.wikipedia.org/wiki/Vincenty%27s_formulae) 
instead of the Haversine distance, which is much more accurate but cumbersome to implement.  
2\. I would vectorize this function and make it more efficient overall. 
Because this dataset is only 7 rows long, it wasn't particularly important, 
but if this was a crucial function that was run in production we would want to vectorize it for speed. 
'''
```

或者，你可以总是以关于前面代码的陈述结束，然后继续第二个问题。至此，我们对*问题 1* 的回答已经完成，看起来应该类似于下面的截图:

![Figure 9.7 – Taking user input 
](image/B16864_09_7.jpg)

图 9.7–接受用户输入

我们现在已经成功回答了*个问题 1* ！我们总是可以手动检查这些机场之间的距离，以获得相同的结果。但是让我们继续我们应用中的第二个问题。

## 回答问题 2

第二个问题要简单得多，只要求文本回复。这里的技巧是尝试添加一些列表或 Python 对象，以便分解大段的文本。首先，我们将解释我们回答这个问题的尝试，然后演示它在数据帧中的外观:

```
'''
For this transformation, there are a few things 
that I would start with. First, I would have to define 
what a unique trip actually was. In order to do this, I would 
group by the origin, the destination, and the departure date 
(for the departure date, often customers will change around 
this departure date, so we should group by the date plus or 
minus at least 1 buffer day to capture all the correct dates).   
Additionally, we can see that often users search from an entire city, 
and then shrink that down into a specific airport. So we should also 
consider a group of individual queries from cities and airpots in the 
same city, as the same search, and do the same for destination.    
From that point, we should add these important columns to each unique search.
'''
```

现在，我们可以想到一些列，当我们表示用户搜索美国主要航空公司的航班时，这些列会很有用。我们可以将它们放入一个示例数据框架中，如下所示:

```
example_df = pd.DataFrame(columns=['userid', 'number_of_queries', 'round_trip', 'distance', 'number_unique_destinations',
                     'number_unique_origins', 'datetime_first_searched','average_length_of_stay',
                     'length_of_search'])
example_row = {'userid':98593, 'number_of_queries':5, 'round_trip':1,
                   'distance':893, 'number_unique_destinations':5,
                     'number_unique_origins':1, 'datetime_first_searched':'2015-01-09',
                   'average_length_of_stay':5, 'length_of_search':4}
st.write(example_df.append(example_row, ignore_index=True))
```

对于问题的其余部分，我们可以添加一些关于如何使用不同方法找到两点之间距离的知识，然后就到此为止:

```
'''
For answering the second part of the question, we should take the euclidian distance 
on two normalized vectors. There are two solid options for comparing two 
entirely numeric rows, the euclidian distance (which is just the straight line 
difference between two values), and the manhattan distance (think of this as the 
distance traveled if you had to use city blocks to travel diagonally across manhattan). 
Because we have normalized data, and the data is not high dimensional or sparse, I 
would recommend using the euclidian distance to start off. This distance would tell 
us how similar two trips were.
'''
```

第二个问题的答案应该和下面的截图差不多:

![Figure 9.8 – Answering Question 2
](image/B16864_09_8.jpg)

图 9.8-回答问题 2

正如您所看到的，这个示例演示了如何在 Streamlit 库的帮助下处理带回家的数据分配，以制作更令人印象深刻的应用。这项工作的最后一步是部署这个 Streamlit 应用，并与招聘人员共享链接。我强烈建议你在 Heroku 上部署这个，以保证其他人看不到该公司提供的问题或数据。您还可以采取进一步的预防措施，例如在应用的开头放置一个文本框，作为应用的黑客密码保护器，如下面的代码块所示:

```
password_attempt = st.text_input('Please Enter The Password')
if password_attempt != 'example_password':
     st.write('Incorrect Password!')
     st.stop()
```

现在，除非用户在文本框中输入`example_password`，否则整个应用不会运行。这当然是不安全的，但是对于相对不重要的应用(至少在保密方面)是有用的，例如带回家的应用:

![Figure 9.9 – Entering the password
](image/B16864_09_9.jpg)

图 9.9–输入密码

如您所见，这个应用加载的唯一方式是输入正确的密码。否则，用户将看到一个空白页。或者，您也可以使用 Streamlit secrets 在 Streamlit 共享中设置密码，这是目前 Streamlit for Teams 中的一项功能，将在 [*第 11 章*](B16864_11_Final_VK_ePub.xhtml#_idTextAnchor122) 、*使用 Streamlit for Teams* 中介绍。

# 总结

这一章是我们迄今为止创建的最关注应用的一章。我们非常关注数据科学和机器学习面试的工作应用和申请周期。此外，我们还学会了如何对我们的应用进行密码保护，如何创建应用来向招聘人员和数据科学招聘经理证明我们是我们所知道的熟练的数据科学家，以及如何通过创建 Streamlit 应用在带回家的数据科学面试中脱颖而出。下一章将关注作为玩具的 Streamlit，您将学习如何为社区创建面向公众的 Streamlit 项目。