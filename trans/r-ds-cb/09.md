

# 九、基于 R 的规则和模式挖掘

本章涵盖以下主题:

*   将数据转换为事务
*   显示交易和关联
*   利用先验规则挖掘关联
*   删除多余的规则
*   可视化关联规则
*   用 Eclat 挖掘频繁项集
*   使用时态信息创建事务
*   用 cSPADE 挖掘频繁序列模式

# 简介

大多数读者都熟悉沃尔玛把啤酒放在尿布旁边，因为它发现这两种产品的购买高度相关。这是数据挖掘的一个例子；它可以帮助我们发现事务数据集中的项目是如何关联的。使用这种技能，企业可以探索项目之间的关系，允许它一起销售相关的项目，以增加销售额。

作为使用关联挖掘识别相关项目的替代方法，数据挖掘的另一个流行应用是从具有时态信息的事务数据集中发现频繁序列模式。这可以用于许多应用，包括预测顾客购物顺序、网页点击流和生物序列。

本章中的方法包括创建和检查事务数据集，使用 Apriori 算法执行关联分析，以各种图形格式可视化关联，以及使用 Eclat 算法查找频繁项集。最后，我们使用时态信息创建事务，并使用 cSPADE 算法发现频繁序列模式。



# 将数据转换成交易

在使用任何规则挖掘算法之前，我们需要将数据从数据帧格式转换成事务。在这个例子中，我们演示了如何使用`arules`包将采购订单数据集转换成事务。

## 准备就绪

从[https://github . com/yw chiu/rcook book/raw/master/chapter 9/product _ by _ user 下载`purchase_order.RData`数据集。RData](https://github.com/ywchiu/rcookbook/raw/master/chapter9/product_by_user.RData) GitHub 链接。

## 怎么做……

执行以下步骤来创建事务处理:

1.  首先安装并加载`arules`包:

    ```

    > install.packages("arules")

    > library(arules)

    ```

2.  使用`load`函数将用户的采购订单加载到 R 会话:

    ```

    > load("product_by_user.RData")

    ```

3.  最后，用`as`函数将`data.table`(或`data.frame`)转换成交易:

    ```

    > trans = as(product_by_user $Product, "transactions")

    > trans

    transactions in sparse format with

     32539 transactions (rows) and

     20054 items (columns)

    ```

## 它是如何工作的……

在挖掘频繁项集或关联规则之前，为该类事务准备数据集是很重要的。在这个菜谱中，我们演示了如何将数据集从`data.table`(或`data.frame`)转换成事务。

我们首先将`arules`包安装并加载到 R 会话中。接下来，我们需要用`load`函数将`purchase_order.RData`加载到 R 会话中。因为我们有一个事务数据集，所以我们可以使用`as`函数将数据转换成事务，这将产生 32，539 个事务和 20，054 个条目。

## 还有更多……

除了将`data.frame`(或`data.table`)类的数据转换成事务，您还可以通过以下步骤将列表或矩阵类的数据转换成事务:

1.  用包含购买记录的三个向量列表:

    ```

    > tr_list = list(c("Apple", "Bread", "Cake"),

    +                c("Apple", "Bread", "Milk"),

    +                c("Bread", "Cake", "Milk"))

    > names(tr_list) = paste("Tr",c(1:3), sep = "")

    ```

2.  接下来，使用`as`函数将数据帧转换成事务:

    ```

    > trans = as(tr_list, "transactions")

    > trans

    transactions in sparse format with

     3 transactions (rows) and

     4 items (columns)

    ```

3.  也可以将矩阵格式的数据转换成事务:

    ```

    > tr_matrix = matrix(

    +   c(1,1,1,0,

    +     1,1,0,1,

    +     0,1,1,1), ncol = 4)

    > dimnames(tr_matrix) =  list(

    +   paste("Tr",c(1:3), sep = ""),

    +   c("Apple","Bread","Cake", "Milk")

    +   )

    > trans2 =  as(tr_matrix, "transactions")

    > trans2

    transactions in sparse format with

     3 transactions (rows) and

     4 items (columns)

    ```



# 显示交易和关联

`arules`包使用它的`transactions`类来存储交易数据。因此，我们必须使用`arules`提供的通用函数来显示事务和关联规则。在这个菜谱中，我们展示了如何用`arules`包中的各种函数来绘制事务和关联规则。

## 准备就绪

通过生成事务并将它们存储在名为`trans`的变量中，确保您已经完成了前面的配方。

## 怎么做……

执行以下步骤显示交易和关联:

1.  首先，获取交易数据的`LIST`表示:

    ```

    > head(LIST(trans),3)

    $'00001'

    [1] "P0014520085"

    $'00002'

    [1] "P0018800250"

    $'00003'

    [1] "P0003926850034" "P0013344760004" "P0013834251"    "P0014251480003"

    ```

2.  接下来，使用`summary`函数显示交易的统计数据和详细信息的汇总:

    ```

    > summary(trans)

    transactions as itemMatrix in sparse format with

     32539 rows (elements/itemsets/transactions) and

     20054 columns (items) and a density of 7.720787e-05 

    most frequent items:

    P0005772981 P0024239865 P0004607050 P0003425855 P0006323656     (Other) 

     611         610         489         462         327       47882 

    element (itemset/transaction) length distribution:

    sizes

     1     2     3     4     5     6     7     8     9    10    11    12    13    14 

    23822  5283  1668   707   355   221   132    88    62    49    29    20    23    19 

     15    16    17    18    19    20    21    22    23    24    27    29    30    32 

     9     8     7     6     1     6     5     3     3     2     4     1     2     1 

     35    44 

     2     1 

     Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 

     1.000   1.000   1.000   1.548   2.000  44.000 

    includes extended item information - examples:

     labels

    1 P0000005913

    2 P0000006020

    3 P0000006591

    includes extended transaction information - examples:

     transactionID

    1         00001

    2         00002

    3         00003

    ```

3.  然后您可以使用`inspect`功能:

    ```

    > inspect(trans[1:3])

     items                                                      transactionID

    1 {P0014520085}                                              00001 

    2 {P0018800250}                                              00002 

    3 {P0003926850034,P0013344760004,P0013834251,P0014251480003} 00003 

    ```

    显示交易
4.  此外，您可以按金额过滤交易:

    ```

    > filter_trans = trans[size(trans) >=3]

    > inspect(filter_trans[1:3])

     items                                                      transactionID

    3 {P0003926850034,P0013344760004,P0013834251,P0014251480003} 00003 

    5 {P0018474750044,P0023729451,P0024077600013,P0024236730}    00005 

    7 {P0003169854,P0008070856,P0020005801,P0024629850}          00007

    ```

5.  您也可以使用 `image`功能直观地检查交易:

    ```

    > image(trans[1:300,1:300])

    ```

6.  为了直观地显示频率/支持条图，使用`itemFrequencyPlot`:

    ```

    > itemFrequencyPlot(trans, topN=10, type="absolute")

    ```

    ![How to do it…](graphics/B04007_09_01.jpg)

    图 1:项目频率条形图

## 它是如何工作的……

创建事务后，我们可以显示关联，以深入了解关系是如何建立的。`arules`包提供了多种检查事务的方法。首先，我们使用`LIST`函数获得事务数据的列表表示。然后，我们可以使用`summary`函数来查看基本描述、最常见的项目和事务长度分布等信息。

接下来，我们使用`inspect`函数来显示前三个事务。除了显示所有的交易之外，还可以通过大小过滤交易，然后使用`inspect`函数显示关联。此外，我们可以使用`image`功能直观地检查交易。最后，我们演示了如何使用频率/支持条图来显示事务数据集的前 10 个最频繁的项目。

## 还有更多……

除了使用`itemFrequencyPlot`来显示频率/条形图，还可以使用`itemFrequency`函数来显示支持分布。更多详情，请使用`help`功能查看以下文档:

```

> help(itemFrequency)

```



# 利用先验规则挖掘关联

关联挖掘是一种技术，可以发现隐藏在交易数据集中的有趣的关系。该方法首先发现所有频繁项集，并从频繁项集生成强关联规则。在这个菜谱中，我们将介绍如何使用 Apriori 规则执行关联分析。

## 准备就绪

通过生成交易并将其存储在变量`trans`中，确保您已经完成了之前的配方。

## 怎么做……

请执行以下步骤来分析关联规则:

1.  用`apriori`发现支持度超过`0.001`和信心超过`0.1` :

    ```

    > rules <- apriori(trans, parameter = list(supp = 0.001, conf = 0.1, target= "rules"))

    > summary(rules)

    set of 6 rules

     rule length distribution (lhs + rhs):sizes

     2 

     6 

     Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 

     2       2       2       2       2       2 

     summary of quality measures:

     support           confidence          lift 

     Min.   :0.001137   Min.   :0.1131   Min.   :16.01 

     1st Qu.:0.001183   1st Qu.:0.1351   1st Qu.:17.72 

     Median :0.001321   Median :0.1503   Median :22.85 

     Mean   :0.001281   Mean   :0.1740   Mean   :22.06 

     3rd Qu.:0.001368   3rd Qu.:0.2098   3rd Qu.:26.21 

     Max.   :0.001383   Max.   :0.2704   Max.   :27.33 

     mining info:

     data ntransactions support confidence

     trans         32539   0.001        0.1

    ```

    的规律
2.  然后可以使用`inspect`来显示所有的规则:

    ```

    > inspect(rules)

     lhs                 rhs              support     confidence lift 

    1 {P0014252070}    => {P0014252066}    0.001321491 0.2704403  27.32874

    2 {P0014252066}    => {P0014252070}    0.001321491 0.1335404  27.32874

    3 {P0006587250003} => {P0006587250014} 0.001137097 0.1608696  16.00775

    4 {P0006587250014} => {P0006587250003} 0.001137097 0.1131498  16.00775

    5 {P0014252055}    => {P0014252066}    0.001382956 0.2261307  22.85113

    6 {P0014252066}    => {P0014252055}    0.001382956 0.1397516  22.85113

    ```

3.  最后，您可以根据可信度对规则进行排序，然后检查所有规则:

    ```

    > rules <- sort(rules, by="confidence", decreasing=TRUE)

    > inspect(rules)

     lhs                 rhs              support     confidence lift 

    1 {P0014252070}    => {P0014252066}    0.001321491 0.2704403  27.32874

    5 {P0014252055}    => {P0014252066}    0.001382956 0.2261307  22.85113

    3 {P0006587250003} => {P0006587250014} 0.001137097 0.1608696  16.00775

    6 {P0014252066}    => {P0014252055}    0.001382956 0.1397516  22.85113

    2 {P0014252066}    => {P0014252070}    0.001321491 0.1335404  27.32874

    4 {P0006587250014} => {P0006587250003} 0.001137097 0.1131498  16.00775

    ```

## 它是如何工作的……

关联挖掘的目的是从事务数据库中发现项之间的关系。通常，关联挖掘过程会查找支持度大于最小支持度的项集。接下来，该过程使用频繁项集来生成置信度大于最小置信度的强规则(例如， *Milk = > Bread* ，购买牛奶的客户可能会购买面包)。根据定义，关联规则可以用 *X= > Y* 的形式表示，其中 *X* 和 *Y* 是不相交的项集。我们可以使用两个术语来衡量关联的强度:**支持度**和**信心度**。支持度显示了在数据集中适用的规则的百分比，而置信度指示了 *X* 和 *Y* 出现在同一事务中的概率:

![How it works…](graphics/B04007_09_09.jpg)

![How it works…](graphics/B04007_09_10.jpg)

其中![How it works…](graphics/B04007_09_11.jpg)表示特定项目集的频率， *N* 表示总体。

由于支持度和置信度仅仅是规则强度的度量，所以仍然可以获得许多具有高支持度和置信度的冗余规则。因此，我们可以使用第三个度量，lift，来评估规则的质量(排名)。根据定义，提升表示一个规则对随机同时出现的 *X* 和 *Y* 的强度。我们可以以下列形式使用 lift:

![How it works…](graphics/B04007_09_12.jpg)

Apriori 是最著名的关联挖掘算法，它执行一个逐层、广度优先的算法来计算候选项集。Apriori 过程从逐级查找频繁项目集(具有最小支持度的项目集)开始。例如，该过程从查找频繁 1 项集开始。然后继续使用频繁 1 项集来查找频繁 2 项集。该过程从频繁 *k* 项集中迭代地发现新的频繁 k+1 项集，直到没有发现频繁项集。最后，该过程利用频繁项目集来生成关联规则:

![How it works…](graphics/B04007_09_02.jpg)

图 Apriori 算法的过程

在这个菜谱中，我们使用 Apriori 算法来查找事务中的关联规则。首先，我们应用 Apriori 算法来搜索支持度超过 0.001 且置信度超过 0.1 的规则。然后我们使用`summary`函数来检查生成的规则的详细信息。从输出摘要中，我们发现 Apriori 算法产生了六条规则。此外，我们可以找到规则长度分布，质量测量的总结，并挖掘信息。在质量度量的总结中，我们发现了三个度量的描述性统计，支持度、置信度和提升度。支持度是包含某个项目集的事务的比例。置信度是规则的正确率。Lift 是响应目标关联规则除以平均响应。

为了探索一些生成的规则，我们可以使用`inspect`函数来查看所有规则。最后，我们可以根据可信度对规则进行排序，并列出可信度最高的规则。因此，我们发现与`P0014252066`关联的`P0014252070`是最有信心的规则，支持度等于`0.001321491`，信心等于`0.2704403`，升力等于`27.32874`。

## 还有更多……

对于那些对使用`Groceries`数据集的研究结果感兴趣的人，以及对如何定义支持度、置信度和升力测量感兴趣的人，请参考以下论文:

*   *挖掘关联规则的概率数据建模的含义*作者*迈克尔·哈斯勒、库尔特·霍尼克、托马斯·罗伊特勒*、*斯普林格*、T6(2006)
*   *预测分析中的建模技术*由*在 M. Spiliopoulou，R. Kruse，C. Borgelt，A*
*   *从数据和信息分析到知识工程，分类、数据分析和知识组织的研究*由*努恩伯格和 w .高尔以及编辑*，*第 598–605 页*。斯普林格出版社。

此外，除了使用`summary`和`inspect`函数来检查关联规则，还可以使用`interestMeasure`来获得额外的兴趣度量:

```

> head(interestMeasure(rules, c("support", "chiSquare", "confidence", "conviction","cosine", "coverage", "leverage", "lift","oddsRatio"), Groceries))

```



# 修剪冗余规则

在生成的规则中，我们有时会发现重复或冗余的规则(例如，一个规则是另一个规则的超级规则)。在这个食谱中，我们将展示如何修剪(或删除)重复或多余的规则。

## 准备就绪

在这个配方中，必须通过生成规则并将这些规则存储在名为`rules`的变量中来完成前面的配方。

## 怎么做……

执行以下步骤删除冗余规则:

1.  首先，你需要识别多余的规则:

    ```

    > rules.sorted = sort(rules, by="lift")

    > subset.matrix = is.subset(rules.sorted, rules.sorted)

    > subset.matrix[lower.tri(subset.matrix, diag=T)] = NA

    > redundant = colSums(subset.matrix, na.rm=T) >= 1

    ```

2.  然后可以删除多余的规则:

    ```

    > rules.pruned = rules.sorted[!redundant]

    > inspect(rules.pruned)

     lhs                 rhs              support     confidence lift 

    1 {P0014252070}    => {P0014252066}    0.001321491 0.2704403  27.32874

    5 {P0014252055}    => {P0014252066}    0.001382956 0.2261307  22.85113

    3 {P0006587250003} => {P0006587250014} 0.001137097 0.1608696  16.00775

    ```

## 它是如何工作的……

支持度和置信度之间的选择是关联挖掘中的主要约束。例如，如果使用高支持阈值，可能会删除稀有项目规则，而不考虑这些规则是否具有高置信度值。另一方面，如果选择使用低支持阈值，关联挖掘会产生大量冗余关联规则，这使得这些规则难以利用和分析。因此，我们需要删除冗余的规则，以便从生成的规则中发现有意义的信息。

在这个食谱中，我们演示了如何删除多余的规则。首先，我们搜索冗余规则。我们通过提升度量对规则进行排序，然后使用`is.subset`函数找到排序规则的子集，这将生成一个`itemMatrix`对象。然后我们可以将矩阵的下三角设为 NA。最后，我们计算生成矩阵的`colSums`，其中 *colSums > =1* 表示特定规则是多余的。

在我们发现冗余规则后，我们可以从排序规则中删除这些规则。最后，我们可以使用`inspect`函数检查删减后的规则。

## 还有更多……

要找到规则的子集或超集，可以对关联规则使用`is.superset`和`is.subset`函数。这两种方法可以生成一个`itemMatrix`对象来显示哪个规则是其他规则子集的超集。更多信息可参考`help`功能:

```

> help(is.superset)

> help(is.subset)

```



# 可视化关联规则

为了探索项之间的关系，可以将关联规则可视化。在下面的菜谱中，我们介绍如何使用`arulesViz`包来可视化关联规则。

## 准备就绪

在这个配方中，必须通过生成规则来完成前面的配方，并将这些规则存储在一个名为`rules.pruned`的变量中。

## 怎么做……

请执行以下步骤来可视化关联规则:

1.  首先安装并加载`arulesViz`包:

    ```

    > install.packages("arulesViz")

    > library(arulesViz)

    ```

2.  然后，您可以根据修剪后的规则制作散点图:

    ```

    > plot(rules.pruned)

    ```

    ![How to do it…](graphics/B04007_09_03.jpg)

    图 3:删减规则的散点图

3.  我们也可以将规则以分组矩阵的形式呈现:

    ```

    > plot(rules.pruned,method="grouped")

    ```

    ![How to do it…](graphics/B04007_09_04.jpg)

    图 4:三个规则的分组矩阵

4.  或者，我们可以用一个图来表示规则:

    ```

    > plot(rules.pruned,method="graph")

    ```

    ![How to do it…](graphics/B04007_09_05.jpg)

    图 5:三个规则的图表

## 它是如何工作的……

作为以文本形式呈现关联规则的替代方法，我们可以使用`arulesViz`来可视化关联规则。`arulesViz`包是一个`arules`扩展包，它提供了许多可视化技术来探索关联规则。要开始使用`arulesViz`，我们首先需要安装并加载`arulesViz`包。然后，我们使用前一个配方中生成的删减规则来制作散点图。规则在散点图上显示为点，以 *x* 轴为支撑， *y* 轴为置信度。图中的阴影显示了规则的解除。

除了制作散点图，`arulesViz`还能让您在分组矩阵或图形中绘制规则。在分组矩阵中，左边的规则显示为列标签，右边的规则显示为行标签。分组矩阵中气球的大小说明了对规则的支持，气球的颜色指示了规则的提升。此外，我们可以发现图形表示中项目之间的关系；每个项集都存在于一个顶点中，它们之间的关系显示为一条边。类似于分组矩阵，分组矩阵中气球的大小表示规则的支持度，气球的颜色表示规则的提升。

## 参见

除了生成静态图，还可以通过在以下步骤中设置`interactive`等于`TRUE`来创建交互图:

```

> plot(rules.pruned,interactive=TRUE)

```

![See also](graphics/B04007_09_06.jpg)

图 6:三个规则的交互式散点图



# 用 Eclat 挖掘频繁项集

由于 Apriori 算法执行广度优先搜索以扫描整个数据库，支持计数相当耗时。或者，如果数据库适合内存，可以使用 Eclat 算法，该算法执行深度优先搜索来计算支持数。因此，Eclat 算法比 Apriori 算法运行得快得多。在这个菜谱中，我们介绍如何使用 Eclat 算法来生成一个频繁项集。

## 准备就绪

在这个配方中，必须通过生成规则来完成前面的配方，并将这些规则存储在一个名为`rules`的变量中。

## 怎么做……

请执行下面的步骤，使用Eclat 算法生成一个频繁项集:

1.  类似于 Apriori 方法，我们可以使用`eclat`函数生成一个频繁项集:

    ```

    > frequentsets=eclat(trans,parameter=list(support=0.01,maxlen=10))

    ```

2.  然后我们可以从生成的频繁项集中获取汇总信息:

    ```

    > summary(frequentsets)

    set of 6 itemsets

    most frequent items:

     P0003425855    P0004607050    P0005772981    P0006323656 P0006587250014 

     1              1              1              1              1 

     (Other) 

     1 

    element (itemset/transaction) length distribution:sizes

    1 

    6 

     Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 

     1       1       1       1       1       1 

    summary of quality measures:

     support 

     Min.   :0.01005 

     1st Qu.:0.01109 

     Median :0.01461 

     Mean   :0.01447 

     3rd Qu.:0.01782 

     Max.   :0.01878 

    includes transaction ID lists: FALSE 

    mining info:

     data ntransactions support

     trans         32539    0.01

    ```

3.  最后，我们可以考察频繁项集:

    ```

    > inspect(sort(frequentsets,by="support"))

     items            support 

    1 {P0005772981}    0.01877747

    2 {P0024239865}    0.01874673

    4 {P0004607050}    0.01502812

    3 {P0003425855}    0.01419835

    5 {P0006587250014} 0.01004948

    6 {P0006323656}    0.01004948

    ```

## 它是如何工作的……

在这个菜谱中，我们引入了另一个算法 Eclat 来执行频繁项集生成。虽然 Apriori 是一种简单易懂的关联挖掘方法，但该算法有两个主要缺点:

*   它会生成大量的候选集
*   它在支持计数方面效率低下，因为它需要多次扫描数据库

与 Apriori 相比，Eclat 使用等价类、深度优先搜索和集合交集，大大提高了支持计数的速度。

在 Apriori 中，该算法使用水平数据布局来存储事务。相比之下，Eclat 使用垂直数据布局来存储每个项目的事务 id(`tid`)列表。Eclat 然后通过交叉两个 *k* 项集的`tid`列表来确定任意 *k+1* 项集的支持度，最后利用频繁项集来生成关联规则:

![How it works…](graphics/B04007_09_07.jpg)

图 Eclat 算法

类似于使用 Apriori 算法的方法，我们可以使用`eclat`函数来生成一个具有给定支持度和最大长度的频繁项集。然后，我们可以使用`summary`函数获得汇总统计数据，其中包括最常见的项目、项目集长度分布、质量度量的汇总以及挖掘信息。最后，根据支持度对频繁项集进行排序，并检测频繁项集。

## 还有更多……

除了 Apriori 和 Eclat，另一种流行的关联挖掘算法是 FP-growth。与 Eclat 类似，这需要深度优先搜索来计算支持度。但是，现在还没有包含这个算法的 R 包可以从 CRAN 下载。如果你对如何将 FP-growth 算法应用于你的交易数据集感兴趣，你可以参考克里斯蒂安·博格特的网页([http://www.borgelt.net/fpgrowth.html](http://www.borgelt.net/fpgrowth.html))了解更多信息。



# 用时态信息创建事务

除了在事务数据库中挖掘有趣的关联，我们还可以使用带有时态信息的事务来挖掘有趣的序列模式。在下面的菜谱中，我们演示了如何使用 web 流量数据集中的时态信息创建事务。

## 准备就绪

从[https://github . com/yw chiu/rcook book/raw/master/chapter 9/traffic 下载`web_traffic.csv`数据集。RData](https://github.com/ywchiu/rcookbook/raw/master/chapter9/traffic.RData) GitHub 链接。

然后，我们可以从加载的数据集中生成事务，以便进行频繁的序列模式挖掘。

## 怎么做……

执行以下步骤来创建带有时态信息的事务:

1.  首先安装并加载`arulesSequences`包:

    ```

    > install.packages("arulesSequences")

    > library(arulesSequences)

    ```

2.  将 web 流量数据加载到 R 会话:

    ```

    > load('traffic.RData')

    ```

3.  用时态信息创建交易数据:

    ```

    > traffic_data<-data.frame(item=traffic$Page)

    > traffic.tran<-as(traffic_data,"transactions")

    > transactionInfo(traffic.tran)$sequenceID <- traffic$sequence

    > transactionInfo(traffic.tran)$eventID<-traffic$Timestamp

    > traffic.tran

    transactions in sparse format with

     17 transactions (rows) and

     6 items (columns)

    ```

4.  使用`inspect`功能检查交易:

    ```

    > inspect(head(traffic.tran))

     items             transactionID sequenceID eventID 

     1 {item=/}          1             1          1458565800

     2 {item=/login}     2             1          1458565803

     3 {item=/profile}   3             1          1458565811

     4 {item=/shop_list} 4             1          1458565814

     5 {item=/}          5             2          1458565802

     6 {item=/login}     6             2          1458565808

    ```

5.  然后，您可以获得具有时态信息的交易的汇总信息:

    ```

    > summary(traffic.tran)

     transactions as itemMatrix in sparse format with

     17 rows (elements/itemsets/transactions) and

     6 columns (items) and a density of 0.1666667 

     most frequent items:

     item=/     item=/login   item=/profile item=/shop_list 

     4               4               4             3 

     item=/contact         (Other) 

     1               1 

     element (itemset/transaction) length distribution:

     sizes

     1 

     17 

     Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 

     1       1       1       1       1       1 

     includes extended item information - examples:

     labels variables   levels

     1        item=/      item        /

     2 item=/contact      item /contact

     3   item=/login      item   /login

     includes extended transaction information - examples:

     transactionID sequenceID    eventID

     1             1          1 1458565800

     2             2          1 1458565803

     3             3          1 1458565811

    ```

## 它是如何工作的……

在挖掘频繁序列模式之前，需要创建带有时态信息的事务。在这个菜谱中，我们将介绍如何使用数据帧中的时态信息创建事务。首先，我们将`web_traffic.csv`作为数据帧加载到 R 会话中。web 流量数据集包含源用户 IP、访问时间戳、访问 URL 和状态代码。在本例中，我们使用原始 IP、时间戳和 URL 来创建事务。

我们将源 IP 转换为序列，然后按照用户序列和事件时间戳对数据集进行排序。我们可以使用`as`函数将列表数据转换成事务数据集。然后我们添加`eventID`和`sequenceID`作为时间信息；`sequenceID`是事件所属的序列，`eventID`表示事件发生的时间。在生成带有时态信息的事务后，可以使用这个数据集进行频繁的序列模式挖掘。

## 还有更多……

除了使用时态信息创建自己的事务之外，如果您已经将数据存储在一个文本文件中，您可以使用`arulesSequences`中的`read_basket`函数将事务数据读入篮子格式。我们还可以读取事务数据集，以进行更频繁的序列模式挖掘:

```

> zaki=read_baskets(con = system.file("misc", "zaki.txt", package = "arulesSequences"), info = c("sequenceID","eventID","SIZE"))

> as(zaki, "data.frame")

 transactionID.sequenceID transactionID.eventID transactionID.SIZE     items

1                         1                    10                  2     {C,D}

2                         1                    15                  3   {A,B,C}

3                         1                    20                  3   {A,B,F}

4                         1                    25                  4 {A,C,D,F}

5                         2                    15                  3   {A,B,F}

6                         2                    20                  1       {E}

7                         3                    10                  3   {A,B,F}

8                         4                    10                  3   {D,G,H}

9                         4                    20                  2     {B,F}

10                        4                    25                  3   {A,G,H}

```



# 用 cSPADE 挖掘频繁序列模式

最著名的频繁序列模式挖掘算法之一是 **SPADE** ( **使用等价类的序列模式发现**)算法，该算法利用垂直数据库的特性，通过高效的格搜索在 ID-list 上执行交集，并允许我们对挖掘的序列进行约束。在这个菜谱中，我们将演示如何使用 cSPADE 来挖掘频繁序列模式。

## 准备就绪

在这个配方中，必须让通过生成带有时态信息的事务来完成前一个配方，并将它存储在一个名为`traffic.tran`的变量中。

## 怎么做……

请执行以下步骤来挖掘频繁序列模式:

1.  首先，使用`cspade`函数生成频繁序列模式:

    ```

    > frequent_pattern <-cspade(traffic.tran,parameter = list(support = 0.50))

    > inspect(frequent_pattern)

     items                           support 

     1 <{item=/}>                  1.00 

     2 <{item=/login}>          1.00 

     3 <{item=/profile}>        0.75 

     4 <{item=/shop_list}>    0.75 

     5 <{item=/}, 

     {item=/shop_list}>      0.75 

     6 <{item=/login}, 

     {item=/shop_list}>      0.75 

     7 <{item=/}, 

     {item=/login}, 

     {item=/shop_list}>      0.75 

     8 <{item=/}, 

     {item=/profile}>          0.75 

     9 <{item=/login}, 

     {item=/profile}>          0.75 

     10 <{item=/}, 

     {item=/login}, 

     {item=/profile}>          0.75 

     11 <{item=/}, 

     {item=/login}>            1.00 

    ```

2.  然后可以查看频繁序列模式的摘要:

    ```

    > summary(frequent_pattern)

    set of 11 sequences with

    most frequent items:

     item=/     item=/login   item=/profile item=/shop_list         (Other) 

     6               6               4               4              14 

    most frequent elements:

     {item=/}     {item=/login}   {item=/profile} {item=/shop_list} 

     6                 6                 4                 4 

     (Other) 

     14 

    element (sequence) size distribution:

    sizes

    1 2 3 

    4 5 2 

    sequence length distribution:

    lengths

    1 2 3 

    4 5 2 

    summary of quality measures:

     support 

     Min.   :0.7500 

     1st Qu.:0.7500 

     Median :0.7500 

     Mean   :0.8182 

     3rd Qu.:0.8750 

     Max.   :1.0000 

    includes transaction ID lists: FALSE 

    mining info:

     data ntransactions nsequences support

     traffic.tran            17          4     0.5

    ```

3.  将生成的序列格式数据转换回数据帧:

    ```

    > as(frequent_pattern, "data.frame")

     sequence    support

    1                                                    <{item=/}>      1.00

    2                                             <{item=/login}>     1.00

    3                                           <{item=/profile}>     0.75

    4                                        <{item=/shop_list}>    0.75

    5                         <{item=/},{item=/shop_list}>    0.75

    6                 <{item=/login},{item=/shop_list}>    0.75

    7  <{item=/},{item=/login},{item=/shop_list}>    0.75

    8                             <{item=/},{item=/profile}>    0.75

    9                     <{item=/login},{item=/profile}>    0.75

    10   <{item=/},{item=/login},{item=/profile}>    0.75

    11                             <{item=/},{item=/login}>    1.00

    ```

## 它是如何工作的……

序列模式挖掘的目的是发现事务中的序列关系或模式。您可以使用模式挖掘结果来预测未来事件，或者向用户推荐项目。

一种流行的序列模式挖掘方法是 SPADE ( **S** 序列 **PA** 模式 **D** 发现使用 **E** 等价类)。SPADE 使用垂直数据布局来存储 ID 列表，其中数据库中的每个输入序列称为 **SID** ，给定输入序列中的每个事件称为 **EID** 。SPADE 过程是通过先验候选生成逐层生成模式来执行的。SPADE 从 ID 列表交集的连接( *n-1* )序列中生成后续的 *n* 序列。如果序列的个数大于最小支持度(`minsup`)，我们可以认为该序列足够频繁。当该过程找不到更频繁的序列时，该算法停止:

![How it works…](graphics/B04007_09_08.jpg)

图 SPADE 算法

在这个菜谱中，我们演示了如何使用频繁序列模式挖掘算法 cSPADE 来挖掘频繁序列模式。首先，由于我们的事务在变量`trans`中加载了时态信息，我们可以使用支持`0.50`的`cspade`函数来生成序列格式的频繁序列模式。然后，我们可以获得汇总信息，比如最频繁出现的项目、序列大小分布、质量度量的汇总以及挖掘信息。我们可以将生成的**序列**信息转换回数据帧格式，因此我们可以检查支持超过`0.50`的频繁序列模式的序列和支持。最后，我们可以从生成的模式中发现用户的访问模式。网站设计者可以检查这些模式，看看如何改善网站的访问流量。

## 参见

如果你对 SPADE 算法的概念和设计感兴趣，可以参考最初发表的论文: *SPADE:一种挖掘频繁序列的高效算法*作者: *M. J. Zaki* ，*机器学习杂志*，*第 42、31–60 页* *(2001)* 。